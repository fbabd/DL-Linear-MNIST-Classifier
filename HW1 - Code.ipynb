{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import transforms \n",
    "import matplotlib.pyplot as plt \n",
    "from torchvision.datasets import MNIST \n",
    "import time \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader \n",
    "import numpy as np "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Write the code for downloading and formatting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_dataset.transform = transform\n",
    "test_dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_data(train_dataset, test_dataset, n = None):\n",
    "    torch.manual_seed(1) \n",
    "    if n is not None:\n",
    "        print(n)\n",
    "        train_data = torch.cat([train_dataset[i][0] for i in range(len(train_dataset))], dim=0)\n",
    "        indices = torch.randperm(len(train_data))[:n]\n",
    "        train_data = torch.stack([train_data[i] for i in indices])\n",
    "        train_targets = torch.zeros(train_dataset.targets.shape[0], 10)\n",
    "        train_targets[torch.arange(train_dataset.targets.shape[0]), train_dataset.targets] = 1\n",
    "        train_targets = torch.stack([train_targets[i] for i in indices])\n",
    "    else:\n",
    "        train_data = torch.cat([train_dataset[i][0] for i in range(len(train_dataset))], dim=0)\n",
    "        train_targets = torch.zeros(train_dataset.targets.shape[0], 10)\n",
    "        train_targets[torch.arange(train_dataset.targets.shape[0]), train_dataset.targets] = 1\n",
    "        \n",
    "    \n",
    "    test_data = torch.cat([test_dataset[i][0] for i in range(len(test_dataset))], dim=0)\n",
    "    test_targets = torch.zeros(test_dataset.targets.shape[0], 10)\n",
    "    test_targets[torch.arange(test_dataset.targets.shape[0]), test_dataset.targets] = 1\n",
    "        \n",
    "    return train_data, test_data, train_targets, test_targets \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = make_train_test_data(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]),\n",
       " torch.Size([10000, 28, 28]),\n",
       " torch.Size([60000, 10]),\n",
       " torch.Size([10000, 10]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_ts.shape, y_tr.shape, y_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706, 0.4941, 0.5333,\n",
       "          0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176,\n",
       "          0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843,\n",
       "          0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
       "          0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275, 0.4235, 0.0039,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922, 0.9922, 0.4667,\n",
       "          0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922,\n",
       "          0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882,\n",
       "          0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765,\n",
       "          0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
       "          0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922, 0.9922,\n",
       "          0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922, 0.9922, 0.7882,\n",
       "          0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902,\n",
       "          0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.3176, 0.0078,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314,\n",
       "          0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000]]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr[0], y_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(X_tr[i], cmap='gray')\n",
    "    ax.set_title(\"label: \" +str(y_tr[i].argmax().item()))\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Train Data\")\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(X_ts[i], cmap='gray')\n",
    "    ax.set_title(\"label: \" +str(y_ts[i].argmax().item()))\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Test Data\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write the code for minibatch SGD implementation for your linear MNIST classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(train_data, test_data, train_targets, test_targets, ITR=500, B = 100, eta=0.01):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accs = []\n",
    "    test_accs = [] \n",
    "    W = torch.randn(train_data.shape[1]*train_data.shape[2] , train_targets.shape[1])               # define the weight matrix \n",
    "    training_time = 0 \n",
    "    for i in range(ITR):                                                                            # Iteration starts (`ITR` times loop)\n",
    "        indices = torch.randperm(len(train_data))                                                   # rearrange the indices of the train samples\n",
    "        start = time.time()                                                                         # start time counter for the iteration\n",
    "        for j in range(0, len(train_data), B):                                                      #   Batch starts (`train_size/B` times loop)\n",
    "            batch_indices = indices[j:j+B]                                                          #   get the train indices for this batch\n",
    "            x_batch = train_data[batch_indices].view(-1, train_data.shape[1]*train_data.shape[2])   #   reshape the train images into 1D\n",
    "            y_batch = train_targets[batch_indices]                                                  #   get train labels for this batch\n",
    "            y_pred = x_batch @ W                                                                    #   predicting train labels \n",
    "            loss = ((y_pred - y_batch)**2).sum() / (2*B)                                            #   calculate loss for this batch of data\n",
    "            \n",
    "            train_acc = (y_pred.argmax(dim=1) == y_batch.argmax(dim=1)).float().mean()              #   calculate accuracy for this batch of data    \n",
    "            grad = torch.matmul(torch.transpose(x_batch, 0, 1), (y_pred - y_batch)) / B             #   calculate the gradients for this batch\n",
    "            \n",
    "            W -= eta * grad                                                                         #   Update the weights based on this batch \n",
    "        training_time += (time.time() - start)                                                      # add time spent for training \n",
    "        train_losses.append(loss.item())                                                            # append train loss for this iteration         \n",
    "        train_accs.append(train_acc.item())                                                         # append train accuracy for this iteration \n",
    "        \n",
    "        # evaluate the model on test set for this iteration \n",
    "        with torch.no_grad():\n",
    "            test_x = test_data.view(-1, train_data.shape[1]*train_data.shape[2])                    # test image flattening to 1D\n",
    "            test_y = test_targets                                                                   # test labels \n",
    "            test_pred = test_x @ W                                                                  # predicting test labels\n",
    "            test_loss = ((test_pred - test_y)**2).sum() / (2*len(test_data))                        # calculating test loss \n",
    "            test_acc = (test_pred.argmax(dim=1) == test_y.argmax(dim=1)).float().mean()             # calculating test accuracy \n",
    "            test_losses.append(test_loss.item())                                                    # append test loss for this iteration \n",
    "            test_accs.append(test_acc.item())                                                       # append test accuracy for this iteration\n",
    "        print(f\"Iteration {i}: Loss = {loss:.4f}, Accuracy = {train_acc:.4f} Test Loss = {test_loss:.4f}, Test Accuracy = {test_acc:.4f}\")\n",
    "\n",
    "    print(f\"Total training time: {training_time:0.2f}s\")\n",
    "    history = dict() \n",
    "    history['acc']       = train_accs \n",
    "    history['loss']      = train_losses\n",
    "    history['test_acc']  = test_accs \n",
    "    history['test_loss'] = test_losses \n",
    "    return history \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "    ax0 = axes[0] \n",
    "    ax0.plot(history['loss'], label='training')\n",
    "    ax0.plot(history['test_loss'], label='test')\n",
    "    ax0.set_xlabel('Iteration')\n",
    "    ax0.set_ylabel('Loss')\n",
    "    ax0.legend()\n",
    "\n",
    "    ax1 = axes[1] \n",
    "    ax1.plot(history['acc'], label='training')\n",
    "    ax1.plot(history['test_acc'], label='test')\n",
    "    ax1.set_xlabel('Iteration')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Run your code with batch sizes B = 1, 10, 100, 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`B=1`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.7468, Accuracy = 1.0000 Test Loss = 0.8865, Test Accuracy = 0.5570\n",
      "Iteration 1: Loss = 0.2408, Accuracy = 1.0000 Test Loss = 0.4903, Test Accuracy = 0.6954\n",
      "Iteration 2: Loss = 0.1556, Accuracy = 1.0000 Test Loss = 0.4225, Test Accuracy = 0.7087\n",
      "Iteration 3: Loss = 0.4108, Accuracy = 0.0000 Test Loss = 0.4517, Test Accuracy = 0.6485\n",
      "Iteration 4: Loss = 0.2358, Accuracy = 1.0000 Test Loss = 0.4915, Test Accuracy = 0.6797\n",
      "Iteration 5: Loss = 0.8525, Accuracy = 0.0000 Test Loss = 0.4895, Test Accuracy = 0.6556\n",
      "Iteration 6: Loss = 0.3473, Accuracy = 1.0000 Test Loss = 0.3786, Test Accuracy = 0.7291\n",
      "Iteration 7: Loss = 0.2354, Accuracy = 1.0000 Test Loss = 0.4483, Test Accuracy = 0.5725\n",
      "Iteration 8: Loss = 0.6311, Accuracy = 1.0000 Test Loss = 0.3916, Test Accuracy = 0.6910\n",
      "Iteration 9: Loss = 0.1125, Accuracy = 1.0000 Test Loss = 0.3631, Test Accuracy = 0.6890\n",
      "Iteration 10: Loss = 0.2425, Accuracy = 1.0000 Test Loss = 0.3801, Test Accuracy = 0.7024\n",
      "Iteration 11: Loss = 0.3133, Accuracy = 1.0000 Test Loss = 0.3440, Test Accuracy = 0.7401\n",
      "Iteration 12: Loss = 0.4071, Accuracy = 1.0000 Test Loss = 0.3665, Test Accuracy = 0.6911\n",
      "Iteration 13: Loss = 0.1148, Accuracy = 1.0000 Test Loss = 0.3746, Test Accuracy = 0.6951\n",
      "Iteration 14: Loss = 0.5404, Accuracy = 1.0000 Test Loss = 0.3574, Test Accuracy = 0.7069\n",
      "Iteration 15: Loss = 0.5349, Accuracy = 0.0000 Test Loss = 0.4204, Test Accuracy = 0.7001\n",
      "Iteration 16: Loss = 0.0171, Accuracy = 1.0000 Test Loss = 0.3403, Test Accuracy = 0.7214\n",
      "Iteration 17: Loss = 0.3317, Accuracy = 1.0000 Test Loss = 0.3640, Test Accuracy = 0.7093\n",
      "Iteration 18: Loss = 0.1761, Accuracy = 1.0000 Test Loss = 0.3786, Test Accuracy = 0.6762\n",
      "Iteration 19: Loss = 0.1851, Accuracy = 1.0000 Test Loss = 0.3510, Test Accuracy = 0.7106\n",
      "Iteration 20: Loss = 0.1812, Accuracy = 1.0000 Test Loss = 0.3285, Test Accuracy = 0.7231\n",
      "Iteration 21: Loss = 0.3458, Accuracy = 1.0000 Test Loss = 0.3579, Test Accuracy = 0.7235\n",
      "Iteration 22: Loss = 0.2908, Accuracy = 1.0000 Test Loss = 0.4301, Test Accuracy = 0.6608\n",
      "Iteration 23: Loss = 0.4745, Accuracy = 1.0000 Test Loss = 0.3595, Test Accuracy = 0.7165\n",
      "Iteration 24: Loss = 0.3965, Accuracy = 0.0000 Test Loss = 0.4229, Test Accuracy = 0.6221\n",
      "Iteration 25: Loss = 0.3616, Accuracy = 0.0000 Test Loss = 0.3407, Test Accuracy = 0.7325\n",
      "Iteration 26: Loss = 0.0805, Accuracy = 1.0000 Test Loss = 0.3426, Test Accuracy = 0.7194\n",
      "Iteration 27: Loss = 0.4765, Accuracy = 0.0000 Test Loss = 0.3579, Test Accuracy = 0.7017\n",
      "Iteration 28: Loss = 0.4501, Accuracy = 1.0000 Test Loss = 0.3360, Test Accuracy = 0.7329\n",
      "Iteration 29: Loss = 0.9633, Accuracy = 0.0000 Test Loss = 0.3574, Test Accuracy = 0.7150\n",
      "Iteration 30: Loss = 0.1769, Accuracy = 1.0000 Test Loss = 0.4050, Test Accuracy = 0.6379\n",
      "Iteration 31: Loss = 0.3803, Accuracy = 1.0000 Test Loss = 0.4014, Test Accuracy = 0.6917\n",
      "Iteration 32: Loss = 0.6383, Accuracy = 0.0000 Test Loss = 0.3654, Test Accuracy = 0.6497\n",
      "Iteration 33: Loss = 1.0935, Accuracy = 0.0000 Test Loss = 0.3910, Test Accuracy = 0.7093\n",
      "Iteration 34: Loss = 0.3669, Accuracy = 1.0000 Test Loss = 0.3399, Test Accuracy = 0.7443\n",
      "Iteration 35: Loss = 0.1209, Accuracy = 1.0000 Test Loss = 0.4192, Test Accuracy = 0.6829\n",
      "Iteration 36: Loss = 0.2566, Accuracy = 1.0000 Test Loss = 0.3367, Test Accuracy = 0.6890\n",
      "Iteration 37: Loss = 0.0833, Accuracy = 1.0000 Test Loss = 0.3359, Test Accuracy = 0.7256\n",
      "Iteration 38: Loss = 0.1473, Accuracy = 1.0000 Test Loss = 0.3652, Test Accuracy = 0.6653\n",
      "Iteration 39: Loss = 0.2200, Accuracy = 1.0000 Test Loss = 0.4292, Test Accuracy = 0.6536\n",
      "Iteration 40: Loss = 0.1565, Accuracy = 1.0000 Test Loss = 0.3399, Test Accuracy = 0.7395\n",
      "Iteration 41: Loss = 0.6404, Accuracy = 1.0000 Test Loss = 0.3848, Test Accuracy = 0.7165\n",
      "Iteration 42: Loss = 0.1494, Accuracy = 1.0000 Test Loss = 0.3459, Test Accuracy = 0.6974\n",
      "Iteration 43: Loss = 0.3814, Accuracy = 0.0000 Test Loss = 0.3506, Test Accuracy = 0.7152\n",
      "Iteration 44: Loss = 0.2620, Accuracy = 1.0000 Test Loss = 0.3466, Test Accuracy = 0.7184\n",
      "Iteration 45: Loss = 0.9296, Accuracy = 0.0000 Test Loss = 0.3952, Test Accuracy = 0.6348\n",
      "Iteration 46: Loss = 0.0818, Accuracy = 1.0000 Test Loss = 0.3020, Test Accuracy = 0.7425\n",
      "Iteration 47: Loss = 0.6905, Accuracy = 0.0000 Test Loss = 0.3792, Test Accuracy = 0.6899\n",
      "Iteration 48: Loss = 0.1444, Accuracy = 1.0000 Test Loss = 0.3733, Test Accuracy = 0.6650\n",
      "Iteration 49: Loss = 0.2516, Accuracy = 1.0000 Test Loss = 0.3031, Test Accuracy = 0.7463\n",
      "Iteration 50: Loss = 0.0926, Accuracy = 1.0000 Test Loss = 0.3418, Test Accuracy = 0.7319\n",
      "Iteration 51: Loss = 0.1655, Accuracy = 1.0000 Test Loss = 0.3563, Test Accuracy = 0.7147\n",
      "Iteration 52: Loss = 0.2470, Accuracy = 1.0000 Test Loss = 0.3422, Test Accuracy = 0.7094\n",
      "Iteration 53: Loss = 0.3561, Accuracy = 1.0000 Test Loss = 0.3952, Test Accuracy = 0.6522\n",
      "Iteration 54: Loss = 0.2647, Accuracy = 1.0000 Test Loss = 0.3461, Test Accuracy = 0.7338\n",
      "Iteration 55: Loss = 0.1895, Accuracy = 1.0000 Test Loss = 0.3607, Test Accuracy = 0.6723\n",
      "Iteration 56: Loss = 0.1588, Accuracy = 1.0000 Test Loss = 0.3352, Test Accuracy = 0.7569\n",
      "Iteration 57: Loss = 0.2917, Accuracy = 1.0000 Test Loss = 0.3544, Test Accuracy = 0.7218\n",
      "Iteration 58: Loss = 0.2678, Accuracy = 1.0000 Test Loss = 0.4410, Test Accuracy = 0.5648\n",
      "Iteration 59: Loss = 0.1851, Accuracy = 1.0000 Test Loss = 0.3516, Test Accuracy = 0.7438\n",
      "Iteration 60: Loss = 0.3361, Accuracy = 1.0000 Test Loss = 0.3566, Test Accuracy = 0.6874\n",
      "Iteration 61: Loss = 0.1079, Accuracy = 1.0000 Test Loss = 0.3396, Test Accuracy = 0.7427\n",
      "Iteration 62: Loss = 0.0503, Accuracy = 1.0000 Test Loss = 0.3141, Test Accuracy = 0.7561\n",
      "Iteration 63: Loss = 0.1170, Accuracy = 1.0000 Test Loss = 0.3736, Test Accuracy = 0.7269\n",
      "Iteration 64: Loss = 0.0345, Accuracy = 1.0000 Test Loss = 0.3253, Test Accuracy = 0.7151\n",
      "Iteration 65: Loss = 0.7283, Accuracy = 0.0000 Test Loss = 0.3886, Test Accuracy = 0.6787\n",
      "Iteration 66: Loss = 0.2341, Accuracy = 1.0000 Test Loss = 0.3744, Test Accuracy = 0.7186\n",
      "Iteration 67: Loss = 0.2138, Accuracy = 1.0000 Test Loss = 0.3760, Test Accuracy = 0.7309\n",
      "Iteration 68: Loss = 0.6975, Accuracy = 0.0000 Test Loss = 0.4659, Test Accuracy = 0.5838\n",
      "Iteration 69: Loss = 0.1547, Accuracy = 1.0000 Test Loss = 0.3198, Test Accuracy = 0.7218\n",
      "Iteration 70: Loss = 0.1554, Accuracy = 1.0000 Test Loss = 0.3584, Test Accuracy = 0.6855\n",
      "Iteration 71: Loss = 0.3373, Accuracy = 0.0000 Test Loss = 0.3640, Test Accuracy = 0.6667\n",
      "Iteration 72: Loss = 0.1738, Accuracy = 1.0000 Test Loss = 0.4080, Test Accuracy = 0.6578\n",
      "Iteration 73: Loss = 0.6239, Accuracy = 0.0000 Test Loss = 0.3711, Test Accuracy = 0.7252\n",
      "Iteration 74: Loss = 0.5211, Accuracy = 1.0000 Test Loss = 0.3386, Test Accuracy = 0.7104\n",
      "Iteration 75: Loss = 0.1974, Accuracy = 1.0000 Test Loss = 0.3183, Test Accuracy = 0.7299\n",
      "Iteration 76: Loss = 0.1300, Accuracy = 1.0000 Test Loss = 0.3882, Test Accuracy = 0.6689\n",
      "Iteration 77: Loss = 0.2950, Accuracy = 1.0000 Test Loss = 0.3584, Test Accuracy = 0.7007\n",
      "Iteration 78: Loss = 0.2878, Accuracy = 1.0000 Test Loss = 0.3185, Test Accuracy = 0.7551\n",
      "Iteration 79: Loss = 0.4524, Accuracy = 0.0000 Test Loss = 0.3616, Test Accuracy = 0.7104\n",
      "Iteration 80: Loss = 0.4842, Accuracy = 0.0000 Test Loss = 0.3280, Test Accuracy = 0.7332\n",
      "Iteration 81: Loss = 0.3872, Accuracy = 1.0000 Test Loss = 0.3706, Test Accuracy = 0.7062\n",
      "Iteration 82: Loss = 0.5072, Accuracy = 0.0000 Test Loss = 0.3969, Test Accuracy = 0.6610\n",
      "Iteration 83: Loss = 0.2028, Accuracy = 1.0000 Test Loss = 0.3447, Test Accuracy = 0.7225\n",
      "Iteration 84: Loss = 1.0044, Accuracy = 0.0000 Test Loss = 0.3526, Test Accuracy = 0.7365\n",
      "Iteration 85: Loss = 0.3865, Accuracy = 1.0000 Test Loss = 0.3765, Test Accuracy = 0.6850\n",
      "Iteration 86: Loss = 0.0929, Accuracy = 1.0000 Test Loss = 0.3587, Test Accuracy = 0.6805\n",
      "Iteration 87: Loss = 0.4696, Accuracy = 0.0000 Test Loss = 0.3772, Test Accuracy = 0.6909\n",
      "Iteration 88: Loss = 0.6343, Accuracy = 0.0000 Test Loss = 0.4101, Test Accuracy = 0.6851\n",
      "Iteration 89: Loss = 0.3793, Accuracy = 0.0000 Test Loss = 0.3172, Test Accuracy = 0.7297\n",
      "Iteration 90: Loss = 0.2276, Accuracy = 1.0000 Test Loss = 0.3799, Test Accuracy = 0.6967\n",
      "Iteration 91: Loss = 0.1804, Accuracy = 1.0000 Test Loss = 0.3520, Test Accuracy = 0.7130\n",
      "Iteration 92: Loss = 0.5025, Accuracy = 0.0000 Test Loss = 0.3978, Test Accuracy = 0.6203\n",
      "Iteration 93: Loss = 0.6544, Accuracy = 0.0000 Test Loss = 0.4361, Test Accuracy = 0.6700\n",
      "Iteration 94: Loss = 0.3236, Accuracy = 1.0000 Test Loss = 0.4092, Test Accuracy = 0.6626\n",
      "Iteration 95: Loss = 0.1278, Accuracy = 1.0000 Test Loss = 0.3390, Test Accuracy = 0.7458\n",
      "Iteration 96: Loss = 0.2696, Accuracy = 1.0000 Test Loss = 0.3522, Test Accuracy = 0.7068\n",
      "Iteration 97: Loss = 0.1241, Accuracy = 1.0000 Test Loss = 0.3364, Test Accuracy = 0.7408\n",
      "Iteration 98: Loss = 0.2283, Accuracy = 1.0000 Test Loss = 0.3567, Test Accuracy = 0.7140\n",
      "Iteration 99: Loss = 0.6533, Accuracy = 0.0000 Test Loss = 0.3625, Test Accuracy = 0.7101\n",
      "Total training time: 762.59s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history1 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=100, B = 1)\n",
    "plot_history(history1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used only 100 epochs. Becasue, I tried with 4000 epochs previously and the line does not improve over the iterations. It converges early. \n",
    "That is why when I am running the models again for the final time, I am using less number of iterations. \n",
    "\n",
    "`Total training time`: 762.59s for 100 epoch. `7.63`s per epoch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`B=10`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 5.4326, Accuracy = 0.3000 Test Loss = 4.8959, Test Accuracy = 0.2515\n",
      "Iteration 1: Loss = 1.7612, Accuracy = 0.4000 Test Loss = 2.3194, Test Accuracy = 0.3311\n",
      "Iteration 2: Loss = 1.6555, Accuracy = 0.6000 Test Loss = 1.5298, Test Accuracy = 0.4245\n",
      "Iteration 3: Loss = 0.8892, Accuracy = 0.7000 Test Loss = 1.0444, Test Accuracy = 0.5138\n",
      "Iteration 4: Loss = 0.4246, Accuracy = 0.9000 Test Loss = 0.8248, Test Accuracy = 0.5678\n",
      "Iteration 5: Loss = 0.6628, Accuracy = 0.5000 Test Loss = 0.6954, Test Accuracy = 0.6248\n",
      "Iteration 6: Loss = 0.8505, Accuracy = 0.5000 Test Loss = 0.6026, Test Accuracy = 0.6647\n",
      "Iteration 7: Loss = 0.3344, Accuracy = 0.8000 Test Loss = 0.5282, Test Accuracy = 0.7046\n",
      "Iteration 8: Loss = 0.7803, Accuracy = 0.7000 Test Loss = 0.4746, Test Accuracy = 0.7199\n",
      "Iteration 9: Loss = 0.5167, Accuracy = 0.7000 Test Loss = 0.4423, Test Accuracy = 0.7425\n",
      "Iteration 10: Loss = 0.3904, Accuracy = 0.7000 Test Loss = 0.4185, Test Accuracy = 0.7428\n",
      "Iteration 11: Loss = 0.2205, Accuracy = 0.9000 Test Loss = 0.3845, Test Accuracy = 0.7684\n",
      "Iteration 12: Loss = 0.2039, Accuracy = 0.8000 Test Loss = 0.3743, Test Accuracy = 0.7774\n",
      "Iteration 13: Loss = 0.2958, Accuracy = 0.7000 Test Loss = 0.3644, Test Accuracy = 0.7634\n",
      "Iteration 14: Loss = 0.1947, Accuracy = 1.0000 Test Loss = 0.3437, Test Accuracy = 0.7830\n",
      "Iteration 15: Loss = 0.2677, Accuracy = 0.8000 Test Loss = 0.3294, Test Accuracy = 0.7920\n",
      "Iteration 16: Loss = 0.4347, Accuracy = 0.4000 Test Loss = 0.3244, Test Accuracy = 0.7866\n",
      "Iteration 17: Loss = 0.4355, Accuracy = 0.8000 Test Loss = 0.3234, Test Accuracy = 0.7893\n",
      "Iteration 18: Loss = 0.2924, Accuracy = 0.8000 Test Loss = 0.3220, Test Accuracy = 0.7735\n",
      "Iteration 19: Loss = 0.2893, Accuracy = 0.8000 Test Loss = 0.3108, Test Accuracy = 0.7898\n",
      "Iteration 20: Loss = 0.6763, Accuracy = 0.6000 Test Loss = 0.2987, Test Accuracy = 0.8047\n",
      "Iteration 21: Loss = 0.2067, Accuracy = 0.8000 Test Loss = 0.2927, Test Accuracy = 0.8111\n",
      "Iteration 22: Loss = 0.4135, Accuracy = 0.9000 Test Loss = 0.2884, Test Accuracy = 0.8138\n",
      "Iteration 23: Loss = 0.2856, Accuracy = 0.7000 Test Loss = 0.2767, Test Accuracy = 0.8139\n",
      "Iteration 24: Loss = 0.2535, Accuracy = 0.8000 Test Loss = 0.2794, Test Accuracy = 0.8069\n",
      "Iteration 25: Loss = 0.2713, Accuracy = 0.8000 Test Loss = 0.2804, Test Accuracy = 0.7974\n",
      "Iteration 26: Loss = 0.4793, Accuracy = 0.8000 Test Loss = 0.2771, Test Accuracy = 0.8105\n",
      "Iteration 27: Loss = 0.2939, Accuracy = 0.8000 Test Loss = 0.2654, Test Accuracy = 0.8286\n",
      "Iteration 28: Loss = 0.3363, Accuracy = 0.8000 Test Loss = 0.2669, Test Accuracy = 0.8216\n",
      "Iteration 29: Loss = 0.2367, Accuracy = 1.0000 Test Loss = 0.2607, Test Accuracy = 0.8266\n",
      "Iteration 30: Loss = 0.4686, Accuracy = 0.5000 Test Loss = 0.2598, Test Accuracy = 0.8202\n",
      "Iteration 31: Loss = 0.2344, Accuracy = 0.9000 Test Loss = 0.2617, Test Accuracy = 0.8164\n",
      "Iteration 32: Loss = 0.4306, Accuracy = 0.8000 Test Loss = 0.2679, Test Accuracy = 0.8135\n",
      "Iteration 33: Loss = 0.2548, Accuracy = 0.7000 Test Loss = 0.2641, Test Accuracy = 0.8104\n",
      "Iteration 34: Loss = 0.2330, Accuracy = 0.7000 Test Loss = 0.2508, Test Accuracy = 0.8282\n",
      "Iteration 35: Loss = 0.1275, Accuracy = 1.0000 Test Loss = 0.2514, Test Accuracy = 0.8223\n",
      "Iteration 36: Loss = 0.1694, Accuracy = 0.9000 Test Loss = 0.2517, Test Accuracy = 0.8338\n",
      "Iteration 37: Loss = 0.1977, Accuracy = 0.9000 Test Loss = 0.2453, Test Accuracy = 0.8312\n",
      "Iteration 38: Loss = 0.2328, Accuracy = 0.8000 Test Loss = 0.2476, Test Accuracy = 0.8319\n",
      "Iteration 39: Loss = 0.2995, Accuracy = 0.7000 Test Loss = 0.2453, Test Accuracy = 0.8317\n",
      "Iteration 40: Loss = 0.1932, Accuracy = 0.9000 Test Loss = 0.2460, Test Accuracy = 0.8344\n",
      "Iteration 41: Loss = 0.3305, Accuracy = 0.7000 Test Loss = 0.2477, Test Accuracy = 0.8208\n",
      "Iteration 42: Loss = 0.2039, Accuracy = 1.0000 Test Loss = 0.2408, Test Accuracy = 0.8327\n",
      "Iteration 43: Loss = 0.1952, Accuracy = 0.8000 Test Loss = 0.2433, Test Accuracy = 0.8342\n",
      "Iteration 44: Loss = 0.2614, Accuracy = 0.8000 Test Loss = 0.2432, Test Accuracy = 0.8268\n",
      "Iteration 45: Loss = 0.1634, Accuracy = 0.9000 Test Loss = 0.2381, Test Accuracy = 0.8327\n",
      "Iteration 46: Loss = 0.2430, Accuracy = 0.7000 Test Loss = 0.2385, Test Accuracy = 0.8377\n",
      "Iteration 47: Loss = 0.2214, Accuracy = 0.9000 Test Loss = 0.2455, Test Accuracy = 0.8178\n",
      "Iteration 48: Loss = 0.2345, Accuracy = 0.6000 Test Loss = 0.2373, Test Accuracy = 0.8345\n",
      "Iteration 49: Loss = 0.2310, Accuracy = 0.7000 Test Loss = 0.2418, Test Accuracy = 0.8233\n",
      "Iteration 50: Loss = 0.2709, Accuracy = 0.7000 Test Loss = 0.2363, Test Accuracy = 0.8340\n",
      "Iteration 51: Loss = 0.1797, Accuracy = 0.8000 Test Loss = 0.2358, Test Accuracy = 0.8270\n",
      "Iteration 52: Loss = 0.2599, Accuracy = 0.8000 Test Loss = 0.2358, Test Accuracy = 0.8383\n",
      "Iteration 53: Loss = 0.2902, Accuracy = 0.7000 Test Loss = 0.2367, Test Accuracy = 0.8396\n",
      "Iteration 54: Loss = 0.2964, Accuracy = 0.7000 Test Loss = 0.2454, Test Accuracy = 0.8294\n",
      "Iteration 55: Loss = 0.1900, Accuracy = 0.9000 Test Loss = 0.2325, Test Accuracy = 0.8346\n",
      "Iteration 56: Loss = 0.2084, Accuracy = 0.9000 Test Loss = 0.2325, Test Accuracy = 0.8326\n",
      "Iteration 57: Loss = 0.2401, Accuracy = 0.9000 Test Loss = 0.2313, Test Accuracy = 0.8391\n",
      "Iteration 58: Loss = 0.3606, Accuracy = 0.7000 Test Loss = 0.2356, Test Accuracy = 0.8319\n",
      "Iteration 59: Loss = 0.2180, Accuracy = 0.8000 Test Loss = 0.2277, Test Accuracy = 0.8353\n",
      "Iteration 60: Loss = 0.2069, Accuracy = 0.9000 Test Loss = 0.2329, Test Accuracy = 0.8356\n",
      "Iteration 61: Loss = 0.1918, Accuracy = 0.9000 Test Loss = 0.2299, Test Accuracy = 0.8279\n",
      "Iteration 62: Loss = 0.2079, Accuracy = 0.8000 Test Loss = 0.2344, Test Accuracy = 0.8330\n",
      "Iteration 63: Loss = 0.2612, Accuracy = 0.9000 Test Loss = 0.2369, Test Accuracy = 0.8208\n",
      "Iteration 64: Loss = 0.1448, Accuracy = 0.9000 Test Loss = 0.2292, Test Accuracy = 0.8358\n",
      "Iteration 65: Loss = 0.1958, Accuracy = 0.9000 Test Loss = 0.2259, Test Accuracy = 0.8405\n",
      "Iteration 66: Loss = 0.1847, Accuracy = 1.0000 Test Loss = 0.2273, Test Accuracy = 0.8372\n",
      "Iteration 67: Loss = 0.2680, Accuracy = 0.8000 Test Loss = 0.2345, Test Accuracy = 0.8261\n",
      "Iteration 68: Loss = 0.1165, Accuracy = 0.9000 Test Loss = 0.2259, Test Accuracy = 0.8415\n",
      "Iteration 69: Loss = 0.2473, Accuracy = 0.8000 Test Loss = 0.2265, Test Accuracy = 0.8439\n",
      "Iteration 70: Loss = 0.1847, Accuracy = 1.0000 Test Loss = 0.2261, Test Accuracy = 0.8322\n",
      "Iteration 71: Loss = 0.2404, Accuracy = 0.9000 Test Loss = 0.2263, Test Accuracy = 0.8357\n",
      "Iteration 72: Loss = 0.2329, Accuracy = 0.9000 Test Loss = 0.2239, Test Accuracy = 0.8379\n",
      "Iteration 73: Loss = 0.2694, Accuracy = 0.8000 Test Loss = 0.2275, Test Accuracy = 0.8326\n",
      "Iteration 74: Loss = 0.2857, Accuracy = 0.7000 Test Loss = 0.2332, Test Accuracy = 0.8312\n",
      "Iteration 75: Loss = 0.2216, Accuracy = 0.8000 Test Loss = 0.2292, Test Accuracy = 0.8289\n",
      "Iteration 76: Loss = 0.1868, Accuracy = 0.7000 Test Loss = 0.2265, Test Accuracy = 0.8355\n",
      "Iteration 77: Loss = 0.2241, Accuracy = 0.8000 Test Loss = 0.2290, Test Accuracy = 0.8318\n",
      "Iteration 78: Loss = 0.1503, Accuracy = 1.0000 Test Loss = 0.2272, Test Accuracy = 0.8309\n",
      "Iteration 79: Loss = 0.1934, Accuracy = 0.8000 Test Loss = 0.2257, Test Accuracy = 0.8311\n",
      "Iteration 80: Loss = 0.1421, Accuracy = 1.0000 Test Loss = 0.2269, Test Accuracy = 0.8433\n",
      "Iteration 81: Loss = 0.1863, Accuracy = 0.9000 Test Loss = 0.2258, Test Accuracy = 0.8334\n",
      "Iteration 82: Loss = 0.2033, Accuracy = 1.0000 Test Loss = 0.2257, Test Accuracy = 0.8304\n",
      "Iteration 83: Loss = 0.3020, Accuracy = 0.8000 Test Loss = 0.2208, Test Accuracy = 0.8424\n",
      "Iteration 84: Loss = 0.2164, Accuracy = 0.8000 Test Loss = 0.2235, Test Accuracy = 0.8392\n",
      "Iteration 85: Loss = 0.2067, Accuracy = 1.0000 Test Loss = 0.2241, Test Accuracy = 0.8439\n",
      "Iteration 86: Loss = 0.1413, Accuracy = 1.0000 Test Loss = 0.2278, Test Accuracy = 0.8318\n",
      "Iteration 87: Loss = 0.1685, Accuracy = 1.0000 Test Loss = 0.2214, Test Accuracy = 0.8444\n",
      "Iteration 88: Loss = 0.1875, Accuracy = 1.0000 Test Loss = 0.2229, Test Accuracy = 0.8277\n",
      "Iteration 89: Loss = 0.2253, Accuracy = 0.8000 Test Loss = 0.2265, Test Accuracy = 0.8408\n",
      "Iteration 90: Loss = 0.2847, Accuracy = 0.5000 Test Loss = 0.2224, Test Accuracy = 0.8444\n",
      "Iteration 91: Loss = 0.2649, Accuracy = 0.9000 Test Loss = 0.2207, Test Accuracy = 0.8342\n",
      "Iteration 92: Loss = 0.2245, Accuracy = 0.8000 Test Loss = 0.2260, Test Accuracy = 0.8391\n",
      "Iteration 93: Loss = 0.1619, Accuracy = 1.0000 Test Loss = 0.2199, Test Accuracy = 0.8419\n",
      "Iteration 94: Loss = 0.2052, Accuracy = 0.8000 Test Loss = 0.2181, Test Accuracy = 0.8426\n",
      "Iteration 95: Loss = 0.2119, Accuracy = 0.7000 Test Loss = 0.2208, Test Accuracy = 0.8412\n",
      "Iteration 96: Loss = 0.2064, Accuracy = 0.9000 Test Loss = 0.2207, Test Accuracy = 0.8472\n",
      "Iteration 97: Loss = 0.2738, Accuracy = 0.9000 Test Loss = 0.2287, Test Accuracy = 0.8257\n",
      "Iteration 98: Loss = 0.1956, Accuracy = 0.9000 Test Loss = 0.2203, Test Accuracy = 0.8381\n",
      "Iteration 99: Loss = 0.2008, Accuracy = 1.0000 Test Loss = 0.2232, Test Accuracy = 0.8447\n",
      "Iteration 100: Loss = 0.2856, Accuracy = 0.7000 Test Loss = 0.2218, Test Accuracy = 0.8339\n",
      "Iteration 101: Loss = 0.1452, Accuracy = 0.9000 Test Loss = 0.2230, Test Accuracy = 0.8239\n",
      "Iteration 102: Loss = 0.3497, Accuracy = 0.5000 Test Loss = 0.2211, Test Accuracy = 0.8490\n",
      "Iteration 103: Loss = 0.2698, Accuracy = 0.7000 Test Loss = 0.2194, Test Accuracy = 0.8432\n",
      "Iteration 104: Loss = 0.1875, Accuracy = 0.9000 Test Loss = 0.2219, Test Accuracy = 0.8386\n",
      "Iteration 105: Loss = 0.3839, Accuracy = 0.6000 Test Loss = 0.2253, Test Accuracy = 0.8374\n",
      "Iteration 106: Loss = 0.1706, Accuracy = 0.9000 Test Loss = 0.2192, Test Accuracy = 0.8445\n",
      "Iteration 107: Loss = 0.1659, Accuracy = 0.9000 Test Loss = 0.2212, Test Accuracy = 0.8412\n",
      "Iteration 108: Loss = 0.2156, Accuracy = 0.9000 Test Loss = 0.2189, Test Accuracy = 0.8393\n",
      "Iteration 109: Loss = 0.2024, Accuracy = 0.9000 Test Loss = 0.2164, Test Accuracy = 0.8410\n",
      "Iteration 110: Loss = 0.1824, Accuracy = 0.9000 Test Loss = 0.2212, Test Accuracy = 0.8447\n",
      "Iteration 111: Loss = 0.1964, Accuracy = 0.8000 Test Loss = 0.2190, Test Accuracy = 0.8474\n",
      "Iteration 112: Loss = 0.1725, Accuracy = 0.9000 Test Loss = 0.2187, Test Accuracy = 0.8362\n",
      "Iteration 113: Loss = 0.2410, Accuracy = 0.8000 Test Loss = 0.2226, Test Accuracy = 0.8343\n",
      "Iteration 114: Loss = 0.1531, Accuracy = 0.9000 Test Loss = 0.2171, Test Accuracy = 0.8437\n",
      "Iteration 115: Loss = 0.1761, Accuracy = 0.9000 Test Loss = 0.2200, Test Accuracy = 0.8400\n",
      "Iteration 116: Loss = 0.1500, Accuracy = 1.0000 Test Loss = 0.2172, Test Accuracy = 0.8346\n",
      "Iteration 117: Loss = 0.1702, Accuracy = 1.0000 Test Loss = 0.2210, Test Accuracy = 0.8314\n",
      "Iteration 118: Loss = 0.1609, Accuracy = 1.0000 Test Loss = 0.2211, Test Accuracy = 0.8337\n",
      "Iteration 119: Loss = 0.2462, Accuracy = 0.7000 Test Loss = 0.2172, Test Accuracy = 0.8350\n",
      "Iteration 120: Loss = 0.1616, Accuracy = 1.0000 Test Loss = 0.2146, Test Accuracy = 0.8444\n",
      "Iteration 121: Loss = 0.1402, Accuracy = 1.0000 Test Loss = 0.2153, Test Accuracy = 0.8368\n",
      "Iteration 122: Loss = 0.2913, Accuracy = 0.6000 Test Loss = 0.2157, Test Accuracy = 0.8452\n",
      "Iteration 123: Loss = 0.1623, Accuracy = 1.0000 Test Loss = 0.2169, Test Accuracy = 0.8327\n",
      "Iteration 124: Loss = 0.2149, Accuracy = 1.0000 Test Loss = 0.2192, Test Accuracy = 0.8418\n",
      "Iteration 125: Loss = 0.2129, Accuracy = 0.7000 Test Loss = 0.2158, Test Accuracy = 0.8377\n",
      "Iteration 126: Loss = 0.1793, Accuracy = 0.9000 Test Loss = 0.2174, Test Accuracy = 0.8384\n",
      "Iteration 127: Loss = 0.1879, Accuracy = 0.8000 Test Loss = 0.2169, Test Accuracy = 0.8357\n",
      "Iteration 128: Loss = 0.1961, Accuracy = 0.9000 Test Loss = 0.2194, Test Accuracy = 0.8303\n",
      "Iteration 129: Loss = 0.1659, Accuracy = 1.0000 Test Loss = 0.2213, Test Accuracy = 0.8406\n",
      "Iteration 130: Loss = 0.1846, Accuracy = 0.9000 Test Loss = 0.2203, Test Accuracy = 0.8330\n",
      "Iteration 131: Loss = 0.2415, Accuracy = 0.8000 Test Loss = 0.2183, Test Accuracy = 0.8485\n",
      "Iteration 132: Loss = 0.2324, Accuracy = 0.8000 Test Loss = 0.2232, Test Accuracy = 0.8352\n",
      "Iteration 133: Loss = 0.2114, Accuracy = 0.8000 Test Loss = 0.2150, Test Accuracy = 0.8433\n",
      "Iteration 134: Loss = 0.2526, Accuracy = 0.8000 Test Loss = 0.2132, Test Accuracy = 0.8378\n",
      "Iteration 135: Loss = 0.2188, Accuracy = 0.8000 Test Loss = 0.2187, Test Accuracy = 0.8322\n",
      "Iteration 136: Loss = 0.1999, Accuracy = 0.8000 Test Loss = 0.2169, Test Accuracy = 0.8414\n",
      "Iteration 137: Loss = 0.2254, Accuracy = 0.8000 Test Loss = 0.2182, Test Accuracy = 0.8391\n",
      "Iteration 138: Loss = 0.1926, Accuracy = 1.0000 Test Loss = 0.2125, Test Accuracy = 0.8413\n",
      "Iteration 139: Loss = 0.2878, Accuracy = 0.8000 Test Loss = 0.2231, Test Accuracy = 0.8184\n",
      "Iteration 140: Loss = 0.1283, Accuracy = 1.0000 Test Loss = 0.2161, Test Accuracy = 0.8440\n",
      "Iteration 141: Loss = 0.1674, Accuracy = 1.0000 Test Loss = 0.2149, Test Accuracy = 0.8399\n",
      "Iteration 142: Loss = 0.2592, Accuracy = 0.8000 Test Loss = 0.2145, Test Accuracy = 0.8445\n",
      "Iteration 143: Loss = 0.1801, Accuracy = 0.9000 Test Loss = 0.2200, Test Accuracy = 0.8388\n",
      "Iteration 144: Loss = 0.2763, Accuracy = 0.8000 Test Loss = 0.2141, Test Accuracy = 0.8464\n",
      "Iteration 145: Loss = 0.1499, Accuracy = 0.9000 Test Loss = 0.2162, Test Accuracy = 0.8385\n",
      "Iteration 146: Loss = 0.2170, Accuracy = 0.9000 Test Loss = 0.2137, Test Accuracy = 0.8415\n",
      "Iteration 147: Loss = 0.2799, Accuracy = 0.8000 Test Loss = 0.2146, Test Accuracy = 0.8315\n",
      "Iteration 148: Loss = 0.2629, Accuracy = 0.7000 Test Loss = 0.2216, Test Accuracy = 0.8336\n",
      "Iteration 149: Loss = 0.2952, Accuracy = 0.6000 Test Loss = 0.2178, Test Accuracy = 0.8322\n",
      "Iteration 150: Loss = 0.1884, Accuracy = 0.9000 Test Loss = 0.2164, Test Accuracy = 0.8426\n",
      "Iteration 151: Loss = 0.1775, Accuracy = 0.9000 Test Loss = 0.2140, Test Accuracy = 0.8334\n",
      "Iteration 152: Loss = 0.1680, Accuracy = 0.9000 Test Loss = 0.2168, Test Accuracy = 0.8413\n",
      "Iteration 153: Loss = 0.2209, Accuracy = 1.0000 Test Loss = 0.2149, Test Accuracy = 0.8418\n",
      "Iteration 154: Loss = 0.2145, Accuracy = 0.7000 Test Loss = 0.2210, Test Accuracy = 0.8392\n",
      "Iteration 155: Loss = 0.2172, Accuracy = 0.7000 Test Loss = 0.2164, Test Accuracy = 0.8437\n",
      "Iteration 156: Loss = 0.1967, Accuracy = 1.0000 Test Loss = 0.2270, Test Accuracy = 0.8076\n",
      "Iteration 157: Loss = 0.1456, Accuracy = 0.9000 Test Loss = 0.2143, Test Accuracy = 0.8377\n",
      "Iteration 158: Loss = 0.1261, Accuracy = 1.0000 Test Loss = 0.2120, Test Accuracy = 0.8480\n",
      "Iteration 159: Loss = 0.1994, Accuracy = 0.8000 Test Loss = 0.2203, Test Accuracy = 0.8224\n",
      "Iteration 160: Loss = 0.2584, Accuracy = 0.8000 Test Loss = 0.2129, Test Accuracy = 0.8423\n",
      "Iteration 161: Loss = 0.3068, Accuracy = 0.6000 Test Loss = 0.2150, Test Accuracy = 0.8443\n",
      "Iteration 162: Loss = 0.1400, Accuracy = 0.9000 Test Loss = 0.2164, Test Accuracy = 0.8424\n",
      "Iteration 163: Loss = 0.1554, Accuracy = 1.0000 Test Loss = 0.2126, Test Accuracy = 0.8423\n",
      "Iteration 164: Loss = 0.1552, Accuracy = 0.8000 Test Loss = 0.2164, Test Accuracy = 0.8466\n",
      "Iteration 165: Loss = 0.2527, Accuracy = 0.9000 Test Loss = 0.2155, Test Accuracy = 0.8395\n",
      "Iteration 166: Loss = 0.1708, Accuracy = 1.0000 Test Loss = 0.2156, Test Accuracy = 0.8351\n",
      "Iteration 167: Loss = 0.2590, Accuracy = 0.6000 Test Loss = 0.2140, Test Accuracy = 0.8431\n",
      "Iteration 168: Loss = 0.1666, Accuracy = 1.0000 Test Loss = 0.2174, Test Accuracy = 0.8435\n",
      "Iteration 169: Loss = 0.2280, Accuracy = 0.7000 Test Loss = 0.2146, Test Accuracy = 0.8495\n",
      "Iteration 170: Loss = 0.1788, Accuracy = 1.0000 Test Loss = 0.2103, Test Accuracy = 0.8477\n",
      "Iteration 171: Loss = 0.2487, Accuracy = 0.7000 Test Loss = 0.2138, Test Accuracy = 0.8394\n",
      "Iteration 172: Loss = 0.2810, Accuracy = 0.7000 Test Loss = 0.2210, Test Accuracy = 0.8379\n",
      "Iteration 173: Loss = 0.2653, Accuracy = 0.5000 Test Loss = 0.2199, Test Accuracy = 0.8288\n",
      "Iteration 174: Loss = 0.1798, Accuracy = 1.0000 Test Loss = 0.2129, Test Accuracy = 0.8478\n",
      "Iteration 175: Loss = 0.2014, Accuracy = 0.9000 Test Loss = 0.2109, Test Accuracy = 0.8521\n",
      "Iteration 176: Loss = 0.2592, Accuracy = 0.8000 Test Loss = 0.2189, Test Accuracy = 0.8326\n",
      "Iteration 177: Loss = 0.2189, Accuracy = 0.8000 Test Loss = 0.2195, Test Accuracy = 0.8437\n",
      "Iteration 178: Loss = 0.1723, Accuracy = 1.0000 Test Loss = 0.2133, Test Accuracy = 0.8472\n",
      "Iteration 179: Loss = 0.1669, Accuracy = 0.9000 Test Loss = 0.2109, Test Accuracy = 0.8473\n",
      "Iteration 180: Loss = 0.1266, Accuracy = 1.0000 Test Loss = 0.2113, Test Accuracy = 0.8386\n",
      "Iteration 181: Loss = 0.1537, Accuracy = 0.9000 Test Loss = 0.2117, Test Accuracy = 0.8406\n",
      "Iteration 182: Loss = 0.2180, Accuracy = 0.9000 Test Loss = 0.2168, Test Accuracy = 0.8246\n",
      "Iteration 183: Loss = 0.1480, Accuracy = 0.9000 Test Loss = 0.2162, Test Accuracy = 0.8348\n",
      "Iteration 184: Loss = 0.3081, Accuracy = 0.7000 Test Loss = 0.2246, Test Accuracy = 0.8382\n",
      "Iteration 185: Loss = 0.1394, Accuracy = 0.9000 Test Loss = 0.2110, Test Accuracy = 0.8415\n",
      "Iteration 186: Loss = 0.3488, Accuracy = 0.9000 Test Loss = 0.2128, Test Accuracy = 0.8468\n",
      "Iteration 187: Loss = 0.2221, Accuracy = 0.8000 Test Loss = 0.2174, Test Accuracy = 0.8431\n",
      "Iteration 188: Loss = 0.1803, Accuracy = 1.0000 Test Loss = 0.2131, Test Accuracy = 0.8424\n",
      "Iteration 189: Loss = 0.2696, Accuracy = 0.8000 Test Loss = 0.2138, Test Accuracy = 0.8414\n",
      "Iteration 190: Loss = 0.3068, Accuracy = 0.6000 Test Loss = 0.2133, Test Accuracy = 0.8501\n",
      "Iteration 191: Loss = 0.1606, Accuracy = 0.9000 Test Loss = 0.2139, Test Accuracy = 0.8398\n",
      "Iteration 192: Loss = 0.2075, Accuracy = 0.8000 Test Loss = 0.2165, Test Accuracy = 0.8446\n",
      "Iteration 193: Loss = 0.2239, Accuracy = 0.8000 Test Loss = 0.2170, Test Accuracy = 0.8383\n",
      "Iteration 194: Loss = 0.3301, Accuracy = 0.6000 Test Loss = 0.2161, Test Accuracy = 0.8394\n",
      "Iteration 195: Loss = 0.1951, Accuracy = 0.7000 Test Loss = 0.2106, Test Accuracy = 0.8504\n",
      "Iteration 196: Loss = 0.3918, Accuracy = 0.5000 Test Loss = 0.2168, Test Accuracy = 0.8340\n",
      "Iteration 197: Loss = 0.2276, Accuracy = 0.8000 Test Loss = 0.2130, Test Accuracy = 0.8340\n",
      "Iteration 198: Loss = 0.2056, Accuracy = 0.8000 Test Loss = 0.2191, Test Accuracy = 0.8366\n",
      "Iteration 199: Loss = 0.2250, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8456\n",
      "Iteration 200: Loss = 0.3110, Accuracy = 0.7000 Test Loss = 0.2108, Test Accuracy = 0.8524\n",
      "Iteration 201: Loss = 0.3348, Accuracy = 0.8000 Test Loss = 0.2178, Test Accuracy = 0.8425\n",
      "Iteration 202: Loss = 0.1666, Accuracy = 0.8000 Test Loss = 0.2122, Test Accuracy = 0.8418\n",
      "Iteration 203: Loss = 0.2181, Accuracy = 0.9000 Test Loss = 0.2133, Test Accuracy = 0.8492\n",
      "Iteration 204: Loss = 0.1737, Accuracy = 0.9000 Test Loss = 0.2191, Test Accuracy = 0.8332\n",
      "Iteration 205: Loss = 0.2034, Accuracy = 0.8000 Test Loss = 0.2125, Test Accuracy = 0.8476\n",
      "Iteration 206: Loss = 0.1674, Accuracy = 0.9000 Test Loss = 0.2138, Test Accuracy = 0.8322\n",
      "Iteration 207: Loss = 0.1224, Accuracy = 0.9000 Test Loss = 0.2136, Test Accuracy = 0.8359\n",
      "Iteration 208: Loss = 0.2092, Accuracy = 0.8000 Test Loss = 0.2193, Test Accuracy = 0.8357\n",
      "Iteration 209: Loss = 0.2108, Accuracy = 0.7000 Test Loss = 0.2163, Test Accuracy = 0.8335\n",
      "Iteration 210: Loss = 0.1300, Accuracy = 1.0000 Test Loss = 0.2101, Test Accuracy = 0.8535\n",
      "Iteration 211: Loss = 0.1827, Accuracy = 0.9000 Test Loss = 0.2106, Test Accuracy = 0.8518\n",
      "Iteration 212: Loss = 0.1895, Accuracy = 0.8000 Test Loss = 0.2140, Test Accuracy = 0.8481\n",
      "Iteration 213: Loss = 0.1768, Accuracy = 0.9000 Test Loss = 0.2146, Test Accuracy = 0.8353\n",
      "Iteration 214: Loss = 0.1770, Accuracy = 0.9000 Test Loss = 0.2166, Test Accuracy = 0.8341\n",
      "Iteration 215: Loss = 0.1496, Accuracy = 0.9000 Test Loss = 0.2134, Test Accuracy = 0.8344\n",
      "Iteration 216: Loss = 0.2408, Accuracy = 0.8000 Test Loss = 0.2116, Test Accuracy = 0.8496\n",
      "Iteration 217: Loss = 0.2696, Accuracy = 0.7000 Test Loss = 0.2169, Test Accuracy = 0.8435\n",
      "Iteration 218: Loss = 0.1734, Accuracy = 0.8000 Test Loss = 0.2125, Test Accuracy = 0.8384\n",
      "Iteration 219: Loss = 0.2191, Accuracy = 0.9000 Test Loss = 0.2107, Test Accuracy = 0.8409\n",
      "Iteration 220: Loss = 0.1763, Accuracy = 0.9000 Test Loss = 0.2097, Test Accuracy = 0.8478\n",
      "Iteration 221: Loss = 0.3471, Accuracy = 0.9000 Test Loss = 0.2128, Test Accuracy = 0.8513\n",
      "Iteration 222: Loss = 0.1794, Accuracy = 0.9000 Test Loss = 0.2120, Test Accuracy = 0.8385\n",
      "Iteration 223: Loss = 0.1684, Accuracy = 0.9000 Test Loss = 0.2186, Test Accuracy = 0.8283\n",
      "Iteration 224: Loss = 0.1880, Accuracy = 0.8000 Test Loss = 0.2116, Test Accuracy = 0.8363\n",
      "Iteration 225: Loss = 0.1938, Accuracy = 0.8000 Test Loss = 0.2085, Test Accuracy = 0.8460\n",
      "Iteration 226: Loss = 0.1221, Accuracy = 1.0000 Test Loss = 0.2142, Test Accuracy = 0.8408\n",
      "Iteration 227: Loss = 0.3770, Accuracy = 0.5000 Test Loss = 0.2110, Test Accuracy = 0.8420\n",
      "Iteration 228: Loss = 0.1419, Accuracy = 1.0000 Test Loss = 0.2153, Test Accuracy = 0.8345\n",
      "Iteration 229: Loss = 0.2013, Accuracy = 0.8000 Test Loss = 0.2138, Test Accuracy = 0.8341\n",
      "Iteration 230: Loss = 0.2265, Accuracy = 0.7000 Test Loss = 0.2131, Test Accuracy = 0.8549\n",
      "Iteration 231: Loss = 0.1405, Accuracy = 1.0000 Test Loss = 0.2142, Test Accuracy = 0.8400\n",
      "Iteration 232: Loss = 0.2154, Accuracy = 0.9000 Test Loss = 0.2123, Test Accuracy = 0.8471\n",
      "Iteration 233: Loss = 0.1505, Accuracy = 1.0000 Test Loss = 0.2129, Test Accuracy = 0.8415\n",
      "Iteration 234: Loss = 0.2637, Accuracy = 0.7000 Test Loss = 0.2133, Test Accuracy = 0.8460\n",
      "Iteration 235: Loss = 0.2701, Accuracy = 0.8000 Test Loss = 0.2131, Test Accuracy = 0.8381\n",
      "Iteration 236: Loss = 0.1908, Accuracy = 1.0000 Test Loss = 0.2150, Test Accuracy = 0.8462\n",
      "Iteration 237: Loss = 0.0821, Accuracy = 1.0000 Test Loss = 0.2112, Test Accuracy = 0.8419\n",
      "Iteration 238: Loss = 0.2141, Accuracy = 0.8000 Test Loss = 0.2138, Test Accuracy = 0.8334\n",
      "Iteration 239: Loss = 0.2024, Accuracy = 0.7000 Test Loss = 0.2148, Test Accuracy = 0.8360\n",
      "Iteration 240: Loss = 0.1970, Accuracy = 0.8000 Test Loss = 0.2165, Test Accuracy = 0.8352\n",
      "Iteration 241: Loss = 0.1700, Accuracy = 0.9000 Test Loss = 0.2089, Test Accuracy = 0.8465\n",
      "Iteration 242: Loss = 0.2556, Accuracy = 0.7000 Test Loss = 0.2180, Test Accuracy = 0.8444\n",
      "Iteration 243: Loss = 0.3153, Accuracy = 0.7000 Test Loss = 0.2096, Test Accuracy = 0.8498\n",
      "Iteration 244: Loss = 0.2509, Accuracy = 0.8000 Test Loss = 0.2090, Test Accuracy = 0.8522\n",
      "Iteration 245: Loss = 0.1665, Accuracy = 1.0000 Test Loss = 0.2121, Test Accuracy = 0.8422\n",
      "Iteration 246: Loss = 0.2808, Accuracy = 0.7000 Test Loss = 0.2122, Test Accuracy = 0.8452\n",
      "Iteration 247: Loss = 0.1723, Accuracy = 0.9000 Test Loss = 0.2163, Test Accuracy = 0.8414\n",
      "Iteration 248: Loss = 0.1774, Accuracy = 0.8000 Test Loss = 0.2168, Test Accuracy = 0.8314\n",
      "Iteration 249: Loss = 0.2168, Accuracy = 0.6000 Test Loss = 0.2130, Test Accuracy = 0.8438\n",
      "Iteration 250: Loss = 0.1782, Accuracy = 1.0000 Test Loss = 0.2103, Test Accuracy = 0.8429\n",
      "Iteration 251: Loss = 0.2293, Accuracy = 0.9000 Test Loss = 0.2109, Test Accuracy = 0.8476\n",
      "Iteration 252: Loss = 0.1737, Accuracy = 0.9000 Test Loss = 0.2159, Test Accuracy = 0.8443\n",
      "Iteration 253: Loss = 0.1423, Accuracy = 1.0000 Test Loss = 0.2130, Test Accuracy = 0.8360\n",
      "Iteration 254: Loss = 0.1965, Accuracy = 0.7000 Test Loss = 0.2096, Test Accuracy = 0.8457\n",
      "Iteration 255: Loss = 0.4654, Accuracy = 0.5000 Test Loss = 0.2246, Test Accuracy = 0.8317\n",
      "Iteration 256: Loss = 0.1948, Accuracy = 0.8000 Test Loss = 0.2127, Test Accuracy = 0.8392\n",
      "Iteration 257: Loss = 0.1909, Accuracy = 0.9000 Test Loss = 0.2118, Test Accuracy = 0.8412\n",
      "Iteration 258: Loss = 0.1737, Accuracy = 0.9000 Test Loss = 0.2126, Test Accuracy = 0.8445\n",
      "Iteration 259: Loss = 0.1778, Accuracy = 0.9000 Test Loss = 0.2103, Test Accuracy = 0.8473\n",
      "Iteration 260: Loss = 0.1163, Accuracy = 1.0000 Test Loss = 0.2097, Test Accuracy = 0.8493\n",
      "Iteration 261: Loss = 0.1576, Accuracy = 1.0000 Test Loss = 0.2096, Test Accuracy = 0.8429\n",
      "Iteration 262: Loss = 0.2045, Accuracy = 0.9000 Test Loss = 0.2104, Test Accuracy = 0.8521\n",
      "Iteration 263: Loss = 0.1192, Accuracy = 1.0000 Test Loss = 0.2104, Test Accuracy = 0.8360\n",
      "Iteration 264: Loss = 0.1745, Accuracy = 1.0000 Test Loss = 0.2127, Test Accuracy = 0.8423\n",
      "Iteration 265: Loss = 0.2307, Accuracy = 0.8000 Test Loss = 0.2133, Test Accuracy = 0.8382\n",
      "Iteration 266: Loss = 0.2455, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8418\n",
      "Iteration 267: Loss = 0.2152, Accuracy = 0.8000 Test Loss = 0.2168, Test Accuracy = 0.8331\n",
      "Iteration 268: Loss = 0.2727, Accuracy = 0.8000 Test Loss = 0.2159, Test Accuracy = 0.8430\n",
      "Iteration 269: Loss = 0.2001, Accuracy = 0.9000 Test Loss = 0.2115, Test Accuracy = 0.8365\n",
      "Iteration 270: Loss = 0.1511, Accuracy = 0.9000 Test Loss = 0.2078, Test Accuracy = 0.8501\n",
      "Iteration 271: Loss = 0.1140, Accuracy = 1.0000 Test Loss = 0.2110, Test Accuracy = 0.8463\n",
      "Iteration 272: Loss = 0.2131, Accuracy = 0.8000 Test Loss = 0.2160, Test Accuracy = 0.8414\n",
      "Iteration 273: Loss = 0.1656, Accuracy = 0.9000 Test Loss = 0.2102, Test Accuracy = 0.8333\n",
      "Iteration 274: Loss = 0.2014, Accuracy = 0.9000 Test Loss = 0.2131, Test Accuracy = 0.8438\n",
      "Iteration 275: Loss = 0.2032, Accuracy = 0.9000 Test Loss = 0.2155, Test Accuracy = 0.8416\n",
      "Iteration 276: Loss = 0.1843, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8499\n",
      "Iteration 277: Loss = 0.3357, Accuracy = 0.6000 Test Loss = 0.2161, Test Accuracy = 0.8287\n",
      "Iteration 278: Loss = 0.2011, Accuracy = 1.0000 Test Loss = 0.2102, Test Accuracy = 0.8470\n",
      "Iteration 279: Loss = 0.2704, Accuracy = 0.7000 Test Loss = 0.2084, Test Accuracy = 0.8456\n",
      "Iteration 280: Loss = 0.1936, Accuracy = 1.0000 Test Loss = 0.2138, Test Accuracy = 0.8345\n",
      "Iteration 281: Loss = 0.2203, Accuracy = 0.8000 Test Loss = 0.2147, Test Accuracy = 0.8449\n",
      "Iteration 282: Loss = 0.1787, Accuracy = 0.8000 Test Loss = 0.2142, Test Accuracy = 0.8392\n",
      "Iteration 283: Loss = 0.2766, Accuracy = 0.8000 Test Loss = 0.2108, Test Accuracy = 0.8389\n",
      "Iteration 284: Loss = 0.2254, Accuracy = 1.0000 Test Loss = 0.2095, Test Accuracy = 0.8420\n",
      "Iteration 285: Loss = 0.1789, Accuracy = 0.8000 Test Loss = 0.2071, Test Accuracy = 0.8381\n",
      "Iteration 286: Loss = 0.3006, Accuracy = 0.8000 Test Loss = 0.2143, Test Accuracy = 0.8350\n",
      "Iteration 287: Loss = 0.2657, Accuracy = 0.9000 Test Loss = 0.2142, Test Accuracy = 0.8376\n",
      "Iteration 288: Loss = 0.1792, Accuracy = 1.0000 Test Loss = 0.2091, Test Accuracy = 0.8374\n",
      "Iteration 289: Loss = 0.1994, Accuracy = 0.8000 Test Loss = 0.2114, Test Accuracy = 0.8413\n",
      "Iteration 290: Loss = 0.1876, Accuracy = 1.0000 Test Loss = 0.2089, Test Accuracy = 0.8427\n",
      "Iteration 291: Loss = 0.1653, Accuracy = 1.0000 Test Loss = 0.2086, Test Accuracy = 0.8457\n",
      "Iteration 292: Loss = 0.1853, Accuracy = 0.9000 Test Loss = 0.2119, Test Accuracy = 0.8503\n",
      "Iteration 293: Loss = 0.2043, Accuracy = 0.7000 Test Loss = 0.2118, Test Accuracy = 0.8400\n",
      "Iteration 294: Loss = 0.2104, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8485\n",
      "Iteration 295: Loss = 0.2240, Accuracy = 0.9000 Test Loss = 0.2119, Test Accuracy = 0.8384\n",
      "Iteration 296: Loss = 0.1756, Accuracy = 0.8000 Test Loss = 0.2111, Test Accuracy = 0.8397\n",
      "Iteration 297: Loss = 0.2221, Accuracy = 0.8000 Test Loss = 0.2125, Test Accuracy = 0.8381\n",
      "Iteration 298: Loss = 0.1983, Accuracy = 0.8000 Test Loss = 0.2150, Test Accuracy = 0.8398\n",
      "Iteration 299: Loss = 0.2419, Accuracy = 0.9000 Test Loss = 0.2118, Test Accuracy = 0.8439\n",
      "Iteration 300: Loss = 0.1866, Accuracy = 0.9000 Test Loss = 0.2131, Test Accuracy = 0.8416\n",
      "Iteration 301: Loss = 0.2594, Accuracy = 0.7000 Test Loss = 0.2064, Test Accuracy = 0.8501\n",
      "Iteration 302: Loss = 0.2417, Accuracy = 0.7000 Test Loss = 0.2089, Test Accuracy = 0.8458\n",
      "Iteration 303: Loss = 0.1425, Accuracy = 0.9000 Test Loss = 0.2086, Test Accuracy = 0.8350\n",
      "Iteration 304: Loss = 0.1645, Accuracy = 0.9000 Test Loss = 0.2121, Test Accuracy = 0.8373\n",
      "Iteration 305: Loss = 0.2129, Accuracy = 0.7000 Test Loss = 0.2168, Test Accuracy = 0.8429\n",
      "Iteration 306: Loss = 0.1713, Accuracy = 1.0000 Test Loss = 0.2106, Test Accuracy = 0.8466\n",
      "Iteration 307: Loss = 0.1500, Accuracy = 1.0000 Test Loss = 0.2101, Test Accuracy = 0.8450\n",
      "Iteration 308: Loss = 0.2533, Accuracy = 0.8000 Test Loss = 0.2175, Test Accuracy = 0.8330\n",
      "Iteration 309: Loss = 0.1128, Accuracy = 1.0000 Test Loss = 0.2113, Test Accuracy = 0.8435\n",
      "Iteration 310: Loss = 0.2027, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8478\n",
      "Iteration 311: Loss = 0.1463, Accuracy = 0.9000 Test Loss = 0.2127, Test Accuracy = 0.8396\n",
      "Iteration 312: Loss = 0.2061, Accuracy = 0.8000 Test Loss = 0.2075, Test Accuracy = 0.8413\n",
      "Iteration 313: Loss = 0.2110, Accuracy = 0.8000 Test Loss = 0.2109, Test Accuracy = 0.8499\n",
      "Iteration 314: Loss = 0.2816, Accuracy = 0.6000 Test Loss = 0.2101, Test Accuracy = 0.8468\n",
      "Iteration 315: Loss = 0.1086, Accuracy = 1.0000 Test Loss = 0.2132, Test Accuracy = 0.8283\n",
      "Iteration 316: Loss = 0.2738, Accuracy = 0.8000 Test Loss = 0.2091, Test Accuracy = 0.8384\n",
      "Iteration 317: Loss = 0.2732, Accuracy = 0.8000 Test Loss = 0.2090, Test Accuracy = 0.8502\n",
      "Iteration 318: Loss = 0.1870, Accuracy = 0.9000 Test Loss = 0.2072, Test Accuracy = 0.8478\n",
      "Iteration 319: Loss = 0.1472, Accuracy = 1.0000 Test Loss = 0.2083, Test Accuracy = 0.8387\n",
      "Iteration 320: Loss = 0.1702, Accuracy = 0.9000 Test Loss = 0.2106, Test Accuracy = 0.8432\n",
      "Iteration 321: Loss = 0.2125, Accuracy = 0.9000 Test Loss = 0.2209, Test Accuracy = 0.8224\n",
      "Iteration 322: Loss = 0.2606, Accuracy = 0.8000 Test Loss = 0.2152, Test Accuracy = 0.8343\n",
      "Iteration 323: Loss = 0.1686, Accuracy = 0.8000 Test Loss = 0.2123, Test Accuracy = 0.8439\n",
      "Iteration 324: Loss = 0.1813, Accuracy = 0.9000 Test Loss = 0.2101, Test Accuracy = 0.8446\n",
      "Iteration 325: Loss = 0.3775, Accuracy = 0.5000 Test Loss = 0.2176, Test Accuracy = 0.8389\n",
      "Iteration 326: Loss = 0.1707, Accuracy = 1.0000 Test Loss = 0.2098, Test Accuracy = 0.8515\n",
      "Iteration 327: Loss = 0.1960, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8477\n",
      "Iteration 328: Loss = 0.2365, Accuracy = 0.7000 Test Loss = 0.2093, Test Accuracy = 0.8337\n",
      "Iteration 329: Loss = 0.1865, Accuracy = 0.9000 Test Loss = 0.2081, Test Accuracy = 0.8416\n",
      "Iteration 330: Loss = 0.1790, Accuracy = 0.9000 Test Loss = 0.2167, Test Accuracy = 0.8466\n",
      "Iteration 331: Loss = 0.1640, Accuracy = 0.9000 Test Loss = 0.2090, Test Accuracy = 0.8470\n",
      "Iteration 332: Loss = 0.2291, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8518\n",
      "Iteration 333: Loss = 0.3171, Accuracy = 0.7000 Test Loss = 0.2086, Test Accuracy = 0.8497\n",
      "Iteration 334: Loss = 0.2341, Accuracy = 0.9000 Test Loss = 0.2113, Test Accuracy = 0.8454\n",
      "Iteration 335: Loss = 0.2241, Accuracy = 0.9000 Test Loss = 0.2161, Test Accuracy = 0.8442\n",
      "Iteration 336: Loss = 0.2165, Accuracy = 0.8000 Test Loss = 0.2104, Test Accuracy = 0.8481\n",
      "Iteration 337: Loss = 0.1956, Accuracy = 0.8000 Test Loss = 0.2190, Test Accuracy = 0.8243\n",
      "Iteration 338: Loss = 0.1849, Accuracy = 1.0000 Test Loss = 0.2091, Test Accuracy = 0.8519\n",
      "Iteration 339: Loss = 0.2157, Accuracy = 0.8000 Test Loss = 0.2124, Test Accuracy = 0.8457\n",
      "Iteration 340: Loss = 0.2543, Accuracy = 0.7000 Test Loss = 0.2136, Test Accuracy = 0.8392\n",
      "Iteration 341: Loss = 0.2831, Accuracy = 0.7000 Test Loss = 0.2076, Test Accuracy = 0.8493\n",
      "Iteration 342: Loss = 0.2504, Accuracy = 0.7000 Test Loss = 0.2094, Test Accuracy = 0.8501\n",
      "Iteration 343: Loss = 0.3235, Accuracy = 0.5000 Test Loss = 0.2086, Test Accuracy = 0.8484\n",
      "Iteration 344: Loss = 0.2450, Accuracy = 0.8000 Test Loss = 0.2101, Test Accuracy = 0.8439\n",
      "Iteration 345: Loss = 0.1910, Accuracy = 0.9000 Test Loss = 0.2104, Test Accuracy = 0.8490\n",
      "Iteration 346: Loss = 0.1661, Accuracy = 1.0000 Test Loss = 0.2098, Test Accuracy = 0.8463\n",
      "Iteration 347: Loss = 0.1941, Accuracy = 0.9000 Test Loss = 0.2106, Test Accuracy = 0.8336\n",
      "Iteration 348: Loss = 0.2450, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8387\n",
      "Iteration 349: Loss = 0.1932, Accuracy = 1.0000 Test Loss = 0.2074, Test Accuracy = 0.8483\n",
      "Iteration 350: Loss = 0.1919, Accuracy = 0.8000 Test Loss = 0.2121, Test Accuracy = 0.8446\n",
      "Iteration 351: Loss = 0.1781, Accuracy = 0.9000 Test Loss = 0.2098, Test Accuracy = 0.8524\n",
      "Iteration 352: Loss = 0.2349, Accuracy = 0.8000 Test Loss = 0.2107, Test Accuracy = 0.8524\n",
      "Iteration 353: Loss = 0.1780, Accuracy = 0.8000 Test Loss = 0.2115, Test Accuracy = 0.8301\n",
      "Iteration 354: Loss = 0.2175, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8433\n",
      "Iteration 355: Loss = 0.2295, Accuracy = 0.7000 Test Loss = 0.2096, Test Accuracy = 0.8431\n",
      "Iteration 356: Loss = 0.2821, Accuracy = 0.7000 Test Loss = 0.2078, Test Accuracy = 0.8458\n",
      "Iteration 357: Loss = 0.2801, Accuracy = 0.8000 Test Loss = 0.2112, Test Accuracy = 0.8372\n",
      "Iteration 358: Loss = 0.1152, Accuracy = 1.0000 Test Loss = 0.2097, Test Accuracy = 0.8467\n",
      "Iteration 359: Loss = 0.1299, Accuracy = 0.9000 Test Loss = 0.2111, Test Accuracy = 0.8283\n",
      "Iteration 360: Loss = 0.1776, Accuracy = 0.9000 Test Loss = 0.2111, Test Accuracy = 0.8497\n",
      "Iteration 361: Loss = 0.1458, Accuracy = 1.0000 Test Loss = 0.2166, Test Accuracy = 0.8252\n",
      "Iteration 362: Loss = 0.2345, Accuracy = 0.7000 Test Loss = 0.2110, Test Accuracy = 0.8440\n",
      "Iteration 363: Loss = 0.3326, Accuracy = 0.7000 Test Loss = 0.2140, Test Accuracy = 0.8452\n",
      "Iteration 364: Loss = 0.2404, Accuracy = 0.7000 Test Loss = 0.2129, Test Accuracy = 0.8453\n",
      "Iteration 365: Loss = 0.1030, Accuracy = 1.0000 Test Loss = 0.2079, Test Accuracy = 0.8363\n",
      "Iteration 366: Loss = 0.2118, Accuracy = 0.9000 Test Loss = 0.2107, Test Accuracy = 0.8482\n",
      "Iteration 367: Loss = 0.1416, Accuracy = 0.9000 Test Loss = 0.2082, Test Accuracy = 0.8408\n",
      "Iteration 368: Loss = 0.1941, Accuracy = 0.8000 Test Loss = 0.2128, Test Accuracy = 0.8372\n",
      "Iteration 369: Loss = 0.1268, Accuracy = 0.9000 Test Loss = 0.2127, Test Accuracy = 0.8370\n",
      "Iteration 370: Loss = 0.1912, Accuracy = 1.0000 Test Loss = 0.2105, Test Accuracy = 0.8447\n",
      "Iteration 371: Loss = 0.2510, Accuracy = 0.8000 Test Loss = 0.2119, Test Accuracy = 0.8357\n",
      "Iteration 372: Loss = 0.1950, Accuracy = 0.8000 Test Loss = 0.2085, Test Accuracy = 0.8392\n",
      "Iteration 373: Loss = 0.1617, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8503\n",
      "Iteration 374: Loss = 0.2218, Accuracy = 0.9000 Test Loss = 0.2099, Test Accuracy = 0.8418\n",
      "Iteration 375: Loss = 0.2817, Accuracy = 0.8000 Test Loss = 0.2140, Test Accuracy = 0.8334\n",
      "Iteration 376: Loss = 0.2514, Accuracy = 0.7000 Test Loss = 0.2098, Test Accuracy = 0.8469\n",
      "Iteration 377: Loss = 0.1424, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8373\n",
      "Iteration 378: Loss = 0.2472, Accuracy = 0.7000 Test Loss = 0.2125, Test Accuracy = 0.8478\n",
      "Iteration 379: Loss = 0.1794, Accuracy = 0.8000 Test Loss = 0.2081, Test Accuracy = 0.8385\n",
      "Iteration 380: Loss = 0.1801, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8463\n",
      "Iteration 381: Loss = 0.1205, Accuracy = 0.9000 Test Loss = 0.2091, Test Accuracy = 0.8408\n",
      "Iteration 382: Loss = 0.1085, Accuracy = 1.0000 Test Loss = 0.2079, Test Accuracy = 0.8381\n",
      "Iteration 383: Loss = 0.2812, Accuracy = 0.6000 Test Loss = 0.2052, Test Accuracy = 0.8469\n",
      "Iteration 384: Loss = 0.1574, Accuracy = 1.0000 Test Loss = 0.2124, Test Accuracy = 0.8435\n",
      "Iteration 385: Loss = 0.1754, Accuracy = 0.8000 Test Loss = 0.2074, Test Accuracy = 0.8533\n",
      "Iteration 386: Loss = 0.3073, Accuracy = 0.6000 Test Loss = 0.2086, Test Accuracy = 0.8454\n",
      "Iteration 387: Loss = 0.1022, Accuracy = 1.0000 Test Loss = 0.2080, Test Accuracy = 0.8458\n",
      "Iteration 388: Loss = 0.1996, Accuracy = 0.8000 Test Loss = 0.2076, Test Accuracy = 0.8483\n",
      "Iteration 389: Loss = 0.2618, Accuracy = 0.7000 Test Loss = 0.2101, Test Accuracy = 0.8511\n",
      "Iteration 390: Loss = 0.6717, Accuracy = 0.6000 Test Loss = 0.2118, Test Accuracy = 0.8517\n",
      "Iteration 391: Loss = 0.1916, Accuracy = 0.9000 Test Loss = 0.2101, Test Accuracy = 0.8423\n",
      "Iteration 392: Loss = 0.2407, Accuracy = 0.9000 Test Loss = 0.2091, Test Accuracy = 0.8494\n",
      "Iteration 393: Loss = 0.1980, Accuracy = 1.0000 Test Loss = 0.2075, Test Accuracy = 0.8460\n",
      "Iteration 394: Loss = 0.2686, Accuracy = 0.7000 Test Loss = 0.2129, Test Accuracy = 0.8408\n",
      "Iteration 395: Loss = 0.2509, Accuracy = 0.9000 Test Loss = 0.2073, Test Accuracy = 0.8464\n",
      "Iteration 396: Loss = 0.1772, Accuracy = 0.9000 Test Loss = 0.2115, Test Accuracy = 0.8351\n",
      "Iteration 397: Loss = 0.1248, Accuracy = 0.9000 Test Loss = 0.2113, Test Accuracy = 0.8221\n",
      "Iteration 398: Loss = 0.2423, Accuracy = 0.9000 Test Loss = 0.2128, Test Accuracy = 0.8478\n",
      "Iteration 399: Loss = 0.2656, Accuracy = 0.8000 Test Loss = 0.2116, Test Accuracy = 0.8399\n",
      "Iteration 400: Loss = 0.1810, Accuracy = 0.9000 Test Loss = 0.2084, Test Accuracy = 0.8394\n",
      "Iteration 401: Loss = 0.2174, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8495\n",
      "Iteration 402: Loss = 0.2493, Accuracy = 0.9000 Test Loss = 0.2079, Test Accuracy = 0.8430\n",
      "Iteration 403: Loss = 0.2228, Accuracy = 0.8000 Test Loss = 0.2112, Test Accuracy = 0.8363\n",
      "Iteration 404: Loss = 0.2698, Accuracy = 0.8000 Test Loss = 0.2124, Test Accuracy = 0.8347\n",
      "Iteration 405: Loss = 0.1764, Accuracy = 0.8000 Test Loss = 0.2137, Test Accuracy = 0.8363\n",
      "Iteration 406: Loss = 0.2201, Accuracy = 0.9000 Test Loss = 0.2075, Test Accuracy = 0.8426\n",
      "Iteration 407: Loss = 0.1427, Accuracy = 1.0000 Test Loss = 0.2075, Test Accuracy = 0.8368\n",
      "Iteration 408: Loss = 0.2423, Accuracy = 0.7000 Test Loss = 0.2096, Test Accuracy = 0.8499\n",
      "Iteration 409: Loss = 0.2430, Accuracy = 0.7000 Test Loss = 0.2094, Test Accuracy = 0.8451\n",
      "Iteration 410: Loss = 0.1606, Accuracy = 1.0000 Test Loss = 0.2067, Test Accuracy = 0.8462\n",
      "Iteration 411: Loss = 0.2410, Accuracy = 0.8000 Test Loss = 0.2101, Test Accuracy = 0.8403\n",
      "Iteration 412: Loss = 0.1984, Accuracy = 0.8000 Test Loss = 0.2105, Test Accuracy = 0.8377\n",
      "Iteration 413: Loss = 0.1815, Accuracy = 0.9000 Test Loss = 0.2103, Test Accuracy = 0.8412\n",
      "Iteration 414: Loss = 0.1797, Accuracy = 0.9000 Test Loss = 0.2098, Test Accuracy = 0.8445\n",
      "Iteration 415: Loss = 0.2463, Accuracy = 0.7000 Test Loss = 0.2126, Test Accuracy = 0.8504\n",
      "Iteration 416: Loss = 0.1966, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8410\n",
      "Iteration 417: Loss = 0.1774, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8425\n",
      "Iteration 418: Loss = 0.1421, Accuracy = 1.0000 Test Loss = 0.2112, Test Accuracy = 0.8302\n",
      "Iteration 419: Loss = 0.2071, Accuracy = 0.8000 Test Loss = 0.2088, Test Accuracy = 0.8438\n",
      "Iteration 420: Loss = 0.2119, Accuracy = 0.9000 Test Loss = 0.2089, Test Accuracy = 0.8412\n",
      "Iteration 421: Loss = 0.1795, Accuracy = 0.8000 Test Loss = 0.2097, Test Accuracy = 0.8418\n",
      "Iteration 422: Loss = 0.2593, Accuracy = 0.6000 Test Loss = 0.2055, Test Accuracy = 0.8524\n",
      "Iteration 423: Loss = 0.2154, Accuracy = 1.0000 Test Loss = 0.2085, Test Accuracy = 0.8436\n",
      "Iteration 424: Loss = 0.1481, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8493\n",
      "Iteration 425: Loss = 0.1888, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8349\n",
      "Iteration 426: Loss = 0.1856, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8529\n",
      "Iteration 427: Loss = 0.2368, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8537\n",
      "Iteration 428: Loss = 0.0951, Accuracy = 1.0000 Test Loss = 0.2103, Test Accuracy = 0.8441\n",
      "Iteration 429: Loss = 0.3065, Accuracy = 0.9000 Test Loss = 0.2102, Test Accuracy = 0.8521\n",
      "Iteration 430: Loss = 0.1551, Accuracy = 0.9000 Test Loss = 0.2078, Test Accuracy = 0.8440\n",
      "Iteration 431: Loss = 0.2124, Accuracy = 0.8000 Test Loss = 0.2150, Test Accuracy = 0.8340\n",
      "Iteration 432: Loss = 0.2055, Accuracy = 0.9000 Test Loss = 0.2082, Test Accuracy = 0.8410\n",
      "Iteration 433: Loss = 0.2358, Accuracy = 0.8000 Test Loss = 0.2124, Test Accuracy = 0.8331\n",
      "Iteration 434: Loss = 0.2057, Accuracy = 0.8000 Test Loss = 0.2061, Test Accuracy = 0.8568\n",
      "Iteration 435: Loss = 0.2197, Accuracy = 0.8000 Test Loss = 0.2076, Test Accuracy = 0.8450\n",
      "Iteration 436: Loss = 0.2146, Accuracy = 0.9000 Test Loss = 0.2075, Test Accuracy = 0.8410\n",
      "Iteration 437: Loss = 0.2364, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8508\n",
      "Iteration 438: Loss = 0.1514, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8506\n",
      "Iteration 439: Loss = 0.2065, Accuracy = 0.7000 Test Loss = 0.2110, Test Accuracy = 0.8457\n",
      "Iteration 440: Loss = 0.2904, Accuracy = 0.7000 Test Loss = 0.2087, Test Accuracy = 0.8400\n",
      "Iteration 441: Loss = 0.1477, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8441\n",
      "Iteration 442: Loss = 0.2939, Accuracy = 0.7000 Test Loss = 0.2134, Test Accuracy = 0.8376\n",
      "Iteration 443: Loss = 0.1847, Accuracy = 0.8000 Test Loss = 0.2131, Test Accuracy = 0.8527\n",
      "Iteration 444: Loss = 0.2041, Accuracy = 0.8000 Test Loss = 0.2103, Test Accuracy = 0.8401\n",
      "Iteration 445: Loss = 0.2272, Accuracy = 0.7000 Test Loss = 0.2081, Test Accuracy = 0.8388\n",
      "Iteration 446: Loss = 0.1774, Accuracy = 0.9000 Test Loss = 0.2084, Test Accuracy = 0.8422\n",
      "Iteration 447: Loss = 0.2394, Accuracy = 0.8000 Test Loss = 0.2080, Test Accuracy = 0.8450\n",
      "Iteration 448: Loss = 0.2601, Accuracy = 0.8000 Test Loss = 0.2110, Test Accuracy = 0.8348\n",
      "Iteration 449: Loss = 0.1967, Accuracy = 1.0000 Test Loss = 0.2124, Test Accuracy = 0.8347\n",
      "Iteration 450: Loss = 0.2468, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8493\n",
      "Iteration 451: Loss = 0.3539, Accuracy = 0.9000 Test Loss = 0.2094, Test Accuracy = 0.8536\n",
      "Iteration 452: Loss = 0.1813, Accuracy = 0.8000 Test Loss = 0.2083, Test Accuracy = 0.8447\n",
      "Iteration 453: Loss = 0.1695, Accuracy = 1.0000 Test Loss = 0.2084, Test Accuracy = 0.8533\n",
      "Iteration 454: Loss = 0.2041, Accuracy = 0.9000 Test Loss = 0.2064, Test Accuracy = 0.8534\n",
      "Iteration 455: Loss = 0.2428, Accuracy = 0.8000 Test Loss = 0.2140, Test Accuracy = 0.8405\n",
      "Iteration 456: Loss = 0.2019, Accuracy = 1.0000 Test Loss = 0.2078, Test Accuracy = 0.8447\n",
      "Iteration 457: Loss = 0.1927, Accuracy = 0.9000 Test Loss = 0.2149, Test Accuracy = 0.8413\n",
      "Iteration 458: Loss = 0.2003, Accuracy = 0.8000 Test Loss = 0.2132, Test Accuracy = 0.8318\n",
      "Iteration 459: Loss = 0.1447, Accuracy = 1.0000 Test Loss = 0.2130, Test Accuracy = 0.8368\n",
      "Iteration 460: Loss = 0.2848, Accuracy = 0.8000 Test Loss = 0.2094, Test Accuracy = 0.8526\n",
      "Iteration 461: Loss = 0.2399, Accuracy = 0.8000 Test Loss = 0.2108, Test Accuracy = 0.8388\n",
      "Iteration 462: Loss = 0.2526, Accuracy = 0.8000 Test Loss = 0.2115, Test Accuracy = 0.8477\n",
      "Iteration 463: Loss = 0.2198, Accuracy = 0.9000 Test Loss = 0.2120, Test Accuracy = 0.8389\n",
      "Iteration 464: Loss = 0.2393, Accuracy = 0.7000 Test Loss = 0.2080, Test Accuracy = 0.8431\n",
      "Iteration 465: Loss = 0.1820, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8468\n",
      "Iteration 466: Loss = 0.2003, Accuracy = 0.9000 Test Loss = 0.2116, Test Accuracy = 0.8401\n",
      "Iteration 467: Loss = 0.2676, Accuracy = 0.7000 Test Loss = 0.2154, Test Accuracy = 0.8399\n",
      "Iteration 468: Loss = 0.1407, Accuracy = 1.0000 Test Loss = 0.2078, Test Accuracy = 0.8494\n",
      "Iteration 469: Loss = 0.2027, Accuracy = 0.8000 Test Loss = 0.2095, Test Accuracy = 0.8427\n",
      "Iteration 470: Loss = 0.1218, Accuracy = 1.0000 Test Loss = 0.2073, Test Accuracy = 0.8410\n",
      "Iteration 471: Loss = 0.3244, Accuracy = 0.5000 Test Loss = 0.2071, Test Accuracy = 0.8486\n",
      "Iteration 472: Loss = 0.2317, Accuracy = 0.8000 Test Loss = 0.2094, Test Accuracy = 0.8438\n",
      "Iteration 473: Loss = 0.1721, Accuracy = 1.0000 Test Loss = 0.2058, Test Accuracy = 0.8514\n",
      "Iteration 474: Loss = 0.1905, Accuracy = 0.9000 Test Loss = 0.2099, Test Accuracy = 0.8362\n",
      "Iteration 475: Loss = 0.2451, Accuracy = 0.7000 Test Loss = 0.2105, Test Accuracy = 0.8432\n",
      "Iteration 476: Loss = 0.1654, Accuracy = 0.9000 Test Loss = 0.2056, Test Accuracy = 0.8397\n",
      "Iteration 477: Loss = 0.2030, Accuracy = 0.9000 Test Loss = 0.2067, Test Accuracy = 0.8408\n",
      "Iteration 478: Loss = 0.1665, Accuracy = 0.9000 Test Loss = 0.2112, Test Accuracy = 0.8273\n",
      "Iteration 479: Loss = 0.1167, Accuracy = 1.0000 Test Loss = 0.2103, Test Accuracy = 0.8267\n",
      "Iteration 480: Loss = 0.2246, Accuracy = 0.9000 Test Loss = 0.2112, Test Accuracy = 0.8422\n",
      "Iteration 481: Loss = 0.1696, Accuracy = 0.9000 Test Loss = 0.2119, Test Accuracy = 0.8373\n",
      "Iteration 482: Loss = 0.2047, Accuracy = 0.8000 Test Loss = 0.2074, Test Accuracy = 0.8435\n",
      "Iteration 483: Loss = 0.3108, Accuracy = 0.7000 Test Loss = 0.2143, Test Accuracy = 0.8297\n",
      "Iteration 484: Loss = 0.1943, Accuracy = 0.8000 Test Loss = 0.2064, Test Accuracy = 0.8502\n",
      "Iteration 485: Loss = 0.1964, Accuracy = 0.9000 Test Loss = 0.2098, Test Accuracy = 0.8470\n",
      "Iteration 486: Loss = 0.2659, Accuracy = 0.6000 Test Loss = 0.2085, Test Accuracy = 0.8452\n",
      "Iteration 487: Loss = 0.2831, Accuracy = 0.7000 Test Loss = 0.2136, Test Accuracy = 0.8413\n",
      "Iteration 488: Loss = 0.1270, Accuracy = 1.0000 Test Loss = 0.2082, Test Accuracy = 0.8431\n",
      "Iteration 489: Loss = 0.2346, Accuracy = 0.7000 Test Loss = 0.2089, Test Accuracy = 0.8349\n",
      "Iteration 490: Loss = 0.1798, Accuracy = 0.9000 Test Loss = 0.2122, Test Accuracy = 0.8326\n",
      "Iteration 491: Loss = 0.1592, Accuracy = 0.9000 Test Loss = 0.2058, Test Accuracy = 0.8379\n",
      "Iteration 492: Loss = 0.2597, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8398\n",
      "Iteration 493: Loss = 0.2462, Accuracy = 0.8000 Test Loss = 0.2189, Test Accuracy = 0.8447\n",
      "Iteration 494: Loss = 0.1999, Accuracy = 1.0000 Test Loss = 0.2216, Test Accuracy = 0.8253\n",
      "Iteration 495: Loss = 0.2367, Accuracy = 0.8000 Test Loss = 0.2097, Test Accuracy = 0.8443\n",
      "Iteration 496: Loss = 0.1889, Accuracy = 0.9000 Test Loss = 0.2079, Test Accuracy = 0.8453\n",
      "Iteration 497: Loss = 0.1738, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8405\n",
      "Iteration 498: Loss = 0.2361, Accuracy = 0.8000 Test Loss = 0.2090, Test Accuracy = 0.8396\n",
      "Iteration 499: Loss = 0.3586, Accuracy = 0.5000 Test Loss = 0.2088, Test Accuracy = 0.8461\n",
      "Iteration 500: Loss = 0.2150, Accuracy = 0.8000 Test Loss = 0.2147, Test Accuracy = 0.8407\n",
      "Iteration 501: Loss = 0.1524, Accuracy = 0.9000 Test Loss = 0.2086, Test Accuracy = 0.8458\n",
      "Iteration 502: Loss = 0.2009, Accuracy = 0.8000 Test Loss = 0.2059, Test Accuracy = 0.8470\n",
      "Iteration 503: Loss = 0.2244, Accuracy = 0.7000 Test Loss = 0.2140, Test Accuracy = 0.8423\n",
      "Iteration 504: Loss = 0.1925, Accuracy = 0.9000 Test Loss = 0.2134, Test Accuracy = 0.8366\n",
      "Iteration 505: Loss = 0.1968, Accuracy = 0.8000 Test Loss = 0.2089, Test Accuracy = 0.8460\n",
      "Iteration 506: Loss = 0.1853, Accuracy = 0.9000 Test Loss = 0.2107, Test Accuracy = 0.8416\n",
      "Iteration 507: Loss = 0.1666, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8394\n",
      "Iteration 508: Loss = 0.1462, Accuracy = 1.0000 Test Loss = 0.2112, Test Accuracy = 0.8411\n",
      "Iteration 509: Loss = 0.2884, Accuracy = 0.6000 Test Loss = 0.2069, Test Accuracy = 0.8526\n",
      "Iteration 510: Loss = 0.2042, Accuracy = 0.9000 Test Loss = 0.2111, Test Accuracy = 0.8327\n",
      "Iteration 511: Loss = 0.1138, Accuracy = 0.9000 Test Loss = 0.2110, Test Accuracy = 0.8384\n",
      "Iteration 512: Loss = 0.1958, Accuracy = 0.9000 Test Loss = 0.2102, Test Accuracy = 0.8431\n",
      "Iteration 513: Loss = 0.2382, Accuracy = 0.7000 Test Loss = 0.2134, Test Accuracy = 0.8442\n",
      "Iteration 514: Loss = 0.2726, Accuracy = 0.7000 Test Loss = 0.2068, Test Accuracy = 0.8453\n",
      "Iteration 515: Loss = 0.2007, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8476\n",
      "Iteration 516: Loss = 0.2091, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8516\n",
      "Iteration 517: Loss = 0.1997, Accuracy = 0.8000 Test Loss = 0.2095, Test Accuracy = 0.8550\n",
      "Iteration 518: Loss = 0.1643, Accuracy = 1.0000 Test Loss = 0.2088, Test Accuracy = 0.8485\n",
      "Iteration 519: Loss = 0.2051, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8427\n",
      "Iteration 520: Loss = 0.1617, Accuracy = 1.0000 Test Loss = 0.2084, Test Accuracy = 0.8423\n",
      "Iteration 521: Loss = 0.1056, Accuracy = 1.0000 Test Loss = 0.2095, Test Accuracy = 0.8410\n",
      "Iteration 522: Loss = 0.2682, Accuracy = 0.5000 Test Loss = 0.2066, Test Accuracy = 0.8508\n",
      "Iteration 523: Loss = 0.1478, Accuracy = 0.9000 Test Loss = 0.2078, Test Accuracy = 0.8529\n",
      "Iteration 524: Loss = 0.1875, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8431\n",
      "Iteration 525: Loss = 0.3407, Accuracy = 0.6000 Test Loss = 0.2145, Test Accuracy = 0.8432\n",
      "Iteration 526: Loss = 0.1871, Accuracy = 0.9000 Test Loss = 0.2077, Test Accuracy = 0.8491\n",
      "Iteration 527: Loss = 0.2319, Accuracy = 0.8000 Test Loss = 0.2065, Test Accuracy = 0.8394\n",
      "Iteration 528: Loss = 0.1760, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8392\n",
      "Iteration 529: Loss = 0.2650, Accuracy = 0.6000 Test Loss = 0.2121, Test Accuracy = 0.8366\n",
      "Iteration 530: Loss = 0.2466, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8419\n",
      "Iteration 531: Loss = 0.1726, Accuracy = 0.8000 Test Loss = 0.2061, Test Accuracy = 0.8546\n",
      "Iteration 532: Loss = 0.2677, Accuracy = 0.7000 Test Loss = 0.2125, Test Accuracy = 0.8440\n",
      "Iteration 533: Loss = 0.1750, Accuracy = 0.9000 Test Loss = 0.2123, Test Accuracy = 0.8420\n",
      "Iteration 534: Loss = 0.2820, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8468\n",
      "Iteration 535: Loss = 0.1480, Accuracy = 0.9000 Test Loss = 0.2097, Test Accuracy = 0.8470\n",
      "Iteration 536: Loss = 0.1364, Accuracy = 1.0000 Test Loss = 0.2051, Test Accuracy = 0.8493\n",
      "Iteration 537: Loss = 0.2496, Accuracy = 0.6000 Test Loss = 0.2108, Test Accuracy = 0.8326\n",
      "Iteration 538: Loss = 0.1781, Accuracy = 1.0000 Test Loss = 0.2077, Test Accuracy = 0.8508\n",
      "Iteration 539: Loss = 0.2895, Accuracy = 0.6000 Test Loss = 0.2169, Test Accuracy = 0.8357\n",
      "Iteration 540: Loss = 0.2612, Accuracy = 0.7000 Test Loss = 0.2080, Test Accuracy = 0.8463\n",
      "Iteration 541: Loss = 0.2874, Accuracy = 0.7000 Test Loss = 0.2101, Test Accuracy = 0.8519\n",
      "Iteration 542: Loss = 0.2298, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8413\n",
      "Iteration 543: Loss = 0.3075, Accuracy = 0.7000 Test Loss = 0.2123, Test Accuracy = 0.8365\n",
      "Iteration 544: Loss = 0.1323, Accuracy = 1.0000 Test Loss = 0.2098, Test Accuracy = 0.8370\n",
      "Iteration 545: Loss = 0.3263, Accuracy = 0.7000 Test Loss = 0.2103, Test Accuracy = 0.8400\n",
      "Iteration 546: Loss = 0.1971, Accuracy = 0.9000 Test Loss = 0.2101, Test Accuracy = 0.8339\n",
      "Iteration 547: Loss = 0.1532, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8435\n",
      "Iteration 548: Loss = 0.1945, Accuracy = 1.0000 Test Loss = 0.2065, Test Accuracy = 0.8444\n",
      "Iteration 549: Loss = 0.1818, Accuracy = 0.9000 Test Loss = 0.2144, Test Accuracy = 0.8339\n",
      "Iteration 550: Loss = 0.2488, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8462\n",
      "Iteration 551: Loss = 0.1534, Accuracy = 1.0000 Test Loss = 0.2054, Test Accuracy = 0.8477\n",
      "Iteration 552: Loss = 0.1731, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8409\n",
      "Iteration 553: Loss = 0.1749, Accuracy = 0.9000 Test Loss = 0.2108, Test Accuracy = 0.8490\n",
      "Iteration 554: Loss = 0.2891, Accuracy = 0.7000 Test Loss = 0.2077, Test Accuracy = 0.8451\n",
      "Iteration 555: Loss = 0.1858, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8325\n",
      "Iteration 556: Loss = 0.1790, Accuracy = 0.8000 Test Loss = 0.2087, Test Accuracy = 0.8455\n",
      "Iteration 557: Loss = 0.1621, Accuracy = 1.0000 Test Loss = 0.2093, Test Accuracy = 0.8473\n",
      "Iteration 558: Loss = 0.2244, Accuracy = 0.8000 Test Loss = 0.2070, Test Accuracy = 0.8450\n",
      "Iteration 559: Loss = 0.2209, Accuracy = 0.8000 Test Loss = 0.2119, Test Accuracy = 0.8430\n",
      "Iteration 560: Loss = 0.1771, Accuracy = 0.8000 Test Loss = 0.2131, Test Accuracy = 0.8351\n",
      "Iteration 561: Loss = 0.1980, Accuracy = 0.8000 Test Loss = 0.2101, Test Accuracy = 0.8465\n",
      "Iteration 562: Loss = 0.2372, Accuracy = 0.8000 Test Loss = 0.2099, Test Accuracy = 0.8421\n",
      "Iteration 563: Loss = 0.1748, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8561\n",
      "Iteration 564: Loss = 0.1676, Accuracy = 0.9000 Test Loss = 0.2099, Test Accuracy = 0.8457\n",
      "Iteration 565: Loss = 0.1123, Accuracy = 1.0000 Test Loss = 0.2090, Test Accuracy = 0.8508\n",
      "Iteration 566: Loss = 0.2579, Accuracy = 0.9000 Test Loss = 0.2102, Test Accuracy = 0.8508\n",
      "Iteration 567: Loss = 0.2456, Accuracy = 0.7000 Test Loss = 0.2106, Test Accuracy = 0.8483\n",
      "Iteration 568: Loss = 0.4127, Accuracy = 0.6000 Test Loss = 0.2205, Test Accuracy = 0.8260\n",
      "Iteration 569: Loss = 0.2006, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8484\n",
      "Iteration 570: Loss = 0.2060, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8462\n",
      "Iteration 571: Loss = 0.2944, Accuracy = 0.7000 Test Loss = 0.2084, Test Accuracy = 0.8535\n",
      "Iteration 572: Loss = 0.1537, Accuracy = 1.0000 Test Loss = 0.2063, Test Accuracy = 0.8421\n",
      "Iteration 573: Loss = 0.1427, Accuracy = 1.0000 Test Loss = 0.2093, Test Accuracy = 0.8490\n",
      "Iteration 574: Loss = 0.2736, Accuracy = 0.7000 Test Loss = 0.2101, Test Accuracy = 0.8303\n",
      "Iteration 575: Loss = 0.2062, Accuracy = 0.8000 Test Loss = 0.2075, Test Accuracy = 0.8350\n",
      "Iteration 576: Loss = 0.2584, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8444\n",
      "Iteration 577: Loss = 0.2515, Accuracy = 0.8000 Test Loss = 0.2106, Test Accuracy = 0.8528\n",
      "Iteration 578: Loss = 0.2035, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8518\n",
      "Iteration 579: Loss = 0.3014, Accuracy = 0.7000 Test Loss = 0.2084, Test Accuracy = 0.8457\n",
      "Iteration 580: Loss = 0.1530, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8465\n",
      "Iteration 581: Loss = 0.1704, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8512\n",
      "Iteration 582: Loss = 0.2115, Accuracy = 0.9000 Test Loss = 0.2104, Test Accuracy = 0.8340\n",
      "Iteration 583: Loss = 0.3739, Accuracy = 0.8000 Test Loss = 0.2075, Test Accuracy = 0.8443\n",
      "Iteration 584: Loss = 0.2528, Accuracy = 0.7000 Test Loss = 0.2086, Test Accuracy = 0.8362\n",
      "Iteration 585: Loss = 0.2948, Accuracy = 0.8000 Test Loss = 0.2125, Test Accuracy = 0.8400\n",
      "Iteration 586: Loss = 0.1903, Accuracy = 0.6000 Test Loss = 0.2082, Test Accuracy = 0.8410\n",
      "Iteration 587: Loss = 0.1443, Accuracy = 1.0000 Test Loss = 0.2124, Test Accuracy = 0.8384\n",
      "Iteration 588: Loss = 0.2983, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8517\n",
      "Iteration 589: Loss = 0.2475, Accuracy = 0.8000 Test Loss = 0.2074, Test Accuracy = 0.8450\n",
      "Iteration 590: Loss = 0.1892, Accuracy = 0.9000 Test Loss = 0.2098, Test Accuracy = 0.8423\n",
      "Iteration 591: Loss = 0.1484, Accuracy = 1.0000 Test Loss = 0.2091, Test Accuracy = 0.8471\n",
      "Iteration 592: Loss = 0.4913, Accuracy = 0.5000 Test Loss = 0.2080, Test Accuracy = 0.8412\n",
      "Iteration 593: Loss = 0.1654, Accuracy = 0.9000 Test Loss = 0.2071, Test Accuracy = 0.8471\n",
      "Iteration 594: Loss = 0.1964, Accuracy = 0.9000 Test Loss = 0.2091, Test Accuracy = 0.8455\n",
      "Iteration 595: Loss = 0.1947, Accuracy = 0.8000 Test Loss = 0.2082, Test Accuracy = 0.8455\n",
      "Iteration 596: Loss = 0.1650, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8511\n",
      "Iteration 597: Loss = 0.2034, Accuracy = 0.9000 Test Loss = 0.2130, Test Accuracy = 0.8448\n",
      "Iteration 598: Loss = 0.1702, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8452\n",
      "Iteration 599: Loss = 0.1541, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8375\n",
      "Iteration 600: Loss = 0.2939, Accuracy = 0.7000 Test Loss = 0.2098, Test Accuracy = 0.8432\n",
      "Iteration 601: Loss = 0.1911, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8485\n",
      "Iteration 602: Loss = 0.1334, Accuracy = 1.0000 Test Loss = 0.2108, Test Accuracy = 0.8388\n",
      "Iteration 603: Loss = 0.1147, Accuracy = 1.0000 Test Loss = 0.2113, Test Accuracy = 0.8422\n",
      "Iteration 604: Loss = 0.2300, Accuracy = 0.7000 Test Loss = 0.2112, Test Accuracy = 0.8482\n",
      "Iteration 605: Loss = 0.1002, Accuracy = 1.0000 Test Loss = 0.2095, Test Accuracy = 0.8371\n",
      "Iteration 606: Loss = 0.1881, Accuracy = 0.9000 Test Loss = 0.2044, Test Accuracy = 0.8519\n",
      "Iteration 607: Loss = 0.2352, Accuracy = 0.8000 Test Loss = 0.2081, Test Accuracy = 0.8466\n",
      "Iteration 608: Loss = 0.2313, Accuracy = 0.8000 Test Loss = 0.2169, Test Accuracy = 0.8242\n",
      "Iteration 609: Loss = 0.1950, Accuracy = 0.7000 Test Loss = 0.2065, Test Accuracy = 0.8465\n",
      "Iteration 610: Loss = 0.1864, Accuracy = 1.0000 Test Loss = 0.2095, Test Accuracy = 0.8425\n",
      "Iteration 611: Loss = 0.2091, Accuracy = 0.7000 Test Loss = 0.2084, Test Accuracy = 0.8385\n",
      "Iteration 612: Loss = 0.2002, Accuracy = 0.9000 Test Loss = 0.2092, Test Accuracy = 0.8358\n",
      "Iteration 613: Loss = 0.3212, Accuracy = 0.7000 Test Loss = 0.2111, Test Accuracy = 0.8415\n",
      "Iteration 614: Loss = 0.3228, Accuracy = 0.6000 Test Loss = 0.2093, Test Accuracy = 0.8354\n",
      "Iteration 615: Loss = 0.2024, Accuracy = 0.9000 Test Loss = 0.2097, Test Accuracy = 0.8423\n",
      "Iteration 616: Loss = 0.2038, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8460\n",
      "Iteration 617: Loss = 0.3022, Accuracy = 0.7000 Test Loss = 0.2065, Test Accuracy = 0.8474\n",
      "Iteration 618: Loss = 0.2697, Accuracy = 0.6000 Test Loss = 0.2136, Test Accuracy = 0.8456\n",
      "Iteration 619: Loss = 0.2506, Accuracy = 0.7000 Test Loss = 0.2087, Test Accuracy = 0.8420\n",
      "Iteration 620: Loss = 0.2626, Accuracy = 0.6000 Test Loss = 0.2092, Test Accuracy = 0.8407\n",
      "Iteration 621: Loss = 0.1546, Accuracy = 1.0000 Test Loss = 0.2081, Test Accuracy = 0.8457\n",
      "Iteration 622: Loss = 0.2142, Accuracy = 0.8000 Test Loss = 0.2084, Test Accuracy = 0.8505\n",
      "Iteration 623: Loss = 0.2656, Accuracy = 0.8000 Test Loss = 0.2101, Test Accuracy = 0.8403\n",
      "Iteration 624: Loss = 0.2097, Accuracy = 0.8000 Test Loss = 0.2109, Test Accuracy = 0.8425\n",
      "Iteration 625: Loss = 0.1905, Accuracy = 0.8000 Test Loss = 0.2073, Test Accuracy = 0.8486\n",
      "Iteration 626: Loss = 0.1321, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8310\n",
      "Iteration 627: Loss = 0.2051, Accuracy = 0.8000 Test Loss = 0.2121, Test Accuracy = 0.8457\n",
      "Iteration 628: Loss = 0.1576, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8432\n",
      "Iteration 629: Loss = 0.2074, Accuracy = 0.7000 Test Loss = 0.2081, Test Accuracy = 0.8457\n",
      "Iteration 630: Loss = 0.2736, Accuracy = 0.8000 Test Loss = 0.2085, Test Accuracy = 0.8508\n",
      "Iteration 631: Loss = 0.3005, Accuracy = 0.7000 Test Loss = 0.2116, Test Accuracy = 0.8269\n",
      "Iteration 632: Loss = 0.2938, Accuracy = 0.7000 Test Loss = 0.2086, Test Accuracy = 0.8475\n",
      "Iteration 633: Loss = 0.3094, Accuracy = 0.8000 Test Loss = 0.2073, Test Accuracy = 0.8535\n",
      "Iteration 634: Loss = 0.1426, Accuracy = 0.9000 Test Loss = 0.2110, Test Accuracy = 0.8427\n",
      "Iteration 635: Loss = 0.1860, Accuracy = 0.8000 Test Loss = 0.2097, Test Accuracy = 0.8465\n",
      "Iteration 636: Loss = 0.1659, Accuracy = 1.0000 Test Loss = 0.2073, Test Accuracy = 0.8452\n",
      "Iteration 637: Loss = 0.2061, Accuracy = 0.8000 Test Loss = 0.2136, Test Accuracy = 0.8299\n",
      "Iteration 638: Loss = 0.1972, Accuracy = 0.8000 Test Loss = 0.2108, Test Accuracy = 0.8391\n",
      "Iteration 639: Loss = 0.1762, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8404\n",
      "Iteration 640: Loss = 0.2137, Accuracy = 0.7000 Test Loss = 0.2054, Test Accuracy = 0.8450\n",
      "Iteration 641: Loss = 0.2062, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8561\n",
      "Iteration 642: Loss = 0.2731, Accuracy = 0.7000 Test Loss = 0.2121, Test Accuracy = 0.8387\n",
      "Iteration 643: Loss = 0.1783, Accuracy = 0.9000 Test Loss = 0.2077, Test Accuracy = 0.8440\n",
      "Iteration 644: Loss = 0.2859, Accuracy = 0.7000 Test Loss = 0.2064, Test Accuracy = 0.8533\n",
      "Iteration 645: Loss = 0.1375, Accuracy = 0.9000 Test Loss = 0.2075, Test Accuracy = 0.8486\n",
      "Iteration 646: Loss = 0.1717, Accuracy = 1.0000 Test Loss = 0.2060, Test Accuracy = 0.8457\n",
      "Iteration 647: Loss = 0.3122, Accuracy = 0.8000 Test Loss = 0.2063, Test Accuracy = 0.8517\n",
      "Iteration 648: Loss = 0.1454, Accuracy = 1.0000 Test Loss = 0.2073, Test Accuracy = 0.8427\n",
      "Iteration 649: Loss = 0.2761, Accuracy = 0.7000 Test Loss = 0.2062, Test Accuracy = 0.8531\n",
      "Iteration 650: Loss = 0.2230, Accuracy = 0.7000 Test Loss = 0.2069, Test Accuracy = 0.8461\n",
      "Iteration 651: Loss = 0.2814, Accuracy = 0.8000 Test Loss = 0.2115, Test Accuracy = 0.8427\n",
      "Iteration 652: Loss = 0.1372, Accuracy = 0.8000 Test Loss = 0.2080, Test Accuracy = 0.8439\n",
      "Iteration 653: Loss = 0.1851, Accuracy = 0.9000 Test Loss = 0.2129, Test Accuracy = 0.8367\n",
      "Iteration 654: Loss = 0.1604, Accuracy = 1.0000 Test Loss = 0.2127, Test Accuracy = 0.8467\n",
      "Iteration 655: Loss = 0.3278, Accuracy = 0.7000 Test Loss = 0.2077, Test Accuracy = 0.8548\n",
      "Iteration 656: Loss = 0.2136, Accuracy = 0.9000 Test Loss = 0.2068, Test Accuracy = 0.8502\n",
      "Iteration 657: Loss = 0.1857, Accuracy = 0.8000 Test Loss = 0.2066, Test Accuracy = 0.8488\n",
      "Iteration 658: Loss = 0.1836, Accuracy = 1.0000 Test Loss = 0.2075, Test Accuracy = 0.8364\n",
      "Iteration 659: Loss = 0.2584, Accuracy = 0.8000 Test Loss = 0.2108, Test Accuracy = 0.8430\n",
      "Iteration 660: Loss = 0.1414, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8488\n",
      "Iteration 661: Loss = 0.2628, Accuracy = 0.7000 Test Loss = 0.2103, Test Accuracy = 0.8514\n",
      "Iteration 662: Loss = 0.1874, Accuracy = 0.9000 Test Loss = 0.2053, Test Accuracy = 0.8436\n",
      "Iteration 663: Loss = 0.1330, Accuracy = 1.0000 Test Loss = 0.2093, Test Accuracy = 0.8369\n",
      "Iteration 664: Loss = 0.1267, Accuracy = 1.0000 Test Loss = 0.2069, Test Accuracy = 0.8411\n",
      "Iteration 665: Loss = 0.1481, Accuracy = 0.9000 Test Loss = 0.2080, Test Accuracy = 0.8389\n",
      "Iteration 666: Loss = 0.1375, Accuracy = 1.0000 Test Loss = 0.2101, Test Accuracy = 0.8382\n",
      "Iteration 667: Loss = 0.2503, Accuracy = 0.8000 Test Loss = 0.2081, Test Accuracy = 0.8469\n",
      "Iteration 668: Loss = 0.1821, Accuracy = 0.9000 Test Loss = 0.2080, Test Accuracy = 0.8432\n",
      "Iteration 669: Loss = 0.2587, Accuracy = 0.8000 Test Loss = 0.2103, Test Accuracy = 0.8532\n",
      "Iteration 670: Loss = 0.2077, Accuracy = 0.9000 Test Loss = 0.2091, Test Accuracy = 0.8404\n",
      "Iteration 671: Loss = 0.2453, Accuracy = 0.8000 Test Loss = 0.2109, Test Accuracy = 0.8393\n",
      "Iteration 672: Loss = 0.1314, Accuracy = 1.0000 Test Loss = 0.2078, Test Accuracy = 0.8457\n",
      "Iteration 673: Loss = 0.2901, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8485\n",
      "Iteration 674: Loss = 0.2670, Accuracy = 0.7000 Test Loss = 0.2145, Test Accuracy = 0.8385\n",
      "Iteration 675: Loss = 0.2130, Accuracy = 0.8000 Test Loss = 0.2048, Test Accuracy = 0.8532\n",
      "Iteration 676: Loss = 0.1770, Accuracy = 0.9000 Test Loss = 0.2137, Test Accuracy = 0.8345\n",
      "Iteration 677: Loss = 0.2218, Accuracy = 0.6000 Test Loss = 0.2091, Test Accuracy = 0.8465\n",
      "Iteration 678: Loss = 0.2368, Accuracy = 0.8000 Test Loss = 0.2118, Test Accuracy = 0.8366\n",
      "Iteration 679: Loss = 0.1476, Accuracy = 1.0000 Test Loss = 0.2087, Test Accuracy = 0.8463\n",
      "Iteration 680: Loss = 0.1603, Accuracy = 0.8000 Test Loss = 0.2114, Test Accuracy = 0.8478\n",
      "Iteration 681: Loss = 0.2360, Accuracy = 0.9000 Test Loss = 0.2089, Test Accuracy = 0.8504\n",
      "Iteration 682: Loss = 0.2384, Accuracy = 0.6000 Test Loss = 0.2061, Test Accuracy = 0.8442\n",
      "Iteration 683: Loss = 0.2398, Accuracy = 0.7000 Test Loss = 0.2077, Test Accuracy = 0.8436\n",
      "Iteration 684: Loss = 0.1239, Accuracy = 1.0000 Test Loss = 0.2075, Test Accuracy = 0.8359\n",
      "Iteration 685: Loss = 0.1704, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8524\n",
      "Iteration 686: Loss = 0.2666, Accuracy = 0.7000 Test Loss = 0.2124, Test Accuracy = 0.8468\n",
      "Iteration 687: Loss = 0.3888, Accuracy = 0.7000 Test Loss = 0.2072, Test Accuracy = 0.8501\n",
      "Iteration 688: Loss = 0.2524, Accuracy = 0.8000 Test Loss = 0.2096, Test Accuracy = 0.8485\n",
      "Iteration 689: Loss = 0.1844, Accuracy = 0.9000 Test Loss = 0.2079, Test Accuracy = 0.8344\n",
      "Iteration 690: Loss = 0.2001, Accuracy = 0.8000 Test Loss = 0.2092, Test Accuracy = 0.8371\n",
      "Iteration 691: Loss = 0.1984, Accuracy = 0.9000 Test Loss = 0.2090, Test Accuracy = 0.8422\n",
      "Iteration 692: Loss = 0.2441, Accuracy = 0.7000 Test Loss = 0.2080, Test Accuracy = 0.8478\n",
      "Iteration 693: Loss = 0.1996, Accuracy = 1.0000 Test Loss = 0.2079, Test Accuracy = 0.8477\n",
      "Iteration 694: Loss = 0.1830, Accuracy = 0.8000 Test Loss = 0.2050, Test Accuracy = 0.8504\n",
      "Iteration 695: Loss = 0.1986, Accuracy = 0.8000 Test Loss = 0.2087, Test Accuracy = 0.8527\n",
      "Iteration 696: Loss = 0.2831, Accuracy = 0.6000 Test Loss = 0.2071, Test Accuracy = 0.8484\n",
      "Iteration 697: Loss = 0.2650, Accuracy = 0.7000 Test Loss = 0.2113, Test Accuracy = 0.8401\n",
      "Iteration 698: Loss = 0.1554, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8464\n",
      "Iteration 699: Loss = 0.1659, Accuracy = 1.0000 Test Loss = 0.2096, Test Accuracy = 0.8517\n",
      "Iteration 700: Loss = 0.2566, Accuracy = 0.7000 Test Loss = 0.2129, Test Accuracy = 0.8456\n",
      "Iteration 701: Loss = 0.2244, Accuracy = 0.8000 Test Loss = 0.2113, Test Accuracy = 0.8377\n",
      "Iteration 702: Loss = 0.2812, Accuracy = 0.7000 Test Loss = 0.2072, Test Accuracy = 0.8466\n",
      "Iteration 703: Loss = 0.1573, Accuracy = 1.0000 Test Loss = 0.2067, Test Accuracy = 0.8463\n",
      "Iteration 704: Loss = 0.2341, Accuracy = 0.7000 Test Loss = 0.2092, Test Accuracy = 0.8431\n",
      "Iteration 705: Loss = 0.1674, Accuracy = 0.8000 Test Loss = 0.2111, Test Accuracy = 0.8361\n",
      "Iteration 706: Loss = 0.1868, Accuracy = 0.8000 Test Loss = 0.2103, Test Accuracy = 0.8388\n",
      "Iteration 707: Loss = 0.1703, Accuracy = 0.9000 Test Loss = 0.2091, Test Accuracy = 0.8442\n",
      "Iteration 708: Loss = 0.1995, Accuracy = 0.8000 Test Loss = 0.2116, Test Accuracy = 0.8320\n",
      "Iteration 709: Loss = 0.2254, Accuracy = 0.9000 Test Loss = 0.2099, Test Accuracy = 0.8435\n",
      "Iteration 710: Loss = 0.2317, Accuracy = 0.7000 Test Loss = 0.2082, Test Accuracy = 0.8469\n",
      "Iteration 711: Loss = 0.1784, Accuracy = 1.0000 Test Loss = 0.2066, Test Accuracy = 0.8397\n",
      "Iteration 712: Loss = 0.2042, Accuracy = 0.8000 Test Loss = 0.2070, Test Accuracy = 0.8530\n",
      "Iteration 713: Loss = 0.1984, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8437\n",
      "Iteration 714: Loss = 0.1519, Accuracy = 1.0000 Test Loss = 0.2065, Test Accuracy = 0.8415\n",
      "Iteration 715: Loss = 0.2909, Accuracy = 0.5000 Test Loss = 0.2074, Test Accuracy = 0.8402\n",
      "Iteration 716: Loss = 0.3312, Accuracy = 0.7000 Test Loss = 0.2076, Test Accuracy = 0.8400\n",
      "Iteration 717: Loss = 0.2103, Accuracy = 0.7000 Test Loss = 0.2092, Test Accuracy = 0.8417\n",
      "Iteration 718: Loss = 0.2441, Accuracy = 0.9000 Test Loss = 0.2072, Test Accuracy = 0.8383\n",
      "Iteration 719: Loss = 0.2409, Accuracy = 0.7000 Test Loss = 0.2051, Test Accuracy = 0.8515\n",
      "Iteration 720: Loss = 0.1638, Accuracy = 1.0000 Test Loss = 0.2104, Test Accuracy = 0.8406\n",
      "Iteration 721: Loss = 0.2423, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8444\n",
      "Iteration 722: Loss = 0.2192, Accuracy = 0.9000 Test Loss = 0.2128, Test Accuracy = 0.8421\n",
      "Iteration 723: Loss = 0.1517, Accuracy = 0.9000 Test Loss = 0.2105, Test Accuracy = 0.8323\n",
      "Iteration 724: Loss = 0.1978, Accuracy = 0.9000 Test Loss = 0.2081, Test Accuracy = 0.8467\n",
      "Iteration 725: Loss = 0.2646, Accuracy = 0.8000 Test Loss = 0.2082, Test Accuracy = 0.8389\n",
      "Iteration 726: Loss = 0.1745, Accuracy = 0.9000 Test Loss = 0.2054, Test Accuracy = 0.8485\n",
      "Iteration 727: Loss = 0.3248, Accuracy = 0.6000 Test Loss = 0.2065, Test Accuracy = 0.8479\n",
      "Iteration 728: Loss = 0.2041, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8456\n",
      "Iteration 729: Loss = 0.3226, Accuracy = 0.6000 Test Loss = 0.2067, Test Accuracy = 0.8428\n",
      "Iteration 730: Loss = 0.1696, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8470\n",
      "Iteration 731: Loss = 0.2676, Accuracy = 0.7000 Test Loss = 0.2089, Test Accuracy = 0.8436\n",
      "Iteration 732: Loss = 0.1485, Accuracy = 1.0000 Test Loss = 0.2062, Test Accuracy = 0.8509\n",
      "Iteration 733: Loss = 0.1602, Accuracy = 1.0000 Test Loss = 0.2091, Test Accuracy = 0.8476\n",
      "Iteration 734: Loss = 0.2412, Accuracy = 0.8000 Test Loss = 0.2070, Test Accuracy = 0.8517\n",
      "Iteration 735: Loss = 0.1892, Accuracy = 0.9000 Test Loss = 0.2069, Test Accuracy = 0.8569\n",
      "Iteration 736: Loss = 0.1358, Accuracy = 1.0000 Test Loss = 0.2050, Test Accuracy = 0.8501\n",
      "Iteration 737: Loss = 0.2330, Accuracy = 0.8000 Test Loss = 0.2067, Test Accuracy = 0.8402\n",
      "Iteration 738: Loss = 0.3758, Accuracy = 0.5000 Test Loss = 0.2148, Test Accuracy = 0.8454\n",
      "Iteration 739: Loss = 0.1844, Accuracy = 0.8000 Test Loss = 0.2116, Test Accuracy = 0.8342\n",
      "Iteration 740: Loss = 0.1167, Accuracy = 0.9000 Test Loss = 0.2062, Test Accuracy = 0.8396\n",
      "Iteration 741: Loss = 0.1310, Accuracy = 0.9000 Test Loss = 0.2082, Test Accuracy = 0.8428\n",
      "Iteration 742: Loss = 0.1550, Accuracy = 0.9000 Test Loss = 0.2089, Test Accuracy = 0.8456\n",
      "Iteration 743: Loss = 0.1772, Accuracy = 0.9000 Test Loss = 0.2064, Test Accuracy = 0.8464\n",
      "Iteration 744: Loss = 0.1945, Accuracy = 0.9000 Test Loss = 0.2109, Test Accuracy = 0.8417\n",
      "Iteration 745: Loss = 0.2296, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8488\n",
      "Iteration 746: Loss = 0.1993, Accuracy = 0.8000 Test Loss = 0.2088, Test Accuracy = 0.8449\n",
      "Iteration 747: Loss = 0.2936, Accuracy = 0.6000 Test Loss = 0.2099, Test Accuracy = 0.8447\n",
      "Iteration 748: Loss = 0.2460, Accuracy = 0.7000 Test Loss = 0.2102, Test Accuracy = 0.8485\n",
      "Iteration 749: Loss = 0.3642, Accuracy = 0.6000 Test Loss = 0.2078, Test Accuracy = 0.8405\n",
      "Iteration 750: Loss = 0.2217, Accuracy = 0.8000 Test Loss = 0.2045, Test Accuracy = 0.8453\n",
      "Iteration 751: Loss = 0.2131, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8411\n",
      "Iteration 752: Loss = 0.2392, Accuracy = 0.9000 Test Loss = 0.2077, Test Accuracy = 0.8475\n",
      "Iteration 753: Loss = 0.1732, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8475\n",
      "Iteration 754: Loss = 0.1617, Accuracy = 1.0000 Test Loss = 0.2124, Test Accuracy = 0.8321\n",
      "Iteration 755: Loss = 0.2783, Accuracy = 0.6000 Test Loss = 0.2066, Test Accuracy = 0.8478\n",
      "Iteration 756: Loss = 0.1847, Accuracy = 0.8000 Test Loss = 0.2109, Test Accuracy = 0.8385\n",
      "Iteration 757: Loss = 0.1615, Accuracy = 0.9000 Test Loss = 0.2082, Test Accuracy = 0.8407\n",
      "Iteration 758: Loss = 0.2345, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8494\n",
      "Iteration 759: Loss = 0.2185, Accuracy = 0.8000 Test Loss = 0.2112, Test Accuracy = 0.8395\n",
      "Iteration 760: Loss = 0.1955, Accuracy = 0.9000 Test Loss = 0.2081, Test Accuracy = 0.8486\n",
      "Iteration 761: Loss = 0.2367, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8471\n",
      "Iteration 762: Loss = 0.1752, Accuracy = 0.8000 Test Loss = 0.2138, Test Accuracy = 0.8386\n",
      "Iteration 763: Loss = 0.2036, Accuracy = 0.9000 Test Loss = 0.2112, Test Accuracy = 0.8403\n",
      "Iteration 764: Loss = 0.1643, Accuracy = 0.9000 Test Loss = 0.2182, Test Accuracy = 0.8203\n",
      "Iteration 765: Loss = 0.2321, Accuracy = 0.7000 Test Loss = 0.2111, Test Accuracy = 0.8398\n",
      "Iteration 766: Loss = 0.1948, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8413\n",
      "Iteration 767: Loss = 0.1781, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8471\n",
      "Iteration 768: Loss = 0.1372, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8373\n",
      "Iteration 769: Loss = 0.2763, Accuracy = 0.8000 Test Loss = 0.2193, Test Accuracy = 0.8292\n",
      "Iteration 770: Loss = 0.1338, Accuracy = 1.0000 Test Loss = 0.2115, Test Accuracy = 0.8378\n",
      "Iteration 771: Loss = 0.1635, Accuracy = 1.0000 Test Loss = 0.2060, Test Accuracy = 0.8531\n",
      "Iteration 772: Loss = 0.1730, Accuracy = 0.9000 Test Loss = 0.2058, Test Accuracy = 0.8497\n",
      "Iteration 773: Loss = 0.1523, Accuracy = 1.0000 Test Loss = 0.2053, Test Accuracy = 0.8497\n",
      "Iteration 774: Loss = 0.1559, Accuracy = 1.0000 Test Loss = 0.2090, Test Accuracy = 0.8444\n",
      "Iteration 775: Loss = 0.2140, Accuracy = 0.9000 Test Loss = 0.2078, Test Accuracy = 0.8448\n",
      "Iteration 776: Loss = 0.1934, Accuracy = 0.9000 Test Loss = 0.2077, Test Accuracy = 0.8403\n",
      "Iteration 777: Loss = 0.2791, Accuracy = 0.7000 Test Loss = 0.2139, Test Accuracy = 0.8415\n",
      "Iteration 778: Loss = 0.1599, Accuracy = 0.9000 Test Loss = 0.2109, Test Accuracy = 0.8428\n",
      "Iteration 779: Loss = 0.1819, Accuracy = 0.9000 Test Loss = 0.2116, Test Accuracy = 0.8470\n",
      "Iteration 780: Loss = 0.2254, Accuracy = 0.9000 Test Loss = 0.2037, Test Accuracy = 0.8395\n",
      "Iteration 781: Loss = 0.1967, Accuracy = 0.9000 Test Loss = 0.2105, Test Accuracy = 0.8519\n",
      "Iteration 782: Loss = 0.1522, Accuracy = 0.9000 Test Loss = 0.2067, Test Accuracy = 0.8419\n",
      "Iteration 783: Loss = 0.1397, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8404\n",
      "Iteration 784: Loss = 0.2037, Accuracy = 0.7000 Test Loss = 0.2135, Test Accuracy = 0.8375\n",
      "Iteration 785: Loss = 0.1734, Accuracy = 1.0000 Test Loss = 0.2114, Test Accuracy = 0.8438\n",
      "Iteration 786: Loss = 0.2979, Accuracy = 0.8000 Test Loss = 0.2143, Test Accuracy = 0.8382\n",
      "Iteration 787: Loss = 0.2561, Accuracy = 0.7000 Test Loss = 0.2070, Test Accuracy = 0.8499\n",
      "Iteration 788: Loss = 0.2021, Accuracy = 0.7000 Test Loss = 0.2059, Test Accuracy = 0.8429\n",
      "Iteration 789: Loss = 0.1513, Accuracy = 0.9000 Test Loss = 0.2106, Test Accuracy = 0.8325\n",
      "Iteration 790: Loss = 0.1736, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8516\n",
      "Iteration 791: Loss = 0.1480, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8365\n",
      "Iteration 792: Loss = 0.2329, Accuracy = 0.8000 Test Loss = 0.2087, Test Accuracy = 0.8395\n",
      "Iteration 793: Loss = 0.2565, Accuracy = 0.8000 Test Loss = 0.2081, Test Accuracy = 0.8450\n",
      "Iteration 794: Loss = 0.2331, Accuracy = 0.8000 Test Loss = 0.2115, Test Accuracy = 0.8434\n",
      "Iteration 795: Loss = 0.1890, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8460\n",
      "Iteration 796: Loss = 0.1755, Accuracy = 1.0000 Test Loss = 0.2050, Test Accuracy = 0.8464\n",
      "Iteration 797: Loss = 0.1729, Accuracy = 1.0000 Test Loss = 0.2087, Test Accuracy = 0.8487\n",
      "Iteration 798: Loss = 0.1655, Accuracy = 0.9000 Test Loss = 0.2120, Test Accuracy = 0.8404\n",
      "Iteration 799: Loss = 0.1605, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8451\n",
      "Iteration 800: Loss = 0.2278, Accuracy = 0.9000 Test Loss = 0.2118, Test Accuracy = 0.8330\n",
      "Iteration 801: Loss = 0.2086, Accuracy = 0.8000 Test Loss = 0.2138, Test Accuracy = 0.8337\n",
      "Iteration 802: Loss = 0.2586, Accuracy = 0.7000 Test Loss = 0.2131, Test Accuracy = 0.8349\n",
      "Iteration 803: Loss = 0.2437, Accuracy = 0.8000 Test Loss = 0.2045, Test Accuracy = 0.8409\n",
      "Iteration 804: Loss = 0.2005, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8534\n",
      "Iteration 805: Loss = 0.1415, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8551\n",
      "Iteration 806: Loss = 0.1961, Accuracy = 1.0000 Test Loss = 0.2058, Test Accuracy = 0.8523\n",
      "Iteration 807: Loss = 0.2813, Accuracy = 0.7000 Test Loss = 0.2077, Test Accuracy = 0.8413\n",
      "Iteration 808: Loss = 0.2051, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8472\n",
      "Iteration 809: Loss = 0.1991, Accuracy = 0.9000 Test Loss = 0.2093, Test Accuracy = 0.8368\n",
      "Iteration 810: Loss = 0.1955, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8470\n",
      "Iteration 811: Loss = 0.1399, Accuracy = 1.0000 Test Loss = 0.2048, Test Accuracy = 0.8452\n",
      "Iteration 812: Loss = 0.1881, Accuracy = 0.9000 Test Loss = 0.2075, Test Accuracy = 0.8536\n",
      "Iteration 813: Loss = 0.1694, Accuracy = 0.9000 Test Loss = 0.2073, Test Accuracy = 0.8444\n",
      "Iteration 814: Loss = 0.1270, Accuracy = 1.0000 Test Loss = 0.2114, Test Accuracy = 0.8511\n",
      "Iteration 815: Loss = 0.3238, Accuracy = 0.7000 Test Loss = 0.2103, Test Accuracy = 0.8428\n",
      "Iteration 816: Loss = 0.2396, Accuracy = 0.8000 Test Loss = 0.2061, Test Accuracy = 0.8455\n",
      "Iteration 817: Loss = 0.2270, Accuracy = 0.7000 Test Loss = 0.2083, Test Accuracy = 0.8488\n",
      "Iteration 818: Loss = 0.2334, Accuracy = 0.8000 Test Loss = 0.2111, Test Accuracy = 0.8498\n",
      "Iteration 819: Loss = 0.2630, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8520\n",
      "Iteration 820: Loss = 0.1716, Accuracy = 1.0000 Test Loss = 0.2087, Test Accuracy = 0.8395\n",
      "Iteration 821: Loss = 0.2823, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8457\n",
      "Iteration 822: Loss = 0.2500, Accuracy = 0.7000 Test Loss = 0.2100, Test Accuracy = 0.8414\n",
      "Iteration 823: Loss = 0.1507, Accuracy = 1.0000 Test Loss = 0.2066, Test Accuracy = 0.8479\n",
      "Iteration 824: Loss = 0.3334, Accuracy = 0.6000 Test Loss = 0.2106, Test Accuracy = 0.8415\n",
      "Iteration 825: Loss = 0.2470, Accuracy = 0.8000 Test Loss = 0.2112, Test Accuracy = 0.8431\n",
      "Iteration 826: Loss = 0.1821, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8483\n",
      "Iteration 827: Loss = 0.2292, Accuracy = 1.0000 Test Loss = 0.2085, Test Accuracy = 0.8472\n",
      "Iteration 828: Loss = 0.1651, Accuracy = 0.9000 Test Loss = 0.2071, Test Accuracy = 0.8439\n",
      "Iteration 829: Loss = 0.2038, Accuracy = 0.8000 Test Loss = 0.2092, Test Accuracy = 0.8441\n",
      "Iteration 830: Loss = 0.1699, Accuracy = 0.8000 Test Loss = 0.2099, Test Accuracy = 0.8526\n",
      "Iteration 831: Loss = 0.2390, Accuracy = 0.8000 Test Loss = 0.2106, Test Accuracy = 0.8243\n",
      "Iteration 832: Loss = 0.2484, Accuracy = 0.6000 Test Loss = 0.2072, Test Accuracy = 0.8468\n",
      "Iteration 833: Loss = 0.2969, Accuracy = 0.7000 Test Loss = 0.2092, Test Accuracy = 0.8439\n",
      "Iteration 834: Loss = 0.3130, Accuracy = 0.7000 Test Loss = 0.2091, Test Accuracy = 0.8361\n",
      "Iteration 835: Loss = 0.1242, Accuracy = 1.0000 Test Loss = 0.2104, Test Accuracy = 0.8471\n",
      "Iteration 836: Loss = 0.2691, Accuracy = 0.7000 Test Loss = 0.2070, Test Accuracy = 0.8404\n",
      "Iteration 837: Loss = 0.2362, Accuracy = 0.8000 Test Loss = 0.2135, Test Accuracy = 0.8473\n",
      "Iteration 838: Loss = 0.1311, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8519\n",
      "Iteration 839: Loss = 0.2074, Accuracy = 1.0000 Test Loss = 0.2118, Test Accuracy = 0.8535\n",
      "Iteration 840: Loss = 0.2588, Accuracy = 0.7000 Test Loss = 0.2113, Test Accuracy = 0.8391\n",
      "Iteration 841: Loss = 0.2680, Accuracy = 0.8000 Test Loss = 0.2067, Test Accuracy = 0.8415\n",
      "Iteration 842: Loss = 0.1251, Accuracy = 1.0000 Test Loss = 0.2069, Test Accuracy = 0.8436\n",
      "Iteration 843: Loss = 0.1489, Accuracy = 0.9000 Test Loss = 0.2054, Test Accuracy = 0.8504\n",
      "Iteration 844: Loss = 0.1578, Accuracy = 1.0000 Test Loss = 0.2064, Test Accuracy = 0.8473\n",
      "Iteration 845: Loss = 0.1716, Accuracy = 0.9000 Test Loss = 0.2113, Test Accuracy = 0.8497\n",
      "Iteration 846: Loss = 0.2170, Accuracy = 0.8000 Test Loss = 0.2082, Test Accuracy = 0.8438\n",
      "Iteration 847: Loss = 0.2304, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8381\n",
      "Iteration 848: Loss = 0.1688, Accuracy = 0.9000 Test Loss = 0.2044, Test Accuracy = 0.8446\n",
      "Iteration 849: Loss = 0.2832, Accuracy = 0.7000 Test Loss = 0.2102, Test Accuracy = 0.8499\n",
      "Iteration 850: Loss = 0.1620, Accuracy = 0.9000 Test Loss = 0.2069, Test Accuracy = 0.8402\n",
      "Iteration 851: Loss = 0.2671, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8466\n",
      "Iteration 852: Loss = 0.1858, Accuracy = 0.9000 Test Loss = 0.2058, Test Accuracy = 0.8468\n",
      "Iteration 853: Loss = 0.2193, Accuracy = 0.9000 Test Loss = 0.2107, Test Accuracy = 0.8383\n",
      "Iteration 854: Loss = 0.2402, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8423\n",
      "Iteration 855: Loss = 0.1952, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8474\n",
      "Iteration 856: Loss = 0.1997, Accuracy = 0.7000 Test Loss = 0.2089, Test Accuracy = 0.8478\n",
      "Iteration 857: Loss = 0.2302, Accuracy = 0.7000 Test Loss = 0.2055, Test Accuracy = 0.8523\n",
      "Iteration 858: Loss = 0.1595, Accuracy = 1.0000 Test Loss = 0.2065, Test Accuracy = 0.8518\n",
      "Iteration 859: Loss = 0.1841, Accuracy = 0.8000 Test Loss = 0.2053, Test Accuracy = 0.8496\n",
      "Iteration 860: Loss = 0.1467, Accuracy = 0.9000 Test Loss = 0.2059, Test Accuracy = 0.8431\n",
      "Iteration 861: Loss = 0.2149, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8387\n",
      "Iteration 862: Loss = 0.1988, Accuracy = 1.0000 Test Loss = 0.2068, Test Accuracy = 0.8438\n",
      "Iteration 863: Loss = 0.1957, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8532\n",
      "Iteration 864: Loss = 0.1949, Accuracy = 0.7000 Test Loss = 0.2080, Test Accuracy = 0.8493\n",
      "Iteration 865: Loss = 0.1787, Accuracy = 1.0000 Test Loss = 0.2046, Test Accuracy = 0.8431\n",
      "Iteration 866: Loss = 0.2540, Accuracy = 0.7000 Test Loss = 0.2084, Test Accuracy = 0.8402\n",
      "Iteration 867: Loss = 0.2030, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8468\n",
      "Iteration 868: Loss = 0.1395, Accuracy = 0.9000 Test Loss = 0.2051, Test Accuracy = 0.8505\n",
      "Iteration 869: Loss = 0.1788, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8426\n",
      "Iteration 870: Loss = 0.1356, Accuracy = 1.0000 Test Loss = 0.2085, Test Accuracy = 0.8325\n",
      "Iteration 871: Loss = 0.1999, Accuracy = 0.8000 Test Loss = 0.2060, Test Accuracy = 0.8462\n",
      "Iteration 872: Loss = 0.2444, Accuracy = 0.6000 Test Loss = 0.2140, Test Accuracy = 0.8319\n",
      "Iteration 873: Loss = 0.3288, Accuracy = 0.6000 Test Loss = 0.2093, Test Accuracy = 0.8501\n",
      "Iteration 874: Loss = 0.1983, Accuracy = 0.9000 Test Loss = 0.2094, Test Accuracy = 0.8327\n",
      "Iteration 875: Loss = 0.2417, Accuracy = 0.8000 Test Loss = 0.2053, Test Accuracy = 0.8519\n",
      "Iteration 876: Loss = 0.1308, Accuracy = 0.9000 Test Loss = 0.2074, Test Accuracy = 0.8475\n",
      "Iteration 877: Loss = 0.2023, Accuracy = 0.7000 Test Loss = 0.2133, Test Accuracy = 0.8404\n",
      "Iteration 878: Loss = 0.2193, Accuracy = 0.8000 Test Loss = 0.2046, Test Accuracy = 0.8512\n",
      "Iteration 879: Loss = 0.2212, Accuracy = 0.7000 Test Loss = 0.2078, Test Accuracy = 0.8469\n",
      "Iteration 880: Loss = 0.2045, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8462\n",
      "Iteration 881: Loss = 0.2259, Accuracy = 0.8000 Test Loss = 0.2122, Test Accuracy = 0.8310\n",
      "Iteration 882: Loss = 0.1734, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8421\n",
      "Iteration 883: Loss = 0.2104, Accuracy = 0.9000 Test Loss = 0.2148, Test Accuracy = 0.8400\n",
      "Iteration 884: Loss = 0.1190, Accuracy = 0.9000 Test Loss = 0.2123, Test Accuracy = 0.8464\n",
      "Iteration 885: Loss = 0.1344, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8495\n",
      "Iteration 886: Loss = 0.1653, Accuracy = 0.9000 Test Loss = 0.2089, Test Accuracy = 0.8365\n",
      "Iteration 887: Loss = 0.1977, Accuracy = 0.9000 Test Loss = 0.2068, Test Accuracy = 0.8372\n",
      "Iteration 888: Loss = 0.2370, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8341\n",
      "Iteration 889: Loss = 0.2791, Accuracy = 0.8000 Test Loss = 0.2073, Test Accuracy = 0.8392\n",
      "Iteration 890: Loss = 0.2749, Accuracy = 0.9000 Test Loss = 0.2098, Test Accuracy = 0.8436\n",
      "Iteration 891: Loss = 0.1437, Accuracy = 1.0000 Test Loss = 0.2087, Test Accuracy = 0.8492\n",
      "Iteration 892: Loss = 0.1915, Accuracy = 0.8000 Test Loss = 0.2062, Test Accuracy = 0.8555\n",
      "Iteration 893: Loss = 0.2882, Accuracy = 0.7000 Test Loss = 0.2140, Test Accuracy = 0.8421\n",
      "Iteration 894: Loss = 0.2038, Accuracy = 0.7000 Test Loss = 0.2067, Test Accuracy = 0.8432\n",
      "Iteration 895: Loss = 0.1826, Accuracy = 1.0000 Test Loss = 0.2075, Test Accuracy = 0.8467\n",
      "Iteration 896: Loss = 0.1547, Accuracy = 0.9000 Test Loss = 0.2077, Test Accuracy = 0.8394\n",
      "Iteration 897: Loss = 0.2015, Accuracy = 0.9000 Test Loss = 0.2058, Test Accuracy = 0.8382\n",
      "Iteration 898: Loss = 0.2600, Accuracy = 0.9000 Test Loss = 0.2071, Test Accuracy = 0.8517\n",
      "Iteration 899: Loss = 0.2540, Accuracy = 0.7000 Test Loss = 0.2068, Test Accuracy = 0.8418\n",
      "Iteration 900: Loss = 0.1832, Accuracy = 0.9000 Test Loss = 0.2062, Test Accuracy = 0.8438\n",
      "Iteration 901: Loss = 0.1880, Accuracy = 0.9000 Test Loss = 0.2040, Test Accuracy = 0.8567\n",
      "Iteration 902: Loss = 0.1917, Accuracy = 0.9000 Test Loss = 0.2081, Test Accuracy = 0.8542\n",
      "Iteration 903: Loss = 0.1351, Accuracy = 1.0000 Test Loss = 0.2092, Test Accuracy = 0.8393\n",
      "Iteration 904: Loss = 0.3199, Accuracy = 0.6000 Test Loss = 0.2128, Test Accuracy = 0.8528\n",
      "Iteration 905: Loss = 0.2817, Accuracy = 0.8000 Test Loss = 0.2087, Test Accuracy = 0.8406\n",
      "Iteration 906: Loss = 0.2469, Accuracy = 0.8000 Test Loss = 0.2065, Test Accuracy = 0.8444\n",
      "Iteration 907: Loss = 0.1774, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8502\n",
      "Iteration 908: Loss = 0.1966, Accuracy = 0.9000 Test Loss = 0.2118, Test Accuracy = 0.8343\n",
      "Iteration 909: Loss = 0.1670, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8394\n",
      "Iteration 910: Loss = 0.2036, Accuracy = 0.8000 Test Loss = 0.2104, Test Accuracy = 0.8439\n",
      "Iteration 911: Loss = 0.2179, Accuracy = 0.9000 Test Loss = 0.2071, Test Accuracy = 0.8393\n",
      "Iteration 912: Loss = 0.2404, Accuracy = 0.7000 Test Loss = 0.2062, Test Accuracy = 0.8427\n",
      "Iteration 913: Loss = 0.1370, Accuracy = 1.0000 Test Loss = 0.2100, Test Accuracy = 0.8457\n",
      "Iteration 914: Loss = 0.1766, Accuracy = 0.9000 Test Loss = 0.2123, Test Accuracy = 0.8353\n",
      "Iteration 915: Loss = 0.2131, Accuracy = 0.8000 Test Loss = 0.2088, Test Accuracy = 0.8430\n",
      "Iteration 916: Loss = 0.2083, Accuracy = 0.9000 Test Loss = 0.2117, Test Accuracy = 0.8486\n",
      "Iteration 917: Loss = 0.2313, Accuracy = 0.8000 Test Loss = 0.2087, Test Accuracy = 0.8403\n",
      "Iteration 918: Loss = 0.1910, Accuracy = 0.9000 Test Loss = 0.2153, Test Accuracy = 0.8268\n",
      "Iteration 919: Loss = 0.2655, Accuracy = 0.8000 Test Loss = 0.2131, Test Accuracy = 0.8489\n",
      "Iteration 920: Loss = 0.1215, Accuracy = 1.0000 Test Loss = 0.2082, Test Accuracy = 0.8310\n",
      "Iteration 921: Loss = 0.1109, Accuracy = 1.0000 Test Loss = 0.2080, Test Accuracy = 0.8399\n",
      "Iteration 922: Loss = 0.1733, Accuracy = 1.0000 Test Loss = 0.2060, Test Accuracy = 0.8468\n",
      "Iteration 923: Loss = 0.1916, Accuracy = 0.9000 Test Loss = 0.2104, Test Accuracy = 0.8429\n",
      "Iteration 924: Loss = 0.1890, Accuracy = 0.9000 Test Loss = 0.2040, Test Accuracy = 0.8440\n",
      "Iteration 925: Loss = 0.2006, Accuracy = 0.8000 Test Loss = 0.2105, Test Accuracy = 0.8394\n",
      "Iteration 926: Loss = 0.1944, Accuracy = 0.7000 Test Loss = 0.2089, Test Accuracy = 0.8370\n",
      "Iteration 927: Loss = 0.2718, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8434\n",
      "Iteration 928: Loss = 0.1870, Accuracy = 0.9000 Test Loss = 0.2037, Test Accuracy = 0.8528\n",
      "Iteration 929: Loss = 0.1161, Accuracy = 1.0000 Test Loss = 0.2094, Test Accuracy = 0.8455\n",
      "Iteration 930: Loss = 0.2552, Accuracy = 0.8000 Test Loss = 0.2127, Test Accuracy = 0.8421\n",
      "Iteration 931: Loss = 0.2696, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8531\n",
      "Iteration 932: Loss = 0.1480, Accuracy = 1.0000 Test Loss = 0.2223, Test Accuracy = 0.8300\n",
      "Iteration 933: Loss = 0.2724, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8468\n",
      "Iteration 934: Loss = 0.1902, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8434\n",
      "Iteration 935: Loss = 0.2022, Accuracy = 0.9000 Test Loss = 0.2112, Test Accuracy = 0.8336\n",
      "Iteration 936: Loss = 0.2078, Accuracy = 0.8000 Test Loss = 0.2080, Test Accuracy = 0.8434\n",
      "Iteration 937: Loss = 0.1985, Accuracy = 1.0000 Test Loss = 0.2055, Test Accuracy = 0.8505\n",
      "Iteration 938: Loss = 0.1421, Accuracy = 0.9000 Test Loss = 0.2057, Test Accuracy = 0.8435\n",
      "Iteration 939: Loss = 0.3017, Accuracy = 0.7000 Test Loss = 0.2052, Test Accuracy = 0.8497\n",
      "Iteration 940: Loss = 0.2320, Accuracy = 0.8000 Test Loss = 0.2144, Test Accuracy = 0.8385\n",
      "Iteration 941: Loss = 0.1643, Accuracy = 0.8000 Test Loss = 0.2083, Test Accuracy = 0.8424\n",
      "Iteration 942: Loss = 0.2612, Accuracy = 0.6000 Test Loss = 0.2070, Test Accuracy = 0.8501\n",
      "Iteration 943: Loss = 0.2274, Accuracy = 0.9000 Test Loss = 0.2092, Test Accuracy = 0.8408\n",
      "Iteration 944: Loss = 0.3111, Accuracy = 0.5000 Test Loss = 0.2251, Test Accuracy = 0.8368\n",
      "Iteration 945: Loss = 0.1257, Accuracy = 0.9000 Test Loss = 0.2057, Test Accuracy = 0.8455\n",
      "Iteration 946: Loss = 0.1634, Accuracy = 1.0000 Test Loss = 0.2154, Test Accuracy = 0.8331\n",
      "Iteration 947: Loss = 0.3390, Accuracy = 0.7000 Test Loss = 0.2088, Test Accuracy = 0.8449\n",
      "Iteration 948: Loss = 0.1739, Accuracy = 1.0000 Test Loss = 0.2117, Test Accuracy = 0.8328\n",
      "Iteration 949: Loss = 0.1931, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8474\n",
      "Iteration 950: Loss = 0.1198, Accuracy = 1.0000 Test Loss = 0.2055, Test Accuracy = 0.8434\n",
      "Iteration 951: Loss = 0.2837, Accuracy = 0.7000 Test Loss = 0.2196, Test Accuracy = 0.8354\n",
      "Iteration 952: Loss = 0.2130, Accuracy = 0.9000 Test Loss = 0.2182, Test Accuracy = 0.8363\n",
      "Iteration 953: Loss = 0.2013, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8476\n",
      "Iteration 954: Loss = 0.2166, Accuracy = 0.8000 Test Loss = 0.2082, Test Accuracy = 0.8403\n",
      "Iteration 955: Loss = 0.1472, Accuracy = 1.0000 Test Loss = 0.2097, Test Accuracy = 0.8380\n",
      "Iteration 956: Loss = 0.1568, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8446\n",
      "Iteration 957: Loss = 0.1984, Accuracy = 0.9000 Test Loss = 0.2047, Test Accuracy = 0.8477\n",
      "Iteration 958: Loss = 0.2041, Accuracy = 0.8000 Test Loss = 0.2088, Test Accuracy = 0.8458\n",
      "Iteration 959: Loss = 0.1713, Accuracy = 0.9000 Test Loss = 0.2106, Test Accuracy = 0.8436\n",
      "Iteration 960: Loss = 0.2090, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8509\n",
      "Iteration 961: Loss = 0.1426, Accuracy = 1.0000 Test Loss = 0.2082, Test Accuracy = 0.8384\n",
      "Iteration 962: Loss = 0.1812, Accuracy = 0.9000 Test Loss = 0.2081, Test Accuracy = 0.8513\n",
      "Iteration 963: Loss = 0.2034, Accuracy = 0.8000 Test Loss = 0.2039, Test Accuracy = 0.8534\n",
      "Iteration 964: Loss = 0.2768, Accuracy = 0.8000 Test Loss = 0.2055, Test Accuracy = 0.8407\n",
      "Iteration 965: Loss = 0.1674, Accuracy = 1.0000 Test Loss = 0.2044, Test Accuracy = 0.8504\n",
      "Iteration 966: Loss = 0.2268, Accuracy = 0.9000 Test Loss = 0.2058, Test Accuracy = 0.8488\n",
      "Iteration 967: Loss = 0.2271, Accuracy = 0.8000 Test Loss = 0.2097, Test Accuracy = 0.8469\n",
      "Iteration 968: Loss = 0.1371, Accuracy = 0.9000 Test Loss = 0.2066, Test Accuracy = 0.8408\n",
      "Iteration 969: Loss = 0.2543, Accuracy = 0.8000 Test Loss = 0.2077, Test Accuracy = 0.8425\n",
      "Iteration 970: Loss = 0.1807, Accuracy = 1.0000 Test Loss = 0.2123, Test Accuracy = 0.8368\n",
      "Iteration 971: Loss = 0.1509, Accuracy = 0.9000 Test Loss = 0.2059, Test Accuracy = 0.8395\n",
      "Iteration 972: Loss = 0.1986, Accuracy = 0.8000 Test Loss = 0.2094, Test Accuracy = 0.8497\n",
      "Iteration 973: Loss = 0.2188, Accuracy = 0.7000 Test Loss = 0.2108, Test Accuracy = 0.8460\n",
      "Iteration 974: Loss = 0.2882, Accuracy = 0.7000 Test Loss = 0.2088, Test Accuracy = 0.8522\n",
      "Iteration 975: Loss = 0.1648, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8457\n",
      "Iteration 976: Loss = 0.2041, Accuracy = 0.7000 Test Loss = 0.2115, Test Accuracy = 0.8298\n",
      "Iteration 977: Loss = 0.3026, Accuracy = 0.6000 Test Loss = 0.2110, Test Accuracy = 0.8460\n",
      "Iteration 978: Loss = 0.2568, Accuracy = 0.7000 Test Loss = 0.2108, Test Accuracy = 0.8413\n",
      "Iteration 979: Loss = 0.1869, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8477\n",
      "Iteration 980: Loss = 0.2053, Accuracy = 0.8000 Test Loss = 0.2061, Test Accuracy = 0.8414\n",
      "Iteration 981: Loss = 0.2497, Accuracy = 0.7000 Test Loss = 0.2049, Test Accuracy = 0.8474\n",
      "Iteration 982: Loss = 0.1405, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8474\n",
      "Iteration 983: Loss = 0.2227, Accuracy = 0.8000 Test Loss = 0.2088, Test Accuracy = 0.8421\n",
      "Iteration 984: Loss = 0.1541, Accuracy = 0.9000 Test Loss = 0.2101, Test Accuracy = 0.8406\n",
      "Iteration 985: Loss = 0.1331, Accuracy = 1.0000 Test Loss = 0.2086, Test Accuracy = 0.8325\n",
      "Iteration 986: Loss = 0.1981, Accuracy = 1.0000 Test Loss = 0.2051, Test Accuracy = 0.8472\n",
      "Iteration 987: Loss = 0.1989, Accuracy = 1.0000 Test Loss = 0.2126, Test Accuracy = 0.8373\n",
      "Iteration 988: Loss = 0.2761, Accuracy = 0.7000 Test Loss = 0.2077, Test Accuracy = 0.8471\n",
      "Iteration 989: Loss = 0.1354, Accuracy = 0.8000 Test Loss = 0.2101, Test Accuracy = 0.8426\n",
      "Iteration 990: Loss = 0.2711, Accuracy = 0.7000 Test Loss = 0.2069, Test Accuracy = 0.8468\n",
      "Iteration 991: Loss = 0.1787, Accuracy = 0.9000 Test Loss = 0.2100, Test Accuracy = 0.8383\n",
      "Iteration 992: Loss = 0.2189, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8464\n",
      "Iteration 993: Loss = 0.1906, Accuracy = 0.8000 Test Loss = 0.2061, Test Accuracy = 0.8349\n",
      "Iteration 994: Loss = 0.2262, Accuracy = 0.8000 Test Loss = 0.2060, Test Accuracy = 0.8470\n",
      "Iteration 995: Loss = 0.2022, Accuracy = 0.9000 Test Loss = 0.2095, Test Accuracy = 0.8396\n",
      "Iteration 996: Loss = 0.1589, Accuracy = 1.0000 Test Loss = 0.2061, Test Accuracy = 0.8402\n",
      "Iteration 997: Loss = 0.1606, Accuracy = 0.9000 Test Loss = 0.2119, Test Accuracy = 0.8522\n",
      "Iteration 998: Loss = 0.2000, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8375\n",
      "Iteration 999: Loss = 0.1937, Accuracy = 0.9000 Test Loss = 0.2054, Test Accuracy = 0.8450\n",
      "Iteration 1000: Loss = 0.2057, Accuracy = 0.8000 Test Loss = 0.2055, Test Accuracy = 0.8467\n",
      "Iteration 1001: Loss = 0.2990, Accuracy = 0.8000 Test Loss = 0.2081, Test Accuracy = 0.8499\n",
      "Iteration 1002: Loss = 0.2501, Accuracy = 0.7000 Test Loss = 0.2065, Test Accuracy = 0.8475\n",
      "Iteration 1003: Loss = 0.1642, Accuracy = 0.9000 Test Loss = 0.2082, Test Accuracy = 0.8353\n",
      "Iteration 1004: Loss = 0.1661, Accuracy = 1.0000 Test Loss = 0.2089, Test Accuracy = 0.8403\n",
      "Iteration 1005: Loss = 0.1865, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8456\n",
      "Iteration 1006: Loss = 0.1469, Accuracy = 1.0000 Test Loss = 0.2047, Test Accuracy = 0.8407\n",
      "Iteration 1007: Loss = 0.1866, Accuracy = 0.9000 Test Loss = 0.2069, Test Accuracy = 0.8471\n",
      "Iteration 1008: Loss = 0.2196, Accuracy = 0.9000 Test Loss = 0.2113, Test Accuracy = 0.8413\n",
      "Iteration 1009: Loss = 0.3050, Accuracy = 0.6000 Test Loss = 0.2118, Test Accuracy = 0.8338\n",
      "Iteration 1010: Loss = 0.2843, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8521\n",
      "Iteration 1011: Loss = 0.2324, Accuracy = 0.7000 Test Loss = 0.2070, Test Accuracy = 0.8401\n",
      "Iteration 1012: Loss = 0.2731, Accuracy = 0.7000 Test Loss = 0.2064, Test Accuracy = 0.8461\n",
      "Iteration 1013: Loss = 0.2865, Accuracy = 0.7000 Test Loss = 0.2062, Test Accuracy = 0.8497\n",
      "Iteration 1014: Loss = 0.0785, Accuracy = 1.0000 Test Loss = 0.2089, Test Accuracy = 0.8418\n",
      "Iteration 1015: Loss = 0.2051, Accuracy = 0.8000 Test Loss = 0.2072, Test Accuracy = 0.8462\n",
      "Iteration 1016: Loss = 0.1928, Accuracy = 1.0000 Test Loss = 0.2056, Test Accuracy = 0.8488\n",
      "Iteration 1017: Loss = 0.2002, Accuracy = 0.9000 Test Loss = 0.2119, Test Accuracy = 0.8521\n",
      "Iteration 1018: Loss = 0.2637, Accuracy = 0.6000 Test Loss = 0.2146, Test Accuracy = 0.8369\n",
      "Iteration 1019: Loss = 0.1964, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8374\n",
      "Iteration 1020: Loss = 0.2736, Accuracy = 0.7000 Test Loss = 0.2157, Test Accuracy = 0.8466\n",
      "Iteration 1021: Loss = 0.2666, Accuracy = 0.6000 Test Loss = 0.2098, Test Accuracy = 0.8409\n",
      "Iteration 1022: Loss = 0.1984, Accuracy = 0.8000 Test Loss = 0.2040, Test Accuracy = 0.8474\n",
      "Iteration 1023: Loss = 0.1177, Accuracy = 1.0000 Test Loss = 0.2075, Test Accuracy = 0.8370\n",
      "Iteration 1024: Loss = 0.2411, Accuracy = 0.7000 Test Loss = 0.2070, Test Accuracy = 0.8388\n",
      "Iteration 1025: Loss = 0.2105, Accuracy = 0.8000 Test Loss = 0.2090, Test Accuracy = 0.8384\n",
      "Iteration 1026: Loss = 0.1597, Accuracy = 0.9000 Test Loss = 0.2068, Test Accuracy = 0.8456\n",
      "Iteration 1027: Loss = 0.2060, Accuracy = 0.8000 Test Loss = 0.2072, Test Accuracy = 0.8507\n",
      "Iteration 1028: Loss = 0.3216, Accuracy = 0.6000 Test Loss = 0.2089, Test Accuracy = 0.8476\n",
      "Iteration 1029: Loss = 0.1623, Accuracy = 0.9000 Test Loss = 0.2108, Test Accuracy = 0.8539\n",
      "Iteration 1030: Loss = 0.2885, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8432\n",
      "Iteration 1031: Loss = 0.2011, Accuracy = 0.9000 Test Loss = 0.2080, Test Accuracy = 0.8454\n",
      "Iteration 1032: Loss = 0.2181, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8398\n",
      "Iteration 1033: Loss = 0.1493, Accuracy = 0.9000 Test Loss = 0.2109, Test Accuracy = 0.8461\n",
      "Iteration 1034: Loss = 0.1742, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8434\n",
      "Iteration 1035: Loss = 0.1863, Accuracy = 0.9000 Test Loss = 0.2074, Test Accuracy = 0.8410\n",
      "Iteration 1036: Loss = 0.2129, Accuracy = 0.8000 Test Loss = 0.2080, Test Accuracy = 0.8449\n",
      "Iteration 1037: Loss = 0.1779, Accuracy = 1.0000 Test Loss = 0.2053, Test Accuracy = 0.8441\n",
      "Iteration 1038: Loss = 0.1454, Accuracy = 1.0000 Test Loss = 0.2063, Test Accuracy = 0.8474\n",
      "Iteration 1039: Loss = 0.1617, Accuracy = 1.0000 Test Loss = 0.2117, Test Accuracy = 0.8337\n",
      "Iteration 1040: Loss = 0.1414, Accuracy = 1.0000 Test Loss = 0.2064, Test Accuracy = 0.8411\n",
      "Iteration 1041: Loss = 0.2096, Accuracy = 0.8000 Test Loss = 0.2080, Test Accuracy = 0.8397\n",
      "Iteration 1042: Loss = 0.3271, Accuracy = 0.7000 Test Loss = 0.2177, Test Accuracy = 0.8308\n",
      "Iteration 1043: Loss = 0.2387, Accuracy = 0.7000 Test Loss = 0.2074, Test Accuracy = 0.8484\n",
      "Iteration 1044: Loss = 0.2049, Accuracy = 0.9000 Test Loss = 0.2084, Test Accuracy = 0.8445\n",
      "Iteration 1045: Loss = 0.2116, Accuracy = 0.7000 Test Loss = 0.2127, Test Accuracy = 0.8446\n",
      "Iteration 1046: Loss = 0.2557, Accuracy = 0.7000 Test Loss = 0.2130, Test Accuracy = 0.8357\n",
      "Iteration 1047: Loss = 0.1571, Accuracy = 0.9000 Test Loss = 0.2064, Test Accuracy = 0.8486\n",
      "Iteration 1048: Loss = 0.1121, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8297\n",
      "Iteration 1049: Loss = 0.1717, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8487\n",
      "Iteration 1050: Loss = 0.2282, Accuracy = 0.8000 Test Loss = 0.2058, Test Accuracy = 0.8510\n",
      "Iteration 1051: Loss = 0.1513, Accuracy = 0.9000 Test Loss = 0.2048, Test Accuracy = 0.8541\n",
      "Iteration 1052: Loss = 0.1722, Accuracy = 0.9000 Test Loss = 0.2081, Test Accuracy = 0.8507\n",
      "Iteration 1053: Loss = 0.2181, Accuracy = 0.8000 Test Loss = 0.2084, Test Accuracy = 0.8542\n",
      "Iteration 1054: Loss = 0.1519, Accuracy = 0.9000 Test Loss = 0.2080, Test Accuracy = 0.8375\n",
      "Iteration 1055: Loss = 0.2295, Accuracy = 0.8000 Test Loss = 0.2064, Test Accuracy = 0.8481\n",
      "Iteration 1056: Loss = 0.1780, Accuracy = 0.8000 Test Loss = 0.2118, Test Accuracy = 0.8379\n",
      "Iteration 1057: Loss = 0.1653, Accuracy = 1.0000 Test Loss = 0.2089, Test Accuracy = 0.8522\n",
      "Iteration 1058: Loss = 0.2232, Accuracy = 0.9000 Test Loss = 0.2072, Test Accuracy = 0.8511\n",
      "Iteration 1059: Loss = 0.1479, Accuracy = 1.0000 Test Loss = 0.2060, Test Accuracy = 0.8484\n",
      "Iteration 1060: Loss = 0.2224, Accuracy = 0.7000 Test Loss = 0.2121, Test Accuracy = 0.8395\n",
      "Iteration 1061: Loss = 0.1334, Accuracy = 0.9000 Test Loss = 0.2094, Test Accuracy = 0.8387\n",
      "Iteration 1062: Loss = 0.2146, Accuracy = 0.7000 Test Loss = 0.2075, Test Accuracy = 0.8456\n",
      "Iteration 1063: Loss = 0.1921, Accuracy = 0.8000 Test Loss = 0.2084, Test Accuracy = 0.8424\n",
      "Iteration 1064: Loss = 0.1913, Accuracy = 0.9000 Test Loss = 0.2059, Test Accuracy = 0.8489\n",
      "Iteration 1065: Loss = 0.2105, Accuracy = 0.9000 Test Loss = 0.2072, Test Accuracy = 0.8411\n",
      "Iteration 1066: Loss = 0.2023, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8505\n",
      "Iteration 1067: Loss = 0.2779, Accuracy = 0.6000 Test Loss = 0.2096, Test Accuracy = 0.8441\n",
      "Iteration 1068: Loss = 0.2329, Accuracy = 0.8000 Test Loss = 0.2091, Test Accuracy = 0.8562\n",
      "Iteration 1069: Loss = 0.1556, Accuracy = 1.0000 Test Loss = 0.2052, Test Accuracy = 0.8412\n",
      "Iteration 1070: Loss = 0.2939, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8479\n",
      "Iteration 1071: Loss = 0.1435, Accuracy = 0.9000 Test Loss = 0.2048, Test Accuracy = 0.8446\n",
      "Iteration 1072: Loss = 0.2769, Accuracy = 0.5000 Test Loss = 0.2090, Test Accuracy = 0.8480\n",
      "Iteration 1073: Loss = 0.1267, Accuracy = 1.0000 Test Loss = 0.2101, Test Accuracy = 0.8428\n",
      "Iteration 1074: Loss = 0.2668, Accuracy = 0.7000 Test Loss = 0.2145, Test Accuracy = 0.8371\n",
      "Iteration 1075: Loss = 0.2455, Accuracy = 0.8000 Test Loss = 0.2056, Test Accuracy = 0.8426\n",
      "Iteration 1076: Loss = 0.2215, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8403\n",
      "Iteration 1077: Loss = 0.2668, Accuracy = 0.8000 Test Loss = 0.2138, Test Accuracy = 0.8427\n",
      "Iteration 1078: Loss = 0.1380, Accuracy = 1.0000 Test Loss = 0.2101, Test Accuracy = 0.8466\n",
      "Iteration 1079: Loss = 0.1033, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8411\n",
      "Iteration 1080: Loss = 0.2895, Accuracy = 0.7000 Test Loss = 0.2064, Test Accuracy = 0.8470\n",
      "Iteration 1081: Loss = 0.2342, Accuracy = 0.9000 Test Loss = 0.2059, Test Accuracy = 0.8439\n",
      "Iteration 1082: Loss = 0.1895, Accuracy = 0.9000 Test Loss = 0.2064, Test Accuracy = 0.8438\n",
      "Iteration 1083: Loss = 0.1231, Accuracy = 1.0000 Test Loss = 0.2054, Test Accuracy = 0.8431\n",
      "Iteration 1084: Loss = 0.2630, Accuracy = 0.6000 Test Loss = 0.2107, Test Accuracy = 0.8443\n",
      "Iteration 1085: Loss = 0.2402, Accuracy = 0.8000 Test Loss = 0.2081, Test Accuracy = 0.8464\n",
      "Iteration 1086: Loss = 0.3074, Accuracy = 0.6000 Test Loss = 0.2087, Test Accuracy = 0.8370\n",
      "Iteration 1087: Loss = 0.2023, Accuracy = 0.8000 Test Loss = 0.2128, Test Accuracy = 0.8361\n",
      "Iteration 1088: Loss = 0.2405, Accuracy = 0.8000 Test Loss = 0.2042, Test Accuracy = 0.8420\n",
      "Iteration 1089: Loss = 0.2688, Accuracy = 0.7000 Test Loss = 0.2109, Test Accuracy = 0.8389\n",
      "Iteration 1090: Loss = 0.2650, Accuracy = 0.7000 Test Loss = 0.2081, Test Accuracy = 0.8430\n",
      "Iteration 1091: Loss = 0.1212, Accuracy = 1.0000 Test Loss = 0.2087, Test Accuracy = 0.8417\n",
      "Iteration 1092: Loss = 0.2454, Accuracy = 0.9000 Test Loss = 0.2149, Test Accuracy = 0.8358\n",
      "Iteration 1093: Loss = 0.1642, Accuracy = 1.0000 Test Loss = 0.2142, Test Accuracy = 0.8424\n",
      "Iteration 1094: Loss = 0.2066, Accuracy = 0.8000 Test Loss = 0.2062, Test Accuracy = 0.8514\n",
      "Iteration 1095: Loss = 0.1971, Accuracy = 0.8000 Test Loss = 0.2090, Test Accuracy = 0.8529\n",
      "Iteration 1096: Loss = 0.1964, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8407\n",
      "Iteration 1097: Loss = 0.1939, Accuracy = 0.8000 Test Loss = 0.2117, Test Accuracy = 0.8420\n",
      "Iteration 1098: Loss = 0.1909, Accuracy = 0.8000 Test Loss = 0.2044, Test Accuracy = 0.8498\n",
      "Iteration 1099: Loss = 0.1939, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8397\n",
      "Iteration 1100: Loss = 0.1518, Accuracy = 1.0000 Test Loss = 0.2112, Test Accuracy = 0.8342\n",
      "Iteration 1101: Loss = 0.1611, Accuracy = 1.0000 Test Loss = 0.2087, Test Accuracy = 0.8439\n",
      "Iteration 1102: Loss = 0.1824, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8397\n",
      "Iteration 1103: Loss = 0.1027, Accuracy = 0.9000 Test Loss = 0.2068, Test Accuracy = 0.8518\n",
      "Iteration 1104: Loss = 0.2190, Accuracy = 0.8000 Test Loss = 0.2047, Test Accuracy = 0.8439\n",
      "Iteration 1105: Loss = 0.1854, Accuracy = 0.9000 Test Loss = 0.2106, Test Accuracy = 0.8407\n",
      "Iteration 1106: Loss = 0.1615, Accuracy = 0.9000 Test Loss = 0.2073, Test Accuracy = 0.8357\n",
      "Iteration 1107: Loss = 0.2076, Accuracy = 0.9000 Test Loss = 0.2046, Test Accuracy = 0.8487\n",
      "Iteration 1108: Loss = 0.2534, Accuracy = 0.7000 Test Loss = 0.2054, Test Accuracy = 0.8428\n",
      "Iteration 1109: Loss = 0.2715, Accuracy = 0.6000 Test Loss = 0.2082, Test Accuracy = 0.8466\n",
      "Iteration 1110: Loss = 0.1965, Accuracy = 0.9000 Test Loss = 0.2097, Test Accuracy = 0.8488\n",
      "Iteration 1111: Loss = 0.2604, Accuracy = 0.8000 Test Loss = 0.2071, Test Accuracy = 0.8377\n",
      "Iteration 1112: Loss = 0.1821, Accuracy = 0.9000 Test Loss = 0.2118, Test Accuracy = 0.8381\n",
      "Iteration 1113: Loss = 0.1601, Accuracy = 1.0000 Test Loss = 0.2067, Test Accuracy = 0.8408\n",
      "Iteration 1114: Loss = 0.2762, Accuracy = 0.7000 Test Loss = 0.2079, Test Accuracy = 0.8392\n",
      "Iteration 1115: Loss = 0.2273, Accuracy = 0.9000 Test Loss = 0.2105, Test Accuracy = 0.8450\n",
      "Iteration 1116: Loss = 0.2936, Accuracy = 0.7000 Test Loss = 0.2094, Test Accuracy = 0.8415\n",
      "Iteration 1117: Loss = 0.1846, Accuracy = 1.0000 Test Loss = 0.2069, Test Accuracy = 0.8338\n",
      "Iteration 1118: Loss = 0.1738, Accuracy = 0.8000 Test Loss = 0.2119, Test Accuracy = 0.8323\n",
      "Iteration 1119: Loss = 0.2956, Accuracy = 0.7000 Test Loss = 0.2119, Test Accuracy = 0.8473\n",
      "Iteration 1120: Loss = 0.2653, Accuracy = 0.8000 Test Loss = 0.2070, Test Accuracy = 0.8420\n",
      "Iteration 1121: Loss = 0.2830, Accuracy = 0.7000 Test Loss = 0.2139, Test Accuracy = 0.8401\n",
      "Iteration 1122: Loss = 0.2291, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8413\n",
      "Iteration 1123: Loss = 0.1715, Accuracy = 0.9000 Test Loss = 0.2142, Test Accuracy = 0.8482\n",
      "Iteration 1124: Loss = 0.3052, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8453\n",
      "Iteration 1125: Loss = 0.2650, Accuracy = 0.9000 Test Loss = 0.2078, Test Accuracy = 0.8485\n",
      "Iteration 1126: Loss = 0.3177, Accuracy = 0.7000 Test Loss = 0.2061, Test Accuracy = 0.8507\n",
      "Iteration 1127: Loss = 0.1616, Accuracy = 1.0000 Test Loss = 0.2065, Test Accuracy = 0.8380\n",
      "Iteration 1128: Loss = 0.1455, Accuracy = 0.9000 Test Loss = 0.2114, Test Accuracy = 0.8380\n",
      "Iteration 1129: Loss = 0.2742, Accuracy = 0.7000 Test Loss = 0.2146, Test Accuracy = 0.8283\n",
      "Iteration 1130: Loss = 0.2602, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8391\n",
      "Iteration 1131: Loss = 0.1879, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8409\n",
      "Iteration 1132: Loss = 0.1565, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8449\n",
      "Iteration 1133: Loss = 0.2403, Accuracy = 0.6000 Test Loss = 0.2074, Test Accuracy = 0.8403\n",
      "Iteration 1134: Loss = 0.2670, Accuracy = 0.8000 Test Loss = 0.2090, Test Accuracy = 0.8456\n",
      "Iteration 1135: Loss = 0.1604, Accuracy = 0.9000 Test Loss = 0.2090, Test Accuracy = 0.8415\n",
      "Iteration 1136: Loss = 0.2125, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8434\n",
      "Iteration 1137: Loss = 0.2465, Accuracy = 0.8000 Test Loss = 0.2119, Test Accuracy = 0.8394\n",
      "Iteration 1138: Loss = 0.2680, Accuracy = 0.7000 Test Loss = 0.2061, Test Accuracy = 0.8454\n",
      "Iteration 1139: Loss = 0.1521, Accuracy = 0.9000 Test Loss = 0.2048, Test Accuracy = 0.8493\n",
      "Iteration 1140: Loss = 0.2119, Accuracy = 0.8000 Test Loss = 0.2061, Test Accuracy = 0.8511\n",
      "Iteration 1141: Loss = 0.1677, Accuracy = 0.9000 Test Loss = 0.2069, Test Accuracy = 0.8404\n",
      "Iteration 1142: Loss = 0.2058, Accuracy = 0.8000 Test Loss = 0.2101, Test Accuracy = 0.8528\n",
      "Iteration 1143: Loss = 0.1754, Accuracy = 0.9000 Test Loss = 0.2105, Test Accuracy = 0.8409\n",
      "Iteration 1144: Loss = 0.2191, Accuracy = 0.9000 Test Loss = 0.2067, Test Accuracy = 0.8425\n",
      "Iteration 1145: Loss = 0.1465, Accuracy = 1.0000 Test Loss = 0.2073, Test Accuracy = 0.8466\n",
      "Iteration 1146: Loss = 0.1738, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8414\n",
      "Iteration 1147: Loss = 0.1563, Accuracy = 0.8000 Test Loss = 0.2077, Test Accuracy = 0.8468\n",
      "Iteration 1148: Loss = 0.2715, Accuracy = 0.8000 Test Loss = 0.2058, Test Accuracy = 0.8442\n",
      "Iteration 1149: Loss = 0.1605, Accuracy = 0.9000 Test Loss = 0.2143, Test Accuracy = 0.8288\n",
      "Iteration 1150: Loss = 0.2566, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8405\n",
      "Iteration 1151: Loss = 0.2875, Accuracy = 0.7000 Test Loss = 0.2110, Test Accuracy = 0.8462\n",
      "Iteration 1152: Loss = 0.1588, Accuracy = 0.9000 Test Loss = 0.2051, Test Accuracy = 0.8412\n",
      "Iteration 1153: Loss = 0.1687, Accuracy = 0.9000 Test Loss = 0.2068, Test Accuracy = 0.8395\n",
      "Iteration 1154: Loss = 0.1511, Accuracy = 0.9000 Test Loss = 0.2039, Test Accuracy = 0.8446\n",
      "Iteration 1155: Loss = 0.1940, Accuracy = 0.9000 Test Loss = 0.2089, Test Accuracy = 0.8405\n",
      "Iteration 1156: Loss = 0.2232, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8439\n",
      "Iteration 1157: Loss = 0.2794, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8468\n",
      "Iteration 1158: Loss = 0.1021, Accuracy = 1.0000 Test Loss = 0.2095, Test Accuracy = 0.8344\n",
      "Iteration 1159: Loss = 0.2041, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8368\n",
      "Iteration 1160: Loss = 0.1806, Accuracy = 0.9000 Test Loss = 0.2092, Test Accuracy = 0.8439\n",
      "Iteration 1161: Loss = 0.2248, Accuracy = 0.8000 Test Loss = 0.2070, Test Accuracy = 0.8536\n",
      "Iteration 1162: Loss = 0.1380, Accuracy = 1.0000 Test Loss = 0.2086, Test Accuracy = 0.8392\n",
      "Iteration 1163: Loss = 0.2574, Accuracy = 0.8000 Test Loss = 0.2091, Test Accuracy = 0.8494\n",
      "Iteration 1164: Loss = 0.2274, Accuracy = 0.7000 Test Loss = 0.2109, Test Accuracy = 0.8350\n",
      "Iteration 1165: Loss = 0.1854, Accuracy = 0.9000 Test Loss = 0.2042, Test Accuracy = 0.8532\n",
      "Iteration 1166: Loss = 0.2430, Accuracy = 0.7000 Test Loss = 0.2053, Test Accuracy = 0.8435\n",
      "Iteration 1167: Loss = 0.2282, Accuracy = 0.8000 Test Loss = 0.2051, Test Accuracy = 0.8435\n",
      "Iteration 1168: Loss = 0.2575, Accuracy = 0.7000 Test Loss = 0.2097, Test Accuracy = 0.8406\n",
      "Iteration 1169: Loss = 0.1686, Accuracy = 1.0000 Test Loss = 0.2081, Test Accuracy = 0.8405\n",
      "Iteration 1170: Loss = 0.1659, Accuracy = 1.0000 Test Loss = 0.2047, Test Accuracy = 0.8492\n",
      "Iteration 1171: Loss = 0.2195, Accuracy = 0.8000 Test Loss = 0.2071, Test Accuracy = 0.8393\n",
      "Iteration 1172: Loss = 0.1431, Accuracy = 1.0000 Test Loss = 0.2072, Test Accuracy = 0.8355\n",
      "Iteration 1173: Loss = 0.1931, Accuracy = 1.0000 Test Loss = 0.2054, Test Accuracy = 0.8460\n",
      "Iteration 1174: Loss = 0.1758, Accuracy = 0.9000 Test Loss = 0.2067, Test Accuracy = 0.8395\n",
      "Iteration 1175: Loss = 0.1719, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8342\n",
      "Iteration 1176: Loss = 0.1655, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8500\n",
      "Iteration 1177: Loss = 0.2495, Accuracy = 0.7000 Test Loss = 0.2063, Test Accuracy = 0.8505\n",
      "Iteration 1178: Loss = 0.1687, Accuracy = 1.0000 Test Loss = 0.2102, Test Accuracy = 0.8491\n",
      "Iteration 1179: Loss = 0.1685, Accuracy = 1.0000 Test Loss = 0.2044, Test Accuracy = 0.8542\n",
      "Iteration 1180: Loss = 0.1329, Accuracy = 1.0000 Test Loss = 0.2095, Test Accuracy = 0.8372\n",
      "Iteration 1181: Loss = 0.1505, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8451\n",
      "Iteration 1182: Loss = 0.1510, Accuracy = 0.9000 Test Loss = 0.2144, Test Accuracy = 0.8282\n",
      "Iteration 1183: Loss = 0.1963, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8433\n",
      "Iteration 1184: Loss = 0.2812, Accuracy = 0.6000 Test Loss = 0.2058, Test Accuracy = 0.8458\n",
      "Iteration 1185: Loss = 0.2527, Accuracy = 0.6000 Test Loss = 0.2085, Test Accuracy = 0.8473\n",
      "Iteration 1186: Loss = 0.1850, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8455\n",
      "Iteration 1187: Loss = 0.1568, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8431\n",
      "Iteration 1188: Loss = 0.2073, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8436\n",
      "Iteration 1189: Loss = 0.2373, Accuracy = 0.8000 Test Loss = 0.2054, Test Accuracy = 0.8471\n",
      "Iteration 1190: Loss = 0.2528, Accuracy = 0.7000 Test Loss = 0.2060, Test Accuracy = 0.8593\n",
      "Iteration 1191: Loss = 0.1471, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8477\n",
      "Iteration 1192: Loss = 0.1986, Accuracy = 0.7000 Test Loss = 0.2072, Test Accuracy = 0.8451\n",
      "Iteration 1193: Loss = 0.1769, Accuracy = 0.9000 Test Loss = 0.2042, Test Accuracy = 0.8558\n",
      "Iteration 1194: Loss = 0.2085, Accuracy = 0.8000 Test Loss = 0.2059, Test Accuracy = 0.8383\n",
      "Iteration 1195: Loss = 0.1853, Accuracy = 0.8000 Test Loss = 0.2109, Test Accuracy = 0.8455\n",
      "Iteration 1196: Loss = 0.1994, Accuracy = 0.9000 Test Loss = 0.2064, Test Accuracy = 0.8457\n",
      "Iteration 1197: Loss = 0.2598, Accuracy = 0.7000 Test Loss = 0.2060, Test Accuracy = 0.8390\n",
      "Iteration 1198: Loss = 0.2229, Accuracy = 0.8000 Test Loss = 0.2074, Test Accuracy = 0.8520\n",
      "Iteration 1199: Loss = 0.1783, Accuracy = 1.0000 Test Loss = 0.2086, Test Accuracy = 0.8417\n",
      "Iteration 1200: Loss = 0.1900, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8310\n",
      "Iteration 1201: Loss = 0.1176, Accuracy = 0.9000 Test Loss = 0.2091, Test Accuracy = 0.8432\n",
      "Iteration 1202: Loss = 0.1930, Accuracy = 0.8000 Test Loss = 0.2058, Test Accuracy = 0.8446\n",
      "Iteration 1203: Loss = 0.1933, Accuracy = 0.7000 Test Loss = 0.2042, Test Accuracy = 0.8491\n",
      "Iteration 1204: Loss = 0.2045, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8485\n",
      "Iteration 1205: Loss = 0.1298, Accuracy = 0.9000 Test Loss = 0.2135, Test Accuracy = 0.8384\n",
      "Iteration 1206: Loss = 0.1554, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8490\n",
      "Iteration 1207: Loss = 0.3201, Accuracy = 0.8000 Test Loss = 0.2058, Test Accuracy = 0.8426\n",
      "Iteration 1208: Loss = 0.1870, Accuracy = 0.9000 Test Loss = 0.2108, Test Accuracy = 0.8368\n",
      "Iteration 1209: Loss = 0.1612, Accuracy = 1.0000 Test Loss = 0.2064, Test Accuracy = 0.8437\n",
      "Iteration 1210: Loss = 0.2209, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8469\n",
      "Iteration 1211: Loss = 0.2153, Accuracy = 0.8000 Test Loss = 0.2052, Test Accuracy = 0.8495\n",
      "Iteration 1212: Loss = 0.1390, Accuracy = 1.0000 Test Loss = 0.2110, Test Accuracy = 0.8268\n",
      "Iteration 1213: Loss = 0.3249, Accuracy = 0.6000 Test Loss = 0.2081, Test Accuracy = 0.8524\n",
      "Iteration 1214: Loss = 0.2210, Accuracy = 0.8000 Test Loss = 0.2117, Test Accuracy = 0.8476\n",
      "Iteration 1215: Loss = 0.1784, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8454\n",
      "Iteration 1216: Loss = 0.2246, Accuracy = 0.8000 Test Loss = 0.2181, Test Accuracy = 0.8273\n",
      "Iteration 1217: Loss = 0.1892, Accuracy = 0.8000 Test Loss = 0.2055, Test Accuracy = 0.8420\n",
      "Iteration 1218: Loss = 0.2888, Accuracy = 0.7000 Test Loss = 0.2095, Test Accuracy = 0.8433\n",
      "Iteration 1219: Loss = 0.1975, Accuracy = 0.9000 Test Loss = 0.2094, Test Accuracy = 0.8445\n",
      "Iteration 1220: Loss = 0.1865, Accuracy = 0.8000 Test Loss = 0.2059, Test Accuracy = 0.8437\n",
      "Iteration 1221: Loss = 0.2257, Accuracy = 0.7000 Test Loss = 0.2073, Test Accuracy = 0.8459\n",
      "Iteration 1222: Loss = 0.1552, Accuracy = 0.9000 Test Loss = 0.2094, Test Accuracy = 0.8383\n",
      "Iteration 1223: Loss = 0.1868, Accuracy = 0.8000 Test Loss = 0.2042, Test Accuracy = 0.8526\n",
      "Iteration 1224: Loss = 0.1814, Accuracy = 1.0000 Test Loss = 0.2122, Test Accuracy = 0.8478\n",
      "Iteration 1225: Loss = 0.2496, Accuracy = 0.7000 Test Loss = 0.2066, Test Accuracy = 0.8372\n",
      "Iteration 1226: Loss = 0.1635, Accuracy = 0.8000 Test Loss = 0.2063, Test Accuracy = 0.8417\n",
      "Iteration 1227: Loss = 0.2079, Accuracy = 0.8000 Test Loss = 0.2094, Test Accuracy = 0.8291\n",
      "Iteration 1228: Loss = 0.3054, Accuracy = 0.5000 Test Loss = 0.2105, Test Accuracy = 0.8417\n",
      "Iteration 1229: Loss = 0.1660, Accuracy = 0.9000 Test Loss = 0.2079, Test Accuracy = 0.8402\n",
      "Iteration 1230: Loss = 0.1389, Accuracy = 1.0000 Test Loss = 0.2074, Test Accuracy = 0.8443\n",
      "Iteration 1231: Loss = 0.2205, Accuracy = 0.8000 Test Loss = 0.2054, Test Accuracy = 0.8450\n",
      "Iteration 1232: Loss = 0.2848, Accuracy = 0.8000 Test Loss = 0.2125, Test Accuracy = 0.8365\n",
      "Iteration 1233: Loss = 0.2366, Accuracy = 0.7000 Test Loss = 0.2052, Test Accuracy = 0.8497\n",
      "Iteration 1234: Loss = 0.2308, Accuracy = 0.9000 Test Loss = 0.2098, Test Accuracy = 0.8429\n",
      "Iteration 1235: Loss = 0.1800, Accuracy = 0.8000 Test Loss = 0.2080, Test Accuracy = 0.8475\n",
      "Iteration 1236: Loss = 0.2991, Accuracy = 0.7000 Test Loss = 0.2085, Test Accuracy = 0.8500\n",
      "Iteration 1237: Loss = 0.1472, Accuracy = 0.9000 Test Loss = 0.2089, Test Accuracy = 0.8287\n",
      "Iteration 1238: Loss = 0.1931, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8386\n",
      "Iteration 1239: Loss = 0.2123, Accuracy = 0.8000 Test Loss = 0.2073, Test Accuracy = 0.8462\n",
      "Iteration 1240: Loss = 0.2139, Accuracy = 0.9000 Test Loss = 0.2122, Test Accuracy = 0.8459\n",
      "Iteration 1241: Loss = 0.2906, Accuracy = 0.6000 Test Loss = 0.2073, Test Accuracy = 0.8412\n",
      "Iteration 1242: Loss = 0.3066, Accuracy = 0.7000 Test Loss = 0.2079, Test Accuracy = 0.8392\n",
      "Iteration 1243: Loss = 0.3359, Accuracy = 0.7000 Test Loss = 0.2124, Test Accuracy = 0.8302\n",
      "Iteration 1244: Loss = 0.3066, Accuracy = 0.6000 Test Loss = 0.2077, Test Accuracy = 0.8540\n",
      "Iteration 1245: Loss = 0.1843, Accuracy = 0.8000 Test Loss = 0.2062, Test Accuracy = 0.8432\n",
      "Iteration 1246: Loss = 0.2124, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8412\n",
      "Iteration 1247: Loss = 0.1510, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8391\n",
      "Iteration 1248: Loss = 0.1768, Accuracy = 0.9000 Test Loss = 0.2078, Test Accuracy = 0.8448\n",
      "Iteration 1249: Loss = 0.1962, Accuracy = 0.8000 Test Loss = 0.2076, Test Accuracy = 0.8516\n",
      "Iteration 1250: Loss = 0.3245, Accuracy = 0.6000 Test Loss = 0.2080, Test Accuracy = 0.8522\n",
      "Iteration 1251: Loss = 0.2660, Accuracy = 0.8000 Test Loss = 0.2125, Test Accuracy = 0.8381\n",
      "Iteration 1252: Loss = 0.1553, Accuracy = 1.0000 Test Loss = 0.2070, Test Accuracy = 0.8361\n",
      "Iteration 1253: Loss = 0.1863, Accuracy = 0.8000 Test Loss = 0.2045, Test Accuracy = 0.8479\n",
      "Iteration 1254: Loss = 0.1649, Accuracy = 1.0000 Test Loss = 0.2046, Test Accuracy = 0.8454\n",
      "Iteration 1255: Loss = 0.2680, Accuracy = 0.7000 Test Loss = 0.2070, Test Accuracy = 0.8457\n",
      "Iteration 1256: Loss = 0.2816, Accuracy = 0.6000 Test Loss = 0.2063, Test Accuracy = 0.8508\n",
      "Iteration 1257: Loss = 0.2078, Accuracy = 0.9000 Test Loss = 0.2084, Test Accuracy = 0.8510\n",
      "Iteration 1258: Loss = 0.2122, Accuracy = 0.7000 Test Loss = 0.2223, Test Accuracy = 0.8241\n",
      "Iteration 1259: Loss = 0.1519, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8447\n",
      "Iteration 1260: Loss = 0.1996, Accuracy = 0.8000 Test Loss = 0.2077, Test Accuracy = 0.8404\n",
      "Iteration 1261: Loss = 0.1439, Accuracy = 1.0000 Test Loss = 0.2057, Test Accuracy = 0.8498\n",
      "Iteration 1262: Loss = 0.3076, Accuracy = 0.7000 Test Loss = 0.2085, Test Accuracy = 0.8498\n",
      "Iteration 1263: Loss = 0.1953, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8407\n",
      "Iteration 1264: Loss = 0.2975, Accuracy = 0.6000 Test Loss = 0.2074, Test Accuracy = 0.8533\n",
      "Iteration 1265: Loss = 0.1811, Accuracy = 0.9000 Test Loss = 0.2067, Test Accuracy = 0.8431\n",
      "Iteration 1266: Loss = 0.1374, Accuracy = 1.0000 Test Loss = 0.2071, Test Accuracy = 0.8498\n",
      "Iteration 1267: Loss = 0.1809, Accuracy = 1.0000 Test Loss = 0.2086, Test Accuracy = 0.8341\n",
      "Iteration 1268: Loss = 0.2695, Accuracy = 0.7000 Test Loss = 0.2141, Test Accuracy = 0.8340\n",
      "Iteration 1269: Loss = 0.1756, Accuracy = 0.9000 Test Loss = 0.2093, Test Accuracy = 0.8482\n",
      "Iteration 1270: Loss = 0.1718, Accuracy = 0.9000 Test Loss = 0.2071, Test Accuracy = 0.8514\n",
      "Iteration 1271: Loss = 0.1684, Accuracy = 0.9000 Test Loss = 0.2047, Test Accuracy = 0.8581\n",
      "Iteration 1272: Loss = 0.2310, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8428\n",
      "Iteration 1273: Loss = 0.1791, Accuracy = 0.8000 Test Loss = 0.2132, Test Accuracy = 0.8298\n",
      "Iteration 1274: Loss = 0.2652, Accuracy = 0.9000 Test Loss = 0.2056, Test Accuracy = 0.8478\n",
      "Iteration 1275: Loss = 0.2250, Accuracy = 0.8000 Test Loss = 0.2126, Test Accuracy = 0.8409\n",
      "Iteration 1276: Loss = 0.1950, Accuracy = 0.8000 Test Loss = 0.2083, Test Accuracy = 0.8461\n",
      "Iteration 1277: Loss = 0.2436, Accuracy = 0.7000 Test Loss = 0.2137, Test Accuracy = 0.8291\n",
      "Iteration 1278: Loss = 0.1554, Accuracy = 0.9000 Test Loss = 0.2112, Test Accuracy = 0.8315\n",
      "Iteration 1279: Loss = 0.3002, Accuracy = 0.7000 Test Loss = 0.2078, Test Accuracy = 0.8391\n",
      "Iteration 1280: Loss = 0.1902, Accuracy = 0.8000 Test Loss = 0.2089, Test Accuracy = 0.8465\n",
      "Iteration 1281: Loss = 0.2552, Accuracy = 0.8000 Test Loss = 0.2046, Test Accuracy = 0.8489\n",
      "Iteration 1282: Loss = 0.2203, Accuracy = 0.7000 Test Loss = 0.2110, Test Accuracy = 0.8435\n",
      "Iteration 1283: Loss = 0.1771, Accuracy = 0.8000 Test Loss = 0.2098, Test Accuracy = 0.8447\n",
      "Iteration 1284: Loss = 0.1575, Accuracy = 0.9000 Test Loss = 0.2074, Test Accuracy = 0.8415\n",
      "Iteration 1285: Loss = 0.1985, Accuracy = 0.8000 Test Loss = 0.2086, Test Accuracy = 0.8399\n",
      "Iteration 1286: Loss = 0.2690, Accuracy = 0.7000 Test Loss = 0.2093, Test Accuracy = 0.8441\n",
      "Iteration 1287: Loss = 0.2096, Accuracy = 0.9000 Test Loss = 0.2068, Test Accuracy = 0.8541\n",
      "Iteration 1288: Loss = 0.1463, Accuracy = 0.9000 Test Loss = 0.2071, Test Accuracy = 0.8429\n",
      "Iteration 1289: Loss = 0.2772, Accuracy = 0.7000 Test Loss = 0.2110, Test Accuracy = 0.8479\n",
      "Iteration 1290: Loss = 0.2166, Accuracy = 0.9000 Test Loss = 0.2106, Test Accuracy = 0.8414\n",
      "Iteration 1291: Loss = 0.2093, Accuracy = 0.8000 Test Loss = 0.2109, Test Accuracy = 0.8359\n",
      "Iteration 1292: Loss = 0.1329, Accuracy = 1.0000 Test Loss = 0.2047, Test Accuracy = 0.8502\n",
      "Iteration 1293: Loss = 0.1378, Accuracy = 0.9000 Test Loss = 0.2052, Test Accuracy = 0.8489\n",
      "Iteration 1294: Loss = 0.2106, Accuracy = 0.8000 Test Loss = 0.2121, Test Accuracy = 0.8463\n",
      "Iteration 1295: Loss = 0.1812, Accuracy = 0.7000 Test Loss = 0.2071, Test Accuracy = 0.8509\n",
      "Iteration 1296: Loss = 0.1427, Accuracy = 1.0000 Test Loss = 0.2048, Test Accuracy = 0.8476\n",
      "Iteration 1297: Loss = 0.2000, Accuracy = 0.6000 Test Loss = 0.2055, Test Accuracy = 0.8497\n",
      "Iteration 1298: Loss = 0.1805, Accuracy = 0.8000 Test Loss = 0.2169, Test Accuracy = 0.8288\n",
      "Iteration 1299: Loss = 0.1791, Accuracy = 0.8000 Test Loss = 0.2077, Test Accuracy = 0.8393\n",
      "Iteration 1300: Loss = 0.1534, Accuracy = 1.0000 Test Loss = 0.2052, Test Accuracy = 0.8484\n",
      "Iteration 1301: Loss = 0.1862, Accuracy = 0.7000 Test Loss = 0.2122, Test Accuracy = 0.8355\n",
      "Iteration 1302: Loss = 0.2905, Accuracy = 0.8000 Test Loss = 0.2071, Test Accuracy = 0.8366\n",
      "Iteration 1303: Loss = 0.2078, Accuracy = 0.8000 Test Loss = 0.2052, Test Accuracy = 0.8445\n",
      "Iteration 1304: Loss = 0.1545, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8377\n",
      "Iteration 1305: Loss = 0.1860, Accuracy = 1.0000 Test Loss = 0.2071, Test Accuracy = 0.8432\n",
      "Iteration 1306: Loss = 0.1929, Accuracy = 0.7000 Test Loss = 0.2072, Test Accuracy = 0.8461\n",
      "Iteration 1307: Loss = 0.1733, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8485\n",
      "Iteration 1308: Loss = 0.2056, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8427\n",
      "Iteration 1309: Loss = 0.2713, Accuracy = 0.7000 Test Loss = 0.2073, Test Accuracy = 0.8432\n",
      "Iteration 1310: Loss = 0.2096, Accuracy = 0.8000 Test Loss = 0.2046, Test Accuracy = 0.8507\n",
      "Iteration 1311: Loss = 0.2049, Accuracy = 0.9000 Test Loss = 0.2075, Test Accuracy = 0.8353\n",
      "Iteration 1312: Loss = 0.2721, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8465\n",
      "Iteration 1313: Loss = 0.1775, Accuracy = 1.0000 Test Loss = 0.2085, Test Accuracy = 0.8453\n",
      "Iteration 1314: Loss = 0.1780, Accuracy = 0.9000 Test Loss = 0.2105, Test Accuracy = 0.8498\n",
      "Iteration 1315: Loss = 0.1732, Accuracy = 1.0000 Test Loss = 0.2089, Test Accuracy = 0.8350\n",
      "Iteration 1316: Loss = 0.2573, Accuracy = 0.8000 Test Loss = 0.2076, Test Accuracy = 0.8410\n",
      "Iteration 1317: Loss = 0.2561, Accuracy = 0.8000 Test Loss = 0.2131, Test Accuracy = 0.8461\n",
      "Iteration 1318: Loss = 0.1756, Accuracy = 0.9000 Test Loss = 0.2069, Test Accuracy = 0.8407\n",
      "Iteration 1319: Loss = 0.2166, Accuracy = 0.8000 Test Loss = 0.2083, Test Accuracy = 0.8519\n",
      "Iteration 1320: Loss = 0.1779, Accuracy = 0.9000 Test Loss = 0.2072, Test Accuracy = 0.8432\n",
      "Iteration 1321: Loss = 0.1950, Accuracy = 1.0000 Test Loss = 0.2072, Test Accuracy = 0.8542\n",
      "Iteration 1322: Loss = 0.1612, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8409\n",
      "Iteration 1323: Loss = 0.1832, Accuracy = 1.0000 Test Loss = 0.2096, Test Accuracy = 0.8370\n",
      "Iteration 1324: Loss = 0.1302, Accuracy = 1.0000 Test Loss = 0.2106, Test Accuracy = 0.8431\n",
      "Iteration 1325: Loss = 0.1132, Accuracy = 1.0000 Test Loss = 0.2092, Test Accuracy = 0.8366\n",
      "Iteration 1326: Loss = 0.2976, Accuracy = 0.7000 Test Loss = 0.2049, Test Accuracy = 0.8425\n",
      "Iteration 1327: Loss = 0.1906, Accuracy = 1.0000 Test Loss = 0.2030, Test Accuracy = 0.8448\n",
      "Iteration 1328: Loss = 0.2066, Accuracy = 0.7000 Test Loss = 0.2119, Test Accuracy = 0.8437\n",
      "Iteration 1329: Loss = 0.1992, Accuracy = 0.8000 Test Loss = 0.2089, Test Accuracy = 0.8400\n",
      "Iteration 1330: Loss = 0.1918, Accuracy = 0.9000 Test Loss = 0.2052, Test Accuracy = 0.8458\n",
      "Iteration 1331: Loss = 0.3187, Accuracy = 0.5000 Test Loss = 0.2056, Test Accuracy = 0.8482\n",
      "Iteration 1332: Loss = 0.2254, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8420\n",
      "Iteration 1333: Loss = 0.1979, Accuracy = 0.8000 Test Loss = 0.2124, Test Accuracy = 0.8388\n",
      "Iteration 1334: Loss = 0.2270, Accuracy = 0.8000 Test Loss = 0.2051, Test Accuracy = 0.8447\n",
      "Iteration 1335: Loss = 0.1829, Accuracy = 0.9000 Test Loss = 0.2143, Test Accuracy = 0.8297\n",
      "Iteration 1336: Loss = 0.1506, Accuracy = 1.0000 Test Loss = 0.2097, Test Accuracy = 0.8372\n",
      "Iteration 1337: Loss = 0.2357, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8481\n",
      "Iteration 1338: Loss = 0.2370, Accuracy = 0.8000 Test Loss = 0.2095, Test Accuracy = 0.8502\n",
      "Iteration 1339: Loss = 0.2004, Accuracy = 0.8000 Test Loss = 0.2121, Test Accuracy = 0.8396\n",
      "Iteration 1340: Loss = 0.1732, Accuracy = 0.9000 Test Loss = 0.2082, Test Accuracy = 0.8385\n",
      "Iteration 1341: Loss = 0.3004, Accuracy = 0.5000 Test Loss = 0.2095, Test Accuracy = 0.8352\n",
      "Iteration 1342: Loss = 0.2310, Accuracy = 0.8000 Test Loss = 0.2060, Test Accuracy = 0.8404\n",
      "Iteration 1343: Loss = 0.2876, Accuracy = 0.7000 Test Loss = 0.2044, Test Accuracy = 0.8457\n",
      "Iteration 1344: Loss = 0.1683, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8451\n",
      "Iteration 1345: Loss = 0.1456, Accuracy = 1.0000 Test Loss = 0.2077, Test Accuracy = 0.8411\n",
      "Iteration 1346: Loss = 0.2169, Accuracy = 0.9000 Test Loss = 0.2123, Test Accuracy = 0.8375\n",
      "Iteration 1347: Loss = 0.3107, Accuracy = 0.6000 Test Loss = 0.2056, Test Accuracy = 0.8508\n",
      "Iteration 1348: Loss = 0.1514, Accuracy = 1.0000 Test Loss = 0.2096, Test Accuracy = 0.8404\n",
      "Iteration 1349: Loss = 0.2829, Accuracy = 0.6000 Test Loss = 0.2077, Test Accuracy = 0.8506\n",
      "Iteration 1350: Loss = 0.2214, Accuracy = 0.8000 Test Loss = 0.2117, Test Accuracy = 0.8346\n",
      "Iteration 1351: Loss = 0.2613, Accuracy = 0.7000 Test Loss = 0.2058, Test Accuracy = 0.8460\n",
      "Iteration 1352: Loss = 0.2107, Accuracy = 0.8000 Test Loss = 0.2054, Test Accuracy = 0.8463\n",
      "Iteration 1353: Loss = 0.1912, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8415\n",
      "Iteration 1354: Loss = 0.2241, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8466\n",
      "Iteration 1355: Loss = 0.1971, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8535\n",
      "Iteration 1356: Loss = 0.1996, Accuracy = 0.8000 Test Loss = 0.2127, Test Accuracy = 0.8351\n",
      "Iteration 1357: Loss = 0.2030, Accuracy = 0.8000 Test Loss = 0.2091, Test Accuracy = 0.8372\n",
      "Iteration 1358: Loss = 0.2723, Accuracy = 0.7000 Test Loss = 0.2068, Test Accuracy = 0.8508\n",
      "Iteration 1359: Loss = 0.1910, Accuracy = 0.9000 Test Loss = 0.2122, Test Accuracy = 0.8411\n",
      "Iteration 1360: Loss = 0.1999, Accuracy = 0.8000 Test Loss = 0.2064, Test Accuracy = 0.8496\n",
      "Iteration 1361: Loss = 0.1974, Accuracy = 0.8000 Test Loss = 0.2058, Test Accuracy = 0.8399\n",
      "Iteration 1362: Loss = 0.2230, Accuracy = 0.8000 Test Loss = 0.2072, Test Accuracy = 0.8542\n",
      "Iteration 1363: Loss = 0.1776, Accuracy = 1.0000 Test Loss = 0.2120, Test Accuracy = 0.8314\n",
      "Iteration 1364: Loss = 0.1278, Accuracy = 0.9000 Test Loss = 0.2133, Test Accuracy = 0.8350\n",
      "Iteration 1365: Loss = 0.1755, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8427\n",
      "Iteration 1366: Loss = 0.2204, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8402\n",
      "Iteration 1367: Loss = 0.1863, Accuracy = 0.9000 Test Loss = 0.2140, Test Accuracy = 0.8319\n",
      "Iteration 1368: Loss = 0.2842, Accuracy = 0.8000 Test Loss = 0.2117, Test Accuracy = 0.8321\n",
      "Iteration 1369: Loss = 0.2621, Accuracy = 0.8000 Test Loss = 0.2096, Test Accuracy = 0.8420\n",
      "Iteration 1370: Loss = 0.2260, Accuracy = 0.9000 Test Loss = 0.2101, Test Accuracy = 0.8353\n",
      "Iteration 1371: Loss = 0.1637, Accuracy = 0.9000 Test Loss = 0.2083, Test Accuracy = 0.8398\n",
      "Iteration 1372: Loss = 0.1832, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8405\n",
      "Iteration 1373: Loss = 0.2484, Accuracy = 0.7000 Test Loss = 0.2112, Test Accuracy = 0.8433\n",
      "Iteration 1374: Loss = 0.1306, Accuracy = 1.0000 Test Loss = 0.2062, Test Accuracy = 0.8433\n",
      "Iteration 1375: Loss = 0.2967, Accuracy = 0.7000 Test Loss = 0.2101, Test Accuracy = 0.8401\n",
      "Iteration 1376: Loss = 0.2249, Accuracy = 0.8000 Test Loss = 0.2106, Test Accuracy = 0.8429\n",
      "Iteration 1377: Loss = 0.1713, Accuracy = 0.8000 Test Loss = 0.2054, Test Accuracy = 0.8440\n",
      "Iteration 1378: Loss = 0.2434, Accuracy = 0.8000 Test Loss = 0.2083, Test Accuracy = 0.8435\n",
      "Iteration 1379: Loss = 0.2608, Accuracy = 0.7000 Test Loss = 0.2061, Test Accuracy = 0.8386\n",
      "Iteration 1380: Loss = 0.2052, Accuracy = 0.9000 Test Loss = 0.2119, Test Accuracy = 0.8353\n",
      "Iteration 1381: Loss = 0.1576, Accuracy = 0.9000 Test Loss = 0.2086, Test Accuracy = 0.8384\n",
      "Iteration 1382: Loss = 0.1623, Accuracy = 0.8000 Test Loss = 0.2084, Test Accuracy = 0.8426\n",
      "Iteration 1383: Loss = 0.1704, Accuracy = 1.0000 Test Loss = 0.2093, Test Accuracy = 0.8298\n",
      "Iteration 1384: Loss = 0.2129, Accuracy = 0.9000 Test Loss = 0.2111, Test Accuracy = 0.8478\n",
      "Iteration 1385: Loss = 0.2013, Accuracy = 0.8000 Test Loss = 0.2092, Test Accuracy = 0.8395\n",
      "Iteration 1386: Loss = 0.2093, Accuracy = 0.8000 Test Loss = 0.2031, Test Accuracy = 0.8451\n",
      "Iteration 1387: Loss = 0.2432, Accuracy = 0.8000 Test Loss = 0.2071, Test Accuracy = 0.8413\n",
      "Iteration 1388: Loss = 0.1192, Accuracy = 1.0000 Test Loss = 0.2043, Test Accuracy = 0.8469\n",
      "Iteration 1389: Loss = 0.1925, Accuracy = 0.8000 Test Loss = 0.2051, Test Accuracy = 0.8418\n",
      "Iteration 1390: Loss = 0.2757, Accuracy = 0.7000 Test Loss = 0.2053, Test Accuracy = 0.8534\n",
      "Iteration 1391: Loss = 0.2349, Accuracy = 0.7000 Test Loss = 0.2077, Test Accuracy = 0.8467\n",
      "Iteration 1392: Loss = 0.2179, Accuracy = 0.9000 Test Loss = 0.2101, Test Accuracy = 0.8416\n",
      "Iteration 1393: Loss = 0.1799, Accuracy = 0.9000 Test Loss = 0.2035, Test Accuracy = 0.8533\n",
      "Iteration 1394: Loss = 0.1806, Accuracy = 1.0000 Test Loss = 0.2112, Test Accuracy = 0.8300\n",
      "Iteration 1395: Loss = 0.3508, Accuracy = 0.4000 Test Loss = 0.2050, Test Accuracy = 0.8489\n",
      "Iteration 1396: Loss = 0.1556, Accuracy = 1.0000 Test Loss = 0.2049, Test Accuracy = 0.8435\n",
      "Iteration 1397: Loss = 0.2257, Accuracy = 0.9000 Test Loss = 0.2105, Test Accuracy = 0.8388\n",
      "Iteration 1398: Loss = 0.2881, Accuracy = 0.7000 Test Loss = 0.2071, Test Accuracy = 0.8412\n",
      "Iteration 1399: Loss = 0.2248, Accuracy = 0.8000 Test Loss = 0.2112, Test Accuracy = 0.8434\n",
      "Iteration 1400: Loss = 0.2051, Accuracy = 0.9000 Test Loss = 0.2103, Test Accuracy = 0.8406\n",
      "Iteration 1401: Loss = 0.1754, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8434\n",
      "Iteration 1402: Loss = 0.1901, Accuracy = 0.9000 Test Loss = 0.2071, Test Accuracy = 0.8502\n",
      "Iteration 1403: Loss = 0.1657, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8461\n",
      "Iteration 1404: Loss = 0.1608, Accuracy = 0.8000 Test Loss = 0.2067, Test Accuracy = 0.8378\n",
      "Iteration 1405: Loss = 0.2134, Accuracy = 0.8000 Test Loss = 0.2082, Test Accuracy = 0.8397\n",
      "Iteration 1406: Loss = 0.2336, Accuracy = 0.8000 Test Loss = 0.2124, Test Accuracy = 0.8346\n",
      "Iteration 1407: Loss = 0.1969, Accuracy = 0.8000 Test Loss = 0.2071, Test Accuracy = 0.8529\n",
      "Iteration 1408: Loss = 0.1907, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8360\n",
      "Iteration 1409: Loss = 0.2802, Accuracy = 0.9000 Test Loss = 0.2056, Test Accuracy = 0.8489\n",
      "Iteration 1410: Loss = 0.3117, Accuracy = 0.7000 Test Loss = 0.2045, Test Accuracy = 0.8463\n",
      "Iteration 1411: Loss = 0.1991, Accuracy = 0.8000 Test Loss = 0.2037, Test Accuracy = 0.8484\n",
      "Iteration 1412: Loss = 0.2628, Accuracy = 0.7000 Test Loss = 0.2060, Test Accuracy = 0.8513\n",
      "Iteration 1413: Loss = 0.1985, Accuracy = 0.9000 Test Loss = 0.2092, Test Accuracy = 0.8412\n",
      "Iteration 1414: Loss = 0.1971, Accuracy = 0.8000 Test Loss = 0.2075, Test Accuracy = 0.8321\n",
      "Iteration 1415: Loss = 0.1626, Accuracy = 1.0000 Test Loss = 0.2111, Test Accuracy = 0.8350\n",
      "Iteration 1416: Loss = 0.1449, Accuracy = 1.0000 Test Loss = 0.2094, Test Accuracy = 0.8431\n",
      "Iteration 1417: Loss = 0.1720, Accuracy = 0.8000 Test Loss = 0.2058, Test Accuracy = 0.8445\n",
      "Iteration 1418: Loss = 0.1827, Accuracy = 0.9000 Test Loss = 0.2074, Test Accuracy = 0.8414\n",
      "Iteration 1419: Loss = 0.2191, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8513\n",
      "Iteration 1420: Loss = 0.2371, Accuracy = 0.8000 Test Loss = 0.2117, Test Accuracy = 0.8395\n",
      "Iteration 1421: Loss = 0.2551, Accuracy = 0.8000 Test Loss = 0.2113, Test Accuracy = 0.8292\n",
      "Iteration 1422: Loss = 0.2185, Accuracy = 0.9000 Test Loss = 0.2117, Test Accuracy = 0.8366\n",
      "Iteration 1423: Loss = 0.2393, Accuracy = 0.8000 Test Loss = 0.2046, Test Accuracy = 0.8494\n",
      "Iteration 1424: Loss = 0.2112, Accuracy = 0.8000 Test Loss = 0.2039, Test Accuracy = 0.8458\n",
      "Iteration 1425: Loss = 0.1061, Accuracy = 1.0000 Test Loss = 0.2079, Test Accuracy = 0.8337\n",
      "Iteration 1426: Loss = 0.2983, Accuracy = 0.6000 Test Loss = 0.2062, Test Accuracy = 0.8507\n",
      "Iteration 1427: Loss = 0.2589, Accuracy = 0.8000 Test Loss = 0.2065, Test Accuracy = 0.8434\n",
      "Iteration 1428: Loss = 0.2963, Accuracy = 0.7000 Test Loss = 0.2067, Test Accuracy = 0.8419\n",
      "Iteration 1429: Loss = 0.2436, Accuracy = 0.8000 Test Loss = 0.2049, Test Accuracy = 0.8415\n",
      "Iteration 1430: Loss = 0.1773, Accuracy = 0.8000 Test Loss = 0.2087, Test Accuracy = 0.8412\n",
      "Iteration 1431: Loss = 0.3130, Accuracy = 0.6000 Test Loss = 0.2085, Test Accuracy = 0.8465\n",
      "Iteration 1432: Loss = 0.2283, Accuracy = 0.8000 Test Loss = 0.2060, Test Accuracy = 0.8392\n",
      "Iteration 1433: Loss = 0.2879, Accuracy = 0.7000 Test Loss = 0.2124, Test Accuracy = 0.8404\n",
      "Iteration 1434: Loss = 0.1481, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8477\n",
      "Iteration 1435: Loss = 0.1504, Accuracy = 1.0000 Test Loss = 0.2086, Test Accuracy = 0.8356\n",
      "Iteration 1436: Loss = 0.3019, Accuracy = 0.6000 Test Loss = 0.2061, Test Accuracy = 0.8491\n",
      "Iteration 1437: Loss = 0.2335, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8396\n",
      "Iteration 1438: Loss = 0.2506, Accuracy = 0.8000 Test Loss = 0.2102, Test Accuracy = 0.8414\n",
      "Iteration 1439: Loss = 0.2360, Accuracy = 0.8000 Test Loss = 0.2055, Test Accuracy = 0.8530\n",
      "Iteration 1440: Loss = 0.1776, Accuracy = 0.8000 Test Loss = 0.2051, Test Accuracy = 0.8470\n",
      "Iteration 1441: Loss = 0.1571, Accuracy = 1.0000 Test Loss = 0.2134, Test Accuracy = 0.8363\n",
      "Iteration 1442: Loss = 0.2214, Accuracy = 0.9000 Test Loss = 0.2084, Test Accuracy = 0.8398\n",
      "Iteration 1443: Loss = 0.1264, Accuracy = 0.9000 Test Loss = 0.2044, Test Accuracy = 0.8451\n",
      "Iteration 1444: Loss = 0.2393, Accuracy = 0.7000 Test Loss = 0.2080, Test Accuracy = 0.8469\n",
      "Iteration 1445: Loss = 0.1756, Accuracy = 0.8000 Test Loss = 0.2066, Test Accuracy = 0.8477\n",
      "Iteration 1446: Loss = 0.2190, Accuracy = 0.9000 Test Loss = 0.2099, Test Accuracy = 0.8395\n",
      "Iteration 1447: Loss = 0.2639, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8440\n",
      "Iteration 1448: Loss = 0.1866, Accuracy = 0.9000 Test Loss = 0.2115, Test Accuracy = 0.8473\n",
      "Iteration 1449: Loss = 0.1517, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8425\n",
      "Iteration 1450: Loss = 0.1376, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8421\n",
      "Iteration 1451: Loss = 0.1838, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8434\n",
      "Iteration 1452: Loss = 0.2925, Accuracy = 0.6000 Test Loss = 0.2069, Test Accuracy = 0.8525\n",
      "Iteration 1453: Loss = 0.1390, Accuracy = 1.0000 Test Loss = 0.2100, Test Accuracy = 0.8353\n",
      "Iteration 1454: Loss = 0.1700, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8456\n",
      "Iteration 1455: Loss = 0.2402, Accuracy = 0.8000 Test Loss = 0.2097, Test Accuracy = 0.8351\n",
      "Iteration 1456: Loss = 0.1662, Accuracy = 0.8000 Test Loss = 0.2060, Test Accuracy = 0.8463\n",
      "Iteration 1457: Loss = 0.2593, Accuracy = 0.7000 Test Loss = 0.2063, Test Accuracy = 0.8441\n",
      "Iteration 1458: Loss = 0.1185, Accuracy = 1.0000 Test Loss = 0.2078, Test Accuracy = 0.8400\n",
      "Iteration 1459: Loss = 0.1498, Accuracy = 1.0000 Test Loss = 0.2089, Test Accuracy = 0.8367\n",
      "Iteration 1460: Loss = 0.2103, Accuracy = 0.9000 Test Loss = 0.2074, Test Accuracy = 0.8515\n",
      "Iteration 1461: Loss = 0.1371, Accuracy = 1.0000 Test Loss = 0.2065, Test Accuracy = 0.8370\n",
      "Iteration 1462: Loss = 0.2399, Accuracy = 0.6000 Test Loss = 0.2083, Test Accuracy = 0.8451\n",
      "Iteration 1463: Loss = 0.2248, Accuracy = 0.9000 Test Loss = 0.2093, Test Accuracy = 0.8415\n",
      "Iteration 1464: Loss = 0.1455, Accuracy = 1.0000 Test Loss = 0.2050, Test Accuracy = 0.8463\n",
      "Iteration 1465: Loss = 0.1468, Accuracy = 0.9000 Test Loss = 0.2072, Test Accuracy = 0.8372\n",
      "Iteration 1466: Loss = 0.3113, Accuracy = 0.6000 Test Loss = 0.2125, Test Accuracy = 0.8428\n",
      "Iteration 1467: Loss = 0.2082, Accuracy = 0.8000 Test Loss = 0.2067, Test Accuracy = 0.8456\n",
      "Iteration 1468: Loss = 0.1744, Accuracy = 0.9000 Test Loss = 0.2073, Test Accuracy = 0.8446\n",
      "Iteration 1469: Loss = 0.1525, Accuracy = 0.9000 Test Loss = 0.2161, Test Accuracy = 0.8318\n",
      "Iteration 1470: Loss = 0.1994, Accuracy = 0.9000 Test Loss = 0.2066, Test Accuracy = 0.8392\n",
      "Iteration 1471: Loss = 0.1755, Accuracy = 1.0000 Test Loss = 0.2063, Test Accuracy = 0.8502\n",
      "Iteration 1472: Loss = 0.2319, Accuracy = 0.8000 Test Loss = 0.2034, Test Accuracy = 0.8389\n",
      "Iteration 1473: Loss = 0.2380, Accuracy = 0.8000 Test Loss = 0.2083, Test Accuracy = 0.8358\n",
      "Iteration 1474: Loss = 0.1654, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8536\n",
      "Iteration 1475: Loss = 0.2292, Accuracy = 0.7000 Test Loss = 0.2038, Test Accuracy = 0.8522\n",
      "Iteration 1476: Loss = 0.1174, Accuracy = 1.0000 Test Loss = 0.2056, Test Accuracy = 0.8477\n",
      "Iteration 1477: Loss = 0.2488, Accuracy = 0.7000 Test Loss = 0.2059, Test Accuracy = 0.8488\n",
      "Iteration 1478: Loss = 0.2030, Accuracy = 0.8000 Test Loss = 0.2085, Test Accuracy = 0.8499\n",
      "Iteration 1479: Loss = 0.1792, Accuracy = 1.0000 Test Loss = 0.2054, Test Accuracy = 0.8482\n",
      "Iteration 1480: Loss = 0.2507, Accuracy = 0.8000 Test Loss = 0.2075, Test Accuracy = 0.8359\n",
      "Iteration 1481: Loss = 0.2113, Accuracy = 0.8000 Test Loss = 0.2045, Test Accuracy = 0.8511\n",
      "Iteration 1482: Loss = 0.2135, Accuracy = 0.8000 Test Loss = 0.2094, Test Accuracy = 0.8383\n",
      "Iteration 1483: Loss = 0.1991, Accuracy = 0.9000 Test Loss = 0.2044, Test Accuracy = 0.8495\n",
      "Iteration 1484: Loss = 0.1811, Accuracy = 1.0000 Test Loss = 0.2075, Test Accuracy = 0.8471\n",
      "Iteration 1485: Loss = 0.2612, Accuracy = 0.8000 Test Loss = 0.2084, Test Accuracy = 0.8330\n",
      "Iteration 1486: Loss = 0.1783, Accuracy = 0.9000 Test Loss = 0.2064, Test Accuracy = 0.8399\n",
      "Iteration 1487: Loss = 0.1649, Accuracy = 0.9000 Test Loss = 0.2091, Test Accuracy = 0.8442\n",
      "Iteration 1488: Loss = 0.1753, Accuracy = 1.0000 Test Loss = 0.2046, Test Accuracy = 0.8424\n",
      "Iteration 1489: Loss = 0.1463, Accuracy = 0.9000 Test Loss = 0.2047, Test Accuracy = 0.8424\n",
      "Iteration 1490: Loss = 0.2607, Accuracy = 0.6000 Test Loss = 0.2111, Test Accuracy = 0.8490\n",
      "Iteration 1491: Loss = 0.2721, Accuracy = 0.8000 Test Loss = 0.2078, Test Accuracy = 0.8560\n",
      "Iteration 1492: Loss = 0.2351, Accuracy = 0.9000 Test Loss = 0.2049, Test Accuracy = 0.8510\n",
      "Iteration 1493: Loss = 0.1592, Accuracy = 1.0000 Test Loss = 0.2076, Test Accuracy = 0.8346\n",
      "Iteration 1494: Loss = 0.1644, Accuracy = 0.9000 Test Loss = 0.2059, Test Accuracy = 0.8457\n",
      "Iteration 1495: Loss = 0.2198, Accuracy = 0.8000 Test Loss = 0.2097, Test Accuracy = 0.8528\n",
      "Iteration 1496: Loss = 0.2034, Accuracy = 0.9000 Test Loss = 0.2078, Test Accuracy = 0.8447\n",
      "Iteration 1497: Loss = 0.1745, Accuracy = 1.0000 Test Loss = 0.2101, Test Accuracy = 0.8336\n",
      "Iteration 1498: Loss = 0.2081, Accuracy = 0.8000 Test Loss = 0.2061, Test Accuracy = 0.8462\n",
      "Iteration 1499: Loss = 0.1924, Accuracy = 0.9000 Test Loss = 0.2045, Test Accuracy = 0.8377\n",
      "Total training time: 1160.95s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history2 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=1500, B = 10)\n",
    "plot_history(history2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used only 1500 epochs. Becasue, I tried with 4000 epochs previously and the line does not improve over the iterations. It converges early. \n",
    "That is why when I am running the models again for the final time, I am using less number of iterations. \n",
    "\n",
    "`Total training time`: 1160.95s for 1500 epochs. `0.77`s per epoch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`B=100`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 27.6212, Accuracy = 0.1400 Test Loss = 25.5890, Test Accuracy = 0.1379\n",
      "Iteration 1: Loss = 15.9729, Accuracy = 0.1300 Test Loss = 16.6215, Test Accuracy = 0.1549\n",
      "Iteration 2: Loss = 13.9294, Accuracy = 0.2200 Test Loss = 12.5842, Test Accuracy = 0.1673\n",
      "Iteration 3: Loss = 8.9295, Accuracy = 0.1600 Test Loss = 10.1827, Test Accuracy = 0.1824\n",
      "Iteration 4: Loss = 8.5734, Accuracy = 0.1600 Test Loss = 8.5728, Test Accuracy = 0.1934\n",
      "Iteration 5: Loss = 7.2811, Accuracy = 0.2300 Test Loss = 7.3613, Test Accuracy = 0.2048\n",
      "Iteration 6: Loss = 7.0605, Accuracy = 0.3100 Test Loss = 6.4593, Test Accuracy = 0.2104\n",
      "Iteration 7: Loss = 5.2826, Accuracy = 0.2300 Test Loss = 5.7221, Test Accuracy = 0.2173\n",
      "Iteration 8: Loss = 5.1966, Accuracy = 0.2600 Test Loss = 5.1371, Test Accuracy = 0.2225\n",
      "Iteration 9: Loss = 4.4050, Accuracy = 0.2700 Test Loss = 4.6323, Test Accuracy = 0.2391\n",
      "Iteration 10: Loss = 4.5124, Accuracy = 0.3000 Test Loss = 4.2148, Test Accuracy = 0.2495\n",
      "Iteration 11: Loss = 3.9349, Accuracy = 0.2900 Test Loss = 3.8674, Test Accuracy = 0.2625\n",
      "Iteration 12: Loss = 3.1011, Accuracy = 0.2400 Test Loss = 3.5591, Test Accuracy = 0.2758\n",
      "Iteration 13: Loss = 3.3428, Accuracy = 0.2600 Test Loss = 3.2853, Test Accuracy = 0.2783\n",
      "Iteration 14: Loss = 3.1556, Accuracy = 0.2800 Test Loss = 3.0593, Test Accuracy = 0.2963\n",
      "Iteration 15: Loss = 2.9054, Accuracy = 0.2700 Test Loss = 2.8463, Test Accuracy = 0.3096\n",
      "Iteration 16: Loss = 3.0773, Accuracy = 0.2900 Test Loss = 2.6742, Test Accuracy = 0.3138\n",
      "Iteration 17: Loss = 2.7371, Accuracy = 0.3500 Test Loss = 2.5116, Test Accuracy = 0.3276\n",
      "Iteration 18: Loss = 2.6828, Accuracy = 0.3600 Test Loss = 2.3570, Test Accuracy = 0.3337\n",
      "Iteration 19: Loss = 2.2027, Accuracy = 0.3900 Test Loss = 2.2252, Test Accuracy = 0.3443\n",
      "Iteration 20: Loss = 2.1853, Accuracy = 0.4000 Test Loss = 2.1015, Test Accuracy = 0.3626\n",
      "Iteration 21: Loss = 1.5705, Accuracy = 0.4200 Test Loss = 1.9919, Test Accuracy = 0.3682\n",
      "Iteration 22: Loss = 2.1956, Accuracy = 0.3800 Test Loss = 1.8968, Test Accuracy = 0.3810\n",
      "Iteration 23: Loss = 2.0617, Accuracy = 0.4500 Test Loss = 1.8069, Test Accuracy = 0.3875\n",
      "Iteration 24: Loss = 1.8561, Accuracy = 0.3400 Test Loss = 1.7222, Test Accuracy = 0.4049\n",
      "Iteration 25: Loss = 1.5122, Accuracy = 0.4500 Test Loss = 1.6495, Test Accuracy = 0.4103\n",
      "Iteration 26: Loss = 1.5913, Accuracy = 0.4400 Test Loss = 1.5768, Test Accuracy = 0.4182\n",
      "Iteration 27: Loss = 1.6484, Accuracy = 0.4400 Test Loss = 1.5109, Test Accuracy = 0.4370\n",
      "Iteration 28: Loss = 1.4900, Accuracy = 0.4200 Test Loss = 1.4551, Test Accuracy = 0.4375\n",
      "Iteration 29: Loss = 1.4772, Accuracy = 0.4500 Test Loss = 1.3984, Test Accuracy = 0.4513\n",
      "Iteration 30: Loss = 1.2632, Accuracy = 0.4500 Test Loss = 1.3448, Test Accuracy = 0.4614\n",
      "Iteration 31: Loss = 1.1425, Accuracy = 0.5300 Test Loss = 1.2965, Test Accuracy = 0.4687\n",
      "Iteration 32: Loss = 1.3051, Accuracy = 0.4100 Test Loss = 1.2552, Test Accuracy = 0.4789\n",
      "Iteration 33: Loss = 1.1058, Accuracy = 0.4600 Test Loss = 1.2137, Test Accuracy = 0.4812\n",
      "Iteration 34: Loss = 1.0515, Accuracy = 0.5600 Test Loss = 1.1733, Test Accuracy = 0.4931\n",
      "Iteration 35: Loss = 1.2943, Accuracy = 0.4700 Test Loss = 1.1401, Test Accuracy = 0.4942\n",
      "Iteration 36: Loss = 1.0391, Accuracy = 0.4900 Test Loss = 1.1014, Test Accuracy = 0.5109\n",
      "Iteration 37: Loss = 1.0722, Accuracy = 0.4600 Test Loss = 1.0702, Test Accuracy = 0.5210\n",
      "Iteration 38: Loss = 0.8097, Accuracy = 0.6100 Test Loss = 1.0386, Test Accuracy = 0.5316\n",
      "Iteration 39: Loss = 1.0857, Accuracy = 0.4900 Test Loss = 1.0091, Test Accuracy = 0.5323\n",
      "Iteration 40: Loss = 0.9190, Accuracy = 0.5500 Test Loss = 0.9820, Test Accuracy = 0.5418\n",
      "Iteration 41: Loss = 1.2140, Accuracy = 0.4900 Test Loss = 0.9568, Test Accuracy = 0.5509\n",
      "Iteration 42: Loss = 1.0519, Accuracy = 0.6000 Test Loss = 0.9341, Test Accuracy = 0.5493\n",
      "Iteration 43: Loss = 1.2272, Accuracy = 0.5000 Test Loss = 0.9122, Test Accuracy = 0.5640\n",
      "Iteration 44: Loss = 0.9354, Accuracy = 0.4500 Test Loss = 0.8892, Test Accuracy = 0.5715\n",
      "Iteration 45: Loss = 0.7495, Accuracy = 0.5600 Test Loss = 0.8671, Test Accuracy = 0.5768\n",
      "Iteration 46: Loss = 1.0249, Accuracy = 0.5400 Test Loss = 0.8501, Test Accuracy = 0.5815\n",
      "Iteration 47: Loss = 1.0879, Accuracy = 0.6600 Test Loss = 0.8298, Test Accuracy = 0.5840\n",
      "Iteration 48: Loss = 0.6864, Accuracy = 0.5500 Test Loss = 0.8130, Test Accuracy = 0.5951\n",
      "Iteration 49: Loss = 0.8387, Accuracy = 0.6100 Test Loss = 0.7963, Test Accuracy = 0.6007\n",
      "Iteration 50: Loss = 0.8743, Accuracy = 0.6100 Test Loss = 0.7799, Test Accuracy = 0.6020\n",
      "Iteration 51: Loss = 0.8214, Accuracy = 0.6700 Test Loss = 0.7633, Test Accuracy = 0.6115\n",
      "Iteration 52: Loss = 0.7246, Accuracy = 0.5700 Test Loss = 0.7486, Test Accuracy = 0.6123\n",
      "Iteration 53: Loss = 0.7792, Accuracy = 0.6100 Test Loss = 0.7344, Test Accuracy = 0.6216\n",
      "Iteration 54: Loss = 0.7377, Accuracy = 0.6500 Test Loss = 0.7228, Test Accuracy = 0.6181\n",
      "Iteration 55: Loss = 0.7487, Accuracy = 0.6000 Test Loss = 0.7100, Test Accuracy = 0.6347\n",
      "Iteration 56: Loss = 0.6542, Accuracy = 0.5800 Test Loss = 0.6962, Test Accuracy = 0.6333\n",
      "Iteration 57: Loss = 0.5761, Accuracy = 0.6700 Test Loss = 0.6836, Test Accuracy = 0.6454\n",
      "Iteration 58: Loss = 0.6729, Accuracy = 0.6600 Test Loss = 0.6714, Test Accuracy = 0.6479\n",
      "Iteration 59: Loss = 0.6779, Accuracy = 0.6000 Test Loss = 0.6609, Test Accuracy = 0.6508\n",
      "Iteration 60: Loss = 0.6252, Accuracy = 0.6600 Test Loss = 0.6512, Test Accuracy = 0.6526\n",
      "Iteration 61: Loss = 0.5955, Accuracy = 0.6800 Test Loss = 0.6416, Test Accuracy = 0.6604\n",
      "Iteration 62: Loss = 0.6369, Accuracy = 0.6200 Test Loss = 0.6334, Test Accuracy = 0.6587\n",
      "Iteration 63: Loss = 0.7461, Accuracy = 0.6300 Test Loss = 0.6218, Test Accuracy = 0.6635\n",
      "Iteration 64: Loss = 0.6430, Accuracy = 0.6400 Test Loss = 0.6128, Test Accuracy = 0.6693\n",
      "Iteration 65: Loss = 0.5259, Accuracy = 0.6500 Test Loss = 0.6040, Test Accuracy = 0.6725\n",
      "Iteration 66: Loss = 0.6867, Accuracy = 0.6800 Test Loss = 0.5971, Test Accuracy = 0.6758\n",
      "Iteration 67: Loss = 0.6409, Accuracy = 0.7300 Test Loss = 0.5882, Test Accuracy = 0.6809\n",
      "Iteration 68: Loss = 0.6311, Accuracy = 0.6400 Test Loss = 0.5803, Test Accuracy = 0.6817\n",
      "Iteration 69: Loss = 0.5059, Accuracy = 0.7700 Test Loss = 0.5726, Test Accuracy = 0.6885\n",
      "Iteration 70: Loss = 0.5377, Accuracy = 0.6900 Test Loss = 0.5644, Test Accuracy = 0.6940\n",
      "Iteration 71: Loss = 0.4363, Accuracy = 0.6600 Test Loss = 0.5577, Test Accuracy = 0.6942\n",
      "Iteration 72: Loss = 0.4543, Accuracy = 0.7700 Test Loss = 0.5519, Test Accuracy = 0.6893\n",
      "Iteration 73: Loss = 0.4888, Accuracy = 0.7400 Test Loss = 0.5452, Test Accuracy = 0.6975\n",
      "Iteration 74: Loss = 0.5650, Accuracy = 0.6600 Test Loss = 0.5382, Test Accuracy = 0.7043\n",
      "Iteration 75: Loss = 0.5570, Accuracy = 0.6700 Test Loss = 0.5322, Test Accuracy = 0.7035\n",
      "Iteration 76: Loss = 0.5288, Accuracy = 0.7200 Test Loss = 0.5270, Test Accuracy = 0.7068\n",
      "Iteration 77: Loss = 0.5580, Accuracy = 0.6500 Test Loss = 0.5201, Test Accuracy = 0.7139\n",
      "Iteration 78: Loss = 0.4773, Accuracy = 0.6700 Test Loss = 0.5157, Test Accuracy = 0.7118\n",
      "Iteration 79: Loss = 0.5308, Accuracy = 0.7100 Test Loss = 0.5102, Test Accuracy = 0.7178\n",
      "Iteration 80: Loss = 0.5565, Accuracy = 0.7200 Test Loss = 0.5061, Test Accuracy = 0.7173\n",
      "Iteration 81: Loss = 0.4379, Accuracy = 0.7900 Test Loss = 0.4996, Test Accuracy = 0.7198\n",
      "Iteration 82: Loss = 0.3786, Accuracy = 0.7900 Test Loss = 0.4954, Test Accuracy = 0.7223\n",
      "Iteration 83: Loss = 0.5257, Accuracy = 0.6400 Test Loss = 0.4897, Test Accuracy = 0.7242\n",
      "Iteration 84: Loss = 0.5016, Accuracy = 0.7200 Test Loss = 0.4858, Test Accuracy = 0.7257\n",
      "Iteration 85: Loss = 0.6821, Accuracy = 0.7500 Test Loss = 0.4805, Test Accuracy = 0.7301\n",
      "Iteration 86: Loss = 0.5311, Accuracy = 0.7200 Test Loss = 0.4771, Test Accuracy = 0.7332\n",
      "Iteration 87: Loss = 0.4757, Accuracy = 0.6900 Test Loss = 0.4716, Test Accuracy = 0.7332\n",
      "Iteration 88: Loss = 0.5356, Accuracy = 0.7600 Test Loss = 0.4682, Test Accuracy = 0.7370\n",
      "Iteration 89: Loss = 0.5680, Accuracy = 0.7200 Test Loss = 0.4642, Test Accuracy = 0.7370\n",
      "Iteration 90: Loss = 0.5183, Accuracy = 0.6800 Test Loss = 0.4596, Test Accuracy = 0.7416\n",
      "Iteration 91: Loss = 0.4143, Accuracy = 0.7400 Test Loss = 0.4561, Test Accuracy = 0.7407\n",
      "Iteration 92: Loss = 0.6308, Accuracy = 0.6800 Test Loss = 0.4529, Test Accuracy = 0.7470\n",
      "Iteration 93: Loss = 0.4063, Accuracy = 0.7800 Test Loss = 0.4487, Test Accuracy = 0.7489\n",
      "Iteration 94: Loss = 0.4356, Accuracy = 0.7900 Test Loss = 0.4449, Test Accuracy = 0.7479\n",
      "Iteration 95: Loss = 0.4784, Accuracy = 0.6700 Test Loss = 0.4417, Test Accuracy = 0.7489\n",
      "Iteration 96: Loss = 0.4027, Accuracy = 0.8000 Test Loss = 0.4382, Test Accuracy = 0.7502\n",
      "Iteration 97: Loss = 0.4493, Accuracy = 0.7600 Test Loss = 0.4352, Test Accuracy = 0.7502\n",
      "Iteration 98: Loss = 0.3901, Accuracy = 0.7600 Test Loss = 0.4314, Test Accuracy = 0.7551\n",
      "Iteration 99: Loss = 0.3461, Accuracy = 0.7300 Test Loss = 0.4285, Test Accuracy = 0.7561\n",
      "Iteration 100: Loss = 0.3326, Accuracy = 0.8200 Test Loss = 0.4260, Test Accuracy = 0.7539\n",
      "Iteration 101: Loss = 0.3531, Accuracy = 0.8000 Test Loss = 0.4230, Test Accuracy = 0.7570\n",
      "Iteration 102: Loss = 0.4888, Accuracy = 0.7300 Test Loss = 0.4215, Test Accuracy = 0.7556\n",
      "Iteration 103: Loss = 0.3993, Accuracy = 0.7300 Test Loss = 0.4163, Test Accuracy = 0.7617\n",
      "Iteration 104: Loss = 0.4796, Accuracy = 0.7000 Test Loss = 0.4153, Test Accuracy = 0.7633\n",
      "Iteration 105: Loss = 0.3642, Accuracy = 0.8400 Test Loss = 0.4110, Test Accuracy = 0.7655\n",
      "Iteration 106: Loss = 0.3038, Accuracy = 0.8300 Test Loss = 0.4086, Test Accuracy = 0.7645\n",
      "Iteration 107: Loss = 0.4496, Accuracy = 0.7700 Test Loss = 0.4063, Test Accuracy = 0.7653\n",
      "Iteration 108: Loss = 0.4496, Accuracy = 0.7400 Test Loss = 0.4037, Test Accuracy = 0.7661\n",
      "Iteration 109: Loss = 0.4000, Accuracy = 0.7500 Test Loss = 0.4006, Test Accuracy = 0.7694\n",
      "Iteration 110: Loss = 0.3535, Accuracy = 0.8200 Test Loss = 0.3993, Test Accuracy = 0.7693\n",
      "Iteration 111: Loss = 0.3243, Accuracy = 0.8200 Test Loss = 0.3969, Test Accuracy = 0.7758\n",
      "Iteration 112: Loss = 0.3935, Accuracy = 0.7700 Test Loss = 0.3942, Test Accuracy = 0.7716\n",
      "Iteration 113: Loss = 0.3572, Accuracy = 0.7700 Test Loss = 0.3921, Test Accuracy = 0.7730\n",
      "Iteration 114: Loss = 0.3315, Accuracy = 0.7100 Test Loss = 0.3898, Test Accuracy = 0.7735\n",
      "Iteration 115: Loss = 0.3583, Accuracy = 0.7000 Test Loss = 0.3873, Test Accuracy = 0.7779\n",
      "Iteration 116: Loss = 0.3982, Accuracy = 0.7600 Test Loss = 0.3858, Test Accuracy = 0.7802\n",
      "Iteration 117: Loss = 0.4368, Accuracy = 0.7600 Test Loss = 0.3828, Test Accuracy = 0.7776\n",
      "Iteration 118: Loss = 0.4733, Accuracy = 0.6400 Test Loss = 0.3809, Test Accuracy = 0.7764\n",
      "Iteration 119: Loss = 0.3389, Accuracy = 0.7800 Test Loss = 0.3792, Test Accuracy = 0.7773\n",
      "Iteration 120: Loss = 0.3638, Accuracy = 0.7300 Test Loss = 0.3767, Test Accuracy = 0.7814\n",
      "Iteration 121: Loss = 0.4502, Accuracy = 0.7500 Test Loss = 0.3746, Test Accuracy = 0.7778\n",
      "Iteration 122: Loss = 0.4106, Accuracy = 0.6800 Test Loss = 0.3738, Test Accuracy = 0.7795\n",
      "Iteration 123: Loss = 0.3976, Accuracy = 0.7600 Test Loss = 0.3713, Test Accuracy = 0.7828\n",
      "Iteration 124: Loss = 0.3170, Accuracy = 0.7800 Test Loss = 0.3698, Test Accuracy = 0.7823\n",
      "Iteration 125: Loss = 0.4263, Accuracy = 0.8500 Test Loss = 0.3678, Test Accuracy = 0.7821\n",
      "Iteration 126: Loss = 0.3474, Accuracy = 0.8200 Test Loss = 0.3661, Test Accuracy = 0.7859\n",
      "Iteration 127: Loss = 0.4796, Accuracy = 0.7600 Test Loss = 0.3642, Test Accuracy = 0.7874\n",
      "Iteration 128: Loss = 0.3791, Accuracy = 0.7100 Test Loss = 0.3629, Test Accuracy = 0.7860\n",
      "Iteration 129: Loss = 0.2821, Accuracy = 0.8400 Test Loss = 0.3616, Test Accuracy = 0.7857\n",
      "Iteration 130: Loss = 0.5378, Accuracy = 0.7600 Test Loss = 0.3598, Test Accuracy = 0.7853\n",
      "Iteration 131: Loss = 0.3848, Accuracy = 0.7400 Test Loss = 0.3580, Test Accuracy = 0.7884\n",
      "Iteration 132: Loss = 0.3409, Accuracy = 0.7500 Test Loss = 0.3567, Test Accuracy = 0.7897\n",
      "Iteration 133: Loss = 0.3514, Accuracy = 0.7400 Test Loss = 0.3557, Test Accuracy = 0.7910\n",
      "Iteration 134: Loss = 0.4197, Accuracy = 0.7500 Test Loss = 0.3534, Test Accuracy = 0.7894\n",
      "Iteration 135: Loss = 0.3375, Accuracy = 0.7200 Test Loss = 0.3522, Test Accuracy = 0.7906\n",
      "Iteration 136: Loss = 0.3546, Accuracy = 0.8000 Test Loss = 0.3498, Test Accuracy = 0.7926\n",
      "Iteration 137: Loss = 0.3295, Accuracy = 0.7900 Test Loss = 0.3489, Test Accuracy = 0.7925\n",
      "Iteration 138: Loss = 0.3391, Accuracy = 0.7700 Test Loss = 0.3472, Test Accuracy = 0.7969\n",
      "Iteration 139: Loss = 0.3749, Accuracy = 0.8100 Test Loss = 0.3467, Test Accuracy = 0.7897\n",
      "Iteration 140: Loss = 0.3001, Accuracy = 0.8400 Test Loss = 0.3441, Test Accuracy = 0.7959\n",
      "Iteration 141: Loss = 0.3213, Accuracy = 0.8300 Test Loss = 0.3438, Test Accuracy = 0.7952\n",
      "Iteration 142: Loss = 0.3962, Accuracy = 0.7000 Test Loss = 0.3427, Test Accuracy = 0.7921\n",
      "Iteration 143: Loss = 0.3033, Accuracy = 0.8200 Test Loss = 0.3408, Test Accuracy = 0.7940\n",
      "Iteration 144: Loss = 0.2953, Accuracy = 0.8000 Test Loss = 0.3394, Test Accuracy = 0.7976\n",
      "Iteration 145: Loss = 0.3259, Accuracy = 0.7100 Test Loss = 0.3388, Test Accuracy = 0.7976\n",
      "Iteration 146: Loss = 0.3585, Accuracy = 0.7500 Test Loss = 0.3373, Test Accuracy = 0.7963\n",
      "Iteration 147: Loss = 0.2855, Accuracy = 0.7900 Test Loss = 0.3350, Test Accuracy = 0.7984\n",
      "Iteration 148: Loss = 0.3809, Accuracy = 0.7200 Test Loss = 0.3340, Test Accuracy = 0.7990\n",
      "Iteration 149: Loss = 0.2847, Accuracy = 0.8000 Test Loss = 0.3333, Test Accuracy = 0.7991\n",
      "Iteration 150: Loss = 0.2914, Accuracy = 0.8000 Test Loss = 0.3315, Test Accuracy = 0.7990\n",
      "Iteration 151: Loss = 0.3295, Accuracy = 0.7900 Test Loss = 0.3310, Test Accuracy = 0.7988\n",
      "Iteration 152: Loss = 0.3552, Accuracy = 0.7700 Test Loss = 0.3307, Test Accuracy = 0.8012\n",
      "Iteration 153: Loss = 0.3385, Accuracy = 0.7800 Test Loss = 0.3296, Test Accuracy = 0.8011\n",
      "Iteration 154: Loss = 0.3296, Accuracy = 0.7300 Test Loss = 0.3277, Test Accuracy = 0.8054\n",
      "Iteration 155: Loss = 0.2982, Accuracy = 0.8200 Test Loss = 0.3277, Test Accuracy = 0.8025\n",
      "Iteration 156: Loss = 0.3148, Accuracy = 0.7900 Test Loss = 0.3259, Test Accuracy = 0.8056\n",
      "Iteration 157: Loss = 0.3852, Accuracy = 0.7300 Test Loss = 0.3248, Test Accuracy = 0.8045\n",
      "Iteration 158: Loss = 0.2884, Accuracy = 0.8000 Test Loss = 0.3238, Test Accuracy = 0.8043\n",
      "Iteration 159: Loss = 0.4111, Accuracy = 0.7900 Test Loss = 0.3228, Test Accuracy = 0.8079\n",
      "Iteration 160: Loss = 0.2943, Accuracy = 0.8500 Test Loss = 0.3219, Test Accuracy = 0.8045\n",
      "Iteration 161: Loss = 0.4096, Accuracy = 0.7900 Test Loss = 0.3208, Test Accuracy = 0.8054\n",
      "Iteration 162: Loss = 0.3150, Accuracy = 0.7100 Test Loss = 0.3197, Test Accuracy = 0.8064\n",
      "Iteration 163: Loss = 0.2487, Accuracy = 0.8600 Test Loss = 0.3182, Test Accuracy = 0.8076\n",
      "Iteration 164: Loss = 0.2869, Accuracy = 0.7900 Test Loss = 0.3176, Test Accuracy = 0.8081\n",
      "Iteration 165: Loss = 0.3315, Accuracy = 0.7400 Test Loss = 0.3162, Test Accuracy = 0.8053\n",
      "Iteration 166: Loss = 0.2782, Accuracy = 0.8700 Test Loss = 0.3170, Test Accuracy = 0.8044\n",
      "Iteration 167: Loss = 0.2614, Accuracy = 0.8700 Test Loss = 0.3148, Test Accuracy = 0.8049\n",
      "Iteration 168: Loss = 0.3250, Accuracy = 0.7400 Test Loss = 0.3137, Test Accuracy = 0.8115\n",
      "Iteration 169: Loss = 0.3013, Accuracy = 0.7800 Test Loss = 0.3135, Test Accuracy = 0.8103\n",
      "Iteration 170: Loss = 0.2917, Accuracy = 0.8100 Test Loss = 0.3121, Test Accuracy = 0.8093\n",
      "Iteration 171: Loss = 0.3795, Accuracy = 0.7200 Test Loss = 0.3126, Test Accuracy = 0.8089\n",
      "Iteration 172: Loss = 0.3011, Accuracy = 0.7000 Test Loss = 0.3113, Test Accuracy = 0.8111\n",
      "Iteration 173: Loss = 0.2836, Accuracy = 0.7600 Test Loss = 0.3101, Test Accuracy = 0.8120\n",
      "Iteration 174: Loss = 0.2702, Accuracy = 0.8300 Test Loss = 0.3087, Test Accuracy = 0.8103\n",
      "Iteration 175: Loss = 0.2649, Accuracy = 0.8700 Test Loss = 0.3078, Test Accuracy = 0.8089\n",
      "Iteration 176: Loss = 0.4002, Accuracy = 0.7200 Test Loss = 0.3072, Test Accuracy = 0.8113\n",
      "Iteration 177: Loss = 0.4186, Accuracy = 0.7900 Test Loss = 0.3064, Test Accuracy = 0.8101\n",
      "Iteration 178: Loss = 0.2772, Accuracy = 0.7700 Test Loss = 0.3055, Test Accuracy = 0.8153\n",
      "Iteration 179: Loss = 0.3447, Accuracy = 0.7900 Test Loss = 0.3048, Test Accuracy = 0.8124\n",
      "Iteration 180: Loss = 0.3001, Accuracy = 0.8000 Test Loss = 0.3046, Test Accuracy = 0.8087\n",
      "Iteration 181: Loss = 0.3363, Accuracy = 0.8000 Test Loss = 0.3037, Test Accuracy = 0.8122\n",
      "Iteration 182: Loss = 0.2925, Accuracy = 0.8400 Test Loss = 0.3027, Test Accuracy = 0.8143\n",
      "Iteration 183: Loss = 0.3096, Accuracy = 0.8300 Test Loss = 0.3026, Test Accuracy = 0.8122\n",
      "Iteration 184: Loss = 0.3226, Accuracy = 0.7200 Test Loss = 0.3013, Test Accuracy = 0.8175\n",
      "Iteration 185: Loss = 0.3615, Accuracy = 0.7000 Test Loss = 0.3010, Test Accuracy = 0.8109\n",
      "Iteration 186: Loss = 0.4043, Accuracy = 0.7800 Test Loss = 0.2997, Test Accuracy = 0.8157\n",
      "Iteration 187: Loss = 0.3609, Accuracy = 0.7500 Test Loss = 0.2990, Test Accuracy = 0.8163\n",
      "Iteration 188: Loss = 0.3100, Accuracy = 0.8300 Test Loss = 0.2984, Test Accuracy = 0.8148\n",
      "Iteration 189: Loss = 0.3287, Accuracy = 0.8200 Test Loss = 0.2978, Test Accuracy = 0.8170\n",
      "Iteration 190: Loss = 0.3054, Accuracy = 0.7900 Test Loss = 0.2974, Test Accuracy = 0.8150\n",
      "Iteration 191: Loss = 0.2631, Accuracy = 0.8400 Test Loss = 0.2959, Test Accuracy = 0.8174\n",
      "Iteration 192: Loss = 0.3606, Accuracy = 0.8400 Test Loss = 0.2963, Test Accuracy = 0.8127\n",
      "Iteration 193: Loss = 0.2693, Accuracy = 0.8100 Test Loss = 0.2950, Test Accuracy = 0.8166\n",
      "Iteration 194: Loss = 0.3022, Accuracy = 0.8300 Test Loss = 0.2947, Test Accuracy = 0.8146\n",
      "Iteration 195: Loss = 0.3653, Accuracy = 0.7600 Test Loss = 0.2942, Test Accuracy = 0.8178\n",
      "Iteration 196: Loss = 0.2986, Accuracy = 0.7900 Test Loss = 0.2933, Test Accuracy = 0.8163\n",
      "Iteration 197: Loss = 0.2779, Accuracy = 0.7700 Test Loss = 0.2926, Test Accuracy = 0.8193\n",
      "Iteration 198: Loss = 0.3071, Accuracy = 0.7600 Test Loss = 0.2922, Test Accuracy = 0.8143\n",
      "Iteration 199: Loss = 0.2782, Accuracy = 0.8700 Test Loss = 0.2915, Test Accuracy = 0.8208\n",
      "Iteration 200: Loss = 0.3320, Accuracy = 0.7600 Test Loss = 0.2908, Test Accuracy = 0.8181\n",
      "Iteration 201: Loss = 0.2747, Accuracy = 0.8000 Test Loss = 0.2897, Test Accuracy = 0.8176\n",
      "Iteration 202: Loss = 0.2825, Accuracy = 0.8500 Test Loss = 0.2898, Test Accuracy = 0.8219\n",
      "Iteration 203: Loss = 0.4094, Accuracy = 0.7600 Test Loss = 0.2886, Test Accuracy = 0.8224\n",
      "Iteration 204: Loss = 0.2310, Accuracy = 0.8900 Test Loss = 0.2879, Test Accuracy = 0.8198\n",
      "Iteration 205: Loss = 0.2891, Accuracy = 0.7600 Test Loss = 0.2881, Test Accuracy = 0.8191\n",
      "Iteration 206: Loss = 0.3090, Accuracy = 0.7500 Test Loss = 0.2875, Test Accuracy = 0.8191\n",
      "Iteration 207: Loss = 0.3059, Accuracy = 0.8100 Test Loss = 0.2866, Test Accuracy = 0.8226\n",
      "Iteration 208: Loss = 0.3143, Accuracy = 0.7700 Test Loss = 0.2870, Test Accuracy = 0.8197\n",
      "Iteration 209: Loss = 0.2634, Accuracy = 0.8400 Test Loss = 0.2860, Test Accuracy = 0.8198\n",
      "Iteration 210: Loss = 0.3047, Accuracy = 0.7700 Test Loss = 0.2854, Test Accuracy = 0.8192\n",
      "Iteration 211: Loss = 0.2593, Accuracy = 0.8800 Test Loss = 0.2845, Test Accuracy = 0.8224\n",
      "Iteration 212: Loss = 0.2793, Accuracy = 0.8100 Test Loss = 0.2851, Test Accuracy = 0.8169\n",
      "Iteration 213: Loss = 0.2628, Accuracy = 0.8200 Test Loss = 0.2833, Test Accuracy = 0.8224\n",
      "Iteration 214: Loss = 0.2826, Accuracy = 0.7600 Test Loss = 0.2833, Test Accuracy = 0.8212\n",
      "Iteration 215: Loss = 0.2644, Accuracy = 0.8300 Test Loss = 0.2819, Test Accuracy = 0.8221\n",
      "Iteration 216: Loss = 0.3127, Accuracy = 0.7900 Test Loss = 0.2821, Test Accuracy = 0.8234\n",
      "Iteration 217: Loss = 0.3481, Accuracy = 0.7800 Test Loss = 0.2818, Test Accuracy = 0.8206\n",
      "Iteration 218: Loss = 0.2671, Accuracy = 0.8900 Test Loss = 0.2811, Test Accuracy = 0.8218\n",
      "Iteration 219: Loss = 0.2643, Accuracy = 0.8800 Test Loss = 0.2811, Test Accuracy = 0.8211\n",
      "Iteration 220: Loss = 0.2376, Accuracy = 0.8300 Test Loss = 0.2806, Test Accuracy = 0.8210\n",
      "Iteration 221: Loss = 0.2916, Accuracy = 0.7900 Test Loss = 0.2800, Test Accuracy = 0.8212\n",
      "Iteration 222: Loss = 0.4003, Accuracy = 0.7600 Test Loss = 0.2790, Test Accuracy = 0.8251\n",
      "Iteration 223: Loss = 0.3605, Accuracy = 0.8000 Test Loss = 0.2788, Test Accuracy = 0.8225\n",
      "Iteration 224: Loss = 0.2598, Accuracy = 0.7700 Test Loss = 0.2786, Test Accuracy = 0.8230\n",
      "Iteration 225: Loss = 0.2502, Accuracy = 0.8400 Test Loss = 0.2778, Test Accuracy = 0.8232\n",
      "Iteration 226: Loss = 0.2983, Accuracy = 0.7800 Test Loss = 0.2771, Test Accuracy = 0.8267\n",
      "Iteration 227: Loss = 0.3040, Accuracy = 0.8000 Test Loss = 0.2772, Test Accuracy = 0.8246\n",
      "Iteration 228: Loss = 0.3577, Accuracy = 0.8300 Test Loss = 0.2765, Test Accuracy = 0.8240\n",
      "Iteration 229: Loss = 0.3211, Accuracy = 0.7600 Test Loss = 0.2773, Test Accuracy = 0.8219\n",
      "Iteration 230: Loss = 0.2588, Accuracy = 0.8600 Test Loss = 0.2755, Test Accuracy = 0.8238\n",
      "Iteration 231: Loss = 0.2446, Accuracy = 0.8900 Test Loss = 0.2754, Test Accuracy = 0.8263\n",
      "Iteration 232: Loss = 0.3381, Accuracy = 0.7800 Test Loss = 0.2753, Test Accuracy = 0.8244\n",
      "Iteration 233: Loss = 0.2602, Accuracy = 0.7700 Test Loss = 0.2738, Test Accuracy = 0.8255\n",
      "Iteration 234: Loss = 0.2948, Accuracy = 0.8200 Test Loss = 0.2740, Test Accuracy = 0.8258\n",
      "Iteration 235: Loss = 0.3259, Accuracy = 0.8300 Test Loss = 0.2750, Test Accuracy = 0.8248\n",
      "Iteration 236: Loss = 0.2525, Accuracy = 0.8200 Test Loss = 0.2734, Test Accuracy = 0.8258\n",
      "Iteration 237: Loss = 0.3079, Accuracy = 0.8100 Test Loss = 0.2732, Test Accuracy = 0.8295\n",
      "Iteration 238: Loss = 0.2323, Accuracy = 0.8600 Test Loss = 0.2729, Test Accuracy = 0.8239\n",
      "Iteration 239: Loss = 0.3510, Accuracy = 0.8500 Test Loss = 0.2721, Test Accuracy = 0.8262\n",
      "Iteration 240: Loss = 0.3070, Accuracy = 0.8100 Test Loss = 0.2722, Test Accuracy = 0.8276\n",
      "Iteration 241: Loss = 0.2996, Accuracy = 0.7500 Test Loss = 0.2708, Test Accuracy = 0.8302\n",
      "Iteration 242: Loss = 0.3806, Accuracy = 0.7900 Test Loss = 0.2708, Test Accuracy = 0.8251\n",
      "Iteration 243: Loss = 0.2782, Accuracy = 0.8100 Test Loss = 0.2702, Test Accuracy = 0.8273\n",
      "Iteration 244: Loss = 0.2908, Accuracy = 0.8100 Test Loss = 0.2702, Test Accuracy = 0.8308\n",
      "Iteration 245: Loss = 0.2455, Accuracy = 0.8300 Test Loss = 0.2696, Test Accuracy = 0.8304\n",
      "Iteration 246: Loss = 0.2742, Accuracy = 0.8000 Test Loss = 0.2693, Test Accuracy = 0.8298\n",
      "Iteration 247: Loss = 0.3928, Accuracy = 0.6800 Test Loss = 0.2691, Test Accuracy = 0.8269\n",
      "Iteration 248: Loss = 0.2866, Accuracy = 0.8200 Test Loss = 0.2696, Test Accuracy = 0.8270\n",
      "Iteration 249: Loss = 0.2414, Accuracy = 0.7600 Test Loss = 0.2686, Test Accuracy = 0.8291\n",
      "Iteration 250: Loss = 0.2308, Accuracy = 0.8300 Test Loss = 0.2679, Test Accuracy = 0.8264\n",
      "Iteration 251: Loss = 0.2840, Accuracy = 0.7800 Test Loss = 0.2676, Test Accuracy = 0.8303\n",
      "Iteration 252: Loss = 0.2904, Accuracy = 0.8300 Test Loss = 0.2669, Test Accuracy = 0.8284\n",
      "Iteration 253: Loss = 0.3474, Accuracy = 0.8500 Test Loss = 0.2668, Test Accuracy = 0.8305\n",
      "Iteration 254: Loss = 0.2569, Accuracy = 0.8200 Test Loss = 0.2664, Test Accuracy = 0.8286\n",
      "Iteration 255: Loss = 0.2238, Accuracy = 0.8200 Test Loss = 0.2657, Test Accuracy = 0.8296\n",
      "Iteration 256: Loss = 0.3482, Accuracy = 0.8000 Test Loss = 0.2658, Test Accuracy = 0.8287\n",
      "Iteration 257: Loss = 0.2627, Accuracy = 0.8400 Test Loss = 0.2656, Test Accuracy = 0.8257\n",
      "Iteration 258: Loss = 0.2433, Accuracy = 0.8300 Test Loss = 0.2660, Test Accuracy = 0.8282\n",
      "Iteration 259: Loss = 0.2714, Accuracy = 0.7800 Test Loss = 0.2652, Test Accuracy = 0.8312\n",
      "Iteration 260: Loss = 0.2159, Accuracy = 0.8600 Test Loss = 0.2647, Test Accuracy = 0.8278\n",
      "Iteration 261: Loss = 0.2465, Accuracy = 0.8300 Test Loss = 0.2642, Test Accuracy = 0.8294\n",
      "Iteration 262: Loss = 0.2335, Accuracy = 0.8500 Test Loss = 0.2640, Test Accuracy = 0.8299\n",
      "Iteration 263: Loss = 0.2530, Accuracy = 0.8400 Test Loss = 0.2632, Test Accuracy = 0.8296\n",
      "Iteration 264: Loss = 0.2016, Accuracy = 0.8600 Test Loss = 0.2631, Test Accuracy = 0.8307\n",
      "Iteration 265: Loss = 0.2126, Accuracy = 0.8800 Test Loss = 0.2627, Test Accuracy = 0.8333\n",
      "Iteration 266: Loss = 0.2517, Accuracy = 0.8300 Test Loss = 0.2629, Test Accuracy = 0.8311\n",
      "Iteration 267: Loss = 0.2615, Accuracy = 0.8200 Test Loss = 0.2620, Test Accuracy = 0.8326\n",
      "Iteration 268: Loss = 0.2569, Accuracy = 0.8500 Test Loss = 0.2614, Test Accuracy = 0.8339\n",
      "Iteration 269: Loss = 0.2831, Accuracy = 0.8100 Test Loss = 0.2618, Test Accuracy = 0.8297\n",
      "Iteration 270: Loss = 0.2298, Accuracy = 0.8600 Test Loss = 0.2614, Test Accuracy = 0.8294\n",
      "Iteration 271: Loss = 0.3545, Accuracy = 0.7900 Test Loss = 0.2610, Test Accuracy = 0.8329\n",
      "Iteration 272: Loss = 0.2468, Accuracy = 0.8700 Test Loss = 0.2607, Test Accuracy = 0.8324\n",
      "Iteration 273: Loss = 0.2782, Accuracy = 0.7900 Test Loss = 0.2606, Test Accuracy = 0.8337\n",
      "Iteration 274: Loss = 0.3049, Accuracy = 0.7900 Test Loss = 0.2598, Test Accuracy = 0.8332\n",
      "Iteration 275: Loss = 0.3086, Accuracy = 0.8400 Test Loss = 0.2600, Test Accuracy = 0.8334\n",
      "Iteration 276: Loss = 0.2358, Accuracy = 0.8200 Test Loss = 0.2594, Test Accuracy = 0.8317\n",
      "Iteration 277: Loss = 0.2711, Accuracy = 0.8100 Test Loss = 0.2593, Test Accuracy = 0.8374\n",
      "Iteration 278: Loss = 0.2262, Accuracy = 0.8400 Test Loss = 0.2586, Test Accuracy = 0.8345\n",
      "Iteration 279: Loss = 0.2433, Accuracy = 0.8300 Test Loss = 0.2586, Test Accuracy = 0.8337\n",
      "Iteration 280: Loss = 0.3084, Accuracy = 0.8600 Test Loss = 0.2596, Test Accuracy = 0.8334\n",
      "Iteration 281: Loss = 0.2607, Accuracy = 0.7800 Test Loss = 0.2584, Test Accuracy = 0.8307\n",
      "Iteration 282: Loss = 0.2712, Accuracy = 0.8400 Test Loss = 0.2582, Test Accuracy = 0.8351\n",
      "Iteration 283: Loss = 0.2353, Accuracy = 0.8000 Test Loss = 0.2578, Test Accuracy = 0.8346\n",
      "Iteration 284: Loss = 0.2501, Accuracy = 0.8100 Test Loss = 0.2577, Test Accuracy = 0.8327\n",
      "Iteration 285: Loss = 0.3617, Accuracy = 0.8200 Test Loss = 0.2573, Test Accuracy = 0.8300\n",
      "Iteration 286: Loss = 0.2949, Accuracy = 0.7800 Test Loss = 0.2573, Test Accuracy = 0.8339\n",
      "Iteration 287: Loss = 0.2454, Accuracy = 0.8300 Test Loss = 0.2567, Test Accuracy = 0.8318\n",
      "Iteration 288: Loss = 0.2470, Accuracy = 0.8200 Test Loss = 0.2562, Test Accuracy = 0.8323\n",
      "Iteration 289: Loss = 0.2613, Accuracy = 0.8500 Test Loss = 0.2557, Test Accuracy = 0.8318\n",
      "Iteration 290: Loss = 0.2475, Accuracy = 0.8100 Test Loss = 0.2560, Test Accuracy = 0.8349\n",
      "Iteration 291: Loss = 0.2706, Accuracy = 0.7800 Test Loss = 0.2557, Test Accuracy = 0.8377\n",
      "Iteration 292: Loss = 0.2216, Accuracy = 0.8100 Test Loss = 0.2551, Test Accuracy = 0.8315\n",
      "Iteration 293: Loss = 0.2657, Accuracy = 0.7600 Test Loss = 0.2546, Test Accuracy = 0.8337\n",
      "Iteration 294: Loss = 0.2284, Accuracy = 0.8400 Test Loss = 0.2545, Test Accuracy = 0.8350\n",
      "Iteration 295: Loss = 0.2300, Accuracy = 0.7900 Test Loss = 0.2545, Test Accuracy = 0.8346\n",
      "Iteration 296: Loss = 0.2399, Accuracy = 0.8400 Test Loss = 0.2547, Test Accuracy = 0.8314\n",
      "Iteration 297: Loss = 0.2796, Accuracy = 0.7900 Test Loss = 0.2540, Test Accuracy = 0.8337\n",
      "Iteration 298: Loss = 0.2535, Accuracy = 0.8000 Test Loss = 0.2541, Test Accuracy = 0.8353\n",
      "Iteration 299: Loss = 0.2588, Accuracy = 0.8200 Test Loss = 0.2540, Test Accuracy = 0.8372\n",
      "Iteration 300: Loss = 0.2258, Accuracy = 0.8300 Test Loss = 0.2532, Test Accuracy = 0.8335\n",
      "Iteration 301: Loss = 0.2211, Accuracy = 0.8700 Test Loss = 0.2531, Test Accuracy = 0.8352\n",
      "Iteration 302: Loss = 0.2317, Accuracy = 0.8500 Test Loss = 0.2532, Test Accuracy = 0.8316\n",
      "Iteration 303: Loss = 0.2436, Accuracy = 0.7700 Test Loss = 0.2528, Test Accuracy = 0.8373\n",
      "Iteration 304: Loss = 0.2447, Accuracy = 0.8800 Test Loss = 0.2524, Test Accuracy = 0.8356\n",
      "Iteration 305: Loss = 0.2644, Accuracy = 0.8100 Test Loss = 0.2521, Test Accuracy = 0.8359\n",
      "Iteration 306: Loss = 0.2779, Accuracy = 0.8200 Test Loss = 0.2519, Test Accuracy = 0.8371\n",
      "Iteration 307: Loss = 0.2703, Accuracy = 0.8000 Test Loss = 0.2520, Test Accuracy = 0.8342\n",
      "Iteration 308: Loss = 0.3061, Accuracy = 0.7800 Test Loss = 0.2517, Test Accuracy = 0.8339\n",
      "Iteration 309: Loss = 0.2759, Accuracy = 0.8300 Test Loss = 0.2516, Test Accuracy = 0.8341\n",
      "Iteration 310: Loss = 0.2233, Accuracy = 0.8500 Test Loss = 0.2515, Test Accuracy = 0.8325\n",
      "Iteration 311: Loss = 0.2214, Accuracy = 0.9100 Test Loss = 0.2510, Test Accuracy = 0.8330\n",
      "Iteration 312: Loss = 0.2380, Accuracy = 0.8200 Test Loss = 0.2508, Test Accuracy = 0.8335\n",
      "Iteration 313: Loss = 0.2650, Accuracy = 0.7800 Test Loss = 0.2505, Test Accuracy = 0.8344\n",
      "Iteration 314: Loss = 0.2312, Accuracy = 0.8200 Test Loss = 0.2509, Test Accuracy = 0.8318\n",
      "Iteration 315: Loss = 0.2645, Accuracy = 0.8400 Test Loss = 0.2502, Test Accuracy = 0.8348\n",
      "Iteration 316: Loss = 0.2442, Accuracy = 0.8000 Test Loss = 0.2504, Test Accuracy = 0.8297\n",
      "Iteration 317: Loss = 0.2705, Accuracy = 0.7800 Test Loss = 0.2501, Test Accuracy = 0.8333\n",
      "Iteration 318: Loss = 0.2874, Accuracy = 0.7900 Test Loss = 0.2494, Test Accuracy = 0.8353\n",
      "Iteration 319: Loss = 0.2484, Accuracy = 0.8800 Test Loss = 0.2492, Test Accuracy = 0.8322\n",
      "Iteration 320: Loss = 0.2813, Accuracy = 0.8500 Test Loss = 0.2492, Test Accuracy = 0.8365\n",
      "Iteration 321: Loss = 0.2443, Accuracy = 0.8400 Test Loss = 0.2493, Test Accuracy = 0.8343\n",
      "Iteration 322: Loss = 0.2065, Accuracy = 0.8500 Test Loss = 0.2493, Test Accuracy = 0.8311\n",
      "Iteration 323: Loss = 0.3201, Accuracy = 0.8200 Test Loss = 0.2491, Test Accuracy = 0.8367\n",
      "Iteration 324: Loss = 0.2655, Accuracy = 0.8000 Test Loss = 0.2489, Test Accuracy = 0.8381\n",
      "Iteration 325: Loss = 0.2917, Accuracy = 0.7700 Test Loss = 0.2480, Test Accuracy = 0.8372\n",
      "Iteration 326: Loss = 0.2287, Accuracy = 0.7800 Test Loss = 0.2484, Test Accuracy = 0.8346\n",
      "Iteration 327: Loss = 0.2178, Accuracy = 0.8600 Test Loss = 0.2475, Test Accuracy = 0.8344\n",
      "Iteration 328: Loss = 0.2891, Accuracy = 0.7300 Test Loss = 0.2475, Test Accuracy = 0.8374\n",
      "Iteration 329: Loss = 0.2313, Accuracy = 0.8200 Test Loss = 0.2471, Test Accuracy = 0.8381\n",
      "Iteration 330: Loss = 0.2512, Accuracy = 0.8800 Test Loss = 0.2476, Test Accuracy = 0.8377\n",
      "Iteration 331: Loss = 0.2472, Accuracy = 0.8200 Test Loss = 0.2469, Test Accuracy = 0.8365\n",
      "Iteration 332: Loss = 0.2480, Accuracy = 0.7900 Test Loss = 0.2465, Test Accuracy = 0.8354\n",
      "Iteration 333: Loss = 0.2491, Accuracy = 0.7800 Test Loss = 0.2467, Test Accuracy = 0.8382\n",
      "Iteration 334: Loss = 0.2680, Accuracy = 0.8900 Test Loss = 0.2468, Test Accuracy = 0.8334\n",
      "Iteration 335: Loss = 0.3083, Accuracy = 0.8000 Test Loss = 0.2464, Test Accuracy = 0.8372\n",
      "Iteration 336: Loss = 0.2791, Accuracy = 0.7900 Test Loss = 0.2461, Test Accuracy = 0.8338\n",
      "Iteration 337: Loss = 0.2533, Accuracy = 0.7800 Test Loss = 0.2460, Test Accuracy = 0.8363\n",
      "Iteration 338: Loss = 0.2951, Accuracy = 0.8100 Test Loss = 0.2464, Test Accuracy = 0.8377\n",
      "Iteration 339: Loss = 0.2637, Accuracy = 0.8700 Test Loss = 0.2463, Test Accuracy = 0.8321\n",
      "Iteration 340: Loss = 0.2754, Accuracy = 0.8100 Test Loss = 0.2448, Test Accuracy = 0.8374\n",
      "Iteration 341: Loss = 0.2345, Accuracy = 0.8200 Test Loss = 0.2453, Test Accuracy = 0.8384\n",
      "Iteration 342: Loss = 0.2373, Accuracy = 0.8200 Test Loss = 0.2454, Test Accuracy = 0.8372\n",
      "Iteration 343: Loss = 0.2391, Accuracy = 0.8900 Test Loss = 0.2449, Test Accuracy = 0.8388\n",
      "Iteration 344: Loss = 0.2650, Accuracy = 0.8100 Test Loss = 0.2455, Test Accuracy = 0.8375\n",
      "Iteration 345: Loss = 0.2344, Accuracy = 0.8300 Test Loss = 0.2446, Test Accuracy = 0.8387\n",
      "Iteration 346: Loss = 0.3041, Accuracy = 0.8000 Test Loss = 0.2443, Test Accuracy = 0.8328\n",
      "Iteration 347: Loss = 0.2498, Accuracy = 0.9000 Test Loss = 0.2448, Test Accuracy = 0.8362\n",
      "Iteration 348: Loss = 0.2322, Accuracy = 0.8000 Test Loss = 0.2438, Test Accuracy = 0.8380\n",
      "Iteration 349: Loss = 0.2888, Accuracy = 0.8100 Test Loss = 0.2437, Test Accuracy = 0.8375\n",
      "Iteration 350: Loss = 0.2549, Accuracy = 0.8300 Test Loss = 0.2438, Test Accuracy = 0.8384\n",
      "Iteration 351: Loss = 0.2661, Accuracy = 0.8800 Test Loss = 0.2436, Test Accuracy = 0.8385\n",
      "Iteration 352: Loss = 0.3088, Accuracy = 0.8400 Test Loss = 0.2433, Test Accuracy = 0.8373\n",
      "Iteration 353: Loss = 0.3216, Accuracy = 0.7900 Test Loss = 0.2429, Test Accuracy = 0.8370\n",
      "Iteration 354: Loss = 0.2140, Accuracy = 0.8600 Test Loss = 0.2431, Test Accuracy = 0.8351\n",
      "Iteration 355: Loss = 0.2766, Accuracy = 0.7700 Test Loss = 0.2435, Test Accuracy = 0.8330\n",
      "Iteration 356: Loss = 0.2851, Accuracy = 0.7600 Test Loss = 0.2430, Test Accuracy = 0.8362\n",
      "Iteration 357: Loss = 0.2239, Accuracy = 0.8600 Test Loss = 0.2426, Test Accuracy = 0.8326\n",
      "Iteration 358: Loss = 0.2323, Accuracy = 0.8900 Test Loss = 0.2426, Test Accuracy = 0.8393\n",
      "Iteration 359: Loss = 0.2276, Accuracy = 0.8600 Test Loss = 0.2420, Test Accuracy = 0.8364\n",
      "Iteration 360: Loss = 0.2774, Accuracy = 0.7700 Test Loss = 0.2427, Test Accuracy = 0.8361\n",
      "Iteration 361: Loss = 0.2410, Accuracy = 0.8400 Test Loss = 0.2424, Test Accuracy = 0.8352\n",
      "Iteration 362: Loss = 0.3500, Accuracy = 0.8100 Test Loss = 0.2428, Test Accuracy = 0.8369\n",
      "Iteration 363: Loss = 0.2276, Accuracy = 0.8000 Test Loss = 0.2420, Test Accuracy = 0.8341\n",
      "Iteration 364: Loss = 0.3110, Accuracy = 0.7900 Test Loss = 0.2417, Test Accuracy = 0.8403\n",
      "Iteration 365: Loss = 0.2814, Accuracy = 0.7800 Test Loss = 0.2412, Test Accuracy = 0.8381\n",
      "Iteration 366: Loss = 0.2137, Accuracy = 0.9000 Test Loss = 0.2413, Test Accuracy = 0.8389\n",
      "Iteration 367: Loss = 0.2440, Accuracy = 0.7900 Test Loss = 0.2414, Test Accuracy = 0.8377\n",
      "Iteration 368: Loss = 0.2261, Accuracy = 0.8500 Test Loss = 0.2408, Test Accuracy = 0.8386\n",
      "Iteration 369: Loss = 0.2411, Accuracy = 0.8100 Test Loss = 0.2410, Test Accuracy = 0.8387\n",
      "Iteration 370: Loss = 0.2573, Accuracy = 0.8200 Test Loss = 0.2407, Test Accuracy = 0.8386\n",
      "Iteration 371: Loss = 0.2443, Accuracy = 0.8000 Test Loss = 0.2402, Test Accuracy = 0.8376\n",
      "Iteration 372: Loss = 0.2106, Accuracy = 0.8600 Test Loss = 0.2407, Test Accuracy = 0.8356\n",
      "Iteration 373: Loss = 0.1957, Accuracy = 0.8800 Test Loss = 0.2402, Test Accuracy = 0.8392\n",
      "Iteration 374: Loss = 0.2017, Accuracy = 0.8600 Test Loss = 0.2398, Test Accuracy = 0.8368\n",
      "Iteration 375: Loss = 0.2339, Accuracy = 0.8300 Test Loss = 0.2398, Test Accuracy = 0.8393\n",
      "Iteration 376: Loss = 0.2282, Accuracy = 0.8100 Test Loss = 0.2398, Test Accuracy = 0.8387\n",
      "Iteration 377: Loss = 0.2670, Accuracy = 0.7600 Test Loss = 0.2402, Test Accuracy = 0.8357\n",
      "Iteration 378: Loss = 0.2422, Accuracy = 0.7700 Test Loss = 0.2395, Test Accuracy = 0.8395\n",
      "Iteration 379: Loss = 0.3615, Accuracy = 0.8200 Test Loss = 0.2394, Test Accuracy = 0.8402\n",
      "Iteration 380: Loss = 0.2542, Accuracy = 0.7600 Test Loss = 0.2395, Test Accuracy = 0.8384\n",
      "Iteration 381: Loss = 0.2475, Accuracy = 0.8300 Test Loss = 0.2392, Test Accuracy = 0.8433\n",
      "Iteration 382: Loss = 0.2074, Accuracy = 0.8600 Test Loss = 0.2389, Test Accuracy = 0.8362\n",
      "Iteration 383: Loss = 0.2397, Accuracy = 0.8100 Test Loss = 0.2387, Test Accuracy = 0.8355\n",
      "Iteration 384: Loss = 0.2240, Accuracy = 0.8000 Test Loss = 0.2386, Test Accuracy = 0.8385\n",
      "Iteration 385: Loss = 0.1912, Accuracy = 0.8600 Test Loss = 0.2393, Test Accuracy = 0.8403\n",
      "Iteration 386: Loss = 0.1896, Accuracy = 0.9100 Test Loss = 0.2388, Test Accuracy = 0.8370\n",
      "Iteration 387: Loss = 0.2444, Accuracy = 0.8300 Test Loss = 0.2388, Test Accuracy = 0.8359\n",
      "Iteration 388: Loss = 0.2778, Accuracy = 0.8100 Test Loss = 0.2383, Test Accuracy = 0.8399\n",
      "Iteration 389: Loss = 0.2675, Accuracy = 0.8500 Test Loss = 0.2388, Test Accuracy = 0.8379\n",
      "Iteration 390: Loss = 0.2480, Accuracy = 0.8600 Test Loss = 0.2383, Test Accuracy = 0.8360\n",
      "Iteration 391: Loss = 0.2160, Accuracy = 0.7900 Test Loss = 0.2381, Test Accuracy = 0.8419\n",
      "Iteration 392: Loss = 0.2613, Accuracy = 0.8200 Test Loss = 0.2387, Test Accuracy = 0.8396\n",
      "Iteration 393: Loss = 0.2436, Accuracy = 0.8400 Test Loss = 0.2377, Test Accuracy = 0.8389\n",
      "Iteration 394: Loss = 0.2527, Accuracy = 0.7500 Test Loss = 0.2373, Test Accuracy = 0.8406\n",
      "Iteration 395: Loss = 0.2302, Accuracy = 0.8300 Test Loss = 0.2374, Test Accuracy = 0.8426\n",
      "Iteration 396: Loss = 0.2115, Accuracy = 0.8400 Test Loss = 0.2371, Test Accuracy = 0.8388\n",
      "Iteration 397: Loss = 0.2361, Accuracy = 0.8500 Test Loss = 0.2373, Test Accuracy = 0.8378\n",
      "Iteration 398: Loss = 0.3574, Accuracy = 0.7600 Test Loss = 0.2375, Test Accuracy = 0.8411\n",
      "Iteration 399: Loss = 0.2286, Accuracy = 0.8600 Test Loss = 0.2370, Test Accuracy = 0.8415\n",
      "Iteration 400: Loss = 0.2516, Accuracy = 0.7700 Test Loss = 0.2374, Test Accuracy = 0.8419\n",
      "Iteration 401: Loss = 0.2346, Accuracy = 0.8400 Test Loss = 0.2366, Test Accuracy = 0.8401\n",
      "Iteration 402: Loss = 0.2299, Accuracy = 0.8300 Test Loss = 0.2366, Test Accuracy = 0.8418\n",
      "Iteration 403: Loss = 0.2442, Accuracy = 0.7900 Test Loss = 0.2371, Test Accuracy = 0.8391\n",
      "Iteration 404: Loss = 0.2121, Accuracy = 0.8600 Test Loss = 0.2367, Test Accuracy = 0.8429\n",
      "Iteration 405: Loss = 0.2577, Accuracy = 0.7700 Test Loss = 0.2366, Test Accuracy = 0.8420\n",
      "Iteration 406: Loss = 0.2365, Accuracy = 0.8800 Test Loss = 0.2362, Test Accuracy = 0.8394\n",
      "Iteration 407: Loss = 0.1688, Accuracy = 0.9200 Test Loss = 0.2362, Test Accuracy = 0.8410\n",
      "Iteration 408: Loss = 0.2113, Accuracy = 0.8400 Test Loss = 0.2353, Test Accuracy = 0.8412\n",
      "Iteration 409: Loss = 0.2663, Accuracy = 0.8100 Test Loss = 0.2354, Test Accuracy = 0.8411\n",
      "Iteration 410: Loss = 0.2372, Accuracy = 0.8600 Test Loss = 0.2355, Test Accuracy = 0.8423\n",
      "Iteration 411: Loss = 0.2301, Accuracy = 0.8700 Test Loss = 0.2361, Test Accuracy = 0.8395\n",
      "Iteration 412: Loss = 0.2772, Accuracy = 0.8500 Test Loss = 0.2355, Test Accuracy = 0.8400\n",
      "Iteration 413: Loss = 0.2588, Accuracy = 0.8000 Test Loss = 0.2355, Test Accuracy = 0.8390\n",
      "Iteration 414: Loss = 0.2226, Accuracy = 0.8500 Test Loss = 0.2349, Test Accuracy = 0.8415\n",
      "Iteration 415: Loss = 0.2626, Accuracy = 0.7600 Test Loss = 0.2349, Test Accuracy = 0.8420\n",
      "Iteration 416: Loss = 0.2385, Accuracy = 0.8300 Test Loss = 0.2351, Test Accuracy = 0.8383\n",
      "Iteration 417: Loss = 0.2157, Accuracy = 0.8300 Test Loss = 0.2348, Test Accuracy = 0.8389\n",
      "Iteration 418: Loss = 0.2300, Accuracy = 0.8300 Test Loss = 0.2351, Test Accuracy = 0.8415\n",
      "Iteration 419: Loss = 0.2383, Accuracy = 0.7800 Test Loss = 0.2348, Test Accuracy = 0.8416\n",
      "Iteration 420: Loss = 0.2385, Accuracy = 0.8400 Test Loss = 0.2345, Test Accuracy = 0.8418\n",
      "Iteration 421: Loss = 0.2553, Accuracy = 0.8100 Test Loss = 0.2342, Test Accuracy = 0.8452\n",
      "Iteration 422: Loss = 0.2414, Accuracy = 0.8200 Test Loss = 0.2341, Test Accuracy = 0.8419\n",
      "Iteration 423: Loss = 0.2468, Accuracy = 0.8400 Test Loss = 0.2344, Test Accuracy = 0.8413\n",
      "Iteration 424: Loss = 0.2126, Accuracy = 0.9100 Test Loss = 0.2342, Test Accuracy = 0.8403\n",
      "Iteration 425: Loss = 0.2175, Accuracy = 0.8800 Test Loss = 0.2341, Test Accuracy = 0.8426\n",
      "Iteration 426: Loss = 0.2099, Accuracy = 0.8600 Test Loss = 0.2337, Test Accuracy = 0.8435\n",
      "Iteration 427: Loss = 0.2409, Accuracy = 0.8100 Test Loss = 0.2337, Test Accuracy = 0.8409\n",
      "Iteration 428: Loss = 0.2459, Accuracy = 0.7800 Test Loss = 0.2339, Test Accuracy = 0.8389\n",
      "Iteration 429: Loss = 0.2342, Accuracy = 0.8600 Test Loss = 0.2333, Test Accuracy = 0.8442\n",
      "Iteration 430: Loss = 0.2467, Accuracy = 0.8100 Test Loss = 0.2336, Test Accuracy = 0.8402\n",
      "Iteration 431: Loss = 0.2433, Accuracy = 0.8200 Test Loss = 0.2333, Test Accuracy = 0.8434\n",
      "Iteration 432: Loss = 0.2464, Accuracy = 0.8100 Test Loss = 0.2337, Test Accuracy = 0.8421\n",
      "Iteration 433: Loss = 0.2281, Accuracy = 0.8400 Test Loss = 0.2330, Test Accuracy = 0.8422\n",
      "Iteration 434: Loss = 0.2278, Accuracy = 0.8500 Test Loss = 0.2331, Test Accuracy = 0.8457\n",
      "Iteration 435: Loss = 0.2229, Accuracy = 0.8500 Test Loss = 0.2329, Test Accuracy = 0.8430\n",
      "Iteration 436: Loss = 0.2178, Accuracy = 0.8300 Test Loss = 0.2327, Test Accuracy = 0.8421\n",
      "Iteration 437: Loss = 0.2189, Accuracy = 0.8900 Test Loss = 0.2328, Test Accuracy = 0.8426\n",
      "Iteration 438: Loss = 0.2497, Accuracy = 0.8100 Test Loss = 0.2327, Test Accuracy = 0.8435\n",
      "Iteration 439: Loss = 0.2018, Accuracy = 0.8500 Test Loss = 0.2324, Test Accuracy = 0.8410\n",
      "Iteration 440: Loss = 0.2303, Accuracy = 0.8700 Test Loss = 0.2325, Test Accuracy = 0.8427\n",
      "Iteration 441: Loss = 0.2216, Accuracy = 0.8400 Test Loss = 0.2324, Test Accuracy = 0.8429\n",
      "Iteration 442: Loss = 0.2131, Accuracy = 0.8400 Test Loss = 0.2321, Test Accuracy = 0.8413\n",
      "Iteration 443: Loss = 0.2984, Accuracy = 0.7800 Test Loss = 0.2329, Test Accuracy = 0.8385\n",
      "Iteration 444: Loss = 0.2332, Accuracy = 0.8500 Test Loss = 0.2321, Test Accuracy = 0.8418\n",
      "Iteration 445: Loss = 0.1916, Accuracy = 0.8600 Test Loss = 0.2319, Test Accuracy = 0.8420\n",
      "Iteration 446: Loss = 0.2180, Accuracy = 0.8600 Test Loss = 0.2324, Test Accuracy = 0.8415\n",
      "Iteration 447: Loss = 0.2636, Accuracy = 0.8600 Test Loss = 0.2319, Test Accuracy = 0.8432\n",
      "Iteration 448: Loss = 0.2421, Accuracy = 0.8300 Test Loss = 0.2322, Test Accuracy = 0.8418\n",
      "Iteration 449: Loss = 0.2263, Accuracy = 0.8100 Test Loss = 0.2319, Test Accuracy = 0.8406\n",
      "Iteration 450: Loss = 0.2169, Accuracy = 0.8300 Test Loss = 0.2313, Test Accuracy = 0.8401\n",
      "Iteration 451: Loss = 0.1905, Accuracy = 0.9000 Test Loss = 0.2313, Test Accuracy = 0.8447\n",
      "Iteration 452: Loss = 0.2286, Accuracy = 0.8400 Test Loss = 0.2311, Test Accuracy = 0.8396\n",
      "Iteration 453: Loss = 0.2253, Accuracy = 0.8200 Test Loss = 0.2317, Test Accuracy = 0.8406\n",
      "Iteration 454: Loss = 0.2454, Accuracy = 0.8500 Test Loss = 0.2309, Test Accuracy = 0.8433\n",
      "Iteration 455: Loss = 0.2392, Accuracy = 0.8500 Test Loss = 0.2317, Test Accuracy = 0.8431\n",
      "Iteration 456: Loss = 0.2093, Accuracy = 0.8900 Test Loss = 0.2313, Test Accuracy = 0.8410\n",
      "Iteration 457: Loss = 0.2237, Accuracy = 0.8300 Test Loss = 0.2313, Test Accuracy = 0.8434\n",
      "Iteration 458: Loss = 0.2106, Accuracy = 0.8700 Test Loss = 0.2308, Test Accuracy = 0.8416\n",
      "Iteration 459: Loss = 0.2536, Accuracy = 0.7600 Test Loss = 0.2312, Test Accuracy = 0.8452\n",
      "Iteration 460: Loss = 0.2188, Accuracy = 0.8900 Test Loss = 0.2310, Test Accuracy = 0.8393\n",
      "Iteration 461: Loss = 0.2458, Accuracy = 0.8200 Test Loss = 0.2303, Test Accuracy = 0.8451\n",
      "Iteration 462: Loss = 0.2839, Accuracy = 0.8300 Test Loss = 0.2305, Test Accuracy = 0.8425\n",
      "Iteration 463: Loss = 0.2084, Accuracy = 0.8100 Test Loss = 0.2305, Test Accuracy = 0.8416\n",
      "Iteration 464: Loss = 0.2425, Accuracy = 0.8300 Test Loss = 0.2313, Test Accuracy = 0.8426\n",
      "Iteration 465: Loss = 0.2396, Accuracy = 0.8800 Test Loss = 0.2305, Test Accuracy = 0.8444\n",
      "Iteration 466: Loss = 0.2237, Accuracy = 0.8500 Test Loss = 0.2310, Test Accuracy = 0.8459\n",
      "Iteration 467: Loss = 0.2013, Accuracy = 0.8600 Test Loss = 0.2297, Test Accuracy = 0.8433\n",
      "Iteration 468: Loss = 0.2295, Accuracy = 0.8000 Test Loss = 0.2305, Test Accuracy = 0.8399\n",
      "Iteration 469: Loss = 0.2264, Accuracy = 0.8300 Test Loss = 0.2299, Test Accuracy = 0.8411\n",
      "Iteration 470: Loss = 0.2379, Accuracy = 0.8300 Test Loss = 0.2295, Test Accuracy = 0.8407\n",
      "Iteration 471: Loss = 0.2308, Accuracy = 0.8200 Test Loss = 0.2300, Test Accuracy = 0.8398\n",
      "Iteration 472: Loss = 0.2511, Accuracy = 0.8000 Test Loss = 0.2298, Test Accuracy = 0.8420\n",
      "Iteration 473: Loss = 0.2567, Accuracy = 0.8400 Test Loss = 0.2300, Test Accuracy = 0.8423\n",
      "Iteration 474: Loss = 0.1901, Accuracy = 0.9300 Test Loss = 0.2296, Test Accuracy = 0.8435\n",
      "Iteration 475: Loss = 0.2046, Accuracy = 0.8600 Test Loss = 0.2295, Test Accuracy = 0.8432\n",
      "Iteration 476: Loss = 0.2043, Accuracy = 0.8500 Test Loss = 0.2296, Test Accuracy = 0.8417\n",
      "Iteration 477: Loss = 0.2037, Accuracy = 0.8400 Test Loss = 0.2295, Test Accuracy = 0.8425\n",
      "Iteration 478: Loss = 0.2073, Accuracy = 0.9100 Test Loss = 0.2293, Test Accuracy = 0.8417\n",
      "Iteration 479: Loss = 0.2626, Accuracy = 0.8700 Test Loss = 0.2288, Test Accuracy = 0.8440\n",
      "Iteration 480: Loss = 0.2000, Accuracy = 0.8400 Test Loss = 0.2290, Test Accuracy = 0.8385\n",
      "Iteration 481: Loss = 0.2358, Accuracy = 0.8400 Test Loss = 0.2285, Test Accuracy = 0.8435\n",
      "Iteration 482: Loss = 0.1947, Accuracy = 0.8600 Test Loss = 0.2289, Test Accuracy = 0.8436\n",
      "Iteration 483: Loss = 0.2828, Accuracy = 0.8200 Test Loss = 0.2287, Test Accuracy = 0.8408\n",
      "Iteration 484: Loss = 0.2101, Accuracy = 0.8800 Test Loss = 0.2287, Test Accuracy = 0.8402\n",
      "Iteration 485: Loss = 0.2311, Accuracy = 0.8000 Test Loss = 0.2286, Test Accuracy = 0.8431\n",
      "Iteration 486: Loss = 0.2203, Accuracy = 0.8500 Test Loss = 0.2285, Test Accuracy = 0.8406\n",
      "Iteration 487: Loss = 0.2737, Accuracy = 0.8000 Test Loss = 0.2284, Test Accuracy = 0.8435\n",
      "Iteration 488: Loss = 0.2508, Accuracy = 0.7900 Test Loss = 0.2284, Test Accuracy = 0.8393\n",
      "Iteration 489: Loss = 0.2071, Accuracy = 0.8900 Test Loss = 0.2281, Test Accuracy = 0.8433\n",
      "Iteration 490: Loss = 0.1797, Accuracy = 0.9400 Test Loss = 0.2280, Test Accuracy = 0.8426\n",
      "Iteration 491: Loss = 0.2579, Accuracy = 0.8100 Test Loss = 0.2282, Test Accuracy = 0.8454\n",
      "Iteration 492: Loss = 0.2319, Accuracy = 0.8900 Test Loss = 0.2283, Test Accuracy = 0.8441\n",
      "Iteration 493: Loss = 0.2245, Accuracy = 0.8500 Test Loss = 0.2283, Test Accuracy = 0.8458\n",
      "Iteration 494: Loss = 0.2470, Accuracy = 0.8400 Test Loss = 0.2284, Test Accuracy = 0.8437\n",
      "Iteration 495: Loss = 0.2380, Accuracy = 0.7700 Test Loss = 0.2278, Test Accuracy = 0.8441\n",
      "Iteration 496: Loss = 0.2108, Accuracy = 0.8800 Test Loss = 0.2280, Test Accuracy = 0.8421\n",
      "Iteration 497: Loss = 0.2285, Accuracy = 0.8500 Test Loss = 0.2276, Test Accuracy = 0.8418\n",
      "Iteration 498: Loss = 0.1988, Accuracy = 0.9000 Test Loss = 0.2280, Test Accuracy = 0.8443\n",
      "Iteration 499: Loss = 0.2418, Accuracy = 0.8600 Test Loss = 0.2274, Test Accuracy = 0.8439\n",
      "Iteration 500: Loss = 0.2361, Accuracy = 0.8000 Test Loss = 0.2273, Test Accuracy = 0.8457\n",
      "Iteration 501: Loss = 0.2711, Accuracy = 0.8200 Test Loss = 0.2275, Test Accuracy = 0.8416\n",
      "Iteration 502: Loss = 0.2358, Accuracy = 0.9000 Test Loss = 0.2273, Test Accuracy = 0.8423\n",
      "Iteration 503: Loss = 0.2066, Accuracy = 0.8700 Test Loss = 0.2279, Test Accuracy = 0.8414\n",
      "Iteration 504: Loss = 0.1944, Accuracy = 0.8700 Test Loss = 0.2278, Test Accuracy = 0.8413\n",
      "Iteration 505: Loss = 0.2423, Accuracy = 0.7400 Test Loss = 0.2279, Test Accuracy = 0.8444\n",
      "Iteration 506: Loss = 0.2228, Accuracy = 0.8400 Test Loss = 0.2269, Test Accuracy = 0.8451\n",
      "Iteration 507: Loss = 0.2313, Accuracy = 0.8300 Test Loss = 0.2271, Test Accuracy = 0.8433\n",
      "Iteration 508: Loss = 0.2134, Accuracy = 0.8500 Test Loss = 0.2269, Test Accuracy = 0.8446\n",
      "Iteration 509: Loss = 0.2085, Accuracy = 0.8900 Test Loss = 0.2269, Test Accuracy = 0.8411\n",
      "Iteration 510: Loss = 0.2451, Accuracy = 0.7800 Test Loss = 0.2264, Test Accuracy = 0.8413\n",
      "Iteration 511: Loss = 0.2268, Accuracy = 0.8000 Test Loss = 0.2269, Test Accuracy = 0.8455\n",
      "Iteration 512: Loss = 0.2313, Accuracy = 0.8000 Test Loss = 0.2266, Test Accuracy = 0.8425\n",
      "Iteration 513: Loss = 0.1776, Accuracy = 0.9100 Test Loss = 0.2266, Test Accuracy = 0.8429\n",
      "Iteration 514: Loss = 0.2042, Accuracy = 0.8900 Test Loss = 0.2265, Test Accuracy = 0.8450\n",
      "Iteration 515: Loss = 0.2241, Accuracy = 0.8300 Test Loss = 0.2266, Test Accuracy = 0.8427\n",
      "Iteration 516: Loss = 0.2505, Accuracy = 0.7700 Test Loss = 0.2264, Test Accuracy = 0.8418\n",
      "Iteration 517: Loss = 0.2096, Accuracy = 0.8800 Test Loss = 0.2266, Test Accuracy = 0.8423\n",
      "Iteration 518: Loss = 0.2184, Accuracy = 0.8600 Test Loss = 0.2261, Test Accuracy = 0.8446\n",
      "Iteration 519: Loss = 0.2286, Accuracy = 0.8200 Test Loss = 0.2261, Test Accuracy = 0.8426\n",
      "Iteration 520: Loss = 0.2216, Accuracy = 0.8300 Test Loss = 0.2262, Test Accuracy = 0.8417\n",
      "Iteration 521: Loss = 0.2375, Accuracy = 0.7900 Test Loss = 0.2260, Test Accuracy = 0.8453\n",
      "Iteration 522: Loss = 0.2347, Accuracy = 0.8400 Test Loss = 0.2260, Test Accuracy = 0.8409\n",
      "Iteration 523: Loss = 0.2136, Accuracy = 0.8100 Test Loss = 0.2255, Test Accuracy = 0.8436\n",
      "Iteration 524: Loss = 0.2297, Accuracy = 0.8000 Test Loss = 0.2265, Test Accuracy = 0.8437\n",
      "Iteration 525: Loss = 0.2487, Accuracy = 0.8300 Test Loss = 0.2268, Test Accuracy = 0.8464\n",
      "Iteration 526: Loss = 0.2344, Accuracy = 0.7900 Test Loss = 0.2266, Test Accuracy = 0.8453\n",
      "Iteration 527: Loss = 0.2058, Accuracy = 0.8400 Test Loss = 0.2258, Test Accuracy = 0.8412\n",
      "Iteration 528: Loss = 0.2301, Accuracy = 0.8300 Test Loss = 0.2258, Test Accuracy = 0.8439\n",
      "Iteration 529: Loss = 0.2196, Accuracy = 0.8800 Test Loss = 0.2258, Test Accuracy = 0.8456\n",
      "Iteration 530: Loss = 0.2361, Accuracy = 0.7900 Test Loss = 0.2259, Test Accuracy = 0.8413\n",
      "Iteration 531: Loss = 0.3144, Accuracy = 0.8300 Test Loss = 0.2255, Test Accuracy = 0.8416\n",
      "Iteration 532: Loss = 0.2166, Accuracy = 0.8800 Test Loss = 0.2257, Test Accuracy = 0.8469\n",
      "Iteration 533: Loss = 0.3013, Accuracy = 0.8300 Test Loss = 0.2254, Test Accuracy = 0.8425\n",
      "Iteration 534: Loss = 0.2284, Accuracy = 0.8100 Test Loss = 0.2257, Test Accuracy = 0.8450\n",
      "Iteration 535: Loss = 0.2147, Accuracy = 0.8400 Test Loss = 0.2254, Test Accuracy = 0.8447\n",
      "Iteration 536: Loss = 0.2155, Accuracy = 0.8700 Test Loss = 0.2251, Test Accuracy = 0.8438\n",
      "Iteration 537: Loss = 0.2572, Accuracy = 0.8200 Test Loss = 0.2255, Test Accuracy = 0.8443\n",
      "Iteration 538: Loss = 0.2178, Accuracy = 0.8700 Test Loss = 0.2250, Test Accuracy = 0.8430\n",
      "Iteration 539: Loss = 0.2095, Accuracy = 0.8300 Test Loss = 0.2245, Test Accuracy = 0.8444\n",
      "Iteration 540: Loss = 0.2345, Accuracy = 0.8100 Test Loss = 0.2254, Test Accuracy = 0.8482\n",
      "Iteration 541: Loss = 0.1971, Accuracy = 0.8600 Test Loss = 0.2249, Test Accuracy = 0.8433\n",
      "Iteration 542: Loss = 0.2164, Accuracy = 0.9000 Test Loss = 0.2249, Test Accuracy = 0.8447\n",
      "Iteration 543: Loss = 0.2588, Accuracy = 0.8100 Test Loss = 0.2248, Test Accuracy = 0.8440\n",
      "Iteration 544: Loss = 0.1815, Accuracy = 0.8700 Test Loss = 0.2256, Test Accuracy = 0.8378\n",
      "Iteration 545: Loss = 0.1884, Accuracy = 0.8800 Test Loss = 0.2251, Test Accuracy = 0.8453\n",
      "Iteration 546: Loss = 0.2236, Accuracy = 0.8400 Test Loss = 0.2242, Test Accuracy = 0.8450\n",
      "Iteration 547: Loss = 0.2537, Accuracy = 0.7600 Test Loss = 0.2244, Test Accuracy = 0.8426\n",
      "Iteration 548: Loss = 0.2135, Accuracy = 0.9000 Test Loss = 0.2249, Test Accuracy = 0.8393\n",
      "Iteration 549: Loss = 0.2202, Accuracy = 0.8200 Test Loss = 0.2238, Test Accuracy = 0.8446\n",
      "Iteration 550: Loss = 0.2147, Accuracy = 0.8200 Test Loss = 0.2250, Test Accuracy = 0.8417\n",
      "Iteration 551: Loss = 0.2264, Accuracy = 0.8200 Test Loss = 0.2243, Test Accuracy = 0.8447\n",
      "Iteration 552: Loss = 0.2061, Accuracy = 0.9100 Test Loss = 0.2248, Test Accuracy = 0.8445\n",
      "Iteration 553: Loss = 0.2301, Accuracy = 0.8500 Test Loss = 0.2240, Test Accuracy = 0.8455\n",
      "Iteration 554: Loss = 0.1902, Accuracy = 0.8500 Test Loss = 0.2242, Test Accuracy = 0.8423\n",
      "Iteration 555: Loss = 0.2529, Accuracy = 0.8400 Test Loss = 0.2245, Test Accuracy = 0.8443\n",
      "Iteration 556: Loss = 0.2071, Accuracy = 0.8500 Test Loss = 0.2239, Test Accuracy = 0.8472\n",
      "Iteration 557: Loss = 0.2312, Accuracy = 0.8300 Test Loss = 0.2243, Test Accuracy = 0.8460\n",
      "Iteration 558: Loss = 0.2408, Accuracy = 0.8100 Test Loss = 0.2238, Test Accuracy = 0.8440\n",
      "Iteration 559: Loss = 0.1924, Accuracy = 0.8600 Test Loss = 0.2241, Test Accuracy = 0.8421\n",
      "Iteration 560: Loss = 0.1923, Accuracy = 0.8900 Test Loss = 0.2239, Test Accuracy = 0.8440\n",
      "Iteration 561: Loss = 0.2164, Accuracy = 0.8300 Test Loss = 0.2240, Test Accuracy = 0.8451\n",
      "Iteration 562: Loss = 0.1972, Accuracy = 0.9000 Test Loss = 0.2237, Test Accuracy = 0.8433\n",
      "Iteration 563: Loss = 0.2009, Accuracy = 0.8500 Test Loss = 0.2235, Test Accuracy = 0.8430\n",
      "Iteration 564: Loss = 0.2107, Accuracy = 0.8500 Test Loss = 0.2234, Test Accuracy = 0.8457\n",
      "Iteration 565: Loss = 0.2220, Accuracy = 0.8300 Test Loss = 0.2238, Test Accuracy = 0.8447\n",
      "Iteration 566: Loss = 0.1927, Accuracy = 0.8600 Test Loss = 0.2235, Test Accuracy = 0.8437\n",
      "Iteration 567: Loss = 0.2066, Accuracy = 0.8500 Test Loss = 0.2234, Test Accuracy = 0.8441\n",
      "Iteration 568: Loss = 0.2070, Accuracy = 0.8500 Test Loss = 0.2230, Test Accuracy = 0.8423\n",
      "Iteration 569: Loss = 0.2611, Accuracy = 0.8100 Test Loss = 0.2229, Test Accuracy = 0.8454\n",
      "Iteration 570: Loss = 0.2112, Accuracy = 0.8800 Test Loss = 0.2237, Test Accuracy = 0.8432\n",
      "Iteration 571: Loss = 0.2116, Accuracy = 0.8200 Test Loss = 0.2227, Test Accuracy = 0.8464\n",
      "Iteration 572: Loss = 0.2493, Accuracy = 0.8200 Test Loss = 0.2228, Test Accuracy = 0.8480\n",
      "Iteration 573: Loss = 0.2541, Accuracy = 0.7700 Test Loss = 0.2231, Test Accuracy = 0.8490\n",
      "Iteration 574: Loss = 0.2451, Accuracy = 0.9200 Test Loss = 0.2235, Test Accuracy = 0.8419\n",
      "Iteration 575: Loss = 0.2349, Accuracy = 0.8400 Test Loss = 0.2231, Test Accuracy = 0.8457\n",
      "Iteration 576: Loss = 0.2059, Accuracy = 0.8400 Test Loss = 0.2233, Test Accuracy = 0.8458\n",
      "Iteration 577: Loss = 0.1799, Accuracy = 0.9100 Test Loss = 0.2230, Test Accuracy = 0.8480\n",
      "Iteration 578: Loss = 0.1928, Accuracy = 0.8800 Test Loss = 0.2226, Test Accuracy = 0.8470\n",
      "Iteration 579: Loss = 0.2316, Accuracy = 0.8300 Test Loss = 0.2229, Test Accuracy = 0.8418\n",
      "Iteration 580: Loss = 0.2072, Accuracy = 0.9000 Test Loss = 0.2226, Test Accuracy = 0.8455\n",
      "Iteration 581: Loss = 0.2402, Accuracy = 0.8200 Test Loss = 0.2224, Test Accuracy = 0.8433\n",
      "Iteration 582: Loss = 0.2388, Accuracy = 0.8000 Test Loss = 0.2225, Test Accuracy = 0.8438\n",
      "Iteration 583: Loss = 0.2245, Accuracy = 0.8500 Test Loss = 0.2227, Test Accuracy = 0.8448\n",
      "Iteration 584: Loss = 0.2268, Accuracy = 0.8000 Test Loss = 0.2222, Test Accuracy = 0.8479\n",
      "Iteration 585: Loss = 0.1871, Accuracy = 0.8700 Test Loss = 0.2225, Test Accuracy = 0.8449\n",
      "Iteration 586: Loss = 0.2364, Accuracy = 0.7800 Test Loss = 0.2225, Test Accuracy = 0.8480\n",
      "Iteration 587: Loss = 0.1918, Accuracy = 0.8600 Test Loss = 0.2232, Test Accuracy = 0.8425\n",
      "Iteration 588: Loss = 0.2224, Accuracy = 0.8300 Test Loss = 0.2225, Test Accuracy = 0.8422\n",
      "Iteration 589: Loss = 0.2168, Accuracy = 0.8400 Test Loss = 0.2222, Test Accuracy = 0.8413\n",
      "Iteration 590: Loss = 0.1962, Accuracy = 0.8500 Test Loss = 0.2222, Test Accuracy = 0.8442\n",
      "Iteration 591: Loss = 0.2455, Accuracy = 0.8400 Test Loss = 0.2220, Test Accuracy = 0.8464\n",
      "Iteration 592: Loss = 0.2540, Accuracy = 0.7800 Test Loss = 0.2231, Test Accuracy = 0.8425\n",
      "Iteration 593: Loss = 0.2205, Accuracy = 0.8500 Test Loss = 0.2220, Test Accuracy = 0.8455\n",
      "Iteration 594: Loss = 0.2312, Accuracy = 0.8300 Test Loss = 0.2224, Test Accuracy = 0.8437\n",
      "Iteration 595: Loss = 0.2104, Accuracy = 0.8600 Test Loss = 0.2222, Test Accuracy = 0.8430\n",
      "Iteration 596: Loss = 0.2274, Accuracy = 0.8500 Test Loss = 0.2223, Test Accuracy = 0.8424\n",
      "Iteration 597: Loss = 0.1984, Accuracy = 0.8700 Test Loss = 0.2223, Test Accuracy = 0.8451\n",
      "Iteration 598: Loss = 0.2484, Accuracy = 0.8400 Test Loss = 0.2218, Test Accuracy = 0.8433\n",
      "Iteration 599: Loss = 0.2291, Accuracy = 0.8200 Test Loss = 0.2219, Test Accuracy = 0.8448\n",
      "Iteration 600: Loss = 0.2772, Accuracy = 0.7800 Test Loss = 0.2217, Test Accuracy = 0.8482\n",
      "Iteration 601: Loss = 0.2061, Accuracy = 0.8700 Test Loss = 0.2219, Test Accuracy = 0.8448\n",
      "Iteration 602: Loss = 0.2092, Accuracy = 0.7900 Test Loss = 0.2221, Test Accuracy = 0.8477\n",
      "Iteration 603: Loss = 0.1659, Accuracy = 0.9100 Test Loss = 0.2221, Test Accuracy = 0.8452\n",
      "Iteration 604: Loss = 0.2344, Accuracy = 0.8200 Test Loss = 0.2212, Test Accuracy = 0.8467\n",
      "Iteration 605: Loss = 0.2048, Accuracy = 0.8700 Test Loss = 0.2216, Test Accuracy = 0.8457\n",
      "Iteration 606: Loss = 0.2236, Accuracy = 0.8700 Test Loss = 0.2213, Test Accuracy = 0.8461\n",
      "Iteration 607: Loss = 0.2290, Accuracy = 0.8200 Test Loss = 0.2210, Test Accuracy = 0.8433\n",
      "Iteration 608: Loss = 0.1875, Accuracy = 0.8700 Test Loss = 0.2211, Test Accuracy = 0.8437\n",
      "Iteration 609: Loss = 0.2116, Accuracy = 0.8500 Test Loss = 0.2210, Test Accuracy = 0.8477\n",
      "Iteration 610: Loss = 0.2062, Accuracy = 0.8300 Test Loss = 0.2214, Test Accuracy = 0.8487\n",
      "Iteration 611: Loss = 0.1911, Accuracy = 0.8700 Test Loss = 0.2214, Test Accuracy = 0.8472\n",
      "Iteration 612: Loss = 0.1914, Accuracy = 0.8900 Test Loss = 0.2215, Test Accuracy = 0.8475\n",
      "Iteration 613: Loss = 0.2152, Accuracy = 0.8500 Test Loss = 0.2212, Test Accuracy = 0.8446\n",
      "Iteration 614: Loss = 0.2331, Accuracy = 0.8200 Test Loss = 0.2211, Test Accuracy = 0.8439\n",
      "Iteration 615: Loss = 0.2203, Accuracy = 0.8500 Test Loss = 0.2210, Test Accuracy = 0.8484\n",
      "Iteration 616: Loss = 0.2111, Accuracy = 0.8800 Test Loss = 0.2214, Test Accuracy = 0.8477\n",
      "Iteration 617: Loss = 0.1958, Accuracy = 0.8500 Test Loss = 0.2213, Test Accuracy = 0.8465\n",
      "Iteration 618: Loss = 0.1807, Accuracy = 0.9000 Test Loss = 0.2210, Test Accuracy = 0.8447\n",
      "Iteration 619: Loss = 0.2650, Accuracy = 0.7200 Test Loss = 0.2213, Test Accuracy = 0.8472\n",
      "Iteration 620: Loss = 0.2070, Accuracy = 0.9100 Test Loss = 0.2207, Test Accuracy = 0.8472\n",
      "Iteration 621: Loss = 0.2301, Accuracy = 0.8100 Test Loss = 0.2206, Test Accuracy = 0.8433\n",
      "Iteration 622: Loss = 0.2215, Accuracy = 0.8400 Test Loss = 0.2212, Test Accuracy = 0.8491\n",
      "Iteration 623: Loss = 0.1938, Accuracy = 0.8700 Test Loss = 0.2209, Test Accuracy = 0.8444\n",
      "Iteration 624: Loss = 0.2438, Accuracy = 0.8000 Test Loss = 0.2204, Test Accuracy = 0.8464\n",
      "Iteration 625: Loss = 0.2100, Accuracy = 0.8400 Test Loss = 0.2207, Test Accuracy = 0.8451\n",
      "Iteration 626: Loss = 0.2444, Accuracy = 0.7700 Test Loss = 0.2205, Test Accuracy = 0.8481\n",
      "Iteration 627: Loss = 0.1954, Accuracy = 0.8600 Test Loss = 0.2208, Test Accuracy = 0.8458\n",
      "Iteration 628: Loss = 0.2189, Accuracy = 0.8500 Test Loss = 0.2203, Test Accuracy = 0.8458\n",
      "Iteration 629: Loss = 0.2862, Accuracy = 0.8300 Test Loss = 0.2203, Test Accuracy = 0.8466\n",
      "Iteration 630: Loss = 0.2080, Accuracy = 0.8700 Test Loss = 0.2206, Test Accuracy = 0.8462\n",
      "Iteration 631: Loss = 0.1923, Accuracy = 0.9000 Test Loss = 0.2215, Test Accuracy = 0.8484\n",
      "Iteration 632: Loss = 0.2062, Accuracy = 0.8100 Test Loss = 0.2203, Test Accuracy = 0.8453\n",
      "Iteration 633: Loss = 0.2331, Accuracy = 0.8100 Test Loss = 0.2206, Test Accuracy = 0.8449\n",
      "Iteration 634: Loss = 0.2308, Accuracy = 0.8100 Test Loss = 0.2206, Test Accuracy = 0.8418\n",
      "Iteration 635: Loss = 0.1986, Accuracy = 0.8400 Test Loss = 0.2200, Test Accuracy = 0.8485\n",
      "Iteration 636: Loss = 0.2161, Accuracy = 0.7900 Test Loss = 0.2196, Test Accuracy = 0.8443\n",
      "Iteration 637: Loss = 0.2222, Accuracy = 0.8400 Test Loss = 0.2201, Test Accuracy = 0.8481\n",
      "Iteration 638: Loss = 0.1921, Accuracy = 0.8500 Test Loss = 0.2199, Test Accuracy = 0.8487\n",
      "Iteration 639: Loss = 0.2873, Accuracy = 0.8100 Test Loss = 0.2199, Test Accuracy = 0.8469\n",
      "Iteration 640: Loss = 0.2061, Accuracy = 0.8500 Test Loss = 0.2204, Test Accuracy = 0.8470\n",
      "Iteration 641: Loss = 0.2285, Accuracy = 0.8300 Test Loss = 0.2206, Test Accuracy = 0.8440\n",
      "Iteration 642: Loss = 0.2058, Accuracy = 0.8400 Test Loss = 0.2201, Test Accuracy = 0.8467\n",
      "Iteration 643: Loss = 0.2039, Accuracy = 0.8300 Test Loss = 0.2201, Test Accuracy = 0.8448\n",
      "Iteration 644: Loss = 0.1966, Accuracy = 0.8400 Test Loss = 0.2203, Test Accuracy = 0.8466\n",
      "Iteration 645: Loss = 0.2191, Accuracy = 0.8400 Test Loss = 0.2199, Test Accuracy = 0.8480\n",
      "Iteration 646: Loss = 0.2458, Accuracy = 0.8500 Test Loss = 0.2195, Test Accuracy = 0.8464\n",
      "Iteration 647: Loss = 0.2244, Accuracy = 0.8500 Test Loss = 0.2195, Test Accuracy = 0.8482\n",
      "Iteration 648: Loss = 0.2335, Accuracy = 0.8000 Test Loss = 0.2194, Test Accuracy = 0.8468\n",
      "Iteration 649: Loss = 0.1572, Accuracy = 0.9600 Test Loss = 0.2195, Test Accuracy = 0.8442\n",
      "Iteration 650: Loss = 0.2426, Accuracy = 0.8000 Test Loss = 0.2199, Test Accuracy = 0.8450\n",
      "Iteration 651: Loss = 0.2211, Accuracy = 0.8400 Test Loss = 0.2195, Test Accuracy = 0.8491\n",
      "Iteration 652: Loss = 0.2339, Accuracy = 0.8100 Test Loss = 0.2196, Test Accuracy = 0.8493\n",
      "Iteration 653: Loss = 0.2088, Accuracy = 0.8600 Test Loss = 0.2194, Test Accuracy = 0.8456\n",
      "Iteration 654: Loss = 0.2463, Accuracy = 0.8600 Test Loss = 0.2203, Test Accuracy = 0.8459\n",
      "Iteration 655: Loss = 0.1773, Accuracy = 0.9000 Test Loss = 0.2201, Test Accuracy = 0.8427\n",
      "Iteration 656: Loss = 0.2139, Accuracy = 0.8200 Test Loss = 0.2191, Test Accuracy = 0.8451\n",
      "Iteration 657: Loss = 0.2142, Accuracy = 0.8000 Test Loss = 0.2198, Test Accuracy = 0.8443\n",
      "Iteration 658: Loss = 0.1983, Accuracy = 0.9100 Test Loss = 0.2197, Test Accuracy = 0.8417\n",
      "Iteration 659: Loss = 0.2013, Accuracy = 0.8800 Test Loss = 0.2195, Test Accuracy = 0.8456\n",
      "Iteration 660: Loss = 0.2131, Accuracy = 0.8300 Test Loss = 0.2190, Test Accuracy = 0.8479\n",
      "Iteration 661: Loss = 0.2002, Accuracy = 0.8300 Test Loss = 0.2187, Test Accuracy = 0.8460\n",
      "Iteration 662: Loss = 0.1851, Accuracy = 0.8600 Test Loss = 0.2191, Test Accuracy = 0.8460\n",
      "Iteration 663: Loss = 0.2014, Accuracy = 0.8800 Test Loss = 0.2187, Test Accuracy = 0.8465\n",
      "Iteration 664: Loss = 0.2238, Accuracy = 0.8100 Test Loss = 0.2193, Test Accuracy = 0.8448\n",
      "Iteration 665: Loss = 0.2182, Accuracy = 0.8300 Test Loss = 0.2187, Test Accuracy = 0.8478\n",
      "Iteration 666: Loss = 0.2051, Accuracy = 0.8100 Test Loss = 0.2187, Test Accuracy = 0.8484\n",
      "Iteration 667: Loss = 0.2196, Accuracy = 0.8200 Test Loss = 0.2190, Test Accuracy = 0.8466\n",
      "Iteration 668: Loss = 0.2678, Accuracy = 0.8000 Test Loss = 0.2189, Test Accuracy = 0.8457\n",
      "Iteration 669: Loss = 0.2134, Accuracy = 0.8100 Test Loss = 0.2193, Test Accuracy = 0.8493\n",
      "Iteration 670: Loss = 0.1899, Accuracy = 0.9000 Test Loss = 0.2190, Test Accuracy = 0.8483\n",
      "Iteration 671: Loss = 0.2104, Accuracy = 0.8200 Test Loss = 0.2190, Test Accuracy = 0.8442\n",
      "Iteration 672: Loss = 0.2122, Accuracy = 0.8200 Test Loss = 0.2184, Test Accuracy = 0.8485\n",
      "Iteration 673: Loss = 0.2282, Accuracy = 0.8000 Test Loss = 0.2193, Test Accuracy = 0.8471\n",
      "Iteration 674: Loss = 0.2017, Accuracy = 0.8200 Test Loss = 0.2185, Test Accuracy = 0.8469\n",
      "Iteration 675: Loss = 0.2155, Accuracy = 0.8200 Test Loss = 0.2192, Test Accuracy = 0.8464\n",
      "Iteration 676: Loss = 0.2170, Accuracy = 0.8000 Test Loss = 0.2181, Test Accuracy = 0.8471\n",
      "Iteration 677: Loss = 0.2034, Accuracy = 0.9000 Test Loss = 0.2182, Test Accuracy = 0.8488\n",
      "Iteration 678: Loss = 0.2244, Accuracy = 0.8100 Test Loss = 0.2187, Test Accuracy = 0.8502\n",
      "Iteration 679: Loss = 0.2115, Accuracy = 0.8800 Test Loss = 0.2188, Test Accuracy = 0.8435\n",
      "Iteration 680: Loss = 0.2060, Accuracy = 0.8300 Test Loss = 0.2196, Test Accuracy = 0.8437\n",
      "Iteration 681: Loss = 0.2324, Accuracy = 0.8400 Test Loss = 0.2188, Test Accuracy = 0.8460\n",
      "Iteration 682: Loss = 0.2048, Accuracy = 0.8200 Test Loss = 0.2184, Test Accuracy = 0.8485\n",
      "Iteration 683: Loss = 0.1916, Accuracy = 0.8400 Test Loss = 0.2184, Test Accuracy = 0.8469\n",
      "Iteration 684: Loss = 0.2239, Accuracy = 0.8200 Test Loss = 0.2183, Test Accuracy = 0.8508\n",
      "Iteration 685: Loss = 0.2413, Accuracy = 0.7700 Test Loss = 0.2191, Test Accuracy = 0.8419\n",
      "Iteration 686: Loss = 0.2097, Accuracy = 0.8100 Test Loss = 0.2183, Test Accuracy = 0.8469\n",
      "Iteration 687: Loss = 0.2300, Accuracy = 0.8100 Test Loss = 0.2185, Test Accuracy = 0.8484\n",
      "Iteration 688: Loss = 0.2404, Accuracy = 0.8300 Test Loss = 0.2183, Test Accuracy = 0.8450\n",
      "Iteration 689: Loss = 0.1733, Accuracy = 0.8900 Test Loss = 0.2182, Test Accuracy = 0.8499\n",
      "Iteration 690: Loss = 0.2050, Accuracy = 0.8700 Test Loss = 0.2182, Test Accuracy = 0.8498\n",
      "Iteration 691: Loss = 0.2518, Accuracy = 0.7400 Test Loss = 0.2181, Test Accuracy = 0.8471\n",
      "Iteration 692: Loss = 0.2030, Accuracy = 0.8600 Test Loss = 0.2179, Test Accuracy = 0.8481\n",
      "Iteration 693: Loss = 0.2070, Accuracy = 0.8000 Test Loss = 0.2179, Test Accuracy = 0.8445\n",
      "Iteration 694: Loss = 0.2088, Accuracy = 0.8500 Test Loss = 0.2185, Test Accuracy = 0.8446\n",
      "Iteration 695: Loss = 0.2259, Accuracy = 0.8200 Test Loss = 0.2182, Test Accuracy = 0.8435\n",
      "Iteration 696: Loss = 0.2278, Accuracy = 0.8300 Test Loss = 0.2183, Test Accuracy = 0.8480\n",
      "Iteration 697: Loss = 0.2119, Accuracy = 0.8700 Test Loss = 0.2176, Test Accuracy = 0.8445\n",
      "Iteration 698: Loss = 0.1991, Accuracy = 0.8400 Test Loss = 0.2182, Test Accuracy = 0.8417\n",
      "Iteration 699: Loss = 0.2040, Accuracy = 0.8100 Test Loss = 0.2180, Test Accuracy = 0.8482\n",
      "Iteration 700: Loss = 0.2419, Accuracy = 0.8000 Test Loss = 0.2194, Test Accuracy = 0.8456\n",
      "Iteration 701: Loss = 0.2107, Accuracy = 0.8600 Test Loss = 0.2177, Test Accuracy = 0.8482\n",
      "Iteration 702: Loss = 0.2281, Accuracy = 0.8200 Test Loss = 0.2178, Test Accuracy = 0.8478\n",
      "Iteration 703: Loss = 0.1751, Accuracy = 0.8800 Test Loss = 0.2173, Test Accuracy = 0.8469\n",
      "Iteration 704: Loss = 0.1861, Accuracy = 0.8700 Test Loss = 0.2176, Test Accuracy = 0.8467\n",
      "Iteration 705: Loss = 0.2188, Accuracy = 0.8200 Test Loss = 0.2172, Test Accuracy = 0.8469\n",
      "Iteration 706: Loss = 0.2028, Accuracy = 0.8400 Test Loss = 0.2182, Test Accuracy = 0.8426\n",
      "Iteration 707: Loss = 0.2159, Accuracy = 0.8100 Test Loss = 0.2178, Test Accuracy = 0.8450\n",
      "Iteration 708: Loss = 0.2561, Accuracy = 0.7900 Test Loss = 0.2171, Test Accuracy = 0.8478\n",
      "Iteration 709: Loss = 0.2267, Accuracy = 0.8200 Test Loss = 0.2173, Test Accuracy = 0.8471\n",
      "Iteration 710: Loss = 0.2173, Accuracy = 0.8700 Test Loss = 0.2174, Test Accuracy = 0.8471\n",
      "Iteration 711: Loss = 0.2293, Accuracy = 0.8700 Test Loss = 0.2173, Test Accuracy = 0.8457\n",
      "Iteration 712: Loss = 0.2516, Accuracy = 0.8100 Test Loss = 0.2176, Test Accuracy = 0.8458\n",
      "Iteration 713: Loss = 0.1980, Accuracy = 0.8400 Test Loss = 0.2171, Test Accuracy = 0.8467\n",
      "Iteration 714: Loss = 0.2014, Accuracy = 0.8500 Test Loss = 0.2181, Test Accuracy = 0.8469\n",
      "Iteration 715: Loss = 0.2202, Accuracy = 0.8300 Test Loss = 0.2172, Test Accuracy = 0.8483\n",
      "Iteration 716: Loss = 0.2162, Accuracy = 0.8200 Test Loss = 0.2174, Test Accuracy = 0.8460\n",
      "Iteration 717: Loss = 0.1963, Accuracy = 0.8900 Test Loss = 0.2173, Test Accuracy = 0.8441\n",
      "Iteration 718: Loss = 0.2139, Accuracy = 0.8600 Test Loss = 0.2176, Test Accuracy = 0.8466\n",
      "Iteration 719: Loss = 0.2000, Accuracy = 0.8800 Test Loss = 0.2171, Test Accuracy = 0.8479\n",
      "Iteration 720: Loss = 0.1927, Accuracy = 0.9400 Test Loss = 0.2171, Test Accuracy = 0.8478\n",
      "Iteration 721: Loss = 0.2267, Accuracy = 0.8800 Test Loss = 0.2170, Test Accuracy = 0.8489\n",
      "Iteration 722: Loss = 0.2115, Accuracy = 0.8400 Test Loss = 0.2174, Test Accuracy = 0.8480\n",
      "Iteration 723: Loss = 0.2176, Accuracy = 0.8100 Test Loss = 0.2176, Test Accuracy = 0.8418\n",
      "Iteration 724: Loss = 0.2453, Accuracy = 0.7900 Test Loss = 0.2167, Test Accuracy = 0.8484\n",
      "Iteration 725: Loss = 0.2216, Accuracy = 0.8500 Test Loss = 0.2177, Test Accuracy = 0.8465\n",
      "Iteration 726: Loss = 0.2756, Accuracy = 0.8400 Test Loss = 0.2169, Test Accuracy = 0.8479\n",
      "Iteration 727: Loss = 0.2387, Accuracy = 0.8100 Test Loss = 0.2170, Test Accuracy = 0.8479\n",
      "Iteration 728: Loss = 0.2131, Accuracy = 0.8800 Test Loss = 0.2173, Test Accuracy = 0.8503\n",
      "Iteration 729: Loss = 0.2114, Accuracy = 0.8800 Test Loss = 0.2165, Test Accuracy = 0.8485\n",
      "Iteration 730: Loss = 0.1739, Accuracy = 0.9300 Test Loss = 0.2172, Test Accuracy = 0.8458\n",
      "Iteration 731: Loss = 0.2162, Accuracy = 0.8500 Test Loss = 0.2167, Test Accuracy = 0.8519\n",
      "Iteration 732: Loss = 0.1826, Accuracy = 0.8800 Test Loss = 0.2168, Test Accuracy = 0.8440\n",
      "Iteration 733: Loss = 0.2497, Accuracy = 0.7600 Test Loss = 0.2171, Test Accuracy = 0.8466\n",
      "Iteration 734: Loss = 0.2137, Accuracy = 0.8400 Test Loss = 0.2175, Test Accuracy = 0.8508\n",
      "Iteration 735: Loss = 0.2349, Accuracy = 0.8100 Test Loss = 0.2167, Test Accuracy = 0.8444\n",
      "Iteration 736: Loss = 0.1884, Accuracy = 0.8700 Test Loss = 0.2164, Test Accuracy = 0.8495\n",
      "Iteration 737: Loss = 0.1927, Accuracy = 0.8400 Test Loss = 0.2177, Test Accuracy = 0.8444\n",
      "Iteration 738: Loss = 0.2039, Accuracy = 0.8100 Test Loss = 0.2168, Test Accuracy = 0.8438\n",
      "Iteration 739: Loss = 0.2603, Accuracy = 0.7700 Test Loss = 0.2168, Test Accuracy = 0.8431\n",
      "Iteration 740: Loss = 0.2017, Accuracy = 0.8700 Test Loss = 0.2163, Test Accuracy = 0.8482\n",
      "Iteration 741: Loss = 0.2250, Accuracy = 0.8600 Test Loss = 0.2164, Test Accuracy = 0.8489\n",
      "Iteration 742: Loss = 0.2529, Accuracy = 0.7900 Test Loss = 0.2166, Test Accuracy = 0.8499\n",
      "Iteration 743: Loss = 0.1840, Accuracy = 0.9000 Test Loss = 0.2169, Test Accuracy = 0.8434\n",
      "Iteration 744: Loss = 0.2300, Accuracy = 0.8400 Test Loss = 0.2165, Test Accuracy = 0.8458\n",
      "Iteration 745: Loss = 0.2122, Accuracy = 0.8000 Test Loss = 0.2166, Test Accuracy = 0.8480\n",
      "Iteration 746: Loss = 0.2040, Accuracy = 0.8100 Test Loss = 0.2169, Test Accuracy = 0.8476\n",
      "Iteration 747: Loss = 0.2208, Accuracy = 0.8400 Test Loss = 0.2168, Test Accuracy = 0.8490\n",
      "Iteration 748: Loss = 0.2342, Accuracy = 0.8100 Test Loss = 0.2160, Test Accuracy = 0.8450\n",
      "Iteration 749: Loss = 0.2204, Accuracy = 0.8500 Test Loss = 0.2165, Test Accuracy = 0.8458\n",
      "Iteration 750: Loss = 0.2359, Accuracy = 0.8400 Test Loss = 0.2162, Test Accuracy = 0.8464\n",
      "Iteration 751: Loss = 0.1893, Accuracy = 0.8800 Test Loss = 0.2165, Test Accuracy = 0.8490\n",
      "Iteration 752: Loss = 0.2038, Accuracy = 0.8300 Test Loss = 0.2161, Test Accuracy = 0.8460\n",
      "Iteration 753: Loss = 0.2196, Accuracy = 0.8100 Test Loss = 0.2167, Test Accuracy = 0.8380\n",
      "Iteration 754: Loss = 0.2216, Accuracy = 0.8200 Test Loss = 0.2163, Test Accuracy = 0.8478\n",
      "Iteration 755: Loss = 0.2087, Accuracy = 0.8300 Test Loss = 0.2163, Test Accuracy = 0.8447\n",
      "Iteration 756: Loss = 0.2363, Accuracy = 0.8800 Test Loss = 0.2164, Test Accuracy = 0.8468\n",
      "Iteration 757: Loss = 0.2039, Accuracy = 0.8300 Test Loss = 0.2159, Test Accuracy = 0.8471\n",
      "Iteration 758: Loss = 0.2159, Accuracy = 0.8500 Test Loss = 0.2163, Test Accuracy = 0.8476\n",
      "Iteration 759: Loss = 0.2123, Accuracy = 0.8800 Test Loss = 0.2162, Test Accuracy = 0.8429\n",
      "Iteration 760: Loss = 0.1970, Accuracy = 0.8700 Test Loss = 0.2159, Test Accuracy = 0.8472\n",
      "Iteration 761: Loss = 0.2139, Accuracy = 0.8200 Test Loss = 0.2159, Test Accuracy = 0.8473\n",
      "Iteration 762: Loss = 0.2077, Accuracy = 0.8700 Test Loss = 0.2159, Test Accuracy = 0.8487\n",
      "Iteration 763: Loss = 0.2463, Accuracy = 0.8000 Test Loss = 0.2165, Test Accuracy = 0.8486\n",
      "Iteration 764: Loss = 0.2343, Accuracy = 0.8400 Test Loss = 0.2158, Test Accuracy = 0.8456\n",
      "Iteration 765: Loss = 0.2149, Accuracy = 0.8500 Test Loss = 0.2157, Test Accuracy = 0.8473\n",
      "Iteration 766: Loss = 0.2015, Accuracy = 0.8800 Test Loss = 0.2159, Test Accuracy = 0.8473\n",
      "Iteration 767: Loss = 0.2408, Accuracy = 0.8700 Test Loss = 0.2165, Test Accuracy = 0.8453\n",
      "Iteration 768: Loss = 0.2051, Accuracy = 0.8500 Test Loss = 0.2157, Test Accuracy = 0.8503\n",
      "Iteration 769: Loss = 0.1975, Accuracy = 0.8300 Test Loss = 0.2155, Test Accuracy = 0.8476\n",
      "Iteration 770: Loss = 0.2295, Accuracy = 0.8300 Test Loss = 0.2162, Test Accuracy = 0.8501\n",
      "Iteration 771: Loss = 0.2012, Accuracy = 0.8700 Test Loss = 0.2156, Test Accuracy = 0.8436\n",
      "Iteration 772: Loss = 0.2276, Accuracy = 0.7900 Test Loss = 0.2155, Test Accuracy = 0.8500\n",
      "Iteration 773: Loss = 0.2082, Accuracy = 0.8800 Test Loss = 0.2160, Test Accuracy = 0.8503\n",
      "Iteration 774: Loss = 0.2040, Accuracy = 0.9000 Test Loss = 0.2160, Test Accuracy = 0.8482\n",
      "Iteration 775: Loss = 0.2188, Accuracy = 0.8400 Test Loss = 0.2157, Test Accuracy = 0.8493\n",
      "Iteration 776: Loss = 0.2313, Accuracy = 0.8300 Test Loss = 0.2156, Test Accuracy = 0.8460\n",
      "Iteration 777: Loss = 0.2121, Accuracy = 0.8700 Test Loss = 0.2154, Test Accuracy = 0.8465\n",
      "Iteration 778: Loss = 0.2178, Accuracy = 0.8100 Test Loss = 0.2158, Test Accuracy = 0.8477\n",
      "Iteration 779: Loss = 0.2137, Accuracy = 0.8300 Test Loss = 0.2155, Test Accuracy = 0.8476\n",
      "Iteration 780: Loss = 0.2525, Accuracy = 0.9100 Test Loss = 0.2156, Test Accuracy = 0.8487\n",
      "Iteration 781: Loss = 0.2188, Accuracy = 0.8200 Test Loss = 0.2156, Test Accuracy = 0.8440\n",
      "Iteration 782: Loss = 0.2262, Accuracy = 0.8100 Test Loss = 0.2159, Test Accuracy = 0.8459\n",
      "Iteration 783: Loss = 0.2201, Accuracy = 0.8400 Test Loss = 0.2159, Test Accuracy = 0.8462\n",
      "Iteration 784: Loss = 0.2320, Accuracy = 0.8100 Test Loss = 0.2159, Test Accuracy = 0.8486\n",
      "Iteration 785: Loss = 0.2383, Accuracy = 0.8600 Test Loss = 0.2157, Test Accuracy = 0.8470\n",
      "Iteration 786: Loss = 0.2213, Accuracy = 0.8400 Test Loss = 0.2150, Test Accuracy = 0.8483\n",
      "Iteration 787: Loss = 0.1863, Accuracy = 0.8900 Test Loss = 0.2152, Test Accuracy = 0.8472\n",
      "Iteration 788: Loss = 0.2102, Accuracy = 0.8300 Test Loss = 0.2152, Test Accuracy = 0.8486\n",
      "Iteration 789: Loss = 0.2113, Accuracy = 0.8300 Test Loss = 0.2154, Test Accuracy = 0.8442\n",
      "Iteration 790: Loss = 0.1943, Accuracy = 0.8600 Test Loss = 0.2154, Test Accuracy = 0.8501\n",
      "Iteration 791: Loss = 0.2000, Accuracy = 0.8700 Test Loss = 0.2154, Test Accuracy = 0.8511\n",
      "Iteration 792: Loss = 0.2271, Accuracy = 0.8100 Test Loss = 0.2150, Test Accuracy = 0.8464\n",
      "Iteration 793: Loss = 0.2187, Accuracy = 0.8400 Test Loss = 0.2150, Test Accuracy = 0.8437\n",
      "Iteration 794: Loss = 0.2042, Accuracy = 0.8600 Test Loss = 0.2151, Test Accuracy = 0.8484\n",
      "Iteration 795: Loss = 0.2002, Accuracy = 0.8900 Test Loss = 0.2150, Test Accuracy = 0.8466\n",
      "Iteration 796: Loss = 0.1809, Accuracy = 0.8900 Test Loss = 0.2156, Test Accuracy = 0.8444\n",
      "Iteration 797: Loss = 0.2240, Accuracy = 0.8300 Test Loss = 0.2153, Test Accuracy = 0.8467\n",
      "Iteration 798: Loss = 0.2343, Accuracy = 0.8200 Test Loss = 0.2153, Test Accuracy = 0.8474\n",
      "Iteration 799: Loss = 0.2550, Accuracy = 0.8400 Test Loss = 0.2155, Test Accuracy = 0.8437\n",
      "Iteration 800: Loss = 0.2461, Accuracy = 0.8100 Test Loss = 0.2146, Test Accuracy = 0.8467\n",
      "Iteration 801: Loss = 0.2126, Accuracy = 0.8400 Test Loss = 0.2149, Test Accuracy = 0.8469\n",
      "Iteration 802: Loss = 0.1905, Accuracy = 0.8300 Test Loss = 0.2150, Test Accuracy = 0.8470\n",
      "Iteration 803: Loss = 0.2065, Accuracy = 0.8800 Test Loss = 0.2144, Test Accuracy = 0.8499\n",
      "Iteration 804: Loss = 0.2209, Accuracy = 0.8100 Test Loss = 0.2149, Test Accuracy = 0.8493\n",
      "Iteration 805: Loss = 0.1951, Accuracy = 0.8300 Test Loss = 0.2151, Test Accuracy = 0.8462\n",
      "Iteration 806: Loss = 0.2206, Accuracy = 0.8100 Test Loss = 0.2148, Test Accuracy = 0.8508\n",
      "Iteration 807: Loss = 0.2101, Accuracy = 0.8900 Test Loss = 0.2145, Test Accuracy = 0.8476\n",
      "Iteration 808: Loss = 0.1846, Accuracy = 0.8800 Test Loss = 0.2153, Test Accuracy = 0.8421\n",
      "Iteration 809: Loss = 0.1948, Accuracy = 0.8500 Test Loss = 0.2148, Test Accuracy = 0.8469\n",
      "Iteration 810: Loss = 0.1793, Accuracy = 0.9000 Test Loss = 0.2148, Test Accuracy = 0.8469\n",
      "Iteration 811: Loss = 0.2342, Accuracy = 0.8200 Test Loss = 0.2155, Test Accuracy = 0.8448\n",
      "Iteration 812: Loss = 0.1808, Accuracy = 0.8800 Test Loss = 0.2150, Test Accuracy = 0.8456\n",
      "Iteration 813: Loss = 0.2072, Accuracy = 0.8500 Test Loss = 0.2151, Test Accuracy = 0.8409\n",
      "Iteration 814: Loss = 0.2052, Accuracy = 0.8400 Test Loss = 0.2145, Test Accuracy = 0.8477\n",
      "Iteration 815: Loss = 0.2060, Accuracy = 0.8800 Test Loss = 0.2144, Test Accuracy = 0.8436\n",
      "Iteration 816: Loss = 0.2380, Accuracy = 0.7900 Test Loss = 0.2149, Test Accuracy = 0.8458\n",
      "Iteration 817: Loss = 0.1940, Accuracy = 0.8900 Test Loss = 0.2146, Test Accuracy = 0.8520\n",
      "Iteration 818: Loss = 0.2289, Accuracy = 0.8500 Test Loss = 0.2147, Test Accuracy = 0.8478\n",
      "Iteration 819: Loss = 0.2028, Accuracy = 0.8400 Test Loss = 0.2146, Test Accuracy = 0.8442\n",
      "Iteration 820: Loss = 0.2000, Accuracy = 0.8400 Test Loss = 0.2148, Test Accuracy = 0.8444\n",
      "Iteration 821: Loss = 0.2131, Accuracy = 0.8600 Test Loss = 0.2144, Test Accuracy = 0.8492\n",
      "Iteration 822: Loss = 0.2092, Accuracy = 0.8400 Test Loss = 0.2147, Test Accuracy = 0.8466\n",
      "Iteration 823: Loss = 0.2297, Accuracy = 0.7800 Test Loss = 0.2141, Test Accuracy = 0.8454\n",
      "Iteration 824: Loss = 0.2155, Accuracy = 0.8300 Test Loss = 0.2147, Test Accuracy = 0.8457\n",
      "Iteration 825: Loss = 0.2120, Accuracy = 0.8500 Test Loss = 0.2141, Test Accuracy = 0.8493\n",
      "Iteration 826: Loss = 0.2280, Accuracy = 0.7800 Test Loss = 0.2144, Test Accuracy = 0.8484\n",
      "Iteration 827: Loss = 0.2078, Accuracy = 0.8300 Test Loss = 0.2144, Test Accuracy = 0.8479\n",
      "Iteration 828: Loss = 0.2216, Accuracy = 0.8800 Test Loss = 0.2143, Test Accuracy = 0.8485\n",
      "Iteration 829: Loss = 0.1844, Accuracy = 0.8700 Test Loss = 0.2151, Test Accuracy = 0.8427\n",
      "Iteration 830: Loss = 0.2064, Accuracy = 0.8100 Test Loss = 0.2145, Test Accuracy = 0.8461\n",
      "Iteration 831: Loss = 0.2196, Accuracy = 0.8400 Test Loss = 0.2147, Test Accuracy = 0.8487\n",
      "Iteration 832: Loss = 0.2275, Accuracy = 0.8400 Test Loss = 0.2140, Test Accuracy = 0.8493\n",
      "Iteration 833: Loss = 0.2651, Accuracy = 0.7800 Test Loss = 0.2148, Test Accuracy = 0.8451\n",
      "Iteration 834: Loss = 0.2342, Accuracy = 0.8000 Test Loss = 0.2138, Test Accuracy = 0.8497\n",
      "Iteration 835: Loss = 0.2376, Accuracy = 0.8600 Test Loss = 0.2140, Test Accuracy = 0.8473\n",
      "Iteration 836: Loss = 0.1969, Accuracy = 0.8300 Test Loss = 0.2147, Test Accuracy = 0.8462\n",
      "Iteration 837: Loss = 0.2036, Accuracy = 0.8900 Test Loss = 0.2139, Test Accuracy = 0.8440\n",
      "Iteration 838: Loss = 0.1913, Accuracy = 0.9000 Test Loss = 0.2142, Test Accuracy = 0.8524\n",
      "Iteration 839: Loss = 0.2588, Accuracy = 0.8400 Test Loss = 0.2138, Test Accuracy = 0.8483\n",
      "Iteration 840: Loss = 0.2105, Accuracy = 0.8300 Test Loss = 0.2142, Test Accuracy = 0.8488\n",
      "Iteration 841: Loss = 0.2372, Accuracy = 0.8200 Test Loss = 0.2144, Test Accuracy = 0.8497\n",
      "Iteration 842: Loss = 0.2120, Accuracy = 0.8100 Test Loss = 0.2147, Test Accuracy = 0.8489\n",
      "Iteration 843: Loss = 0.1994, Accuracy = 0.8600 Test Loss = 0.2140, Test Accuracy = 0.8478\n",
      "Iteration 844: Loss = 0.2551, Accuracy = 0.7900 Test Loss = 0.2141, Test Accuracy = 0.8464\n",
      "Iteration 845: Loss = 0.2120, Accuracy = 0.8700 Test Loss = 0.2141, Test Accuracy = 0.8469\n",
      "Iteration 846: Loss = 0.2041, Accuracy = 0.8200 Test Loss = 0.2138, Test Accuracy = 0.8470\n",
      "Iteration 847: Loss = 0.2149, Accuracy = 0.8700 Test Loss = 0.2140, Test Accuracy = 0.8490\n",
      "Iteration 848: Loss = 0.2564, Accuracy = 0.8800 Test Loss = 0.2139, Test Accuracy = 0.8440\n",
      "Iteration 849: Loss = 0.2862, Accuracy = 0.8700 Test Loss = 0.2142, Test Accuracy = 0.8505\n",
      "Iteration 850: Loss = 0.2224, Accuracy = 0.8400 Test Loss = 0.2132, Test Accuracy = 0.8495\n",
      "Iteration 851: Loss = 0.1995, Accuracy = 0.8400 Test Loss = 0.2136, Test Accuracy = 0.8482\n",
      "Iteration 852: Loss = 0.2017, Accuracy = 0.8500 Test Loss = 0.2136, Test Accuracy = 0.8467\n",
      "Iteration 853: Loss = 0.2781, Accuracy = 0.8500 Test Loss = 0.2135, Test Accuracy = 0.8467\n",
      "Iteration 854: Loss = 0.2100, Accuracy = 0.8500 Test Loss = 0.2135, Test Accuracy = 0.8499\n",
      "Iteration 855: Loss = 0.1871, Accuracy = 0.8800 Test Loss = 0.2137, Test Accuracy = 0.8480\n",
      "Iteration 856: Loss = 0.1934, Accuracy = 0.8900 Test Loss = 0.2137, Test Accuracy = 0.8470\n",
      "Iteration 857: Loss = 0.2295, Accuracy = 0.7900 Test Loss = 0.2136, Test Accuracy = 0.8451\n",
      "Iteration 858: Loss = 0.2049, Accuracy = 0.8800 Test Loss = 0.2134, Test Accuracy = 0.8485\n",
      "Iteration 859: Loss = 0.2094, Accuracy = 0.8300 Test Loss = 0.2138, Test Accuracy = 0.8457\n",
      "Iteration 860: Loss = 0.2059, Accuracy = 0.8800 Test Loss = 0.2138, Test Accuracy = 0.8489\n",
      "Iteration 861: Loss = 0.2117, Accuracy = 0.7900 Test Loss = 0.2134, Test Accuracy = 0.8492\n",
      "Iteration 862: Loss = 0.2153, Accuracy = 0.8700 Test Loss = 0.2138, Test Accuracy = 0.8475\n",
      "Iteration 863: Loss = 0.2022, Accuracy = 0.8400 Test Loss = 0.2143, Test Accuracy = 0.8419\n",
      "Iteration 864: Loss = 0.2018, Accuracy = 0.8500 Test Loss = 0.2141, Test Accuracy = 0.8511\n",
      "Iteration 865: Loss = 0.2263, Accuracy = 0.8800 Test Loss = 0.2139, Test Accuracy = 0.8473\n",
      "Iteration 866: Loss = 0.2045, Accuracy = 0.8600 Test Loss = 0.2138, Test Accuracy = 0.8477\n",
      "Iteration 867: Loss = 0.1897, Accuracy = 0.8500 Test Loss = 0.2133, Test Accuracy = 0.8512\n",
      "Iteration 868: Loss = 0.2261, Accuracy = 0.8500 Test Loss = 0.2139, Test Accuracy = 0.8460\n",
      "Iteration 869: Loss = 0.2219, Accuracy = 0.8300 Test Loss = 0.2133, Test Accuracy = 0.8470\n",
      "Iteration 870: Loss = 0.2226, Accuracy = 0.8700 Test Loss = 0.2134, Test Accuracy = 0.8476\n",
      "Iteration 871: Loss = 0.1986, Accuracy = 0.8300 Test Loss = 0.2133, Test Accuracy = 0.8482\n",
      "Iteration 872: Loss = 0.2153, Accuracy = 0.8300 Test Loss = 0.2137, Test Accuracy = 0.8463\n",
      "Iteration 873: Loss = 0.2223, Accuracy = 0.8600 Test Loss = 0.2135, Test Accuracy = 0.8461\n",
      "Iteration 874: Loss = 0.2223, Accuracy = 0.8400 Test Loss = 0.2135, Test Accuracy = 0.8479\n",
      "Iteration 875: Loss = 0.2319, Accuracy = 0.7600 Test Loss = 0.2134, Test Accuracy = 0.8469\n",
      "Iteration 876: Loss = 0.1978, Accuracy = 0.8500 Test Loss = 0.2134, Test Accuracy = 0.8503\n",
      "Iteration 877: Loss = 0.2186, Accuracy = 0.8000 Test Loss = 0.2129, Test Accuracy = 0.8478\n",
      "Iteration 878: Loss = 0.2103, Accuracy = 0.8100 Test Loss = 0.2131, Test Accuracy = 0.8474\n",
      "Iteration 879: Loss = 0.2291, Accuracy = 0.8200 Test Loss = 0.2131, Test Accuracy = 0.8466\n",
      "Iteration 880: Loss = 0.1745, Accuracy = 0.8600 Test Loss = 0.2133, Test Accuracy = 0.8485\n",
      "Iteration 881: Loss = 0.2436, Accuracy = 0.8200 Test Loss = 0.2137, Test Accuracy = 0.8477\n",
      "Iteration 882: Loss = 0.2064, Accuracy = 0.8300 Test Loss = 0.2133, Test Accuracy = 0.8506\n",
      "Iteration 883: Loss = 0.2333, Accuracy = 0.7700 Test Loss = 0.2133, Test Accuracy = 0.8438\n",
      "Iteration 884: Loss = 0.1829, Accuracy = 0.8500 Test Loss = 0.2128, Test Accuracy = 0.8459\n",
      "Iteration 885: Loss = 0.1997, Accuracy = 0.8700 Test Loss = 0.2128, Test Accuracy = 0.8462\n",
      "Iteration 886: Loss = 0.2676, Accuracy = 0.8000 Test Loss = 0.2133, Test Accuracy = 0.8476\n",
      "Iteration 887: Loss = 0.2533, Accuracy = 0.8400 Test Loss = 0.2133, Test Accuracy = 0.8512\n",
      "Iteration 888: Loss = 0.2053, Accuracy = 0.8900 Test Loss = 0.2133, Test Accuracy = 0.8464\n",
      "Iteration 889: Loss = 0.1908, Accuracy = 0.9300 Test Loss = 0.2127, Test Accuracy = 0.8485\n",
      "Iteration 890: Loss = 0.2708, Accuracy = 0.8000 Test Loss = 0.2132, Test Accuracy = 0.8493\n",
      "Iteration 891: Loss = 0.2258, Accuracy = 0.7800 Test Loss = 0.2130, Test Accuracy = 0.8497\n",
      "Iteration 892: Loss = 0.2051, Accuracy = 0.8600 Test Loss = 0.2129, Test Accuracy = 0.8460\n",
      "Iteration 893: Loss = 0.1866, Accuracy = 0.8700 Test Loss = 0.2130, Test Accuracy = 0.8475\n",
      "Iteration 894: Loss = 0.1900, Accuracy = 0.8600 Test Loss = 0.2132, Test Accuracy = 0.8468\n",
      "Iteration 895: Loss = 0.1985, Accuracy = 0.8800 Test Loss = 0.2133, Test Accuracy = 0.8486\n",
      "Iteration 896: Loss = 0.1984, Accuracy = 0.8400 Test Loss = 0.2125, Test Accuracy = 0.8470\n",
      "Iteration 897: Loss = 0.2015, Accuracy = 0.8500 Test Loss = 0.2127, Test Accuracy = 0.8496\n",
      "Iteration 898: Loss = 0.1922, Accuracy = 0.8900 Test Loss = 0.2126, Test Accuracy = 0.8476\n",
      "Iteration 899: Loss = 0.1949, Accuracy = 0.8400 Test Loss = 0.2127, Test Accuracy = 0.8458\n",
      "Iteration 900: Loss = 0.2220, Accuracy = 0.8200 Test Loss = 0.2127, Test Accuracy = 0.8501\n",
      "Iteration 901: Loss = 0.2177, Accuracy = 0.8700 Test Loss = 0.2134, Test Accuracy = 0.8466\n",
      "Iteration 902: Loss = 0.2077, Accuracy = 0.8300 Test Loss = 0.2128, Test Accuracy = 0.8447\n",
      "Iteration 903: Loss = 0.2122, Accuracy = 0.8400 Test Loss = 0.2126, Test Accuracy = 0.8491\n",
      "Iteration 904: Loss = 0.2325, Accuracy = 0.8200 Test Loss = 0.2129, Test Accuracy = 0.8497\n",
      "Iteration 905: Loss = 0.2166, Accuracy = 0.8900 Test Loss = 0.2127, Test Accuracy = 0.8471\n",
      "Iteration 906: Loss = 0.1995, Accuracy = 0.8400 Test Loss = 0.2126, Test Accuracy = 0.8470\n",
      "Iteration 907: Loss = 0.1977, Accuracy = 0.8800 Test Loss = 0.2127, Test Accuracy = 0.8512\n",
      "Iteration 908: Loss = 0.2005, Accuracy = 0.8800 Test Loss = 0.2127, Test Accuracy = 0.8489\n",
      "Iteration 909: Loss = 0.2403, Accuracy = 0.8100 Test Loss = 0.2126, Test Accuracy = 0.8509\n",
      "Iteration 910: Loss = 0.2140, Accuracy = 0.8500 Test Loss = 0.2125, Test Accuracy = 0.8480\n",
      "Iteration 911: Loss = 0.2025, Accuracy = 0.8900 Test Loss = 0.2135, Test Accuracy = 0.8416\n",
      "Iteration 912: Loss = 0.2052, Accuracy = 0.8600 Test Loss = 0.2133, Test Accuracy = 0.8451\n",
      "Iteration 913: Loss = 0.2092, Accuracy = 0.8500 Test Loss = 0.2123, Test Accuracy = 0.8471\n",
      "Iteration 914: Loss = 0.1678, Accuracy = 0.9300 Test Loss = 0.2129, Test Accuracy = 0.8474\n",
      "Iteration 915: Loss = 0.2203, Accuracy = 0.8300 Test Loss = 0.2127, Test Accuracy = 0.8460\n",
      "Iteration 916: Loss = 0.2050, Accuracy = 0.8400 Test Loss = 0.2126, Test Accuracy = 0.8513\n",
      "Iteration 917: Loss = 0.2206, Accuracy = 0.8200 Test Loss = 0.2121, Test Accuracy = 0.8511\n",
      "Iteration 918: Loss = 0.1861, Accuracy = 0.8900 Test Loss = 0.2122, Test Accuracy = 0.8522\n",
      "Iteration 919: Loss = 0.2102, Accuracy = 0.8300 Test Loss = 0.2124, Test Accuracy = 0.8495\n",
      "Iteration 920: Loss = 0.2152, Accuracy = 0.8500 Test Loss = 0.2124, Test Accuracy = 0.8498\n",
      "Iteration 921: Loss = 0.1961, Accuracy = 0.8800 Test Loss = 0.2130, Test Accuracy = 0.8427\n",
      "Iteration 922: Loss = 0.2368, Accuracy = 0.8100 Test Loss = 0.2125, Test Accuracy = 0.8474\n",
      "Iteration 923: Loss = 0.2110, Accuracy = 0.8600 Test Loss = 0.2126, Test Accuracy = 0.8477\n",
      "Iteration 924: Loss = 0.1962, Accuracy = 0.8600 Test Loss = 0.2121, Test Accuracy = 0.8480\n",
      "Iteration 925: Loss = 0.2092, Accuracy = 0.8300 Test Loss = 0.2120, Test Accuracy = 0.8486\n",
      "Iteration 926: Loss = 0.1884, Accuracy = 0.8800 Test Loss = 0.2122, Test Accuracy = 0.8481\n",
      "Iteration 927: Loss = 0.2345, Accuracy = 0.8000 Test Loss = 0.2128, Test Accuracy = 0.8506\n",
      "Iteration 928: Loss = 0.1935, Accuracy = 0.8500 Test Loss = 0.2125, Test Accuracy = 0.8497\n",
      "Iteration 929: Loss = 0.2048, Accuracy = 0.8600 Test Loss = 0.2125, Test Accuracy = 0.8452\n",
      "Iteration 930: Loss = 0.1892, Accuracy = 0.8800 Test Loss = 0.2122, Test Accuracy = 0.8473\n",
      "Iteration 931: Loss = 0.2239, Accuracy = 0.8100 Test Loss = 0.2121, Test Accuracy = 0.8482\n",
      "Iteration 932: Loss = 0.1926, Accuracy = 0.9100 Test Loss = 0.2121, Test Accuracy = 0.8485\n",
      "Iteration 933: Loss = 0.2003, Accuracy = 0.8600 Test Loss = 0.2122, Test Accuracy = 0.8510\n",
      "Iteration 934: Loss = 0.1965, Accuracy = 0.8500 Test Loss = 0.2121, Test Accuracy = 0.8472\n",
      "Iteration 935: Loss = 0.2133, Accuracy = 0.8100 Test Loss = 0.2122, Test Accuracy = 0.8499\n",
      "Iteration 936: Loss = 0.2253, Accuracy = 0.8200 Test Loss = 0.2123, Test Accuracy = 0.8501\n",
      "Iteration 937: Loss = 0.2341, Accuracy = 0.7800 Test Loss = 0.2122, Test Accuracy = 0.8493\n",
      "Iteration 938: Loss = 0.1950, Accuracy = 0.8600 Test Loss = 0.2120, Test Accuracy = 0.8498\n",
      "Iteration 939: Loss = 0.2269, Accuracy = 0.8200 Test Loss = 0.2123, Test Accuracy = 0.8483\n",
      "Iteration 940: Loss = 0.2353, Accuracy = 0.8200 Test Loss = 0.2125, Test Accuracy = 0.8472\n",
      "Iteration 941: Loss = 0.2175, Accuracy = 0.8400 Test Loss = 0.2122, Test Accuracy = 0.8495\n",
      "Iteration 942: Loss = 0.2057, Accuracy = 0.8000 Test Loss = 0.2118, Test Accuracy = 0.8532\n",
      "Iteration 943: Loss = 0.1885, Accuracy = 0.8600 Test Loss = 0.2121, Test Accuracy = 0.8475\n",
      "Iteration 944: Loss = 0.2033, Accuracy = 0.8500 Test Loss = 0.2120, Test Accuracy = 0.8499\n",
      "Iteration 945: Loss = 0.2127, Accuracy = 0.8000 Test Loss = 0.2130, Test Accuracy = 0.8468\n",
      "Iteration 946: Loss = 0.2094, Accuracy = 0.8400 Test Loss = 0.2119, Test Accuracy = 0.8519\n",
      "Iteration 947: Loss = 0.2084, Accuracy = 0.8500 Test Loss = 0.2119, Test Accuracy = 0.8449\n",
      "Iteration 948: Loss = 0.1977, Accuracy = 0.8500 Test Loss = 0.2127, Test Accuracy = 0.8494\n",
      "Iteration 949: Loss = 0.2411, Accuracy = 0.8300 Test Loss = 0.2116, Test Accuracy = 0.8492\n",
      "Iteration 950: Loss = 0.2169, Accuracy = 0.8000 Test Loss = 0.2124, Test Accuracy = 0.8506\n",
      "Iteration 951: Loss = 0.2063, Accuracy = 0.8500 Test Loss = 0.2119, Test Accuracy = 0.8477\n",
      "Iteration 952: Loss = 0.1612, Accuracy = 0.9400 Test Loss = 0.2126, Test Accuracy = 0.8455\n",
      "Iteration 953: Loss = 0.2272, Accuracy = 0.8000 Test Loss = 0.2115, Test Accuracy = 0.8530\n",
      "Iteration 954: Loss = 0.2028, Accuracy = 0.8400 Test Loss = 0.2114, Test Accuracy = 0.8526\n",
      "Iteration 955: Loss = 0.1818, Accuracy = 0.8500 Test Loss = 0.2118, Test Accuracy = 0.8453\n",
      "Iteration 956: Loss = 0.2039, Accuracy = 0.8400 Test Loss = 0.2116, Test Accuracy = 0.8489\n",
      "Iteration 957: Loss = 0.2725, Accuracy = 0.8800 Test Loss = 0.2126, Test Accuracy = 0.8460\n",
      "Iteration 958: Loss = 0.2493, Accuracy = 0.8300 Test Loss = 0.2118, Test Accuracy = 0.8482\n",
      "Iteration 959: Loss = 0.2037, Accuracy = 0.8500 Test Loss = 0.2119, Test Accuracy = 0.8482\n",
      "Iteration 960: Loss = 0.1943, Accuracy = 0.8400 Test Loss = 0.2117, Test Accuracy = 0.8458\n",
      "Iteration 961: Loss = 0.2087, Accuracy = 0.8100 Test Loss = 0.2116, Test Accuracy = 0.8472\n",
      "Iteration 962: Loss = 0.2147, Accuracy = 0.8600 Test Loss = 0.2117, Test Accuracy = 0.8531\n",
      "Iteration 963: Loss = 0.2278, Accuracy = 0.8800 Test Loss = 0.2121, Test Accuracy = 0.8517\n",
      "Iteration 964: Loss = 0.2218, Accuracy = 0.8100 Test Loss = 0.2115, Test Accuracy = 0.8501\n",
      "Iteration 965: Loss = 0.2034, Accuracy = 0.8500 Test Loss = 0.2118, Test Accuracy = 0.8484\n",
      "Iteration 966: Loss = 0.2572, Accuracy = 0.8100 Test Loss = 0.2117, Test Accuracy = 0.8511\n",
      "Iteration 967: Loss = 0.2017, Accuracy = 0.8600 Test Loss = 0.2116, Test Accuracy = 0.8457\n",
      "Iteration 968: Loss = 0.2300, Accuracy = 0.8600 Test Loss = 0.2118, Test Accuracy = 0.8450\n",
      "Iteration 969: Loss = 0.2132, Accuracy = 0.8500 Test Loss = 0.2117, Test Accuracy = 0.8495\n",
      "Iteration 970: Loss = 0.2467, Accuracy = 0.7900 Test Loss = 0.2116, Test Accuracy = 0.8468\n",
      "Iteration 971: Loss = 0.2269, Accuracy = 0.8400 Test Loss = 0.2121, Test Accuracy = 0.8464\n",
      "Iteration 972: Loss = 0.2502, Accuracy = 0.8500 Test Loss = 0.2114, Test Accuracy = 0.8492\n",
      "Iteration 973: Loss = 0.2031, Accuracy = 0.8500 Test Loss = 0.2117, Test Accuracy = 0.8482\n",
      "Iteration 974: Loss = 0.2135, Accuracy = 0.8100 Test Loss = 0.2117, Test Accuracy = 0.8495\n",
      "Iteration 975: Loss = 0.1954, Accuracy = 0.8900 Test Loss = 0.2112, Test Accuracy = 0.8508\n",
      "Iteration 976: Loss = 0.2248, Accuracy = 0.8400 Test Loss = 0.2119, Test Accuracy = 0.8498\n",
      "Iteration 977: Loss = 0.1854, Accuracy = 0.8800 Test Loss = 0.2112, Test Accuracy = 0.8506\n",
      "Iteration 978: Loss = 0.2524, Accuracy = 0.8500 Test Loss = 0.2115, Test Accuracy = 0.8500\n",
      "Iteration 979: Loss = 0.2074, Accuracy = 0.8500 Test Loss = 0.2118, Test Accuracy = 0.8450\n",
      "Iteration 980: Loss = 0.2133, Accuracy = 0.8800 Test Loss = 0.2115, Test Accuracy = 0.8465\n",
      "Iteration 981: Loss = 0.1666, Accuracy = 0.9000 Test Loss = 0.2113, Test Accuracy = 0.8465\n",
      "Iteration 982: Loss = 0.2454, Accuracy = 0.8100 Test Loss = 0.2119, Test Accuracy = 0.8502\n",
      "Iteration 983: Loss = 0.1797, Accuracy = 0.9100 Test Loss = 0.2120, Test Accuracy = 0.8461\n",
      "Iteration 984: Loss = 0.2142, Accuracy = 0.8100 Test Loss = 0.2114, Test Accuracy = 0.8495\n",
      "Iteration 985: Loss = 0.2099, Accuracy = 0.8500 Test Loss = 0.2109, Test Accuracy = 0.8490\n",
      "Iteration 986: Loss = 0.2345, Accuracy = 0.7900 Test Loss = 0.2111, Test Accuracy = 0.8500\n",
      "Iteration 987: Loss = 0.1807, Accuracy = 0.9100 Test Loss = 0.2115, Test Accuracy = 0.8476\n",
      "Iteration 988: Loss = 0.2039, Accuracy = 0.8600 Test Loss = 0.2110, Test Accuracy = 0.8466\n",
      "Iteration 989: Loss = 0.1972, Accuracy = 0.8900 Test Loss = 0.2112, Test Accuracy = 0.8481\n",
      "Iteration 990: Loss = 0.2493, Accuracy = 0.8700 Test Loss = 0.2118, Test Accuracy = 0.8484\n",
      "Iteration 991: Loss = 0.2194, Accuracy = 0.8400 Test Loss = 0.2110, Test Accuracy = 0.8480\n",
      "Iteration 992: Loss = 0.1932, Accuracy = 0.8900 Test Loss = 0.2109, Test Accuracy = 0.8508\n",
      "Iteration 993: Loss = 0.2055, Accuracy = 0.8500 Test Loss = 0.2116, Test Accuracy = 0.8425\n",
      "Iteration 994: Loss = 0.2008, Accuracy = 0.8400 Test Loss = 0.2113, Test Accuracy = 0.8484\n",
      "Iteration 995: Loss = 0.1961, Accuracy = 0.8700 Test Loss = 0.2117, Test Accuracy = 0.8498\n",
      "Iteration 996: Loss = 0.2168, Accuracy = 0.8100 Test Loss = 0.2116, Test Accuracy = 0.8537\n",
      "Iteration 997: Loss = 0.2263, Accuracy = 0.8000 Test Loss = 0.2112, Test Accuracy = 0.8524\n",
      "Iteration 998: Loss = 0.2402, Accuracy = 0.8300 Test Loss = 0.2116, Test Accuracy = 0.8461\n",
      "Iteration 999: Loss = 0.2009, Accuracy = 0.8700 Test Loss = 0.2114, Test Accuracy = 0.8472\n",
      "Iteration 1000: Loss = 0.2465, Accuracy = 0.8200 Test Loss = 0.2113, Test Accuracy = 0.8499\n",
      "Iteration 1001: Loss = 0.2007, Accuracy = 0.9000 Test Loss = 0.2109, Test Accuracy = 0.8512\n",
      "Iteration 1002: Loss = 0.1783, Accuracy = 0.8700 Test Loss = 0.2108, Test Accuracy = 0.8501\n",
      "Iteration 1003: Loss = 0.2360, Accuracy = 0.8000 Test Loss = 0.2116, Test Accuracy = 0.8511\n",
      "Iteration 1004: Loss = 0.1967, Accuracy = 0.8400 Test Loss = 0.2107, Test Accuracy = 0.8495\n",
      "Iteration 1005: Loss = 0.1845, Accuracy = 0.9200 Test Loss = 0.2108, Test Accuracy = 0.8506\n",
      "Iteration 1006: Loss = 0.2403, Accuracy = 0.8100 Test Loss = 0.2118, Test Accuracy = 0.8493\n",
      "Iteration 1007: Loss = 0.1977, Accuracy = 0.8800 Test Loss = 0.2109, Test Accuracy = 0.8516\n",
      "Iteration 1008: Loss = 0.2097, Accuracy = 0.8600 Test Loss = 0.2108, Test Accuracy = 0.8467\n",
      "Iteration 1009: Loss = 0.2221, Accuracy = 0.8500 Test Loss = 0.2111, Test Accuracy = 0.8482\n",
      "Iteration 1010: Loss = 0.2113, Accuracy = 0.8500 Test Loss = 0.2110, Test Accuracy = 0.8505\n",
      "Iteration 1011: Loss = 0.1899, Accuracy = 0.8500 Test Loss = 0.2110, Test Accuracy = 0.8486\n",
      "Iteration 1012: Loss = 0.2033, Accuracy = 0.8700 Test Loss = 0.2110, Test Accuracy = 0.8470\n",
      "Iteration 1013: Loss = 0.1908, Accuracy = 0.8900 Test Loss = 0.2116, Test Accuracy = 0.8483\n",
      "Iteration 1014: Loss = 0.1962, Accuracy = 0.8700 Test Loss = 0.2115, Test Accuracy = 0.8489\n",
      "Iteration 1015: Loss = 0.1939, Accuracy = 0.8500 Test Loss = 0.2115, Test Accuracy = 0.8476\n",
      "Iteration 1016: Loss = 0.2021, Accuracy = 0.8600 Test Loss = 0.2117, Test Accuracy = 0.8472\n",
      "Iteration 1017: Loss = 0.1972, Accuracy = 0.9000 Test Loss = 0.2112, Test Accuracy = 0.8481\n",
      "Iteration 1018: Loss = 0.2096, Accuracy = 0.8200 Test Loss = 0.2105, Test Accuracy = 0.8507\n",
      "Iteration 1019: Loss = 0.2101, Accuracy = 0.8200 Test Loss = 0.2109, Test Accuracy = 0.8508\n",
      "Iteration 1020: Loss = 0.2105, Accuracy = 0.8400 Test Loss = 0.2108, Test Accuracy = 0.8474\n",
      "Iteration 1021: Loss = 0.2058, Accuracy = 0.8600 Test Loss = 0.2113, Test Accuracy = 0.8473\n",
      "Iteration 1022: Loss = 0.1939, Accuracy = 0.8500 Test Loss = 0.2109, Test Accuracy = 0.8485\n",
      "Iteration 1023: Loss = 0.2142, Accuracy = 0.8300 Test Loss = 0.2108, Test Accuracy = 0.8508\n",
      "Iteration 1024: Loss = 0.1955, Accuracy = 0.9200 Test Loss = 0.2109, Test Accuracy = 0.8504\n",
      "Iteration 1025: Loss = 0.2209, Accuracy = 0.8300 Test Loss = 0.2110, Test Accuracy = 0.8474\n",
      "Iteration 1026: Loss = 0.2342, Accuracy = 0.8300 Test Loss = 0.2103, Test Accuracy = 0.8496\n",
      "Iteration 1027: Loss = 0.2299, Accuracy = 0.7800 Test Loss = 0.2110, Test Accuracy = 0.8502\n",
      "Iteration 1028: Loss = 0.2309, Accuracy = 0.7800 Test Loss = 0.2103, Test Accuracy = 0.8528\n",
      "Iteration 1029: Loss = 0.1940, Accuracy = 0.8900 Test Loss = 0.2108, Test Accuracy = 0.8524\n",
      "Iteration 1030: Loss = 0.2111, Accuracy = 0.8200 Test Loss = 0.2107, Test Accuracy = 0.8485\n",
      "Iteration 1031: Loss = 0.2051, Accuracy = 0.8900 Test Loss = 0.2110, Test Accuracy = 0.8462\n",
      "Iteration 1032: Loss = 0.1863, Accuracy = 0.9000 Test Loss = 0.2104, Test Accuracy = 0.8492\n",
      "Iteration 1033: Loss = 0.2021, Accuracy = 0.8700 Test Loss = 0.2113, Test Accuracy = 0.8478\n",
      "Iteration 1034: Loss = 0.2223, Accuracy = 0.8200 Test Loss = 0.2108, Test Accuracy = 0.8484\n",
      "Iteration 1035: Loss = 0.1994, Accuracy = 0.8300 Test Loss = 0.2105, Test Accuracy = 0.8506\n",
      "Iteration 1036: Loss = 0.2067, Accuracy = 0.8800 Test Loss = 0.2106, Test Accuracy = 0.8515\n",
      "Iteration 1037: Loss = 0.2305, Accuracy = 0.8100 Test Loss = 0.2112, Test Accuracy = 0.8473\n",
      "Iteration 1038: Loss = 0.1947, Accuracy = 0.8700 Test Loss = 0.2106, Test Accuracy = 0.8503\n",
      "Iteration 1039: Loss = 0.2108, Accuracy = 0.8700 Test Loss = 0.2105, Test Accuracy = 0.8489\n",
      "Iteration 1040: Loss = 0.1898, Accuracy = 0.8600 Test Loss = 0.2106, Test Accuracy = 0.8497\n",
      "Iteration 1041: Loss = 0.2047, Accuracy = 0.8000 Test Loss = 0.2106, Test Accuracy = 0.8473\n",
      "Iteration 1042: Loss = 0.2117, Accuracy = 0.8500 Test Loss = 0.2101, Test Accuracy = 0.8495\n",
      "Iteration 1043: Loss = 0.1842, Accuracy = 0.8700 Test Loss = 0.2106, Test Accuracy = 0.8471\n",
      "Iteration 1044: Loss = 0.2621, Accuracy = 0.7600 Test Loss = 0.2113, Test Accuracy = 0.8512\n",
      "Iteration 1045: Loss = 0.2009, Accuracy = 0.8800 Test Loss = 0.2105, Test Accuracy = 0.8460\n",
      "Iteration 1046: Loss = 0.2283, Accuracy = 0.8100 Test Loss = 0.2106, Test Accuracy = 0.8520\n",
      "Iteration 1047: Loss = 0.2246, Accuracy = 0.8200 Test Loss = 0.2103, Test Accuracy = 0.8491\n",
      "Iteration 1048: Loss = 0.2225, Accuracy = 0.7900 Test Loss = 0.2108, Test Accuracy = 0.8513\n",
      "Iteration 1049: Loss = 0.2115, Accuracy = 0.7800 Test Loss = 0.2106, Test Accuracy = 0.8474\n",
      "Iteration 1050: Loss = 0.1950, Accuracy = 0.8000 Test Loss = 0.2105, Test Accuracy = 0.8457\n",
      "Iteration 1051: Loss = 0.1931, Accuracy = 0.8400 Test Loss = 0.2104, Test Accuracy = 0.8508\n",
      "Iteration 1052: Loss = 0.1873, Accuracy = 0.8300 Test Loss = 0.2110, Test Accuracy = 0.8540\n",
      "Iteration 1053: Loss = 0.1994, Accuracy = 0.9100 Test Loss = 0.2104, Test Accuracy = 0.8505\n",
      "Iteration 1054: Loss = 0.2089, Accuracy = 0.8100 Test Loss = 0.2110, Test Accuracy = 0.8501\n",
      "Iteration 1055: Loss = 0.2209, Accuracy = 0.8500 Test Loss = 0.2105, Test Accuracy = 0.8448\n",
      "Iteration 1056: Loss = 0.2061, Accuracy = 0.8200 Test Loss = 0.2103, Test Accuracy = 0.8505\n",
      "Iteration 1057: Loss = 0.2088, Accuracy = 0.8300 Test Loss = 0.2103, Test Accuracy = 0.8470\n",
      "Iteration 1058: Loss = 0.2279, Accuracy = 0.7900 Test Loss = 0.2110, Test Accuracy = 0.8483\n",
      "Iteration 1059: Loss = 0.2336, Accuracy = 0.8400 Test Loss = 0.2101, Test Accuracy = 0.8447\n",
      "Iteration 1060: Loss = 0.2033, Accuracy = 0.8400 Test Loss = 0.2105, Test Accuracy = 0.8474\n",
      "Iteration 1061: Loss = 0.2115, Accuracy = 0.8400 Test Loss = 0.2108, Test Accuracy = 0.8516\n",
      "Iteration 1062: Loss = 0.1880, Accuracy = 0.8800 Test Loss = 0.2107, Test Accuracy = 0.8478\n",
      "Iteration 1063: Loss = 0.2027, Accuracy = 0.8700 Test Loss = 0.2101, Test Accuracy = 0.8483\n",
      "Iteration 1064: Loss = 0.1880, Accuracy = 0.9000 Test Loss = 0.2101, Test Accuracy = 0.8497\n",
      "Iteration 1065: Loss = 0.1803, Accuracy = 0.8900 Test Loss = 0.2101, Test Accuracy = 0.8502\n",
      "Iteration 1066: Loss = 0.2027, Accuracy = 0.8600 Test Loss = 0.2109, Test Accuracy = 0.8448\n",
      "Iteration 1067: Loss = 0.1951, Accuracy = 0.8900 Test Loss = 0.2103, Test Accuracy = 0.8470\n",
      "Iteration 1068: Loss = 0.2249, Accuracy = 0.8000 Test Loss = 0.2103, Test Accuracy = 0.8518\n",
      "Iteration 1069: Loss = 0.2171, Accuracy = 0.8200 Test Loss = 0.2105, Test Accuracy = 0.8464\n",
      "Iteration 1070: Loss = 0.1896, Accuracy = 0.8600 Test Loss = 0.2103, Test Accuracy = 0.8494\n",
      "Iteration 1071: Loss = 0.2370, Accuracy = 0.7900 Test Loss = 0.2103, Test Accuracy = 0.8507\n",
      "Iteration 1072: Loss = 0.2247, Accuracy = 0.8500 Test Loss = 0.2105, Test Accuracy = 0.8501\n",
      "Iteration 1073: Loss = 0.2201, Accuracy = 0.8200 Test Loss = 0.2107, Test Accuracy = 0.8465\n",
      "Iteration 1074: Loss = 0.2072, Accuracy = 0.8400 Test Loss = 0.2103, Test Accuracy = 0.8521\n",
      "Iteration 1075: Loss = 0.2718, Accuracy = 0.8700 Test Loss = 0.2099, Test Accuracy = 0.8484\n",
      "Iteration 1076: Loss = 0.2205, Accuracy = 0.8100 Test Loss = 0.2099, Test Accuracy = 0.8487\n",
      "Iteration 1077: Loss = 0.1944, Accuracy = 0.8700 Test Loss = 0.2101, Test Accuracy = 0.8509\n",
      "Iteration 1078: Loss = 0.2067, Accuracy = 0.8800 Test Loss = 0.2105, Test Accuracy = 0.8524\n",
      "Iteration 1079: Loss = 0.2151, Accuracy = 0.8200 Test Loss = 0.2100, Test Accuracy = 0.8484\n",
      "Iteration 1080: Loss = 0.1813, Accuracy = 0.8200 Test Loss = 0.2103, Test Accuracy = 0.8481\n",
      "Iteration 1081: Loss = 0.2050, Accuracy = 0.8100 Test Loss = 0.2105, Test Accuracy = 0.8504\n",
      "Iteration 1082: Loss = 0.1721, Accuracy = 0.8800 Test Loss = 0.2103, Test Accuracy = 0.8529\n",
      "Iteration 1083: Loss = 0.1925, Accuracy = 0.8800 Test Loss = 0.2102, Test Accuracy = 0.8486\n",
      "Iteration 1084: Loss = 0.1924, Accuracy = 0.8600 Test Loss = 0.2100, Test Accuracy = 0.8468\n",
      "Iteration 1085: Loss = 0.2281, Accuracy = 0.8000 Test Loss = 0.2109, Test Accuracy = 0.8479\n",
      "Iteration 1086: Loss = 0.2306, Accuracy = 0.8300 Test Loss = 0.2105, Test Accuracy = 0.8542\n",
      "Iteration 1087: Loss = 0.2220, Accuracy = 0.8000 Test Loss = 0.2096, Test Accuracy = 0.8491\n",
      "Iteration 1088: Loss = 0.2009, Accuracy = 0.8600 Test Loss = 0.2100, Test Accuracy = 0.8478\n",
      "Iteration 1089: Loss = 0.2063, Accuracy = 0.8600 Test Loss = 0.2102, Test Accuracy = 0.8535\n",
      "Iteration 1090: Loss = 0.1983, Accuracy = 0.8900 Test Loss = 0.2097, Test Accuracy = 0.8516\n",
      "Iteration 1091: Loss = 0.2674, Accuracy = 0.8300 Test Loss = 0.2102, Test Accuracy = 0.8486\n",
      "Iteration 1092: Loss = 0.2106, Accuracy = 0.8700 Test Loss = 0.2100, Test Accuracy = 0.8517\n",
      "Iteration 1093: Loss = 0.2472, Accuracy = 0.7800 Test Loss = 0.2097, Test Accuracy = 0.8502\n",
      "Iteration 1094: Loss = 0.1990, Accuracy = 0.8500 Test Loss = 0.2100, Test Accuracy = 0.8531\n",
      "Iteration 1095: Loss = 0.2269, Accuracy = 0.8200 Test Loss = 0.2099, Test Accuracy = 0.8496\n",
      "Iteration 1096: Loss = 0.2462, Accuracy = 0.7900 Test Loss = 0.2100, Test Accuracy = 0.8454\n",
      "Iteration 1097: Loss = 0.2361, Accuracy = 0.7900 Test Loss = 0.2102, Test Accuracy = 0.8520\n",
      "Iteration 1098: Loss = 0.1851, Accuracy = 0.8800 Test Loss = 0.2096, Test Accuracy = 0.8507\n",
      "Iteration 1099: Loss = 0.1933, Accuracy = 0.8900 Test Loss = 0.2098, Test Accuracy = 0.8466\n",
      "Iteration 1100: Loss = 0.2104, Accuracy = 0.8200 Test Loss = 0.2100, Test Accuracy = 0.8479\n",
      "Iteration 1101: Loss = 0.2004, Accuracy = 0.8600 Test Loss = 0.2100, Test Accuracy = 0.8469\n",
      "Iteration 1102: Loss = 0.1918, Accuracy = 0.8600 Test Loss = 0.2094, Test Accuracy = 0.8489\n",
      "Iteration 1103: Loss = 0.2239, Accuracy = 0.8300 Test Loss = 0.2102, Test Accuracy = 0.8491\n",
      "Iteration 1104: Loss = 0.2166, Accuracy = 0.8300 Test Loss = 0.2094, Test Accuracy = 0.8504\n",
      "Iteration 1105: Loss = 0.2070, Accuracy = 0.8800 Test Loss = 0.2095, Test Accuracy = 0.8510\n",
      "Iteration 1106: Loss = 0.2132, Accuracy = 0.8400 Test Loss = 0.2107, Test Accuracy = 0.8493\n",
      "Iteration 1107: Loss = 0.1957, Accuracy = 0.8300 Test Loss = 0.2100, Test Accuracy = 0.8514\n",
      "Iteration 1108: Loss = 0.2523, Accuracy = 0.7700 Test Loss = 0.2099, Test Accuracy = 0.8529\n",
      "Iteration 1109: Loss = 0.1894, Accuracy = 0.8800 Test Loss = 0.2102, Test Accuracy = 0.8483\n",
      "Iteration 1110: Loss = 0.2149, Accuracy = 0.8200 Test Loss = 0.2096, Test Accuracy = 0.8507\n",
      "Iteration 1111: Loss = 0.2183, Accuracy = 0.8300 Test Loss = 0.2096, Test Accuracy = 0.8477\n",
      "Iteration 1112: Loss = 0.2059, Accuracy = 0.8600 Test Loss = 0.2097, Test Accuracy = 0.8530\n",
      "Iteration 1113: Loss = 0.1742, Accuracy = 0.8900 Test Loss = 0.2099, Test Accuracy = 0.8503\n",
      "Iteration 1114: Loss = 0.1776, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8476\n",
      "Iteration 1115: Loss = 0.1978, Accuracy = 0.8700 Test Loss = 0.2096, Test Accuracy = 0.8476\n",
      "Iteration 1116: Loss = 0.2307, Accuracy = 0.7900 Test Loss = 0.2095, Test Accuracy = 0.8485\n",
      "Iteration 1117: Loss = 0.2354, Accuracy = 0.8000 Test Loss = 0.2099, Test Accuracy = 0.8469\n",
      "Iteration 1118: Loss = 0.2039, Accuracy = 0.8600 Test Loss = 0.2093, Test Accuracy = 0.8468\n",
      "Iteration 1119: Loss = 0.1971, Accuracy = 0.8500 Test Loss = 0.2095, Test Accuracy = 0.8460\n",
      "Iteration 1120: Loss = 0.1952, Accuracy = 0.8400 Test Loss = 0.2096, Test Accuracy = 0.8492\n",
      "Iteration 1121: Loss = 0.2093, Accuracy = 0.8200 Test Loss = 0.2100, Test Accuracy = 0.8487\n",
      "Iteration 1122: Loss = 0.1921, Accuracy = 0.8300 Test Loss = 0.2100, Test Accuracy = 0.8492\n",
      "Iteration 1123: Loss = 0.2074, Accuracy = 0.8400 Test Loss = 0.2094, Test Accuracy = 0.8470\n",
      "Iteration 1124: Loss = 0.1823, Accuracy = 0.8900 Test Loss = 0.2095, Test Accuracy = 0.8482\n",
      "Iteration 1125: Loss = 0.2299, Accuracy = 0.8700 Test Loss = 0.2098, Test Accuracy = 0.8469\n",
      "Iteration 1126: Loss = 0.2081, Accuracy = 0.8500 Test Loss = 0.2092, Test Accuracy = 0.8502\n",
      "Iteration 1127: Loss = 0.2098, Accuracy = 0.9100 Test Loss = 0.2095, Test Accuracy = 0.8476\n",
      "Iteration 1128: Loss = 0.2199, Accuracy = 0.8900 Test Loss = 0.2101, Test Accuracy = 0.8459\n",
      "Iteration 1129: Loss = 0.1991, Accuracy = 0.8300 Test Loss = 0.2094, Test Accuracy = 0.8467\n",
      "Iteration 1130: Loss = 0.2032, Accuracy = 0.8900 Test Loss = 0.2096, Test Accuracy = 0.8478\n",
      "Iteration 1131: Loss = 0.2099, Accuracy = 0.8300 Test Loss = 0.2095, Test Accuracy = 0.8483\n",
      "Iteration 1132: Loss = 0.1675, Accuracy = 0.9000 Test Loss = 0.2104, Test Accuracy = 0.8436\n",
      "Iteration 1133: Loss = 0.2636, Accuracy = 0.8600 Test Loss = 0.2102, Test Accuracy = 0.8481\n",
      "Iteration 1134: Loss = 0.2162, Accuracy = 0.7900 Test Loss = 0.2092, Test Accuracy = 0.8512\n",
      "Iteration 1135: Loss = 0.1896, Accuracy = 0.9400 Test Loss = 0.2097, Test Accuracy = 0.8465\n",
      "Iteration 1136: Loss = 0.1913, Accuracy = 0.8700 Test Loss = 0.2094, Test Accuracy = 0.8498\n",
      "Iteration 1137: Loss = 0.2154, Accuracy = 0.9000 Test Loss = 0.2097, Test Accuracy = 0.8494\n",
      "Iteration 1138: Loss = 0.1957, Accuracy = 0.8200 Test Loss = 0.2096, Test Accuracy = 0.8481\n",
      "Iteration 1139: Loss = 0.2173, Accuracy = 0.8300 Test Loss = 0.2091, Test Accuracy = 0.8523\n",
      "Iteration 1140: Loss = 0.2240, Accuracy = 0.8800 Test Loss = 0.2098, Test Accuracy = 0.8457\n",
      "Iteration 1141: Loss = 0.2386, Accuracy = 0.8300 Test Loss = 0.2098, Test Accuracy = 0.8456\n",
      "Iteration 1142: Loss = 0.1917, Accuracy = 0.8700 Test Loss = 0.2094, Test Accuracy = 0.8469\n",
      "Iteration 1143: Loss = 0.2083, Accuracy = 0.8200 Test Loss = 0.2093, Test Accuracy = 0.8508\n",
      "Iteration 1144: Loss = 0.2209, Accuracy = 0.8400 Test Loss = 0.2096, Test Accuracy = 0.8466\n",
      "Iteration 1145: Loss = 0.1884, Accuracy = 0.8300 Test Loss = 0.2091, Test Accuracy = 0.8515\n",
      "Iteration 1146: Loss = 0.2186, Accuracy = 0.8600 Test Loss = 0.2091, Test Accuracy = 0.8509\n",
      "Iteration 1147: Loss = 0.2113, Accuracy = 0.8200 Test Loss = 0.2098, Test Accuracy = 0.8497\n",
      "Iteration 1148: Loss = 0.1981, Accuracy = 0.8900 Test Loss = 0.2089, Test Accuracy = 0.8517\n",
      "Iteration 1149: Loss = 0.2082, Accuracy = 0.8300 Test Loss = 0.2099, Test Accuracy = 0.8485\n",
      "Iteration 1150: Loss = 0.2056, Accuracy = 0.8500 Test Loss = 0.2092, Test Accuracy = 0.8499\n",
      "Iteration 1151: Loss = 0.1952, Accuracy = 0.8700 Test Loss = 0.2094, Test Accuracy = 0.8490\n",
      "Iteration 1152: Loss = 0.1740, Accuracy = 0.9000 Test Loss = 0.2097, Test Accuracy = 0.8470\n",
      "Iteration 1153: Loss = 0.2216, Accuracy = 0.8400 Test Loss = 0.2094, Test Accuracy = 0.8522\n",
      "Iteration 1154: Loss = 0.2090, Accuracy = 0.8300 Test Loss = 0.2095, Test Accuracy = 0.8469\n",
      "Iteration 1155: Loss = 0.1966, Accuracy = 0.8800 Test Loss = 0.2094, Test Accuracy = 0.8438\n",
      "Iteration 1156: Loss = 0.2174, Accuracy = 0.8300 Test Loss = 0.2093, Test Accuracy = 0.8540\n",
      "Iteration 1157: Loss = 0.1961, Accuracy = 0.9000 Test Loss = 0.2096, Test Accuracy = 0.8545\n",
      "Iteration 1158: Loss = 0.2088, Accuracy = 0.8300 Test Loss = 0.2090, Test Accuracy = 0.8498\n",
      "Iteration 1159: Loss = 0.1837, Accuracy = 0.9100 Test Loss = 0.2098, Test Accuracy = 0.8492\n",
      "Iteration 1160: Loss = 0.1963, Accuracy = 0.8500 Test Loss = 0.2095, Test Accuracy = 0.8452\n",
      "Iteration 1161: Loss = 0.2322, Accuracy = 0.8000 Test Loss = 0.2094, Test Accuracy = 0.8496\n",
      "Iteration 1162: Loss = 0.1927, Accuracy = 0.8600 Test Loss = 0.2091, Test Accuracy = 0.8468\n",
      "Iteration 1163: Loss = 0.1848, Accuracy = 0.8900 Test Loss = 0.2092, Test Accuracy = 0.8484\n",
      "Iteration 1164: Loss = 0.1925, Accuracy = 0.8200 Test Loss = 0.2093, Test Accuracy = 0.8478\n",
      "Iteration 1165: Loss = 0.1994, Accuracy = 0.8700 Test Loss = 0.2094, Test Accuracy = 0.8471\n",
      "Iteration 1166: Loss = 0.2362, Accuracy = 0.8000 Test Loss = 0.2089, Test Accuracy = 0.8488\n",
      "Iteration 1167: Loss = 0.2103, Accuracy = 0.8200 Test Loss = 0.2087, Test Accuracy = 0.8489\n",
      "Iteration 1168: Loss = 0.2157, Accuracy = 0.8600 Test Loss = 0.2092, Test Accuracy = 0.8507\n",
      "Iteration 1169: Loss = 0.1886, Accuracy = 0.8500 Test Loss = 0.2091, Test Accuracy = 0.8496\n",
      "Iteration 1170: Loss = 0.2067, Accuracy = 0.8700 Test Loss = 0.2088, Test Accuracy = 0.8497\n",
      "Iteration 1171: Loss = 0.2404, Accuracy = 0.8500 Test Loss = 0.2090, Test Accuracy = 0.8495\n",
      "Iteration 1172: Loss = 0.2522, Accuracy = 0.7800 Test Loss = 0.2097, Test Accuracy = 0.8501\n",
      "Iteration 1173: Loss = 0.1779, Accuracy = 0.8800 Test Loss = 0.2092, Test Accuracy = 0.8499\n",
      "Iteration 1174: Loss = 0.2027, Accuracy = 0.8600 Test Loss = 0.2090, Test Accuracy = 0.8474\n",
      "Iteration 1175: Loss = 0.2140, Accuracy = 0.8000 Test Loss = 0.2093, Test Accuracy = 0.8495\n",
      "Iteration 1176: Loss = 0.2242, Accuracy = 0.8100 Test Loss = 0.2092, Test Accuracy = 0.8464\n",
      "Iteration 1177: Loss = 0.1994, Accuracy = 0.8500 Test Loss = 0.2097, Test Accuracy = 0.8436\n",
      "Iteration 1178: Loss = 0.1846, Accuracy = 0.8600 Test Loss = 0.2092, Test Accuracy = 0.8480\n",
      "Iteration 1179: Loss = 0.2004, Accuracy = 0.8700 Test Loss = 0.2088, Test Accuracy = 0.8499\n",
      "Iteration 1180: Loss = 0.2291, Accuracy = 0.8000 Test Loss = 0.2091, Test Accuracy = 0.8460\n",
      "Iteration 1181: Loss = 0.1928, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8472\n",
      "Iteration 1182: Loss = 0.1822, Accuracy = 0.8400 Test Loss = 0.2095, Test Accuracy = 0.8471\n",
      "Iteration 1183: Loss = 0.2275, Accuracy = 0.7800 Test Loss = 0.2090, Test Accuracy = 0.8538\n",
      "Iteration 1184: Loss = 0.2227, Accuracy = 0.8200 Test Loss = 0.2088, Test Accuracy = 0.8499\n",
      "Iteration 1185: Loss = 0.2258, Accuracy = 0.7600 Test Loss = 0.2086, Test Accuracy = 0.8520\n",
      "Iteration 1186: Loss = 0.1856, Accuracy = 0.8900 Test Loss = 0.2092, Test Accuracy = 0.8488\n",
      "Iteration 1187: Loss = 0.2265, Accuracy = 0.8400 Test Loss = 0.2094, Test Accuracy = 0.8500\n",
      "Iteration 1188: Loss = 0.2232, Accuracy = 0.7700 Test Loss = 0.2096, Test Accuracy = 0.8469\n",
      "Iteration 1189: Loss = 0.2131, Accuracy = 0.8200 Test Loss = 0.2091, Test Accuracy = 0.8453\n",
      "Iteration 1190: Loss = 0.1863, Accuracy = 0.8500 Test Loss = 0.2086, Test Accuracy = 0.8507\n",
      "Iteration 1191: Loss = 0.1935, Accuracy = 0.8300 Test Loss = 0.2087, Test Accuracy = 0.8480\n",
      "Iteration 1192: Loss = 0.2075, Accuracy = 0.8800 Test Loss = 0.2091, Test Accuracy = 0.8465\n",
      "Iteration 1193: Loss = 0.1939, Accuracy = 0.8400 Test Loss = 0.2087, Test Accuracy = 0.8495\n",
      "Iteration 1194: Loss = 0.2044, Accuracy = 0.8100 Test Loss = 0.2088, Test Accuracy = 0.8504\n",
      "Iteration 1195: Loss = 0.2053, Accuracy = 0.8600 Test Loss = 0.2085, Test Accuracy = 0.8519\n",
      "Iteration 1196: Loss = 0.2070, Accuracy = 0.8400 Test Loss = 0.2086, Test Accuracy = 0.8492\n",
      "Iteration 1197: Loss = 0.2025, Accuracy = 0.8500 Test Loss = 0.2089, Test Accuracy = 0.8481\n",
      "Iteration 1198: Loss = 0.2022, Accuracy = 0.8400 Test Loss = 0.2091, Test Accuracy = 0.8481\n",
      "Iteration 1199: Loss = 0.1731, Accuracy = 0.9000 Test Loss = 0.2085, Test Accuracy = 0.8466\n",
      "Iteration 1200: Loss = 0.1648, Accuracy = 0.9300 Test Loss = 0.2087, Test Accuracy = 0.8484\n",
      "Iteration 1201: Loss = 0.2200, Accuracy = 0.8600 Test Loss = 0.2087, Test Accuracy = 0.8503\n",
      "Iteration 1202: Loss = 0.2227, Accuracy = 0.8500 Test Loss = 0.2086, Test Accuracy = 0.8522\n",
      "Iteration 1203: Loss = 0.1882, Accuracy = 0.8800 Test Loss = 0.2087, Test Accuracy = 0.8512\n",
      "Iteration 1204: Loss = 0.2263, Accuracy = 0.8100 Test Loss = 0.2095, Test Accuracy = 0.8482\n",
      "Iteration 1205: Loss = 0.2067, Accuracy = 0.8300 Test Loss = 0.2084, Test Accuracy = 0.8495\n",
      "Iteration 1206: Loss = 0.2161, Accuracy = 0.8300 Test Loss = 0.2089, Test Accuracy = 0.8486\n",
      "Iteration 1207: Loss = 0.2049, Accuracy = 0.8400 Test Loss = 0.2086, Test Accuracy = 0.8535\n",
      "Iteration 1208: Loss = 0.2246, Accuracy = 0.8300 Test Loss = 0.2089, Test Accuracy = 0.8519\n",
      "Iteration 1209: Loss = 0.2389, Accuracy = 0.8000 Test Loss = 0.2090, Test Accuracy = 0.8468\n",
      "Iteration 1210: Loss = 0.1860, Accuracy = 0.8900 Test Loss = 0.2085, Test Accuracy = 0.8501\n",
      "Iteration 1211: Loss = 0.2103, Accuracy = 0.8300 Test Loss = 0.2086, Test Accuracy = 0.8518\n",
      "Iteration 1212: Loss = 0.1783, Accuracy = 0.8800 Test Loss = 0.2086, Test Accuracy = 0.8491\n",
      "Iteration 1213: Loss = 0.1996, Accuracy = 0.8900 Test Loss = 0.2090, Test Accuracy = 0.8467\n",
      "Iteration 1214: Loss = 0.2083, Accuracy = 0.8500 Test Loss = 0.2089, Test Accuracy = 0.8489\n",
      "Iteration 1215: Loss = 0.2163, Accuracy = 0.8400 Test Loss = 0.2083, Test Accuracy = 0.8498\n",
      "Iteration 1216: Loss = 0.1980, Accuracy = 0.8200 Test Loss = 0.2087, Test Accuracy = 0.8487\n",
      "Iteration 1217: Loss = 0.2581, Accuracy = 0.8000 Test Loss = 0.2084, Test Accuracy = 0.8465\n",
      "Iteration 1218: Loss = 0.2036, Accuracy = 0.8400 Test Loss = 0.2090, Test Accuracy = 0.8479\n",
      "Iteration 1219: Loss = 0.1988, Accuracy = 0.8300 Test Loss = 0.2088, Test Accuracy = 0.8502\n",
      "Iteration 1220: Loss = 0.2246, Accuracy = 0.8200 Test Loss = 0.2087, Test Accuracy = 0.8478\n",
      "Iteration 1221: Loss = 0.2118, Accuracy = 0.8300 Test Loss = 0.2092, Test Accuracy = 0.8456\n",
      "Iteration 1222: Loss = 0.1880, Accuracy = 0.8600 Test Loss = 0.2088, Test Accuracy = 0.8497\n",
      "Iteration 1223: Loss = 0.1800, Accuracy = 0.9200 Test Loss = 0.2092, Test Accuracy = 0.8486\n",
      "Iteration 1224: Loss = 0.2156, Accuracy = 0.8200 Test Loss = 0.2087, Test Accuracy = 0.8526\n",
      "Iteration 1225: Loss = 0.2023, Accuracy = 0.8700 Test Loss = 0.2088, Test Accuracy = 0.8516\n",
      "Iteration 1226: Loss = 0.2147, Accuracy = 0.8400 Test Loss = 0.2086, Test Accuracy = 0.8459\n",
      "Iteration 1227: Loss = 0.2224, Accuracy = 0.8300 Test Loss = 0.2083, Test Accuracy = 0.8483\n",
      "Iteration 1228: Loss = 0.1979, Accuracy = 0.8400 Test Loss = 0.2084, Test Accuracy = 0.8495\n",
      "Iteration 1229: Loss = 0.2117, Accuracy = 0.8500 Test Loss = 0.2086, Test Accuracy = 0.8513\n",
      "Iteration 1230: Loss = 0.2563, Accuracy = 0.7800 Test Loss = 0.2090, Test Accuracy = 0.8505\n",
      "Iteration 1231: Loss = 0.1707, Accuracy = 0.9000 Test Loss = 0.2088, Test Accuracy = 0.8455\n",
      "Iteration 1232: Loss = 0.1970, Accuracy = 0.8800 Test Loss = 0.2088, Test Accuracy = 0.8474\n",
      "Iteration 1233: Loss = 0.1796, Accuracy = 0.8600 Test Loss = 0.2087, Test Accuracy = 0.8456\n",
      "Iteration 1234: Loss = 0.1842, Accuracy = 0.8900 Test Loss = 0.2086, Test Accuracy = 0.8494\n",
      "Iteration 1235: Loss = 0.1874, Accuracy = 0.8400 Test Loss = 0.2087, Test Accuracy = 0.8480\n",
      "Iteration 1236: Loss = 0.1936, Accuracy = 0.8600 Test Loss = 0.2089, Test Accuracy = 0.8490\n",
      "Iteration 1237: Loss = 0.1852, Accuracy = 0.8600 Test Loss = 0.2082, Test Accuracy = 0.8502\n",
      "Iteration 1238: Loss = 0.1883, Accuracy = 0.8400 Test Loss = 0.2086, Test Accuracy = 0.8518\n",
      "Iteration 1239: Loss = 0.2180, Accuracy = 0.8200 Test Loss = 0.2088, Test Accuracy = 0.8484\n",
      "Iteration 1240: Loss = 0.1974, Accuracy = 0.8400 Test Loss = 0.2083, Test Accuracy = 0.8479\n",
      "Iteration 1241: Loss = 0.2037, Accuracy = 0.8700 Test Loss = 0.2090, Test Accuracy = 0.8501\n",
      "Iteration 1242: Loss = 0.2010, Accuracy = 0.8600 Test Loss = 0.2091, Test Accuracy = 0.8491\n",
      "Iteration 1243: Loss = 0.2088, Accuracy = 0.8700 Test Loss = 0.2083, Test Accuracy = 0.8521\n",
      "Iteration 1244: Loss = 0.1824, Accuracy = 0.8800 Test Loss = 0.2080, Test Accuracy = 0.8468\n",
      "Iteration 1245: Loss = 0.2016, Accuracy = 0.8700 Test Loss = 0.2083, Test Accuracy = 0.8494\n",
      "Iteration 1246: Loss = 0.2009, Accuracy = 0.8800 Test Loss = 0.2088, Test Accuracy = 0.8502\n",
      "Iteration 1247: Loss = 0.2190, Accuracy = 0.8000 Test Loss = 0.2087, Test Accuracy = 0.8488\n",
      "Iteration 1248: Loss = 0.1893, Accuracy = 0.9000 Test Loss = 0.2084, Test Accuracy = 0.8476\n",
      "Iteration 1249: Loss = 0.1927, Accuracy = 0.8600 Test Loss = 0.2086, Test Accuracy = 0.8525\n",
      "Iteration 1250: Loss = 0.2453, Accuracy = 0.7700 Test Loss = 0.2084, Test Accuracy = 0.8512\n",
      "Iteration 1251: Loss = 0.2251, Accuracy = 0.8400 Test Loss = 0.2081, Test Accuracy = 0.8486\n",
      "Iteration 1252: Loss = 0.1930, Accuracy = 0.8200 Test Loss = 0.2082, Test Accuracy = 0.8502\n",
      "Iteration 1253: Loss = 0.1964, Accuracy = 0.8400 Test Loss = 0.2083, Test Accuracy = 0.8523\n",
      "Iteration 1254: Loss = 0.1757, Accuracy = 0.9000 Test Loss = 0.2087, Test Accuracy = 0.8428\n",
      "Iteration 1255: Loss = 0.1862, Accuracy = 0.8700 Test Loss = 0.2086, Test Accuracy = 0.8465\n",
      "Iteration 1256: Loss = 0.1986, Accuracy = 0.8500 Test Loss = 0.2081, Test Accuracy = 0.8502\n",
      "Iteration 1257: Loss = 0.1821, Accuracy = 0.8900 Test Loss = 0.2082, Test Accuracy = 0.8490\n",
      "Iteration 1258: Loss = 0.2113, Accuracy = 0.8200 Test Loss = 0.2081, Test Accuracy = 0.8482\n",
      "Iteration 1259: Loss = 0.2210, Accuracy = 0.7800 Test Loss = 0.2080, Test Accuracy = 0.8527\n",
      "Iteration 1260: Loss = 0.1994, Accuracy = 0.8600 Test Loss = 0.2083, Test Accuracy = 0.8485\n",
      "Iteration 1261: Loss = 0.1972, Accuracy = 0.9200 Test Loss = 0.2080, Test Accuracy = 0.8498\n",
      "Iteration 1262: Loss = 0.2452, Accuracy = 0.7800 Test Loss = 0.2081, Test Accuracy = 0.8516\n",
      "Iteration 1263: Loss = 0.1819, Accuracy = 0.9200 Test Loss = 0.2084, Test Accuracy = 0.8505\n",
      "Iteration 1264: Loss = 0.2333, Accuracy = 0.8100 Test Loss = 0.2085, Test Accuracy = 0.8527\n",
      "Iteration 1265: Loss = 0.1782, Accuracy = 0.9100 Test Loss = 0.2083, Test Accuracy = 0.8480\n",
      "Iteration 1266: Loss = 0.2113, Accuracy = 0.8700 Test Loss = 0.2081, Test Accuracy = 0.8495\n",
      "Iteration 1267: Loss = 0.1857, Accuracy = 0.8500 Test Loss = 0.2086, Test Accuracy = 0.8462\n",
      "Iteration 1268: Loss = 0.2298, Accuracy = 0.8300 Test Loss = 0.2083, Test Accuracy = 0.8501\n",
      "Iteration 1269: Loss = 0.2501, Accuracy = 0.8100 Test Loss = 0.2088, Test Accuracy = 0.8496\n",
      "Iteration 1270: Loss = 0.2234, Accuracy = 0.8300 Test Loss = 0.2081, Test Accuracy = 0.8511\n",
      "Iteration 1271: Loss = 0.2101, Accuracy = 0.8200 Test Loss = 0.2079, Test Accuracy = 0.8525\n",
      "Iteration 1272: Loss = 0.1833, Accuracy = 0.8900 Test Loss = 0.2080, Test Accuracy = 0.8525\n",
      "Iteration 1273: Loss = 0.2057, Accuracy = 0.8400 Test Loss = 0.2082, Test Accuracy = 0.8488\n",
      "Iteration 1274: Loss = 0.2235, Accuracy = 0.8000 Test Loss = 0.2081, Test Accuracy = 0.8495\n",
      "Iteration 1275: Loss = 0.2275, Accuracy = 0.7700 Test Loss = 0.2081, Test Accuracy = 0.8516\n",
      "Iteration 1276: Loss = 0.2082, Accuracy = 0.8200 Test Loss = 0.2081, Test Accuracy = 0.8508\n",
      "Iteration 1277: Loss = 0.2005, Accuracy = 0.8400 Test Loss = 0.2084, Test Accuracy = 0.8472\n",
      "Iteration 1278: Loss = 0.2352, Accuracy = 0.8600 Test Loss = 0.2082, Test Accuracy = 0.8528\n",
      "Iteration 1279: Loss = 0.2230, Accuracy = 0.8400 Test Loss = 0.2079, Test Accuracy = 0.8505\n",
      "Iteration 1280: Loss = 0.2370, Accuracy = 0.8500 Test Loss = 0.2077, Test Accuracy = 0.8492\n",
      "Iteration 1281: Loss = 0.2222, Accuracy = 0.7900 Test Loss = 0.2083, Test Accuracy = 0.8497\n",
      "Iteration 1282: Loss = 0.1922, Accuracy = 0.8600 Test Loss = 0.2077, Test Accuracy = 0.8510\n",
      "Iteration 1283: Loss = 0.2537, Accuracy = 0.7700 Test Loss = 0.2080, Test Accuracy = 0.8522\n",
      "Iteration 1284: Loss = 0.1815, Accuracy = 0.8800 Test Loss = 0.2088, Test Accuracy = 0.8456\n",
      "Iteration 1285: Loss = 0.2280, Accuracy = 0.8300 Test Loss = 0.2077, Test Accuracy = 0.8524\n",
      "Iteration 1286: Loss = 0.2001, Accuracy = 0.8500 Test Loss = 0.2085, Test Accuracy = 0.8469\n",
      "Iteration 1287: Loss = 0.2099, Accuracy = 0.8300 Test Loss = 0.2081, Test Accuracy = 0.8459\n",
      "Iteration 1288: Loss = 0.1743, Accuracy = 0.8900 Test Loss = 0.2079, Test Accuracy = 0.8474\n",
      "Iteration 1289: Loss = 0.1842, Accuracy = 0.8600 Test Loss = 0.2078, Test Accuracy = 0.8528\n",
      "Iteration 1290: Loss = 0.1958, Accuracy = 0.8600 Test Loss = 0.2079, Test Accuracy = 0.8497\n",
      "Iteration 1291: Loss = 0.2159, Accuracy = 0.8200 Test Loss = 0.2078, Test Accuracy = 0.8538\n",
      "Iteration 1292: Loss = 0.2410, Accuracy = 0.7800 Test Loss = 0.2079, Test Accuracy = 0.8476\n",
      "Iteration 1293: Loss = 0.2059, Accuracy = 0.8100 Test Loss = 0.2081, Test Accuracy = 0.8476\n",
      "Iteration 1294: Loss = 0.2065, Accuracy = 0.8200 Test Loss = 0.2083, Test Accuracy = 0.8482\n",
      "Iteration 1295: Loss = 0.1924, Accuracy = 0.8700 Test Loss = 0.2077, Test Accuracy = 0.8491\n",
      "Iteration 1296: Loss = 0.2346, Accuracy = 0.7900 Test Loss = 0.2078, Test Accuracy = 0.8491\n",
      "Iteration 1297: Loss = 0.2293, Accuracy = 0.8100 Test Loss = 0.2081, Test Accuracy = 0.8503\n",
      "Iteration 1298: Loss = 0.2197, Accuracy = 0.8000 Test Loss = 0.2079, Test Accuracy = 0.8516\n",
      "Iteration 1299: Loss = 0.2270, Accuracy = 0.8400 Test Loss = 0.2081, Test Accuracy = 0.8486\n",
      "Iteration 1300: Loss = 0.1609, Accuracy = 0.8900 Test Loss = 0.2078, Test Accuracy = 0.8483\n",
      "Iteration 1301: Loss = 0.2102, Accuracy = 0.8100 Test Loss = 0.2082, Test Accuracy = 0.8487\n",
      "Iteration 1302: Loss = 0.2056, Accuracy = 0.8400 Test Loss = 0.2076, Test Accuracy = 0.8529\n",
      "Iteration 1303: Loss = 0.1992, Accuracy = 0.8400 Test Loss = 0.2078, Test Accuracy = 0.8528\n",
      "Iteration 1304: Loss = 0.2513, Accuracy = 0.8200 Test Loss = 0.2075, Test Accuracy = 0.8496\n",
      "Iteration 1305: Loss = 0.2026, Accuracy = 0.8200 Test Loss = 0.2081, Test Accuracy = 0.8530\n",
      "Iteration 1306: Loss = 0.2182, Accuracy = 0.8300 Test Loss = 0.2082, Test Accuracy = 0.8493\n",
      "Iteration 1307: Loss = 0.2452, Accuracy = 0.8100 Test Loss = 0.2075, Test Accuracy = 0.8515\n",
      "Iteration 1308: Loss = 0.1881, Accuracy = 0.9000 Test Loss = 0.2076, Test Accuracy = 0.8491\n",
      "Iteration 1309: Loss = 0.2253, Accuracy = 0.8200 Test Loss = 0.2079, Test Accuracy = 0.8521\n",
      "Iteration 1310: Loss = 0.2168, Accuracy = 0.8300 Test Loss = 0.2077, Test Accuracy = 0.8490\n",
      "Iteration 1311: Loss = 0.2006, Accuracy = 0.8700 Test Loss = 0.2079, Test Accuracy = 0.8464\n",
      "Iteration 1312: Loss = 0.2318, Accuracy = 0.7600 Test Loss = 0.2076, Test Accuracy = 0.8495\n",
      "Iteration 1313: Loss = 0.2342, Accuracy = 0.7600 Test Loss = 0.2076, Test Accuracy = 0.8497\n",
      "Iteration 1314: Loss = 0.1762, Accuracy = 0.8800 Test Loss = 0.2078, Test Accuracy = 0.8483\n",
      "Iteration 1315: Loss = 0.2137, Accuracy = 0.8300 Test Loss = 0.2081, Test Accuracy = 0.8444\n",
      "Iteration 1316: Loss = 0.1892, Accuracy = 0.8800 Test Loss = 0.2078, Test Accuracy = 0.8488\n",
      "Iteration 1317: Loss = 0.1808, Accuracy = 0.8900 Test Loss = 0.2084, Test Accuracy = 0.8464\n",
      "Iteration 1318: Loss = 0.2250, Accuracy = 0.8100 Test Loss = 0.2076, Test Accuracy = 0.8505\n",
      "Iteration 1319: Loss = 0.2303, Accuracy = 0.8200 Test Loss = 0.2079, Test Accuracy = 0.8533\n",
      "Iteration 1320: Loss = 0.2177, Accuracy = 0.8200 Test Loss = 0.2079, Test Accuracy = 0.8461\n",
      "Iteration 1321: Loss = 0.1735, Accuracy = 0.9100 Test Loss = 0.2077, Test Accuracy = 0.8451\n",
      "Iteration 1322: Loss = 0.2106, Accuracy = 0.8600 Test Loss = 0.2091, Test Accuracy = 0.8491\n",
      "Iteration 1323: Loss = 0.2267, Accuracy = 0.8000 Test Loss = 0.2080, Test Accuracy = 0.8480\n",
      "Iteration 1324: Loss = 0.1985, Accuracy = 0.9200 Test Loss = 0.2079, Test Accuracy = 0.8487\n",
      "Iteration 1325: Loss = 0.1917, Accuracy = 0.8400 Test Loss = 0.2076, Test Accuracy = 0.8531\n",
      "Iteration 1326: Loss = 0.1951, Accuracy = 0.8600 Test Loss = 0.2078, Test Accuracy = 0.8496\n",
      "Iteration 1327: Loss = 0.2346, Accuracy = 0.7700 Test Loss = 0.2074, Test Accuracy = 0.8501\n",
      "Iteration 1328: Loss = 0.2045, Accuracy = 0.8700 Test Loss = 0.2075, Test Accuracy = 0.8538\n",
      "Iteration 1329: Loss = 0.2073, Accuracy = 0.8900 Test Loss = 0.2075, Test Accuracy = 0.8542\n",
      "Iteration 1330: Loss = 0.2063, Accuracy = 0.8600 Test Loss = 0.2077, Test Accuracy = 0.8502\n",
      "Iteration 1331: Loss = 0.2188, Accuracy = 0.8900 Test Loss = 0.2079, Test Accuracy = 0.8457\n",
      "Iteration 1332: Loss = 0.2138, Accuracy = 0.8300 Test Loss = 0.2076, Test Accuracy = 0.8534\n",
      "Iteration 1333: Loss = 0.2084, Accuracy = 0.8600 Test Loss = 0.2077, Test Accuracy = 0.8513\n",
      "Iteration 1334: Loss = 0.2454, Accuracy = 0.8000 Test Loss = 0.2077, Test Accuracy = 0.8531\n",
      "Iteration 1335: Loss = 0.2090, Accuracy = 0.8400 Test Loss = 0.2075, Test Accuracy = 0.8496\n",
      "Iteration 1336: Loss = 0.1916, Accuracy = 0.8600 Test Loss = 0.2075, Test Accuracy = 0.8492\n",
      "Iteration 1337: Loss = 0.2389, Accuracy = 0.7900 Test Loss = 0.2073, Test Accuracy = 0.8517\n",
      "Iteration 1338: Loss = 0.1860, Accuracy = 0.8500 Test Loss = 0.2080, Test Accuracy = 0.8482\n",
      "Iteration 1339: Loss = 0.2101, Accuracy = 0.8600 Test Loss = 0.2080, Test Accuracy = 0.8520\n",
      "Iteration 1340: Loss = 0.1696, Accuracy = 0.9100 Test Loss = 0.2073, Test Accuracy = 0.8520\n",
      "Iteration 1341: Loss = 0.1915, Accuracy = 0.8700 Test Loss = 0.2073, Test Accuracy = 0.8475\n",
      "Iteration 1342: Loss = 0.2309, Accuracy = 0.7700 Test Loss = 0.2075, Test Accuracy = 0.8495\n",
      "Iteration 1343: Loss = 0.2124, Accuracy = 0.7800 Test Loss = 0.2075, Test Accuracy = 0.8483\n",
      "Iteration 1344: Loss = 0.2289, Accuracy = 0.8400 Test Loss = 0.2074, Test Accuracy = 0.8523\n",
      "Iteration 1345: Loss = 0.2156, Accuracy = 0.8500 Test Loss = 0.2076, Test Accuracy = 0.8495\n",
      "Iteration 1346: Loss = 0.2020, Accuracy = 0.8500 Test Loss = 0.2077, Test Accuracy = 0.8489\n",
      "Iteration 1347: Loss = 0.2318, Accuracy = 0.7600 Test Loss = 0.2074, Test Accuracy = 0.8471\n",
      "Iteration 1348: Loss = 0.1887, Accuracy = 0.8600 Test Loss = 0.2076, Test Accuracy = 0.8510\n",
      "Iteration 1349: Loss = 0.2030, Accuracy = 0.8900 Test Loss = 0.2073, Test Accuracy = 0.8518\n",
      "Iteration 1350: Loss = 0.2149, Accuracy = 0.7900 Test Loss = 0.2075, Test Accuracy = 0.8534\n",
      "Iteration 1351: Loss = 0.2187, Accuracy = 0.8300 Test Loss = 0.2077, Test Accuracy = 0.8513\n",
      "Iteration 1352: Loss = 0.2067, Accuracy = 0.8600 Test Loss = 0.2077, Test Accuracy = 0.8472\n",
      "Iteration 1353: Loss = 0.1997, Accuracy = 0.8700 Test Loss = 0.2077, Test Accuracy = 0.8479\n",
      "Iteration 1354: Loss = 0.1840, Accuracy = 0.8500 Test Loss = 0.2077, Test Accuracy = 0.8485\n",
      "Iteration 1355: Loss = 0.1717, Accuracy = 0.8600 Test Loss = 0.2073, Test Accuracy = 0.8493\n",
      "Iteration 1356: Loss = 0.2026, Accuracy = 0.8300 Test Loss = 0.2075, Test Accuracy = 0.8491\n",
      "Iteration 1357: Loss = 0.1890, Accuracy = 0.8700 Test Loss = 0.2075, Test Accuracy = 0.8511\n",
      "Iteration 1358: Loss = 0.1993, Accuracy = 0.8300 Test Loss = 0.2073, Test Accuracy = 0.8497\n",
      "Iteration 1359: Loss = 0.2142, Accuracy = 0.8700 Test Loss = 0.2073, Test Accuracy = 0.8501\n",
      "Iteration 1360: Loss = 0.2176, Accuracy = 0.8300 Test Loss = 0.2069, Test Accuracy = 0.8468\n",
      "Iteration 1361: Loss = 0.2011, Accuracy = 0.8400 Test Loss = 0.2071, Test Accuracy = 0.8513\n",
      "Iteration 1362: Loss = 0.1782, Accuracy = 0.8700 Test Loss = 0.2076, Test Accuracy = 0.8472\n",
      "Iteration 1363: Loss = 0.1985, Accuracy = 0.8400 Test Loss = 0.2074, Test Accuracy = 0.8463\n",
      "Iteration 1364: Loss = 0.1828, Accuracy = 0.8800 Test Loss = 0.2069, Test Accuracy = 0.8508\n",
      "Iteration 1365: Loss = 0.2051, Accuracy = 0.8200 Test Loss = 0.2073, Test Accuracy = 0.8535\n",
      "Iteration 1366: Loss = 0.1914, Accuracy = 0.8500 Test Loss = 0.2075, Test Accuracy = 0.8508\n",
      "Iteration 1367: Loss = 0.2106, Accuracy = 0.8100 Test Loss = 0.2073, Test Accuracy = 0.8517\n",
      "Iteration 1368: Loss = 0.2066, Accuracy = 0.8500 Test Loss = 0.2071, Test Accuracy = 0.8499\n",
      "Iteration 1369: Loss = 0.2113, Accuracy = 0.8500 Test Loss = 0.2071, Test Accuracy = 0.8502\n",
      "Iteration 1370: Loss = 0.2410, Accuracy = 0.7900 Test Loss = 0.2078, Test Accuracy = 0.8508\n",
      "Iteration 1371: Loss = 0.1948, Accuracy = 0.8400 Test Loss = 0.2073, Test Accuracy = 0.8513\n",
      "Iteration 1372: Loss = 0.2383, Accuracy = 0.8000 Test Loss = 0.2073, Test Accuracy = 0.8502\n",
      "Iteration 1373: Loss = 0.1861, Accuracy = 0.9000 Test Loss = 0.2070, Test Accuracy = 0.8512\n",
      "Iteration 1374: Loss = 0.2086, Accuracy = 0.8300 Test Loss = 0.2078, Test Accuracy = 0.8483\n",
      "Iteration 1375: Loss = 0.2206, Accuracy = 0.8500 Test Loss = 0.2075, Test Accuracy = 0.8483\n",
      "Iteration 1376: Loss = 0.2112, Accuracy = 0.8900 Test Loss = 0.2069, Test Accuracy = 0.8510\n",
      "Iteration 1377: Loss = 0.1873, Accuracy = 0.8500 Test Loss = 0.2070, Test Accuracy = 0.8482\n",
      "Iteration 1378: Loss = 0.2056, Accuracy = 0.8600 Test Loss = 0.2078, Test Accuracy = 0.8522\n",
      "Iteration 1379: Loss = 0.1766, Accuracy = 0.8800 Test Loss = 0.2077, Test Accuracy = 0.8510\n",
      "Iteration 1380: Loss = 0.1875, Accuracy = 0.9000 Test Loss = 0.2074, Test Accuracy = 0.8519\n",
      "Iteration 1381: Loss = 0.1898, Accuracy = 0.9000 Test Loss = 0.2075, Test Accuracy = 0.8479\n",
      "Iteration 1382: Loss = 0.2232, Accuracy = 0.8000 Test Loss = 0.2072, Test Accuracy = 0.8478\n",
      "Iteration 1383: Loss = 0.1829, Accuracy = 0.8800 Test Loss = 0.2072, Test Accuracy = 0.8517\n",
      "Iteration 1384: Loss = 0.2054, Accuracy = 0.8400 Test Loss = 0.2072, Test Accuracy = 0.8517\n",
      "Iteration 1385: Loss = 0.1864, Accuracy = 0.8700 Test Loss = 0.2071, Test Accuracy = 0.8522\n",
      "Iteration 1386: Loss = 0.2280, Accuracy = 0.7800 Test Loss = 0.2078, Test Accuracy = 0.8522\n",
      "Iteration 1387: Loss = 0.2354, Accuracy = 0.8000 Test Loss = 0.2071, Test Accuracy = 0.8522\n",
      "Iteration 1388: Loss = 0.2023, Accuracy = 0.8300 Test Loss = 0.2069, Test Accuracy = 0.8500\n",
      "Iteration 1389: Loss = 0.1921, Accuracy = 0.8700 Test Loss = 0.2084, Test Accuracy = 0.8517\n",
      "Iteration 1390: Loss = 0.1994, Accuracy = 0.8500 Test Loss = 0.2070, Test Accuracy = 0.8513\n",
      "Iteration 1391: Loss = 0.1792, Accuracy = 0.8500 Test Loss = 0.2071, Test Accuracy = 0.8482\n",
      "Iteration 1392: Loss = 0.2302, Accuracy = 0.7900 Test Loss = 0.2078, Test Accuracy = 0.8561\n",
      "Iteration 1393: Loss = 0.2278, Accuracy = 0.8600 Test Loss = 0.2072, Test Accuracy = 0.8524\n",
      "Iteration 1394: Loss = 0.2255, Accuracy = 0.8200 Test Loss = 0.2072, Test Accuracy = 0.8535\n",
      "Iteration 1395: Loss = 0.2105, Accuracy = 0.8100 Test Loss = 0.2075, Test Accuracy = 0.8473\n",
      "Iteration 1396: Loss = 0.2330, Accuracy = 0.8200 Test Loss = 0.2070, Test Accuracy = 0.8519\n",
      "Iteration 1397: Loss = 0.1827, Accuracy = 0.8600 Test Loss = 0.2077, Test Accuracy = 0.8493\n",
      "Iteration 1398: Loss = 0.1697, Accuracy = 0.9400 Test Loss = 0.2070, Test Accuracy = 0.8479\n",
      "Iteration 1399: Loss = 0.1998, Accuracy = 0.8900 Test Loss = 0.2068, Test Accuracy = 0.8481\n",
      "Iteration 1400: Loss = 0.1924, Accuracy = 0.8400 Test Loss = 0.2069, Test Accuracy = 0.8494\n",
      "Iteration 1401: Loss = 0.2038, Accuracy = 0.8800 Test Loss = 0.2078, Test Accuracy = 0.8471\n",
      "Iteration 1402: Loss = 0.2063, Accuracy = 0.8400 Test Loss = 0.2070, Test Accuracy = 0.8500\n",
      "Iteration 1403: Loss = 0.1820, Accuracy = 0.9000 Test Loss = 0.2068, Test Accuracy = 0.8489\n",
      "Iteration 1404: Loss = 0.2301, Accuracy = 0.8000 Test Loss = 0.2069, Test Accuracy = 0.8522\n",
      "Iteration 1405: Loss = 0.2109, Accuracy = 0.8500 Test Loss = 0.2071, Test Accuracy = 0.8493\n",
      "Iteration 1406: Loss = 0.2245, Accuracy = 0.7900 Test Loss = 0.2068, Test Accuracy = 0.8518\n",
      "Iteration 1407: Loss = 0.2011, Accuracy = 0.8300 Test Loss = 0.2069, Test Accuracy = 0.8458\n",
      "Iteration 1408: Loss = 0.2059, Accuracy = 0.8400 Test Loss = 0.2073, Test Accuracy = 0.8500\n",
      "Iteration 1409: Loss = 0.2219, Accuracy = 0.8600 Test Loss = 0.2069, Test Accuracy = 0.8513\n",
      "Iteration 1410: Loss = 0.1717, Accuracy = 0.9200 Test Loss = 0.2079, Test Accuracy = 0.8487\n",
      "Iteration 1411: Loss = 0.1936, Accuracy = 0.8800 Test Loss = 0.2066, Test Accuracy = 0.8504\n",
      "Iteration 1412: Loss = 0.2253, Accuracy = 0.7600 Test Loss = 0.2068, Test Accuracy = 0.8494\n",
      "Iteration 1413: Loss = 0.2312, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8510\n",
      "Iteration 1414: Loss = 0.2658, Accuracy = 0.8400 Test Loss = 0.2067, Test Accuracy = 0.8530\n",
      "Iteration 1415: Loss = 0.2174, Accuracy = 0.8000 Test Loss = 0.2076, Test Accuracy = 0.8466\n",
      "Iteration 1416: Loss = 0.1785, Accuracy = 0.8800 Test Loss = 0.2068, Test Accuracy = 0.8545\n",
      "Iteration 1417: Loss = 0.2014, Accuracy = 0.8900 Test Loss = 0.2069, Test Accuracy = 0.8511\n",
      "Iteration 1418: Loss = 0.1846, Accuracy = 0.9400 Test Loss = 0.2067, Test Accuracy = 0.8515\n",
      "Iteration 1419: Loss = 0.2536, Accuracy = 0.8300 Test Loss = 0.2070, Test Accuracy = 0.8513\n",
      "Iteration 1420: Loss = 0.2042, Accuracy = 0.8400 Test Loss = 0.2075, Test Accuracy = 0.8466\n",
      "Iteration 1421: Loss = 0.2005, Accuracy = 0.8200 Test Loss = 0.2071, Test Accuracy = 0.8489\n",
      "Iteration 1422: Loss = 0.2213, Accuracy = 0.7900 Test Loss = 0.2069, Test Accuracy = 0.8538\n",
      "Iteration 1423: Loss = 0.2232, Accuracy = 0.8000 Test Loss = 0.2066, Test Accuracy = 0.8535\n",
      "Iteration 1424: Loss = 0.1860, Accuracy = 0.8600 Test Loss = 0.2072, Test Accuracy = 0.8460\n",
      "Iteration 1425: Loss = 0.2210, Accuracy = 0.8900 Test Loss = 0.2069, Test Accuracy = 0.8477\n",
      "Iteration 1426: Loss = 0.1929, Accuracy = 0.8700 Test Loss = 0.2071, Test Accuracy = 0.8525\n",
      "Iteration 1427: Loss = 0.2012, Accuracy = 0.8100 Test Loss = 0.2075, Test Accuracy = 0.8492\n",
      "Iteration 1428: Loss = 0.2202, Accuracy = 0.7900 Test Loss = 0.2070, Test Accuracy = 0.8482\n",
      "Iteration 1429: Loss = 0.1893, Accuracy = 0.8600 Test Loss = 0.2071, Test Accuracy = 0.8533\n",
      "Iteration 1430: Loss = 0.2046, Accuracy = 0.8300 Test Loss = 0.2072, Test Accuracy = 0.8521\n",
      "Iteration 1431: Loss = 0.1957, Accuracy = 0.8700 Test Loss = 0.2067, Test Accuracy = 0.8524\n",
      "Iteration 1432: Loss = 0.2043, Accuracy = 0.8500 Test Loss = 0.2070, Test Accuracy = 0.8467\n",
      "Iteration 1433: Loss = 0.1982, Accuracy = 0.8700 Test Loss = 0.2072, Test Accuracy = 0.8526\n",
      "Iteration 1434: Loss = 0.2103, Accuracy = 0.8700 Test Loss = 0.2066, Test Accuracy = 0.8497\n",
      "Iteration 1435: Loss = 0.1967, Accuracy = 0.8500 Test Loss = 0.2067, Test Accuracy = 0.8491\n",
      "Iteration 1436: Loss = 0.2063, Accuracy = 0.8500 Test Loss = 0.2068, Test Accuracy = 0.8457\n",
      "Iteration 1437: Loss = 0.2007, Accuracy = 0.8500 Test Loss = 0.2065, Test Accuracy = 0.8511\n",
      "Iteration 1438: Loss = 0.2020, Accuracy = 0.8100 Test Loss = 0.2066, Test Accuracy = 0.8511\n",
      "Iteration 1439: Loss = 0.1798, Accuracy = 0.8800 Test Loss = 0.2068, Test Accuracy = 0.8521\n",
      "Iteration 1440: Loss = 0.1837, Accuracy = 0.8600 Test Loss = 0.2068, Test Accuracy = 0.8475\n",
      "Iteration 1441: Loss = 0.2479, Accuracy = 0.7800 Test Loss = 0.2066, Test Accuracy = 0.8493\n",
      "Iteration 1442: Loss = 0.2001, Accuracy = 0.8500 Test Loss = 0.2067, Test Accuracy = 0.8512\n",
      "Iteration 1443: Loss = 0.2168, Accuracy = 0.8300 Test Loss = 0.2065, Test Accuracy = 0.8496\n",
      "Iteration 1444: Loss = 0.2040, Accuracy = 0.8600 Test Loss = 0.2066, Test Accuracy = 0.8502\n",
      "Iteration 1445: Loss = 0.2120, Accuracy = 0.8600 Test Loss = 0.2065, Test Accuracy = 0.8533\n",
      "Iteration 1446: Loss = 0.2687, Accuracy = 0.7800 Test Loss = 0.2065, Test Accuracy = 0.8502\n",
      "Iteration 1447: Loss = 0.2202, Accuracy = 0.8100 Test Loss = 0.2067, Test Accuracy = 0.8508\n",
      "Iteration 1448: Loss = 0.1942, Accuracy = 0.8900 Test Loss = 0.2064, Test Accuracy = 0.8515\n",
      "Iteration 1449: Loss = 0.1974, Accuracy = 0.8600 Test Loss = 0.2068, Test Accuracy = 0.8534\n",
      "Iteration 1450: Loss = 0.1715, Accuracy = 0.9100 Test Loss = 0.2069, Test Accuracy = 0.8499\n",
      "Iteration 1451: Loss = 0.2217, Accuracy = 0.8500 Test Loss = 0.2065, Test Accuracy = 0.8456\n",
      "Iteration 1452: Loss = 0.1898, Accuracy = 0.8800 Test Loss = 0.2066, Test Accuracy = 0.8505\n",
      "Iteration 1453: Loss = 0.2183, Accuracy = 0.8900 Test Loss = 0.2064, Test Accuracy = 0.8523\n",
      "Iteration 1454: Loss = 0.2132, Accuracy = 0.8700 Test Loss = 0.2068, Test Accuracy = 0.8527\n",
      "Iteration 1455: Loss = 0.2191, Accuracy = 0.7800 Test Loss = 0.2067, Test Accuracy = 0.8491\n",
      "Iteration 1456: Loss = 0.1833, Accuracy = 0.9100 Test Loss = 0.2069, Test Accuracy = 0.8519\n",
      "Iteration 1457: Loss = 0.2220, Accuracy = 0.8200 Test Loss = 0.2066, Test Accuracy = 0.8507\n",
      "Iteration 1458: Loss = 0.2367, Accuracy = 0.7700 Test Loss = 0.2069, Test Accuracy = 0.8532\n",
      "Iteration 1459: Loss = 0.2475, Accuracy = 0.8100 Test Loss = 0.2067, Test Accuracy = 0.8522\n",
      "Iteration 1460: Loss = 0.2184, Accuracy = 0.7900 Test Loss = 0.2071, Test Accuracy = 0.8488\n",
      "Iteration 1461: Loss = 0.2009, Accuracy = 0.8700 Test Loss = 0.2066, Test Accuracy = 0.8535\n",
      "Iteration 1462: Loss = 0.2125, Accuracy = 0.8300 Test Loss = 0.2064, Test Accuracy = 0.8501\n",
      "Iteration 1463: Loss = 0.1980, Accuracy = 0.8500 Test Loss = 0.2068, Test Accuracy = 0.8479\n",
      "Iteration 1464: Loss = 0.1957, Accuracy = 0.8600 Test Loss = 0.2066, Test Accuracy = 0.8502\n",
      "Iteration 1465: Loss = 0.2100, Accuracy = 0.8700 Test Loss = 0.2079, Test Accuracy = 0.8457\n",
      "Iteration 1466: Loss = 0.2145, Accuracy = 0.8800 Test Loss = 0.2065, Test Accuracy = 0.8518\n",
      "Iteration 1467: Loss = 0.2009, Accuracy = 0.8000 Test Loss = 0.2074, Test Accuracy = 0.8520\n",
      "Iteration 1468: Loss = 0.2168, Accuracy = 0.8300 Test Loss = 0.2068, Test Accuracy = 0.8498\n",
      "Iteration 1469: Loss = 0.2050, Accuracy = 0.8200 Test Loss = 0.2065, Test Accuracy = 0.8504\n",
      "Iteration 1470: Loss = 0.2528, Accuracy = 0.8000 Test Loss = 0.2068, Test Accuracy = 0.8495\n",
      "Iteration 1471: Loss = 0.2458, Accuracy = 0.8000 Test Loss = 0.2066, Test Accuracy = 0.8478\n",
      "Iteration 1472: Loss = 0.2016, Accuracy = 0.8500 Test Loss = 0.2065, Test Accuracy = 0.8507\n",
      "Iteration 1473: Loss = 0.2071, Accuracy = 0.8300 Test Loss = 0.2064, Test Accuracy = 0.8462\n",
      "Iteration 1474: Loss = 0.1866, Accuracy = 0.8600 Test Loss = 0.2066, Test Accuracy = 0.8515\n",
      "Iteration 1475: Loss = 0.2268, Accuracy = 0.8400 Test Loss = 0.2078, Test Accuracy = 0.8471\n",
      "Iteration 1476: Loss = 0.1653, Accuracy = 0.8900 Test Loss = 0.2066, Test Accuracy = 0.8503\n",
      "Iteration 1477: Loss = 0.1985, Accuracy = 0.8500 Test Loss = 0.2069, Test Accuracy = 0.8471\n",
      "Iteration 1478: Loss = 0.2029, Accuracy = 0.8500 Test Loss = 0.2064, Test Accuracy = 0.8524\n",
      "Iteration 1479: Loss = 0.1836, Accuracy = 0.8300 Test Loss = 0.2065, Test Accuracy = 0.8490\n",
      "Iteration 1480: Loss = 0.2138, Accuracy = 0.8400 Test Loss = 0.2068, Test Accuracy = 0.8477\n",
      "Iteration 1481: Loss = 0.2247, Accuracy = 0.8500 Test Loss = 0.2065, Test Accuracy = 0.8509\n",
      "Iteration 1482: Loss = 0.2048, Accuracy = 0.8300 Test Loss = 0.2066, Test Accuracy = 0.8461\n",
      "Iteration 1483: Loss = 0.1908, Accuracy = 0.8700 Test Loss = 0.2074, Test Accuracy = 0.8479\n",
      "Iteration 1484: Loss = 0.2023, Accuracy = 0.8400 Test Loss = 0.2066, Test Accuracy = 0.8474\n",
      "Iteration 1485: Loss = 0.2233, Accuracy = 0.8200 Test Loss = 0.2070, Test Accuracy = 0.8504\n",
      "Iteration 1486: Loss = 0.2039, Accuracy = 0.8400 Test Loss = 0.2070, Test Accuracy = 0.8488\n",
      "Iteration 1487: Loss = 0.2103, Accuracy = 0.8800 Test Loss = 0.2064, Test Accuracy = 0.8473\n",
      "Iteration 1488: Loss = 0.1737, Accuracy = 0.9000 Test Loss = 0.2063, Test Accuracy = 0.8491\n",
      "Iteration 1489: Loss = 0.2273, Accuracy = 0.8300 Test Loss = 0.2067, Test Accuracy = 0.8501\n",
      "Iteration 1490: Loss = 0.2295, Accuracy = 0.7800 Test Loss = 0.2066, Test Accuracy = 0.8489\n",
      "Iteration 1491: Loss = 0.2195, Accuracy = 0.7800 Test Loss = 0.2070, Test Accuracy = 0.8520\n",
      "Iteration 1492: Loss = 0.2032, Accuracy = 0.8100 Test Loss = 0.2060, Test Accuracy = 0.8511\n",
      "Iteration 1493: Loss = 0.2136, Accuracy = 0.8100 Test Loss = 0.2063, Test Accuracy = 0.8523\n",
      "Iteration 1494: Loss = 0.2212, Accuracy = 0.8400 Test Loss = 0.2065, Test Accuracy = 0.8489\n",
      "Iteration 1495: Loss = 0.1875, Accuracy = 0.8700 Test Loss = 0.2063, Test Accuracy = 0.8517\n",
      "Iteration 1496: Loss = 0.1974, Accuracy = 0.8200 Test Loss = 0.2070, Test Accuracy = 0.8511\n",
      "Iteration 1497: Loss = 0.1984, Accuracy = 0.8600 Test Loss = 0.2065, Test Accuracy = 0.8507\n",
      "Iteration 1498: Loss = 0.2110, Accuracy = 0.8400 Test Loss = 0.2067, Test Accuracy = 0.8511\n",
      "Iteration 1499: Loss = 0.2212, Accuracy = 0.8000 Test Loss = 0.2062, Test Accuracy = 0.8490\n",
      "Iteration 1500: Loss = 0.2067, Accuracy = 0.8700 Test Loss = 0.2063, Test Accuracy = 0.8507\n",
      "Iteration 1501: Loss = 0.1972, Accuracy = 0.8400 Test Loss = 0.2066, Test Accuracy = 0.8484\n",
      "Iteration 1502: Loss = 0.1840, Accuracy = 0.9100 Test Loss = 0.2061, Test Accuracy = 0.8503\n",
      "Iteration 1503: Loss = 0.1985, Accuracy = 0.8400 Test Loss = 0.2067, Test Accuracy = 0.8494\n",
      "Iteration 1504: Loss = 0.1778, Accuracy = 0.8800 Test Loss = 0.2066, Test Accuracy = 0.8492\n",
      "Iteration 1505: Loss = 0.2253, Accuracy = 0.8100 Test Loss = 0.2061, Test Accuracy = 0.8501\n",
      "Iteration 1506: Loss = 0.1913, Accuracy = 0.8700 Test Loss = 0.2062, Test Accuracy = 0.8498\n",
      "Iteration 1507: Loss = 0.1998, Accuracy = 0.8600 Test Loss = 0.2064, Test Accuracy = 0.8485\n",
      "Iteration 1508: Loss = 0.2341, Accuracy = 0.8800 Test Loss = 0.2063, Test Accuracy = 0.8499\n",
      "Iteration 1509: Loss = 0.2335, Accuracy = 0.8300 Test Loss = 0.2071, Test Accuracy = 0.8484\n",
      "Iteration 1510: Loss = 0.1868, Accuracy = 0.8800 Test Loss = 0.2062, Test Accuracy = 0.8519\n",
      "Iteration 1511: Loss = 0.2067, Accuracy = 0.8100 Test Loss = 0.2062, Test Accuracy = 0.8515\n",
      "Iteration 1512: Loss = 0.2054, Accuracy = 0.8100 Test Loss = 0.2069, Test Accuracy = 0.8542\n",
      "Iteration 1513: Loss = 0.1990, Accuracy = 0.8600 Test Loss = 0.2064, Test Accuracy = 0.8480\n",
      "Iteration 1514: Loss = 0.1743, Accuracy = 0.9000 Test Loss = 0.2065, Test Accuracy = 0.8477\n",
      "Iteration 1515: Loss = 0.1861, Accuracy = 0.8800 Test Loss = 0.2068, Test Accuracy = 0.8474\n",
      "Iteration 1516: Loss = 0.1669, Accuracy = 0.9400 Test Loss = 0.2063, Test Accuracy = 0.8501\n",
      "Iteration 1517: Loss = 0.1949, Accuracy = 0.8700 Test Loss = 0.2069, Test Accuracy = 0.8506\n",
      "Iteration 1518: Loss = 0.2082, Accuracy = 0.8300 Test Loss = 0.2063, Test Accuracy = 0.8504\n",
      "Iteration 1519: Loss = 0.1982, Accuracy = 0.8300 Test Loss = 0.2059, Test Accuracy = 0.8502\n",
      "Iteration 1520: Loss = 0.1616, Accuracy = 0.9200 Test Loss = 0.2058, Test Accuracy = 0.8470\n",
      "Iteration 1521: Loss = 0.2109, Accuracy = 0.8300 Test Loss = 0.2060, Test Accuracy = 0.8510\n",
      "Iteration 1522: Loss = 0.2113, Accuracy = 0.8400 Test Loss = 0.2060, Test Accuracy = 0.8512\n",
      "Iteration 1523: Loss = 0.1974, Accuracy = 0.8800 Test Loss = 0.2068, Test Accuracy = 0.8490\n",
      "Iteration 1524: Loss = 0.1988, Accuracy = 0.8400 Test Loss = 0.2060, Test Accuracy = 0.8521\n",
      "Iteration 1525: Loss = 0.1850, Accuracy = 0.8800 Test Loss = 0.2064, Test Accuracy = 0.8491\n",
      "Iteration 1526: Loss = 0.2120, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8499\n",
      "Iteration 1527: Loss = 0.1921, Accuracy = 0.8400 Test Loss = 0.2062, Test Accuracy = 0.8515\n",
      "Iteration 1528: Loss = 0.2034, Accuracy = 0.8400 Test Loss = 0.2059, Test Accuracy = 0.8524\n",
      "Iteration 1529: Loss = 0.2048, Accuracy = 0.8600 Test Loss = 0.2064, Test Accuracy = 0.8526\n",
      "Iteration 1530: Loss = 0.1888, Accuracy = 0.8800 Test Loss = 0.2061, Test Accuracy = 0.8505\n",
      "Iteration 1531: Loss = 0.1952, Accuracy = 0.8600 Test Loss = 0.2061, Test Accuracy = 0.8483\n",
      "Iteration 1532: Loss = 0.2175, Accuracy = 0.8000 Test Loss = 0.2063, Test Accuracy = 0.8549\n",
      "Iteration 1533: Loss = 0.2164, Accuracy = 0.8100 Test Loss = 0.2063, Test Accuracy = 0.8499\n",
      "Iteration 1534: Loss = 0.2329, Accuracy = 0.8400 Test Loss = 0.2062, Test Accuracy = 0.8535\n",
      "Iteration 1535: Loss = 0.2323, Accuracy = 0.7900 Test Loss = 0.2065, Test Accuracy = 0.8512\n",
      "Iteration 1536: Loss = 0.1627, Accuracy = 0.8800 Test Loss = 0.2061, Test Accuracy = 0.8480\n",
      "Iteration 1537: Loss = 0.2379, Accuracy = 0.7500 Test Loss = 0.2068, Test Accuracy = 0.8473\n",
      "Iteration 1538: Loss = 0.1853, Accuracy = 0.8600 Test Loss = 0.2070, Test Accuracy = 0.8479\n",
      "Iteration 1539: Loss = 0.2089, Accuracy = 0.8700 Test Loss = 0.2065, Test Accuracy = 0.8489\n",
      "Iteration 1540: Loss = 0.1805, Accuracy = 0.8900 Test Loss = 0.2059, Test Accuracy = 0.8482\n",
      "Iteration 1541: Loss = 0.1873, Accuracy = 0.8600 Test Loss = 0.2059, Test Accuracy = 0.8484\n",
      "Iteration 1542: Loss = 0.1722, Accuracy = 0.9200 Test Loss = 0.2067, Test Accuracy = 0.8478\n",
      "Iteration 1543: Loss = 0.2241, Accuracy = 0.8500 Test Loss = 0.2061, Test Accuracy = 0.8476\n",
      "Iteration 1544: Loss = 0.2071, Accuracy = 0.8400 Test Loss = 0.2060, Test Accuracy = 0.8529\n",
      "Iteration 1545: Loss = 0.1843, Accuracy = 0.8600 Test Loss = 0.2060, Test Accuracy = 0.8525\n",
      "Iteration 1546: Loss = 0.1947, Accuracy = 0.8800 Test Loss = 0.2058, Test Accuracy = 0.8498\n",
      "Iteration 1547: Loss = 0.1702, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8522\n",
      "Iteration 1548: Loss = 0.2082, Accuracy = 0.8200 Test Loss = 0.2063, Test Accuracy = 0.8498\n",
      "Iteration 1549: Loss = 0.2179, Accuracy = 0.7600 Test Loss = 0.2068, Test Accuracy = 0.8486\n",
      "Iteration 1550: Loss = 0.1798, Accuracy = 0.8800 Test Loss = 0.2057, Test Accuracy = 0.8505\n",
      "Iteration 1551: Loss = 0.2123, Accuracy = 0.8000 Test Loss = 0.2066, Test Accuracy = 0.8467\n",
      "Iteration 1552: Loss = 0.1970, Accuracy = 0.8500 Test Loss = 0.2060, Test Accuracy = 0.8508\n",
      "Iteration 1553: Loss = 0.2016, Accuracy = 0.8500 Test Loss = 0.2062, Test Accuracy = 0.8538\n",
      "Iteration 1554: Loss = 0.2232, Accuracy = 0.8100 Test Loss = 0.2063, Test Accuracy = 0.8506\n",
      "Iteration 1555: Loss = 0.1853, Accuracy = 0.8900 Test Loss = 0.2060, Test Accuracy = 0.8476\n",
      "Iteration 1556: Loss = 0.1805, Accuracy = 0.8800 Test Loss = 0.2060, Test Accuracy = 0.8511\n",
      "Iteration 1557: Loss = 0.1815, Accuracy = 0.9000 Test Loss = 0.2064, Test Accuracy = 0.8500\n",
      "Iteration 1558: Loss = 0.2306, Accuracy = 0.8500 Test Loss = 0.2063, Test Accuracy = 0.8510\n",
      "Iteration 1559: Loss = 0.2103, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8509\n",
      "Iteration 1560: Loss = 0.1979, Accuracy = 0.8600 Test Loss = 0.2062, Test Accuracy = 0.8499\n",
      "Iteration 1561: Loss = 0.2006, Accuracy = 0.8200 Test Loss = 0.2055, Test Accuracy = 0.8503\n",
      "Iteration 1562: Loss = 0.1828, Accuracy = 0.8700 Test Loss = 0.2064, Test Accuracy = 0.8451\n",
      "Iteration 1563: Loss = 0.1876, Accuracy = 0.8900 Test Loss = 0.2056, Test Accuracy = 0.8478\n",
      "Iteration 1564: Loss = 0.2000, Accuracy = 0.8800 Test Loss = 0.2057, Test Accuracy = 0.8531\n",
      "Iteration 1565: Loss = 0.1880, Accuracy = 0.8700 Test Loss = 0.2059, Test Accuracy = 0.8543\n",
      "Iteration 1566: Loss = 0.2086, Accuracy = 0.8500 Test Loss = 0.2055, Test Accuracy = 0.8507\n",
      "Iteration 1567: Loss = 0.2047, Accuracy = 0.8500 Test Loss = 0.2062, Test Accuracy = 0.8513\n",
      "Iteration 1568: Loss = 0.2187, Accuracy = 0.8200 Test Loss = 0.2059, Test Accuracy = 0.8515\n",
      "Iteration 1569: Loss = 0.2223, Accuracy = 0.8100 Test Loss = 0.2058, Test Accuracy = 0.8515\n",
      "Iteration 1570: Loss = 0.2078, Accuracy = 0.8300 Test Loss = 0.2058, Test Accuracy = 0.8505\n",
      "Iteration 1571: Loss = 0.1870, Accuracy = 0.8400 Test Loss = 0.2059, Test Accuracy = 0.8492\n",
      "Iteration 1572: Loss = 0.2074, Accuracy = 0.8400 Test Loss = 0.2056, Test Accuracy = 0.8518\n",
      "Iteration 1573: Loss = 0.1839, Accuracy = 0.8900 Test Loss = 0.2063, Test Accuracy = 0.8501\n",
      "Iteration 1574: Loss = 0.1786, Accuracy = 0.8700 Test Loss = 0.2057, Test Accuracy = 0.8525\n",
      "Iteration 1575: Loss = 0.2255, Accuracy = 0.8100 Test Loss = 0.2059, Test Accuracy = 0.8513\n",
      "Iteration 1576: Loss = 0.2496, Accuracy = 0.7700 Test Loss = 0.2059, Test Accuracy = 0.8479\n",
      "Iteration 1577: Loss = 0.1867, Accuracy = 0.8800 Test Loss = 0.2061, Test Accuracy = 0.8525\n",
      "Iteration 1578: Loss = 0.2145, Accuracy = 0.8400 Test Loss = 0.2059, Test Accuracy = 0.8479\n",
      "Iteration 1579: Loss = 0.1917, Accuracy = 0.9000 Test Loss = 0.2062, Test Accuracy = 0.8512\n",
      "Iteration 1580: Loss = 0.2370, Accuracy = 0.7900 Test Loss = 0.2058, Test Accuracy = 0.8477\n",
      "Iteration 1581: Loss = 0.1812, Accuracy = 0.8700 Test Loss = 0.2064, Test Accuracy = 0.8507\n",
      "Iteration 1582: Loss = 0.2090, Accuracy = 0.8400 Test Loss = 0.2062, Test Accuracy = 0.8487\n",
      "Iteration 1583: Loss = 0.2249, Accuracy = 0.7800 Test Loss = 0.2057, Test Accuracy = 0.8496\n",
      "Iteration 1584: Loss = 0.2198, Accuracy = 0.8300 Test Loss = 0.2059, Test Accuracy = 0.8502\n",
      "Iteration 1585: Loss = 0.1887, Accuracy = 0.8400 Test Loss = 0.2065, Test Accuracy = 0.8493\n",
      "Iteration 1586: Loss = 0.2258, Accuracy = 0.8000 Test Loss = 0.2059, Test Accuracy = 0.8500\n",
      "Iteration 1587: Loss = 0.1976, Accuracy = 0.9000 Test Loss = 0.2060, Test Accuracy = 0.8556\n",
      "Iteration 1588: Loss = 0.2073, Accuracy = 0.8700 Test Loss = 0.2062, Test Accuracy = 0.8483\n",
      "Iteration 1589: Loss = 0.2100, Accuracy = 0.8300 Test Loss = 0.2054, Test Accuracy = 0.8542\n",
      "Iteration 1590: Loss = 0.2074, Accuracy = 0.8400 Test Loss = 0.2057, Test Accuracy = 0.8502\n",
      "Iteration 1591: Loss = 0.2144, Accuracy = 0.8200 Test Loss = 0.2056, Test Accuracy = 0.8489\n",
      "Iteration 1592: Loss = 0.1905, Accuracy = 0.8500 Test Loss = 0.2065, Test Accuracy = 0.8527\n",
      "Iteration 1593: Loss = 0.2219, Accuracy = 0.7900 Test Loss = 0.2061, Test Accuracy = 0.8509\n",
      "Iteration 1594: Loss = 0.1730, Accuracy = 0.9000 Test Loss = 0.2057, Test Accuracy = 0.8524\n",
      "Iteration 1595: Loss = 0.2389, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8500\n",
      "Iteration 1596: Loss = 0.2020, Accuracy = 0.8200 Test Loss = 0.2055, Test Accuracy = 0.8506\n",
      "Iteration 1597: Loss = 0.1884, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8480\n",
      "Iteration 1598: Loss = 0.1750, Accuracy = 0.9200 Test Loss = 0.2062, Test Accuracy = 0.8464\n",
      "Iteration 1599: Loss = 0.1784, Accuracy = 0.9200 Test Loss = 0.2058, Test Accuracy = 0.8511\n",
      "Iteration 1600: Loss = 0.2397, Accuracy = 0.8100 Test Loss = 0.2058, Test Accuracy = 0.8473\n",
      "Iteration 1601: Loss = 0.2153, Accuracy = 0.8200 Test Loss = 0.2063, Test Accuracy = 0.8536\n",
      "Iteration 1602: Loss = 0.2470, Accuracy = 0.8200 Test Loss = 0.2058, Test Accuracy = 0.8523\n",
      "Iteration 1603: Loss = 0.2273, Accuracy = 0.7600 Test Loss = 0.2055, Test Accuracy = 0.8515\n",
      "Iteration 1604: Loss = 0.1711, Accuracy = 0.8600 Test Loss = 0.2057, Test Accuracy = 0.8500\n",
      "Iteration 1605: Loss = 0.2138, Accuracy = 0.8200 Test Loss = 0.2062, Test Accuracy = 0.8468\n",
      "Iteration 1606: Loss = 0.1843, Accuracy = 0.8900 Test Loss = 0.2061, Test Accuracy = 0.8485\n",
      "Iteration 1607: Loss = 0.1952, Accuracy = 0.8400 Test Loss = 0.2057, Test Accuracy = 0.8518\n",
      "Iteration 1608: Loss = 0.1856, Accuracy = 0.8400 Test Loss = 0.2056, Test Accuracy = 0.8502\n",
      "Iteration 1609: Loss = 0.1995, Accuracy = 0.8300 Test Loss = 0.2058, Test Accuracy = 0.8533\n",
      "Iteration 1610: Loss = 0.2181, Accuracy = 0.8100 Test Loss = 0.2054, Test Accuracy = 0.8495\n",
      "Iteration 1611: Loss = 0.2016, Accuracy = 0.8300 Test Loss = 0.2059, Test Accuracy = 0.8499\n",
      "Iteration 1612: Loss = 0.1935, Accuracy = 0.8400 Test Loss = 0.2061, Test Accuracy = 0.8531\n",
      "Iteration 1613: Loss = 0.1789, Accuracy = 0.8600 Test Loss = 0.2058, Test Accuracy = 0.8495\n",
      "Iteration 1614: Loss = 0.1927, Accuracy = 0.8900 Test Loss = 0.2056, Test Accuracy = 0.8492\n",
      "Iteration 1615: Loss = 0.1653, Accuracy = 0.8700 Test Loss = 0.2061, Test Accuracy = 0.8503\n",
      "Iteration 1616: Loss = 0.1935, Accuracy = 0.8800 Test Loss = 0.2059, Test Accuracy = 0.8497\n",
      "Iteration 1617: Loss = 0.2172, Accuracy = 0.8300 Test Loss = 0.2060, Test Accuracy = 0.8487\n",
      "Iteration 1618: Loss = 0.2018, Accuracy = 0.8800 Test Loss = 0.2059, Test Accuracy = 0.8514\n",
      "Iteration 1619: Loss = 0.1944, Accuracy = 0.8400 Test Loss = 0.2060, Test Accuracy = 0.8460\n",
      "Iteration 1620: Loss = 0.2012, Accuracy = 0.8700 Test Loss = 0.2061, Test Accuracy = 0.8500\n",
      "Iteration 1621: Loss = 0.2394, Accuracy = 0.8500 Test Loss = 0.2059, Test Accuracy = 0.8514\n",
      "Iteration 1622: Loss = 0.2017, Accuracy = 0.8700 Test Loss = 0.2054, Test Accuracy = 0.8478\n",
      "Iteration 1623: Loss = 0.2176, Accuracy = 0.8300 Test Loss = 0.2057, Test Accuracy = 0.8494\n",
      "Iteration 1624: Loss = 0.2005, Accuracy = 0.8800 Test Loss = 0.2060, Test Accuracy = 0.8502\n",
      "Iteration 1625: Loss = 0.2136, Accuracy = 0.8100 Test Loss = 0.2052, Test Accuracy = 0.8510\n",
      "Iteration 1626: Loss = 0.1800, Accuracy = 0.8800 Test Loss = 0.2062, Test Accuracy = 0.8470\n",
      "Iteration 1627: Loss = 0.1994, Accuracy = 0.8900 Test Loss = 0.2057, Test Accuracy = 0.8507\n",
      "Iteration 1628: Loss = 0.2266, Accuracy = 0.8100 Test Loss = 0.2056, Test Accuracy = 0.8525\n",
      "Iteration 1629: Loss = 0.1961, Accuracy = 0.8500 Test Loss = 0.2059, Test Accuracy = 0.8517\n",
      "Iteration 1630: Loss = 0.1910, Accuracy = 0.8800 Test Loss = 0.2054, Test Accuracy = 0.8526\n",
      "Iteration 1631: Loss = 0.1908, Accuracy = 0.8600 Test Loss = 0.2059, Test Accuracy = 0.8469\n",
      "Iteration 1632: Loss = 0.2271, Accuracy = 0.8300 Test Loss = 0.2056, Test Accuracy = 0.8521\n",
      "Iteration 1633: Loss = 0.2160, Accuracy = 0.8400 Test Loss = 0.2056, Test Accuracy = 0.8509\n",
      "Iteration 1634: Loss = 0.2060, Accuracy = 0.8200 Test Loss = 0.2061, Test Accuracy = 0.8474\n",
      "Iteration 1635: Loss = 0.1789, Accuracy = 0.9000 Test Loss = 0.2056, Test Accuracy = 0.8495\n",
      "Iteration 1636: Loss = 0.2056, Accuracy = 0.8400 Test Loss = 0.2056, Test Accuracy = 0.8519\n",
      "Iteration 1637: Loss = 0.2423, Accuracy = 0.7800 Test Loss = 0.2057, Test Accuracy = 0.8533\n",
      "Iteration 1638: Loss = 0.1795, Accuracy = 0.8900 Test Loss = 0.2058, Test Accuracy = 0.8523\n",
      "Iteration 1639: Loss = 0.2127, Accuracy = 0.8400 Test Loss = 0.2058, Test Accuracy = 0.8534\n",
      "Iteration 1640: Loss = 0.1972, Accuracy = 0.8500 Test Loss = 0.2059, Test Accuracy = 0.8499\n",
      "Iteration 1641: Loss = 0.2043, Accuracy = 0.8600 Test Loss = 0.2057, Test Accuracy = 0.8523\n",
      "Iteration 1642: Loss = 0.2103, Accuracy = 0.8100 Test Loss = 0.2060, Test Accuracy = 0.8489\n",
      "Iteration 1643: Loss = 0.1915, Accuracy = 0.8400 Test Loss = 0.2055, Test Accuracy = 0.8529\n",
      "Iteration 1644: Loss = 0.2079, Accuracy = 0.8300 Test Loss = 0.2056, Test Accuracy = 0.8487\n",
      "Iteration 1645: Loss = 0.1906, Accuracy = 0.8700 Test Loss = 0.2052, Test Accuracy = 0.8525\n",
      "Iteration 1646: Loss = 0.2063, Accuracy = 0.8900 Test Loss = 0.2055, Test Accuracy = 0.8524\n",
      "Iteration 1647: Loss = 0.1999, Accuracy = 0.8100 Test Loss = 0.2057, Test Accuracy = 0.8455\n",
      "Iteration 1648: Loss = 0.2090, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8503\n",
      "Iteration 1649: Loss = 0.1999, Accuracy = 0.8500 Test Loss = 0.2056, Test Accuracy = 0.8516\n",
      "Iteration 1650: Loss = 0.2123, Accuracy = 0.8400 Test Loss = 0.2056, Test Accuracy = 0.8551\n",
      "Iteration 1651: Loss = 0.2230, Accuracy = 0.8300 Test Loss = 0.2055, Test Accuracy = 0.8492\n",
      "Iteration 1652: Loss = 0.2097, Accuracy = 0.8700 Test Loss = 0.2058, Test Accuracy = 0.8534\n",
      "Iteration 1653: Loss = 0.2069, Accuracy = 0.8300 Test Loss = 0.2054, Test Accuracy = 0.8538\n",
      "Iteration 1654: Loss = 0.2289, Accuracy = 0.8900 Test Loss = 0.2055, Test Accuracy = 0.8474\n",
      "Iteration 1655: Loss = 0.1745, Accuracy = 0.8800 Test Loss = 0.2057, Test Accuracy = 0.8513\n",
      "Iteration 1656: Loss = 0.2276, Accuracy = 0.8100 Test Loss = 0.2056, Test Accuracy = 0.8519\n",
      "Iteration 1657: Loss = 0.1733, Accuracy = 0.9000 Test Loss = 0.2052, Test Accuracy = 0.8506\n",
      "Iteration 1658: Loss = 0.1959, Accuracy = 0.8400 Test Loss = 0.2057, Test Accuracy = 0.8514\n",
      "Iteration 1659: Loss = 0.2091, Accuracy = 0.8700 Test Loss = 0.2052, Test Accuracy = 0.8524\n",
      "Iteration 1660: Loss = 0.1996, Accuracy = 0.8900 Test Loss = 0.2053, Test Accuracy = 0.8486\n",
      "Iteration 1661: Loss = 0.2387, Accuracy = 0.7300 Test Loss = 0.2055, Test Accuracy = 0.8512\n",
      "Iteration 1662: Loss = 0.1862, Accuracy = 0.8700 Test Loss = 0.2056, Test Accuracy = 0.8520\n",
      "Iteration 1663: Loss = 0.1833, Accuracy = 0.8700 Test Loss = 0.2055, Test Accuracy = 0.8500\n",
      "Iteration 1664: Loss = 0.2177, Accuracy = 0.8200 Test Loss = 0.2057, Test Accuracy = 0.8483\n",
      "Iteration 1665: Loss = 0.2200, Accuracy = 0.8600 Test Loss = 0.2059, Test Accuracy = 0.8553\n",
      "Iteration 1666: Loss = 0.2366, Accuracy = 0.8000 Test Loss = 0.2053, Test Accuracy = 0.8525\n",
      "Iteration 1667: Loss = 0.1982, Accuracy = 0.8000 Test Loss = 0.2057, Test Accuracy = 0.8481\n",
      "Iteration 1668: Loss = 0.2168, Accuracy = 0.8000 Test Loss = 0.2054, Test Accuracy = 0.8546\n",
      "Iteration 1669: Loss = 0.2036, Accuracy = 0.8100 Test Loss = 0.2060, Test Accuracy = 0.8512\n",
      "Iteration 1670: Loss = 0.2031, Accuracy = 0.8400 Test Loss = 0.2053, Test Accuracy = 0.8489\n",
      "Iteration 1671: Loss = 0.2128, Accuracy = 0.8000 Test Loss = 0.2053, Test Accuracy = 0.8499\n",
      "Iteration 1672: Loss = 0.2030, Accuracy = 0.8500 Test Loss = 0.2055, Test Accuracy = 0.8489\n",
      "Iteration 1673: Loss = 0.2200, Accuracy = 0.7900 Test Loss = 0.2054, Test Accuracy = 0.8531\n",
      "Iteration 1674: Loss = 0.1936, Accuracy = 0.8700 Test Loss = 0.2055, Test Accuracy = 0.8482\n",
      "Iteration 1675: Loss = 0.1986, Accuracy = 0.8300 Test Loss = 0.2058, Test Accuracy = 0.8482\n",
      "Iteration 1676: Loss = 0.2125, Accuracy = 0.8500 Test Loss = 0.2054, Test Accuracy = 0.8492\n",
      "Iteration 1677: Loss = 0.2158, Accuracy = 0.8000 Test Loss = 0.2058, Test Accuracy = 0.8484\n",
      "Iteration 1678: Loss = 0.1743, Accuracy = 0.9100 Test Loss = 0.2057, Test Accuracy = 0.8547\n",
      "Iteration 1679: Loss = 0.2516, Accuracy = 0.7800 Test Loss = 0.2056, Test Accuracy = 0.8541\n",
      "Iteration 1680: Loss = 0.1894, Accuracy = 0.8600 Test Loss = 0.2049, Test Accuracy = 0.8476\n",
      "Iteration 1681: Loss = 0.1927, Accuracy = 0.8500 Test Loss = 0.2054, Test Accuracy = 0.8533\n",
      "Iteration 1682: Loss = 0.1771, Accuracy = 0.8900 Test Loss = 0.2053, Test Accuracy = 0.8495\n",
      "Iteration 1683: Loss = 0.1827, Accuracy = 0.9100 Test Loss = 0.2051, Test Accuracy = 0.8516\n",
      "Iteration 1684: Loss = 0.2296, Accuracy = 0.8400 Test Loss = 0.2056, Test Accuracy = 0.8483\n",
      "Iteration 1685: Loss = 0.1837, Accuracy = 0.8900 Test Loss = 0.2051, Test Accuracy = 0.8512\n",
      "Iteration 1686: Loss = 0.2268, Accuracy = 0.8000 Test Loss = 0.2052, Test Accuracy = 0.8543\n",
      "Iteration 1687: Loss = 0.2144, Accuracy = 0.8200 Test Loss = 0.2057, Test Accuracy = 0.8558\n",
      "Iteration 1688: Loss = 0.1569, Accuracy = 0.9200 Test Loss = 0.2062, Test Accuracy = 0.8469\n",
      "Iteration 1689: Loss = 0.2004, Accuracy = 0.9000 Test Loss = 0.2054, Test Accuracy = 0.8478\n",
      "Iteration 1690: Loss = 0.2267, Accuracy = 0.8400 Test Loss = 0.2050, Test Accuracy = 0.8544\n",
      "Iteration 1691: Loss = 0.1977, Accuracy = 0.8600 Test Loss = 0.2054, Test Accuracy = 0.8503\n",
      "Iteration 1692: Loss = 0.2133, Accuracy = 0.8600 Test Loss = 0.2051, Test Accuracy = 0.8495\n",
      "Iteration 1693: Loss = 0.2268, Accuracy = 0.7900 Test Loss = 0.2054, Test Accuracy = 0.8507\n",
      "Iteration 1694: Loss = 0.1875, Accuracy = 0.8600 Test Loss = 0.2052, Test Accuracy = 0.8506\n",
      "Iteration 1695: Loss = 0.2106, Accuracy = 0.8000 Test Loss = 0.2056, Test Accuracy = 0.8530\n",
      "Iteration 1696: Loss = 0.2000, Accuracy = 0.8700 Test Loss = 0.2056, Test Accuracy = 0.8492\n",
      "Iteration 1697: Loss = 0.2291, Accuracy = 0.8500 Test Loss = 0.2055, Test Accuracy = 0.8521\n",
      "Iteration 1698: Loss = 0.1840, Accuracy = 0.9000 Test Loss = 0.2059, Test Accuracy = 0.8493\n",
      "Iteration 1699: Loss = 0.1580, Accuracy = 0.8800 Test Loss = 0.2054, Test Accuracy = 0.8469\n",
      "Iteration 1700: Loss = 0.2210, Accuracy = 0.8000 Test Loss = 0.2052, Test Accuracy = 0.8504\n",
      "Iteration 1701: Loss = 0.1880, Accuracy = 0.8800 Test Loss = 0.2052, Test Accuracy = 0.8510\n",
      "Iteration 1702: Loss = 0.2239, Accuracy = 0.8000 Test Loss = 0.2051, Test Accuracy = 0.8496\n",
      "Iteration 1703: Loss = 0.1823, Accuracy = 0.8600 Test Loss = 0.2057, Test Accuracy = 0.8506\n",
      "Iteration 1704: Loss = 0.2116, Accuracy = 0.7900 Test Loss = 0.2054, Test Accuracy = 0.8522\n",
      "Iteration 1705: Loss = 0.1937, Accuracy = 0.8400 Test Loss = 0.2047, Test Accuracy = 0.8509\n",
      "Iteration 1706: Loss = 0.1923, Accuracy = 0.8900 Test Loss = 0.2051, Test Accuracy = 0.8510\n",
      "Iteration 1707: Loss = 0.2187, Accuracy = 0.7900 Test Loss = 0.2054, Test Accuracy = 0.8527\n",
      "Iteration 1708: Loss = 0.2025, Accuracy = 0.8900 Test Loss = 0.2049, Test Accuracy = 0.8491\n",
      "Iteration 1709: Loss = 0.1948, Accuracy = 0.8500 Test Loss = 0.2054, Test Accuracy = 0.8469\n",
      "Iteration 1710: Loss = 0.1633, Accuracy = 0.9200 Test Loss = 0.2054, Test Accuracy = 0.8478\n",
      "Iteration 1711: Loss = 0.1847, Accuracy = 0.9000 Test Loss = 0.2061, Test Accuracy = 0.8504\n",
      "Iteration 1712: Loss = 0.2115, Accuracy = 0.8300 Test Loss = 0.2054, Test Accuracy = 0.8504\n",
      "Iteration 1713: Loss = 0.1965, Accuracy = 0.8600 Test Loss = 0.2057, Test Accuracy = 0.8497\n",
      "Iteration 1714: Loss = 0.2188, Accuracy = 0.8600 Test Loss = 0.2052, Test Accuracy = 0.8521\n",
      "Iteration 1715: Loss = 0.2074, Accuracy = 0.8500 Test Loss = 0.2053, Test Accuracy = 0.8540\n",
      "Iteration 1716: Loss = 0.2219, Accuracy = 0.8100 Test Loss = 0.2057, Test Accuracy = 0.8495\n",
      "Iteration 1717: Loss = 0.1968, Accuracy = 0.8400 Test Loss = 0.2056, Test Accuracy = 0.8535\n",
      "Iteration 1718: Loss = 0.2103, Accuracy = 0.8200 Test Loss = 0.2058, Test Accuracy = 0.8522\n",
      "Iteration 1719: Loss = 0.2012, Accuracy = 0.8800 Test Loss = 0.2054, Test Accuracy = 0.8483\n",
      "Iteration 1720: Loss = 0.2073, Accuracy = 0.8800 Test Loss = 0.2052, Test Accuracy = 0.8491\n",
      "Iteration 1721: Loss = 0.2093, Accuracy = 0.8300 Test Loss = 0.2049, Test Accuracy = 0.8525\n",
      "Iteration 1722: Loss = 0.1811, Accuracy = 0.8800 Test Loss = 0.2052, Test Accuracy = 0.8515\n",
      "Iteration 1723: Loss = 0.2074, Accuracy = 0.8400 Test Loss = 0.2050, Test Accuracy = 0.8505\n",
      "Iteration 1724: Loss = 0.2250, Accuracy = 0.8200 Test Loss = 0.2051, Test Accuracy = 0.8533\n",
      "Iteration 1725: Loss = 0.1814, Accuracy = 0.8700 Test Loss = 0.2049, Test Accuracy = 0.8473\n",
      "Iteration 1726: Loss = 0.2367, Accuracy = 0.8100 Test Loss = 0.2051, Test Accuracy = 0.8497\n",
      "Iteration 1727: Loss = 0.1886, Accuracy = 0.8700 Test Loss = 0.2053, Test Accuracy = 0.8549\n",
      "Iteration 1728: Loss = 0.2255, Accuracy = 0.8300 Test Loss = 0.2052, Test Accuracy = 0.8537\n",
      "Iteration 1729: Loss = 0.1636, Accuracy = 0.9300 Test Loss = 0.2051, Test Accuracy = 0.8469\n",
      "Iteration 1730: Loss = 0.1984, Accuracy = 0.8400 Test Loss = 0.2048, Test Accuracy = 0.8518\n",
      "Iteration 1731: Loss = 0.1845, Accuracy = 0.8900 Test Loss = 0.2050, Test Accuracy = 0.8484\n",
      "Iteration 1732: Loss = 0.1922, Accuracy = 0.9200 Test Loss = 0.2053, Test Accuracy = 0.8545\n",
      "Iteration 1733: Loss = 0.1935, Accuracy = 0.8500 Test Loss = 0.2049, Test Accuracy = 0.8514\n",
      "Iteration 1734: Loss = 0.1987, Accuracy = 0.8700 Test Loss = 0.2050, Test Accuracy = 0.8479\n",
      "Iteration 1735: Loss = 0.2344, Accuracy = 0.7900 Test Loss = 0.2054, Test Accuracy = 0.8487\n",
      "Iteration 1736: Loss = 0.1980, Accuracy = 0.8500 Test Loss = 0.2052, Test Accuracy = 0.8505\n",
      "Iteration 1737: Loss = 0.2048, Accuracy = 0.8800 Test Loss = 0.2052, Test Accuracy = 0.8533\n",
      "Iteration 1738: Loss = 0.1972, Accuracy = 0.8500 Test Loss = 0.2050, Test Accuracy = 0.8489\n",
      "Iteration 1739: Loss = 0.2318, Accuracy = 0.8200 Test Loss = 0.2054, Test Accuracy = 0.8474\n",
      "Iteration 1740: Loss = 0.2129, Accuracy = 0.8300 Test Loss = 0.2051, Test Accuracy = 0.8500\n",
      "Iteration 1741: Loss = 0.2666, Accuracy = 0.8500 Test Loss = 0.2055, Test Accuracy = 0.8527\n",
      "Iteration 1742: Loss = 0.2015, Accuracy = 0.8500 Test Loss = 0.2053, Test Accuracy = 0.8542\n",
      "Iteration 1743: Loss = 0.1839, Accuracy = 0.8700 Test Loss = 0.2054, Test Accuracy = 0.8466\n",
      "Iteration 1744: Loss = 0.1728, Accuracy = 0.8800 Test Loss = 0.2052, Test Accuracy = 0.8491\n",
      "Iteration 1745: Loss = 0.2460, Accuracy = 0.7800 Test Loss = 0.2054, Test Accuracy = 0.8532\n",
      "Iteration 1746: Loss = 0.1790, Accuracy = 0.9400 Test Loss = 0.2049, Test Accuracy = 0.8508\n",
      "Iteration 1747: Loss = 0.1745, Accuracy = 0.8800 Test Loss = 0.2048, Test Accuracy = 0.8525\n",
      "Iteration 1748: Loss = 0.1947, Accuracy = 0.8700 Test Loss = 0.2055, Test Accuracy = 0.8479\n",
      "Iteration 1749: Loss = 0.1817, Accuracy = 0.8800 Test Loss = 0.2054, Test Accuracy = 0.8466\n",
      "Iteration 1750: Loss = 0.2199, Accuracy = 0.8000 Test Loss = 0.2051, Test Accuracy = 0.8518\n",
      "Iteration 1751: Loss = 0.2024, Accuracy = 0.8600 Test Loss = 0.2051, Test Accuracy = 0.8508\n",
      "Iteration 1752: Loss = 0.1858, Accuracy = 0.8600 Test Loss = 0.2050, Test Accuracy = 0.8461\n",
      "Iteration 1753: Loss = 0.1698, Accuracy = 0.9000 Test Loss = 0.2050, Test Accuracy = 0.8474\n",
      "Iteration 1754: Loss = 0.2153, Accuracy = 0.8500 Test Loss = 0.2049, Test Accuracy = 0.8512\n",
      "Iteration 1755: Loss = 0.1814, Accuracy = 0.9000 Test Loss = 0.2054, Test Accuracy = 0.8514\n",
      "Iteration 1756: Loss = 0.2325, Accuracy = 0.8300 Test Loss = 0.2053, Test Accuracy = 0.8504\n",
      "Iteration 1757: Loss = 0.2107, Accuracy = 0.8300 Test Loss = 0.2051, Test Accuracy = 0.8535\n",
      "Iteration 1758: Loss = 0.2076, Accuracy = 0.8300 Test Loss = 0.2050, Test Accuracy = 0.8512\n",
      "Iteration 1759: Loss = 0.1860, Accuracy = 0.8700 Test Loss = 0.2051, Test Accuracy = 0.8481\n",
      "Iteration 1760: Loss = 0.2108, Accuracy = 0.8200 Test Loss = 0.2053, Test Accuracy = 0.8474\n",
      "Iteration 1761: Loss = 0.1963, Accuracy = 0.8600 Test Loss = 0.2059, Test Accuracy = 0.8462\n",
      "Iteration 1762: Loss = 0.2038, Accuracy = 0.8300 Test Loss = 0.2049, Test Accuracy = 0.8500\n",
      "Iteration 1763: Loss = 0.1713, Accuracy = 0.8800 Test Loss = 0.2051, Test Accuracy = 0.8503\n",
      "Iteration 1764: Loss = 0.1950, Accuracy = 0.8500 Test Loss = 0.2048, Test Accuracy = 0.8494\n",
      "Iteration 1765: Loss = 0.1979, Accuracy = 0.8800 Test Loss = 0.2057, Test Accuracy = 0.8479\n",
      "Iteration 1766: Loss = 0.1858, Accuracy = 0.8600 Test Loss = 0.2053, Test Accuracy = 0.8502\n",
      "Iteration 1767: Loss = 0.1768, Accuracy = 0.8700 Test Loss = 0.2055, Test Accuracy = 0.8464\n",
      "Iteration 1768: Loss = 0.2248, Accuracy = 0.7800 Test Loss = 0.2050, Test Accuracy = 0.8511\n",
      "Iteration 1769: Loss = 0.1908, Accuracy = 0.8700 Test Loss = 0.2049, Test Accuracy = 0.8511\n",
      "Iteration 1770: Loss = 0.2383, Accuracy = 0.8000 Test Loss = 0.2054, Test Accuracy = 0.8542\n",
      "Iteration 1771: Loss = 0.1802, Accuracy = 0.8900 Test Loss = 0.2049, Test Accuracy = 0.8542\n",
      "Iteration 1772: Loss = 0.1962, Accuracy = 0.8100 Test Loss = 0.2049, Test Accuracy = 0.8512\n",
      "Iteration 1773: Loss = 0.2167, Accuracy = 0.7900 Test Loss = 0.2049, Test Accuracy = 0.8527\n",
      "Iteration 1774: Loss = 0.2192, Accuracy = 0.8100 Test Loss = 0.2048, Test Accuracy = 0.8467\n",
      "Iteration 1775: Loss = 0.1871, Accuracy = 0.9100 Test Loss = 0.2046, Test Accuracy = 0.8496\n",
      "Iteration 1776: Loss = 0.2118, Accuracy = 0.8400 Test Loss = 0.2050, Test Accuracy = 0.8510\n",
      "Iteration 1777: Loss = 0.1987, Accuracy = 0.8700 Test Loss = 0.2049, Test Accuracy = 0.8497\n",
      "Iteration 1778: Loss = 0.2153, Accuracy = 0.8300 Test Loss = 0.2053, Test Accuracy = 0.8519\n",
      "Iteration 1779: Loss = 0.1859, Accuracy = 0.8800 Test Loss = 0.2047, Test Accuracy = 0.8489\n",
      "Iteration 1780: Loss = 0.2055, Accuracy = 0.8400 Test Loss = 0.2047, Test Accuracy = 0.8483\n",
      "Iteration 1781: Loss = 0.1984, Accuracy = 0.9100 Test Loss = 0.2050, Test Accuracy = 0.8528\n",
      "Iteration 1782: Loss = 0.2088, Accuracy = 0.8200 Test Loss = 0.2048, Test Accuracy = 0.8523\n",
      "Iteration 1783: Loss = 0.1911, Accuracy = 0.8800 Test Loss = 0.2049, Test Accuracy = 0.8532\n",
      "Iteration 1784: Loss = 0.2082, Accuracy = 0.8200 Test Loss = 0.2047, Test Accuracy = 0.8492\n",
      "Iteration 1785: Loss = 0.2037, Accuracy = 0.8400 Test Loss = 0.2055, Test Accuracy = 0.8481\n",
      "Iteration 1786: Loss = 0.2122, Accuracy = 0.8200 Test Loss = 0.2047, Test Accuracy = 0.8519\n",
      "Iteration 1787: Loss = 0.1852, Accuracy = 0.8700 Test Loss = 0.2047, Test Accuracy = 0.8519\n",
      "Iteration 1788: Loss = 0.1945, Accuracy = 0.8300 Test Loss = 0.2051, Test Accuracy = 0.8520\n",
      "Iteration 1789: Loss = 0.1864, Accuracy = 0.8500 Test Loss = 0.2050, Test Accuracy = 0.8514\n",
      "Iteration 1790: Loss = 0.2051, Accuracy = 0.8400 Test Loss = 0.2052, Test Accuracy = 0.8524\n",
      "Iteration 1791: Loss = 0.1842, Accuracy = 0.9300 Test Loss = 0.2049, Test Accuracy = 0.8495\n",
      "Iteration 1792: Loss = 0.2259, Accuracy = 0.8300 Test Loss = 0.2051, Test Accuracy = 0.8516\n",
      "Iteration 1793: Loss = 0.2416, Accuracy = 0.8100 Test Loss = 0.2050, Test Accuracy = 0.8495\n",
      "Iteration 1794: Loss = 0.1900, Accuracy = 0.8800 Test Loss = 0.2052, Test Accuracy = 0.8486\n",
      "Iteration 1795: Loss = 0.2145, Accuracy = 0.8700 Test Loss = 0.2048, Test Accuracy = 0.8517\n",
      "Iteration 1796: Loss = 0.2178, Accuracy = 0.8100 Test Loss = 0.2051, Test Accuracy = 0.8520\n",
      "Iteration 1797: Loss = 0.2038, Accuracy = 0.8300 Test Loss = 0.2052, Test Accuracy = 0.8485\n",
      "Iteration 1798: Loss = 0.2039, Accuracy = 0.8800 Test Loss = 0.2047, Test Accuracy = 0.8503\n",
      "Iteration 1799: Loss = 0.2165, Accuracy = 0.7700 Test Loss = 0.2051, Test Accuracy = 0.8491\n",
      "Iteration 1800: Loss = 0.2108, Accuracy = 0.8000 Test Loss = 0.2046, Test Accuracy = 0.8477\n",
      "Iteration 1801: Loss = 0.1684, Accuracy = 0.8700 Test Loss = 0.2050, Test Accuracy = 0.8528\n",
      "Iteration 1802: Loss = 0.2057, Accuracy = 0.8600 Test Loss = 0.2048, Test Accuracy = 0.8511\n",
      "Iteration 1803: Loss = 0.1977, Accuracy = 0.8600 Test Loss = 0.2057, Test Accuracy = 0.8478\n",
      "Iteration 1804: Loss = 0.2058, Accuracy = 0.8300 Test Loss = 0.2052, Test Accuracy = 0.8473\n",
      "Iteration 1805: Loss = 0.2127, Accuracy = 0.8400 Test Loss = 0.2051, Test Accuracy = 0.8460\n",
      "Iteration 1806: Loss = 0.1937, Accuracy = 0.8800 Test Loss = 0.2045, Test Accuracy = 0.8486\n",
      "Iteration 1807: Loss = 0.2379, Accuracy = 0.8300 Test Loss = 0.2046, Test Accuracy = 0.8495\n",
      "Iteration 1808: Loss = 0.2292, Accuracy = 0.8600 Test Loss = 0.2054, Test Accuracy = 0.8500\n",
      "Iteration 1809: Loss = 0.1846, Accuracy = 0.8700 Test Loss = 0.2048, Test Accuracy = 0.8502\n",
      "Iteration 1810: Loss = 0.2178, Accuracy = 0.8800 Test Loss = 0.2052, Test Accuracy = 0.8490\n",
      "Iteration 1811: Loss = 0.1661, Accuracy = 0.9100 Test Loss = 0.2049, Test Accuracy = 0.8474\n",
      "Iteration 1812: Loss = 0.2065, Accuracy = 0.8800 Test Loss = 0.2048, Test Accuracy = 0.8519\n",
      "Iteration 1813: Loss = 0.1769, Accuracy = 0.9000 Test Loss = 0.2055, Test Accuracy = 0.8479\n",
      "Iteration 1814: Loss = 0.1754, Accuracy = 0.8800 Test Loss = 0.2050, Test Accuracy = 0.8495\n",
      "Iteration 1815: Loss = 0.1864, Accuracy = 0.9100 Test Loss = 0.2047, Test Accuracy = 0.8546\n",
      "Iteration 1816: Loss = 0.1949, Accuracy = 0.9000 Test Loss = 0.2052, Test Accuracy = 0.8538\n",
      "Iteration 1817: Loss = 0.1933, Accuracy = 0.8600 Test Loss = 0.2047, Test Accuracy = 0.8491\n",
      "Iteration 1818: Loss = 0.2470, Accuracy = 0.7900 Test Loss = 0.2053, Test Accuracy = 0.8460\n",
      "Iteration 1819: Loss = 0.1959, Accuracy = 0.8700 Test Loss = 0.2046, Test Accuracy = 0.8543\n",
      "Iteration 1820: Loss = 0.1920, Accuracy = 0.8500 Test Loss = 0.2047, Test Accuracy = 0.8529\n",
      "Iteration 1821: Loss = 0.2153, Accuracy = 0.8400 Test Loss = 0.2046, Test Accuracy = 0.8510\n",
      "Iteration 1822: Loss = 0.2162, Accuracy = 0.8100 Test Loss = 0.2051, Test Accuracy = 0.8486\n",
      "Iteration 1823: Loss = 0.2011, Accuracy = 0.8900 Test Loss = 0.2063, Test Accuracy = 0.8497\n",
      "Iteration 1824: Loss = 0.1999, Accuracy = 0.8500 Test Loss = 0.2045, Test Accuracy = 0.8504\n",
      "Iteration 1825: Loss = 0.2015, Accuracy = 0.8600 Test Loss = 0.2046, Test Accuracy = 0.8501\n",
      "Iteration 1826: Loss = 0.1914, Accuracy = 0.8500 Test Loss = 0.2045, Test Accuracy = 0.8496\n",
      "Iteration 1827: Loss = 0.2204, Accuracy = 0.7900 Test Loss = 0.2049, Test Accuracy = 0.8521\n",
      "Iteration 1828: Loss = 0.2175, Accuracy = 0.8200 Test Loss = 0.2047, Test Accuracy = 0.8516\n",
      "Iteration 1829: Loss = 0.1773, Accuracy = 0.8800 Test Loss = 0.2048, Test Accuracy = 0.8527\n",
      "Iteration 1830: Loss = 0.2126, Accuracy = 0.8200 Test Loss = 0.2051, Test Accuracy = 0.8497\n",
      "Iteration 1831: Loss = 0.2284, Accuracy = 0.7900 Test Loss = 0.2053, Test Accuracy = 0.8487\n",
      "Iteration 1832: Loss = 0.2146, Accuracy = 0.8000 Test Loss = 0.2047, Test Accuracy = 0.8504\n",
      "Iteration 1833: Loss = 0.2116, Accuracy = 0.8100 Test Loss = 0.2047, Test Accuracy = 0.8522\n",
      "Iteration 1834: Loss = 0.1685, Accuracy = 0.9400 Test Loss = 0.2050, Test Accuracy = 0.8515\n",
      "Iteration 1835: Loss = 0.2015, Accuracy = 0.8500 Test Loss = 0.2042, Test Accuracy = 0.8542\n",
      "Iteration 1836: Loss = 0.2257, Accuracy = 0.8200 Test Loss = 0.2044, Test Accuracy = 0.8512\n",
      "Iteration 1837: Loss = 0.1832, Accuracy = 0.9000 Test Loss = 0.2052, Test Accuracy = 0.8486\n",
      "Iteration 1838: Loss = 0.1688, Accuracy = 0.8500 Test Loss = 0.2052, Test Accuracy = 0.8476\n",
      "Iteration 1839: Loss = 0.1892, Accuracy = 0.8900 Test Loss = 0.2051, Test Accuracy = 0.8513\n",
      "Iteration 1840: Loss = 0.1927, Accuracy = 0.9100 Test Loss = 0.2054, Test Accuracy = 0.8474\n",
      "Iteration 1841: Loss = 0.2381, Accuracy = 0.8100 Test Loss = 0.2043, Test Accuracy = 0.8499\n",
      "Iteration 1842: Loss = 0.2013, Accuracy = 0.8700 Test Loss = 0.2047, Test Accuracy = 0.8509\n",
      "Iteration 1843: Loss = 0.2793, Accuracy = 0.7300 Test Loss = 0.2047, Test Accuracy = 0.8511\n",
      "Iteration 1844: Loss = 0.1928, Accuracy = 0.8700 Test Loss = 0.2047, Test Accuracy = 0.8486\n",
      "Iteration 1845: Loss = 0.1890, Accuracy = 0.8400 Test Loss = 0.2049, Test Accuracy = 0.8541\n",
      "Iteration 1846: Loss = 0.2227, Accuracy = 0.7900 Test Loss = 0.2043, Test Accuracy = 0.8478\n",
      "Iteration 1847: Loss = 0.2171, Accuracy = 0.8200 Test Loss = 0.2048, Test Accuracy = 0.8488\n",
      "Iteration 1848: Loss = 0.1978, Accuracy = 0.8500 Test Loss = 0.2046, Test Accuracy = 0.8499\n",
      "Iteration 1849: Loss = 0.1999, Accuracy = 0.8400 Test Loss = 0.2045, Test Accuracy = 0.8511\n",
      "Iteration 1850: Loss = 0.1781, Accuracy = 0.8800 Test Loss = 0.2047, Test Accuracy = 0.8504\n",
      "Iteration 1851: Loss = 0.2051, Accuracy = 0.8600 Test Loss = 0.2044, Test Accuracy = 0.8532\n",
      "Iteration 1852: Loss = 0.2204, Accuracy = 0.8600 Test Loss = 0.2050, Test Accuracy = 0.8535\n",
      "Iteration 1853: Loss = 0.1737, Accuracy = 0.9100 Test Loss = 0.2052, Test Accuracy = 0.8482\n",
      "Iteration 1854: Loss = 0.1886, Accuracy = 0.8500 Test Loss = 0.2049, Test Accuracy = 0.8489\n",
      "Iteration 1855: Loss = 0.2161, Accuracy = 0.8700 Test Loss = 0.2047, Test Accuracy = 0.8515\n",
      "Iteration 1856: Loss = 0.2261, Accuracy = 0.8200 Test Loss = 0.2043, Test Accuracy = 0.8535\n",
      "Iteration 1857: Loss = 0.1929, Accuracy = 0.8900 Test Loss = 0.2045, Test Accuracy = 0.8543\n",
      "Iteration 1858: Loss = 0.2049, Accuracy = 0.8400 Test Loss = 0.2045, Test Accuracy = 0.8492\n",
      "Iteration 1859: Loss = 0.2019, Accuracy = 0.8400 Test Loss = 0.2046, Test Accuracy = 0.8503\n",
      "Iteration 1860: Loss = 0.1883, Accuracy = 0.8600 Test Loss = 0.2050, Test Accuracy = 0.8492\n",
      "Iteration 1861: Loss = 0.1896, Accuracy = 0.8600 Test Loss = 0.2047, Test Accuracy = 0.8516\n",
      "Iteration 1862: Loss = 0.2143, Accuracy = 0.8200 Test Loss = 0.2048, Test Accuracy = 0.8523\n",
      "Iteration 1863: Loss = 0.1977, Accuracy = 0.9000 Test Loss = 0.2044, Test Accuracy = 0.8541\n",
      "Iteration 1864: Loss = 0.2249, Accuracy = 0.7900 Test Loss = 0.2044, Test Accuracy = 0.8524\n",
      "Iteration 1865: Loss = 0.2651, Accuracy = 0.7700 Test Loss = 0.2043, Test Accuracy = 0.8537\n",
      "Iteration 1866: Loss = 0.2034, Accuracy = 0.8300 Test Loss = 0.2052, Test Accuracy = 0.8493\n",
      "Iteration 1867: Loss = 0.2352, Accuracy = 0.8300 Test Loss = 0.2047, Test Accuracy = 0.8548\n",
      "Iteration 1868: Loss = 0.1905, Accuracy = 0.8500 Test Loss = 0.2044, Test Accuracy = 0.8553\n",
      "Iteration 1869: Loss = 0.1939, Accuracy = 0.9000 Test Loss = 0.2044, Test Accuracy = 0.8549\n",
      "Iteration 1870: Loss = 0.2279, Accuracy = 0.8100 Test Loss = 0.2046, Test Accuracy = 0.8487\n",
      "Iteration 1871: Loss = 0.2336, Accuracy = 0.7800 Test Loss = 0.2045, Test Accuracy = 0.8519\n",
      "Iteration 1872: Loss = 0.1843, Accuracy = 0.8600 Test Loss = 0.2042, Test Accuracy = 0.8527\n",
      "Iteration 1873: Loss = 0.2019, Accuracy = 0.8200 Test Loss = 0.2045, Test Accuracy = 0.8502\n",
      "Iteration 1874: Loss = 0.1996, Accuracy = 0.8300 Test Loss = 0.2044, Test Accuracy = 0.8486\n",
      "Iteration 1875: Loss = 0.2068, Accuracy = 0.8300 Test Loss = 0.2045, Test Accuracy = 0.8492\n",
      "Iteration 1876: Loss = 0.2039, Accuracy = 0.8300 Test Loss = 0.2046, Test Accuracy = 0.8541\n",
      "Iteration 1877: Loss = 0.2128, Accuracy = 0.8400 Test Loss = 0.2048, Test Accuracy = 0.8479\n",
      "Iteration 1878: Loss = 0.1947, Accuracy = 0.8900 Test Loss = 0.2042, Test Accuracy = 0.8484\n",
      "Iteration 1879: Loss = 0.2172, Accuracy = 0.8400 Test Loss = 0.2040, Test Accuracy = 0.8522\n",
      "Iteration 1880: Loss = 0.1862, Accuracy = 0.8400 Test Loss = 0.2045, Test Accuracy = 0.8490\n",
      "Iteration 1881: Loss = 0.1906, Accuracy = 0.8800 Test Loss = 0.2044, Test Accuracy = 0.8489\n",
      "Iteration 1882: Loss = 0.2293, Accuracy = 0.8100 Test Loss = 0.2047, Test Accuracy = 0.8502\n",
      "Iteration 1883: Loss = 0.2075, Accuracy = 0.8700 Test Loss = 0.2052, Test Accuracy = 0.8528\n",
      "Iteration 1884: Loss = 0.1977, Accuracy = 0.8000 Test Loss = 0.2047, Test Accuracy = 0.8530\n",
      "Iteration 1885: Loss = 0.2238, Accuracy = 0.8100 Test Loss = 0.2050, Test Accuracy = 0.8490\n",
      "Iteration 1886: Loss = 0.2151, Accuracy = 0.7900 Test Loss = 0.2042, Test Accuracy = 0.8518\n",
      "Iteration 1887: Loss = 0.2028, Accuracy = 0.8400 Test Loss = 0.2046, Test Accuracy = 0.8524\n",
      "Iteration 1888: Loss = 0.1917, Accuracy = 0.8700 Test Loss = 0.2051, Test Accuracy = 0.8489\n",
      "Iteration 1889: Loss = 0.2284, Accuracy = 0.8500 Test Loss = 0.2046, Test Accuracy = 0.8528\n",
      "Iteration 1890: Loss = 0.2076, Accuracy = 0.8700 Test Loss = 0.2049, Test Accuracy = 0.8489\n",
      "Iteration 1891: Loss = 0.2280, Accuracy = 0.8000 Test Loss = 0.2043, Test Accuracy = 0.8515\n",
      "Iteration 1892: Loss = 0.1858, Accuracy = 0.8800 Test Loss = 0.2051, Test Accuracy = 0.8487\n",
      "Iteration 1893: Loss = 0.2143, Accuracy = 0.8700 Test Loss = 0.2044, Test Accuracy = 0.8510\n",
      "Iteration 1894: Loss = 0.1925, Accuracy = 0.8700 Test Loss = 0.2045, Test Accuracy = 0.8498\n",
      "Iteration 1895: Loss = 0.2055, Accuracy = 0.8600 Test Loss = 0.2044, Test Accuracy = 0.8488\n",
      "Iteration 1896: Loss = 0.2142, Accuracy = 0.8400 Test Loss = 0.2044, Test Accuracy = 0.8530\n",
      "Iteration 1897: Loss = 0.1957, Accuracy = 0.9000 Test Loss = 0.2041, Test Accuracy = 0.8489\n",
      "Iteration 1898: Loss = 0.2088, Accuracy = 0.8200 Test Loss = 0.2046, Test Accuracy = 0.8523\n",
      "Iteration 1899: Loss = 0.2071, Accuracy = 0.8400 Test Loss = 0.2046, Test Accuracy = 0.8511\n",
      "Iteration 1900: Loss = 0.2323, Accuracy = 0.7700 Test Loss = 0.2043, Test Accuracy = 0.8514\n",
      "Iteration 1901: Loss = 0.2018, Accuracy = 0.8600 Test Loss = 0.2046, Test Accuracy = 0.8520\n",
      "Iteration 1902: Loss = 0.1826, Accuracy = 0.8400 Test Loss = 0.2048, Test Accuracy = 0.8490\n",
      "Iteration 1903: Loss = 0.2021, Accuracy = 0.8200 Test Loss = 0.2047, Test Accuracy = 0.8486\n",
      "Iteration 1904: Loss = 0.2108, Accuracy = 0.8200 Test Loss = 0.2047, Test Accuracy = 0.8490\n",
      "Iteration 1905: Loss = 0.1986, Accuracy = 0.8400 Test Loss = 0.2042, Test Accuracy = 0.8485\n",
      "Iteration 1906: Loss = 0.1914, Accuracy = 0.8400 Test Loss = 0.2048, Test Accuracy = 0.8476\n",
      "Iteration 1907: Loss = 0.2421, Accuracy = 0.8300 Test Loss = 0.2046, Test Accuracy = 0.8543\n",
      "Iteration 1908: Loss = 0.1924, Accuracy = 0.8400 Test Loss = 0.2040, Test Accuracy = 0.8508\n",
      "Iteration 1909: Loss = 0.1976, Accuracy = 0.8400 Test Loss = 0.2046, Test Accuracy = 0.8484\n",
      "Iteration 1910: Loss = 0.2329, Accuracy = 0.8400 Test Loss = 0.2042, Test Accuracy = 0.8498\n",
      "Iteration 1911: Loss = 0.2331, Accuracy = 0.7800 Test Loss = 0.2045, Test Accuracy = 0.8507\n",
      "Iteration 1912: Loss = 0.1993, Accuracy = 0.8300 Test Loss = 0.2046, Test Accuracy = 0.8515\n",
      "Iteration 1913: Loss = 0.2038, Accuracy = 0.8300 Test Loss = 0.2045, Test Accuracy = 0.8487\n",
      "Iteration 1914: Loss = 0.2093, Accuracy = 0.8000 Test Loss = 0.2043, Test Accuracy = 0.8507\n",
      "Iteration 1915: Loss = 0.2000, Accuracy = 0.8700 Test Loss = 0.2041, Test Accuracy = 0.8549\n",
      "Iteration 1916: Loss = 0.2062, Accuracy = 0.8300 Test Loss = 0.2042, Test Accuracy = 0.8519\n",
      "Iteration 1917: Loss = 0.1942, Accuracy = 0.8500 Test Loss = 0.2041, Test Accuracy = 0.8466\n",
      "Iteration 1918: Loss = 0.1953, Accuracy = 0.8700 Test Loss = 0.2042, Test Accuracy = 0.8505\n",
      "Iteration 1919: Loss = 0.1897, Accuracy = 0.8600 Test Loss = 0.2047, Test Accuracy = 0.8522\n",
      "Iteration 1920: Loss = 0.2279, Accuracy = 0.8100 Test Loss = 0.2041, Test Accuracy = 0.8490\n",
      "Iteration 1921: Loss = 0.1970, Accuracy = 0.8500 Test Loss = 0.2046, Test Accuracy = 0.8517\n",
      "Iteration 1922: Loss = 0.1981, Accuracy = 0.8400 Test Loss = 0.2048, Test Accuracy = 0.8461\n",
      "Iteration 1923: Loss = 0.2005, Accuracy = 0.8300 Test Loss = 0.2043, Test Accuracy = 0.8507\n",
      "Iteration 1924: Loss = 0.2162, Accuracy = 0.8400 Test Loss = 0.2044, Test Accuracy = 0.8507\n",
      "Iteration 1925: Loss = 0.2049, Accuracy = 0.8700 Test Loss = 0.2040, Test Accuracy = 0.8534\n",
      "Iteration 1926: Loss = 0.1967, Accuracy = 0.8400 Test Loss = 0.2048, Test Accuracy = 0.8482\n",
      "Iteration 1927: Loss = 0.1857, Accuracy = 0.8500 Test Loss = 0.2047, Test Accuracy = 0.8534\n",
      "Iteration 1928: Loss = 0.2255, Accuracy = 0.8000 Test Loss = 0.2046, Test Accuracy = 0.8514\n",
      "Iteration 1929: Loss = 0.2073, Accuracy = 0.8700 Test Loss = 0.2044, Test Accuracy = 0.8494\n",
      "Iteration 1930: Loss = 0.2349, Accuracy = 0.7800 Test Loss = 0.2041, Test Accuracy = 0.8525\n",
      "Iteration 1931: Loss = 0.1854, Accuracy = 0.8700 Test Loss = 0.2040, Test Accuracy = 0.8489\n",
      "Iteration 1932: Loss = 0.1938, Accuracy = 0.8800 Test Loss = 0.2041, Test Accuracy = 0.8503\n",
      "Iteration 1933: Loss = 0.1796, Accuracy = 0.8800 Test Loss = 0.2045, Test Accuracy = 0.8513\n",
      "Iteration 1934: Loss = 0.2048, Accuracy = 0.8800 Test Loss = 0.2046, Test Accuracy = 0.8506\n",
      "Iteration 1935: Loss = 0.1854, Accuracy = 0.9100 Test Loss = 0.2038, Test Accuracy = 0.8501\n",
      "Iteration 1936: Loss = 0.2106, Accuracy = 0.8400 Test Loss = 0.2043, Test Accuracy = 0.8503\n",
      "Iteration 1937: Loss = 0.2530, Accuracy = 0.8400 Test Loss = 0.2044, Test Accuracy = 0.8515\n",
      "Iteration 1938: Loss = 0.1693, Accuracy = 0.8800 Test Loss = 0.2048, Test Accuracy = 0.8505\n",
      "Iteration 1939: Loss = 0.1913, Accuracy = 0.8800 Test Loss = 0.2043, Test Accuracy = 0.8497\n",
      "Iteration 1940: Loss = 0.2148, Accuracy = 0.8300 Test Loss = 0.2040, Test Accuracy = 0.8537\n",
      "Iteration 1941: Loss = 0.1978, Accuracy = 0.8700 Test Loss = 0.2048, Test Accuracy = 0.8509\n",
      "Iteration 1942: Loss = 0.2384, Accuracy = 0.8200 Test Loss = 0.2044, Test Accuracy = 0.8476\n",
      "Iteration 1943: Loss = 0.2172, Accuracy = 0.8300 Test Loss = 0.2042, Test Accuracy = 0.8472\n",
      "Iteration 1944: Loss = 0.2046, Accuracy = 0.8800 Test Loss = 0.2041, Test Accuracy = 0.8514\n",
      "Iteration 1945: Loss = 0.2195, Accuracy = 0.8200 Test Loss = 0.2043, Test Accuracy = 0.8521\n",
      "Iteration 1946: Loss = 0.2305, Accuracy = 0.7900 Test Loss = 0.2039, Test Accuracy = 0.8529\n",
      "Iteration 1947: Loss = 0.2105, Accuracy = 0.8200 Test Loss = 0.2041, Test Accuracy = 0.8513\n",
      "Iteration 1948: Loss = 0.1708, Accuracy = 0.8500 Test Loss = 0.2042, Test Accuracy = 0.8496\n",
      "Iteration 1949: Loss = 0.1989, Accuracy = 0.8300 Test Loss = 0.2042, Test Accuracy = 0.8465\n",
      "Iteration 1950: Loss = 0.1836, Accuracy = 0.9100 Test Loss = 0.2041, Test Accuracy = 0.8541\n",
      "Iteration 1951: Loss = 0.2106, Accuracy = 0.8500 Test Loss = 0.2045, Test Accuracy = 0.8502\n",
      "Iteration 1952: Loss = 0.2169, Accuracy = 0.8200 Test Loss = 0.2041, Test Accuracy = 0.8533\n",
      "Iteration 1953: Loss = 0.1841, Accuracy = 0.8800 Test Loss = 0.2044, Test Accuracy = 0.8508\n",
      "Iteration 1954: Loss = 0.1847, Accuracy = 0.8800 Test Loss = 0.2044, Test Accuracy = 0.8511\n",
      "Iteration 1955: Loss = 0.2163, Accuracy = 0.8600 Test Loss = 0.2041, Test Accuracy = 0.8480\n",
      "Iteration 1956: Loss = 0.2030, Accuracy = 0.8500 Test Loss = 0.2058, Test Accuracy = 0.8492\n",
      "Iteration 1957: Loss = 0.1811, Accuracy = 0.8600 Test Loss = 0.2042, Test Accuracy = 0.8513\n",
      "Iteration 1958: Loss = 0.2028, Accuracy = 0.8200 Test Loss = 0.2046, Test Accuracy = 0.8533\n",
      "Iteration 1959: Loss = 0.2121, Accuracy = 0.8500 Test Loss = 0.2045, Test Accuracy = 0.8497\n",
      "Iteration 1960: Loss = 0.2310, Accuracy = 0.8300 Test Loss = 0.2045, Test Accuracy = 0.8508\n",
      "Iteration 1961: Loss = 0.2089, Accuracy = 0.8400 Test Loss = 0.2041, Test Accuracy = 0.8513\n",
      "Iteration 1962: Loss = 0.1950, Accuracy = 0.8100 Test Loss = 0.2046, Test Accuracy = 0.8510\n",
      "Iteration 1963: Loss = 0.2091, Accuracy = 0.8600 Test Loss = 0.2045, Test Accuracy = 0.8509\n",
      "Iteration 1964: Loss = 0.1771, Accuracy = 0.8900 Test Loss = 0.2043, Test Accuracy = 0.8536\n",
      "Iteration 1965: Loss = 0.1657, Accuracy = 0.9000 Test Loss = 0.2042, Test Accuracy = 0.8469\n",
      "Iteration 1966: Loss = 0.2025, Accuracy = 0.8900 Test Loss = 0.2050, Test Accuracy = 0.8462\n",
      "Iteration 1967: Loss = 0.2065, Accuracy = 0.8100 Test Loss = 0.2045, Test Accuracy = 0.8526\n",
      "Iteration 1968: Loss = 0.2268, Accuracy = 0.8300 Test Loss = 0.2039, Test Accuracy = 0.8537\n",
      "Iteration 1969: Loss = 0.2214, Accuracy = 0.8400 Test Loss = 0.2042, Test Accuracy = 0.8523\n",
      "Iteration 1970: Loss = 0.1755, Accuracy = 0.8600 Test Loss = 0.2039, Test Accuracy = 0.8477\n",
      "Iteration 1971: Loss = 0.2145, Accuracy = 0.8500 Test Loss = 0.2042, Test Accuracy = 0.8464\n",
      "Iteration 1972: Loss = 0.2116, Accuracy = 0.8400 Test Loss = 0.2045, Test Accuracy = 0.8524\n",
      "Iteration 1973: Loss = 0.1880, Accuracy = 0.8600 Test Loss = 0.2047, Test Accuracy = 0.8502\n",
      "Iteration 1974: Loss = 0.1808, Accuracy = 0.8900 Test Loss = 0.2040, Test Accuracy = 0.8505\n",
      "Iteration 1975: Loss = 0.1901, Accuracy = 0.8600 Test Loss = 0.2042, Test Accuracy = 0.8481\n",
      "Iteration 1976: Loss = 0.2023, Accuracy = 0.8400 Test Loss = 0.2040, Test Accuracy = 0.8509\n",
      "Iteration 1977: Loss = 0.2106, Accuracy = 0.8000 Test Loss = 0.2042, Test Accuracy = 0.8539\n",
      "Iteration 1978: Loss = 0.2107, Accuracy = 0.8600 Test Loss = 0.2040, Test Accuracy = 0.8506\n",
      "Iteration 1979: Loss = 0.1930, Accuracy = 0.8600 Test Loss = 0.2041, Test Accuracy = 0.8525\n",
      "Iteration 1980: Loss = 0.2154, Accuracy = 0.8600 Test Loss = 0.2040, Test Accuracy = 0.8540\n",
      "Iteration 1981: Loss = 0.2010, Accuracy = 0.8300 Test Loss = 0.2040, Test Accuracy = 0.8510\n",
      "Iteration 1982: Loss = 0.2101, Accuracy = 0.8000 Test Loss = 0.2040, Test Accuracy = 0.8547\n",
      "Iteration 1983: Loss = 0.2033, Accuracy = 0.8200 Test Loss = 0.2041, Test Accuracy = 0.8521\n",
      "Iteration 1984: Loss = 0.2143, Accuracy = 0.8300 Test Loss = 0.2039, Test Accuracy = 0.8535\n",
      "Iteration 1985: Loss = 0.2158, Accuracy = 0.8200 Test Loss = 0.2038, Test Accuracy = 0.8509\n",
      "Iteration 1986: Loss = 0.2047, Accuracy = 0.8700 Test Loss = 0.2043, Test Accuracy = 0.8505\n",
      "Iteration 1987: Loss = 0.1936, Accuracy = 0.8800 Test Loss = 0.2039, Test Accuracy = 0.8522\n",
      "Iteration 1988: Loss = 0.1835, Accuracy = 0.8800 Test Loss = 0.2042, Test Accuracy = 0.8514\n",
      "Iteration 1989: Loss = 0.1692, Accuracy = 0.9000 Test Loss = 0.2045, Test Accuracy = 0.8492\n",
      "Iteration 1990: Loss = 0.2047, Accuracy = 0.8300 Test Loss = 0.2039, Test Accuracy = 0.8490\n",
      "Iteration 1991: Loss = 0.1965, Accuracy = 0.9000 Test Loss = 0.2044, Test Accuracy = 0.8512\n",
      "Iteration 1992: Loss = 0.2244, Accuracy = 0.8100 Test Loss = 0.2040, Test Accuracy = 0.8508\n",
      "Iteration 1993: Loss = 0.1969, Accuracy = 0.9000 Test Loss = 0.2047, Test Accuracy = 0.8468\n",
      "Iteration 1994: Loss = 0.1820, Accuracy = 0.8900 Test Loss = 0.2038, Test Accuracy = 0.8539\n",
      "Iteration 1995: Loss = 0.2054, Accuracy = 0.8700 Test Loss = 0.2044, Test Accuracy = 0.8493\n",
      "Iteration 1996: Loss = 0.2061, Accuracy = 0.8400 Test Loss = 0.2039, Test Accuracy = 0.8502\n",
      "Iteration 1997: Loss = 0.2056, Accuracy = 0.8700 Test Loss = 0.2041, Test Accuracy = 0.8522\n",
      "Iteration 1998: Loss = 0.1809, Accuracy = 0.8900 Test Loss = 0.2040, Test Accuracy = 0.8509\n",
      "Iteration 1999: Loss = 0.2120, Accuracy = 0.8200 Test Loss = 0.2041, Test Accuracy = 0.8515\n",
      "Iteration 2000: Loss = 0.2062, Accuracy = 0.8600 Test Loss = 0.2041, Test Accuracy = 0.8524\n",
      "Iteration 2001: Loss = 0.1934, Accuracy = 0.8000 Test Loss = 0.2041, Test Accuracy = 0.8544\n",
      "Iteration 2002: Loss = 0.1958, Accuracy = 0.8700 Test Loss = 0.2043, Test Accuracy = 0.8481\n",
      "Iteration 2003: Loss = 0.1920, Accuracy = 0.7900 Test Loss = 0.2042, Test Accuracy = 0.8509\n",
      "Iteration 2004: Loss = 0.1924, Accuracy = 0.8200 Test Loss = 0.2045, Test Accuracy = 0.8526\n",
      "Iteration 2005: Loss = 0.1859, Accuracy = 0.8600 Test Loss = 0.2044, Test Accuracy = 0.8527\n",
      "Iteration 2006: Loss = 0.2107, Accuracy = 0.8000 Test Loss = 0.2041, Test Accuracy = 0.8478\n",
      "Iteration 2007: Loss = 0.1785, Accuracy = 0.9000 Test Loss = 0.2041, Test Accuracy = 0.8475\n",
      "Iteration 2008: Loss = 0.2181, Accuracy = 0.8300 Test Loss = 0.2043, Test Accuracy = 0.8520\n",
      "Iteration 2009: Loss = 0.1977, Accuracy = 0.8400 Test Loss = 0.2048, Test Accuracy = 0.8538\n",
      "Iteration 2010: Loss = 0.2066, Accuracy = 0.8300 Test Loss = 0.2044, Test Accuracy = 0.8502\n",
      "Iteration 2011: Loss = 0.1802, Accuracy = 0.8600 Test Loss = 0.2039, Test Accuracy = 0.8515\n",
      "Iteration 2012: Loss = 0.1888, Accuracy = 0.8600 Test Loss = 0.2037, Test Accuracy = 0.8501\n",
      "Iteration 2013: Loss = 0.1846, Accuracy = 0.8700 Test Loss = 0.2039, Test Accuracy = 0.8492\n",
      "Iteration 2014: Loss = 0.1889, Accuracy = 0.9100 Test Loss = 0.2039, Test Accuracy = 0.8502\n",
      "Iteration 2015: Loss = 0.2302, Accuracy = 0.8500 Test Loss = 0.2043, Test Accuracy = 0.8525\n",
      "Iteration 2016: Loss = 0.1962, Accuracy = 0.8500 Test Loss = 0.2042, Test Accuracy = 0.8552\n",
      "Iteration 2017: Loss = 0.1866, Accuracy = 0.8800 Test Loss = 0.2040, Test Accuracy = 0.8507\n",
      "Iteration 2018: Loss = 0.2109, Accuracy = 0.8700 Test Loss = 0.2037, Test Accuracy = 0.8497\n",
      "Iteration 2019: Loss = 0.2093, Accuracy = 0.8200 Test Loss = 0.2040, Test Accuracy = 0.8517\n",
      "Iteration 2020: Loss = 0.1727, Accuracy = 0.8700 Test Loss = 0.2037, Test Accuracy = 0.8498\n",
      "Iteration 2021: Loss = 0.2146, Accuracy = 0.8200 Test Loss = 0.2042, Test Accuracy = 0.8506\n",
      "Iteration 2022: Loss = 0.1896, Accuracy = 0.8700 Test Loss = 0.2049, Test Accuracy = 0.8497\n",
      "Iteration 2023: Loss = 0.2051, Accuracy = 0.8800 Test Loss = 0.2040, Test Accuracy = 0.8512\n",
      "Iteration 2024: Loss = 0.1815, Accuracy = 0.8700 Test Loss = 0.2047, Test Accuracy = 0.8470\n",
      "Iteration 2025: Loss = 0.2025, Accuracy = 0.8400 Test Loss = 0.2037, Test Accuracy = 0.8527\n",
      "Iteration 2026: Loss = 0.2010, Accuracy = 0.8700 Test Loss = 0.2039, Test Accuracy = 0.8500\n",
      "Iteration 2027: Loss = 0.1780, Accuracy = 0.8500 Test Loss = 0.2040, Test Accuracy = 0.8513\n",
      "Iteration 2028: Loss = 0.2111, Accuracy = 0.8600 Test Loss = 0.2040, Test Accuracy = 0.8506\n",
      "Iteration 2029: Loss = 0.1799, Accuracy = 0.8800 Test Loss = 0.2045, Test Accuracy = 0.8465\n",
      "Iteration 2030: Loss = 0.2190, Accuracy = 0.8000 Test Loss = 0.2041, Test Accuracy = 0.8498\n",
      "Iteration 2031: Loss = 0.1829, Accuracy = 0.8400 Test Loss = 0.2040, Test Accuracy = 0.8519\n",
      "Iteration 2032: Loss = 0.2077, Accuracy = 0.8300 Test Loss = 0.2038, Test Accuracy = 0.8531\n",
      "Iteration 2033: Loss = 0.2045, Accuracy = 0.8700 Test Loss = 0.2040, Test Accuracy = 0.8529\n",
      "Iteration 2034: Loss = 0.2399, Accuracy = 0.8300 Test Loss = 0.2039, Test Accuracy = 0.8502\n",
      "Iteration 2035: Loss = 0.1938, Accuracy = 0.8800 Test Loss = 0.2038, Test Accuracy = 0.8527\n",
      "Iteration 2036: Loss = 0.1876, Accuracy = 0.9100 Test Loss = 0.2039, Test Accuracy = 0.8509\n",
      "Iteration 2037: Loss = 0.2063, Accuracy = 0.8300 Test Loss = 0.2041, Test Accuracy = 0.8526\n",
      "Iteration 2038: Loss = 0.1941, Accuracy = 0.8300 Test Loss = 0.2040, Test Accuracy = 0.8499\n",
      "Iteration 2039: Loss = 0.1816, Accuracy = 0.8700 Test Loss = 0.2042, Test Accuracy = 0.8543\n",
      "Iteration 2040: Loss = 0.1896, Accuracy = 0.8400 Test Loss = 0.2043, Test Accuracy = 0.8532\n",
      "Iteration 2041: Loss = 0.1874, Accuracy = 0.8900 Test Loss = 0.2038, Test Accuracy = 0.8514\n",
      "Iteration 2042: Loss = 0.1968, Accuracy = 0.8500 Test Loss = 0.2047, Test Accuracy = 0.8507\n",
      "Iteration 2043: Loss = 0.2247, Accuracy = 0.8200 Test Loss = 0.2042, Test Accuracy = 0.8495\n",
      "Iteration 2044: Loss = 0.2248, Accuracy = 0.8100 Test Loss = 0.2045, Test Accuracy = 0.8534\n",
      "Iteration 2045: Loss = 0.2188, Accuracy = 0.8400 Test Loss = 0.2047, Test Accuracy = 0.8495\n",
      "Iteration 2046: Loss = 0.1990, Accuracy = 0.8600 Test Loss = 0.2046, Test Accuracy = 0.8524\n",
      "Iteration 2047: Loss = 0.1831, Accuracy = 0.8700 Test Loss = 0.2045, Test Accuracy = 0.8515\n",
      "Iteration 2048: Loss = 0.1976, Accuracy = 0.8600 Test Loss = 0.2038, Test Accuracy = 0.8514\n",
      "Iteration 2049: Loss = 0.1700, Accuracy = 0.8900 Test Loss = 0.2039, Test Accuracy = 0.8531\n",
      "Iteration 2050: Loss = 0.1866, Accuracy = 0.8400 Test Loss = 0.2036, Test Accuracy = 0.8498\n",
      "Iteration 2051: Loss = 0.2051, Accuracy = 0.8400 Test Loss = 0.2041, Test Accuracy = 0.8524\n",
      "Iteration 2052: Loss = 0.1931, Accuracy = 0.9000 Test Loss = 0.2036, Test Accuracy = 0.8504\n",
      "Iteration 2053: Loss = 0.2041, Accuracy = 0.8100 Test Loss = 0.2038, Test Accuracy = 0.8505\n",
      "Iteration 2054: Loss = 0.2049, Accuracy = 0.7900 Test Loss = 0.2043, Test Accuracy = 0.8514\n",
      "Iteration 2055: Loss = 0.2050, Accuracy = 0.8600 Test Loss = 0.2040, Test Accuracy = 0.8498\n",
      "Iteration 2056: Loss = 0.2296, Accuracy = 0.8300 Test Loss = 0.2041, Test Accuracy = 0.8523\n",
      "Iteration 2057: Loss = 0.2279, Accuracy = 0.7900 Test Loss = 0.2040, Test Accuracy = 0.8477\n",
      "Iteration 2058: Loss = 0.1926, Accuracy = 0.8200 Test Loss = 0.2036, Test Accuracy = 0.8509\n",
      "Iteration 2059: Loss = 0.2331, Accuracy = 0.7800 Test Loss = 0.2036, Test Accuracy = 0.8495\n",
      "Iteration 2060: Loss = 0.2277, Accuracy = 0.7700 Test Loss = 0.2036, Test Accuracy = 0.8531\n",
      "Iteration 2061: Loss = 0.1957, Accuracy = 0.8500 Test Loss = 0.2041, Test Accuracy = 0.8465\n",
      "Iteration 2062: Loss = 0.1978, Accuracy = 0.9000 Test Loss = 0.2037, Test Accuracy = 0.8483\n",
      "Iteration 2063: Loss = 0.1983, Accuracy = 0.8400 Test Loss = 0.2041, Test Accuracy = 0.8465\n",
      "Iteration 2064: Loss = 0.2251, Accuracy = 0.8200 Test Loss = 0.2036, Test Accuracy = 0.8525\n",
      "Iteration 2065: Loss = 0.2009, Accuracy = 0.8300 Test Loss = 0.2039, Test Accuracy = 0.8513\n",
      "Iteration 2066: Loss = 0.2237, Accuracy = 0.8000 Test Loss = 0.2037, Test Accuracy = 0.8523\n",
      "Iteration 2067: Loss = 0.2559, Accuracy = 0.7700 Test Loss = 0.2040, Test Accuracy = 0.8504\n",
      "Iteration 2068: Loss = 0.1866, Accuracy = 0.8600 Test Loss = 0.2044, Test Accuracy = 0.8499\n",
      "Iteration 2069: Loss = 0.2095, Accuracy = 0.8100 Test Loss = 0.2041, Test Accuracy = 0.8499\n",
      "Iteration 2070: Loss = 0.1998, Accuracy = 0.8800 Test Loss = 0.2037, Test Accuracy = 0.8470\n",
      "Iteration 2071: Loss = 0.2123, Accuracy = 0.8800 Test Loss = 0.2038, Test Accuracy = 0.8532\n",
      "Iteration 2072: Loss = 0.2050, Accuracy = 0.8600 Test Loss = 0.2037, Test Accuracy = 0.8492\n",
      "Iteration 2073: Loss = 0.1756, Accuracy = 0.9000 Test Loss = 0.2039, Test Accuracy = 0.8511\n",
      "Iteration 2074: Loss = 0.1822, Accuracy = 0.8900 Test Loss = 0.2038, Test Accuracy = 0.8517\n",
      "Iteration 2075: Loss = 0.2053, Accuracy = 0.8300 Test Loss = 0.2041, Test Accuracy = 0.8451\n",
      "Iteration 2076: Loss = 0.2145, Accuracy = 0.8800 Test Loss = 0.2038, Test Accuracy = 0.8513\n",
      "Iteration 2077: Loss = 0.1892, Accuracy = 0.8800 Test Loss = 0.2041, Test Accuracy = 0.8478\n",
      "Iteration 2078: Loss = 0.2091, Accuracy = 0.8600 Test Loss = 0.2044, Test Accuracy = 0.8486\n",
      "Iteration 2079: Loss = 0.1975, Accuracy = 0.8800 Test Loss = 0.2040, Test Accuracy = 0.8516\n",
      "Iteration 2080: Loss = 0.1765, Accuracy = 0.8400 Test Loss = 0.2039, Test Accuracy = 0.8464\n",
      "Iteration 2081: Loss = 0.1943, Accuracy = 0.8500 Test Loss = 0.2044, Test Accuracy = 0.8499\n",
      "Iteration 2082: Loss = 0.2279, Accuracy = 0.8100 Test Loss = 0.2040, Test Accuracy = 0.8513\n",
      "Iteration 2083: Loss = 0.1914, Accuracy = 0.8800 Test Loss = 0.2041, Test Accuracy = 0.8487\n",
      "Iteration 2084: Loss = 0.2317, Accuracy = 0.7700 Test Loss = 0.2044, Test Accuracy = 0.8549\n",
      "Iteration 2085: Loss = 0.1930, Accuracy = 0.8400 Test Loss = 0.2045, Test Accuracy = 0.8510\n",
      "Iteration 2086: Loss = 0.2317, Accuracy = 0.8100 Test Loss = 0.2035, Test Accuracy = 0.8518\n",
      "Iteration 2087: Loss = 0.2323, Accuracy = 0.8100 Test Loss = 0.2038, Test Accuracy = 0.8515\n",
      "Iteration 2088: Loss = 0.2023, Accuracy = 0.8400 Test Loss = 0.2042, Test Accuracy = 0.8487\n",
      "Iteration 2089: Loss = 0.1960, Accuracy = 0.8500 Test Loss = 0.2044, Test Accuracy = 0.8499\n",
      "Iteration 2090: Loss = 0.2309, Accuracy = 0.8100 Test Loss = 0.2039, Test Accuracy = 0.8529\n",
      "Iteration 2091: Loss = 0.1836, Accuracy = 0.8900 Test Loss = 0.2043, Test Accuracy = 0.8502\n",
      "Iteration 2092: Loss = 0.2056, Accuracy = 0.8700 Test Loss = 0.2042, Test Accuracy = 0.8508\n",
      "Iteration 2093: Loss = 0.1688, Accuracy = 0.9200 Test Loss = 0.2039, Test Accuracy = 0.8525\n",
      "Iteration 2094: Loss = 0.2423, Accuracy = 0.7800 Test Loss = 0.2036, Test Accuracy = 0.8511\n",
      "Iteration 2095: Loss = 0.2284, Accuracy = 0.8000 Test Loss = 0.2047, Test Accuracy = 0.8473\n",
      "Iteration 2096: Loss = 0.1664, Accuracy = 0.9100 Test Loss = 0.2036, Test Accuracy = 0.8530\n",
      "Iteration 2097: Loss = 0.1884, Accuracy = 0.9000 Test Loss = 0.2040, Test Accuracy = 0.8543\n",
      "Iteration 2098: Loss = 0.2190, Accuracy = 0.7700 Test Loss = 0.2038, Test Accuracy = 0.8498\n",
      "Iteration 2099: Loss = 0.2391, Accuracy = 0.7800 Test Loss = 0.2039, Test Accuracy = 0.8493\n",
      "Iteration 2100: Loss = 0.2186, Accuracy = 0.8000 Test Loss = 0.2039, Test Accuracy = 0.8530\n",
      "Iteration 2101: Loss = 0.2259, Accuracy = 0.8100 Test Loss = 0.2040, Test Accuracy = 0.8510\n",
      "Iteration 2102: Loss = 0.1930, Accuracy = 0.8400 Test Loss = 0.2040, Test Accuracy = 0.8507\n",
      "Iteration 2103: Loss = 0.2154, Accuracy = 0.8400 Test Loss = 0.2041, Test Accuracy = 0.8538\n",
      "Iteration 2104: Loss = 0.1913, Accuracy = 0.8100 Test Loss = 0.2041, Test Accuracy = 0.8546\n",
      "Iteration 2105: Loss = 0.2077, Accuracy = 0.8400 Test Loss = 0.2035, Test Accuracy = 0.8519\n",
      "Iteration 2106: Loss = 0.1875, Accuracy = 0.8600 Test Loss = 0.2035, Test Accuracy = 0.8510\n",
      "Iteration 2107: Loss = 0.2005, Accuracy = 0.8100 Test Loss = 0.2043, Test Accuracy = 0.8472\n",
      "Iteration 2108: Loss = 0.1925, Accuracy = 0.8800 Test Loss = 0.2038, Test Accuracy = 0.8545\n",
      "Iteration 2109: Loss = 0.1846, Accuracy = 0.8800 Test Loss = 0.2037, Test Accuracy = 0.8552\n",
      "Iteration 2110: Loss = 0.1844, Accuracy = 0.8700 Test Loss = 0.2040, Test Accuracy = 0.8483\n",
      "Iteration 2111: Loss = 0.2159, Accuracy = 0.8100 Test Loss = 0.2039, Test Accuracy = 0.8504\n",
      "Iteration 2112: Loss = 0.2040, Accuracy = 0.8100 Test Loss = 0.2039, Test Accuracy = 0.8521\n",
      "Iteration 2113: Loss = 0.2129, Accuracy = 0.8400 Test Loss = 0.2037, Test Accuracy = 0.8503\n",
      "Iteration 2114: Loss = 0.2080, Accuracy = 0.8600 Test Loss = 0.2041, Test Accuracy = 0.8504\n",
      "Iteration 2115: Loss = 0.2413, Accuracy = 0.8800 Test Loss = 0.2045, Test Accuracy = 0.8540\n",
      "Iteration 2116: Loss = 0.2107, Accuracy = 0.8300 Test Loss = 0.2045, Test Accuracy = 0.8477\n",
      "Iteration 2117: Loss = 0.1911, Accuracy = 0.9200 Test Loss = 0.2039, Test Accuracy = 0.8513\n",
      "Iteration 2118: Loss = 0.2228, Accuracy = 0.8100 Test Loss = 0.2040, Test Accuracy = 0.8524\n",
      "Iteration 2119: Loss = 0.1932, Accuracy = 0.8400 Test Loss = 0.2038, Test Accuracy = 0.8532\n",
      "Iteration 2120: Loss = 0.1884, Accuracy = 0.8700 Test Loss = 0.2037, Test Accuracy = 0.8496\n",
      "Iteration 2121: Loss = 0.1819, Accuracy = 0.8800 Test Loss = 0.2042, Test Accuracy = 0.8510\n",
      "Iteration 2122: Loss = 0.2170, Accuracy = 0.8400 Test Loss = 0.2038, Test Accuracy = 0.8503\n",
      "Iteration 2123: Loss = 0.2156, Accuracy = 0.8500 Test Loss = 0.2037, Test Accuracy = 0.8497\n",
      "Iteration 2124: Loss = 0.2261, Accuracy = 0.8300 Test Loss = 0.2038, Test Accuracy = 0.8505\n",
      "Iteration 2125: Loss = 0.1902, Accuracy = 0.8500 Test Loss = 0.2039, Test Accuracy = 0.8484\n",
      "Iteration 2126: Loss = 0.1844, Accuracy = 0.8500 Test Loss = 0.2037, Test Accuracy = 0.8521\n",
      "Iteration 2127: Loss = 0.2057, Accuracy = 0.7900 Test Loss = 0.2035, Test Accuracy = 0.8509\n",
      "Iteration 2128: Loss = 0.2043, Accuracy = 0.8200 Test Loss = 0.2040, Test Accuracy = 0.8488\n",
      "Iteration 2129: Loss = 0.2008, Accuracy = 0.8200 Test Loss = 0.2040, Test Accuracy = 0.8521\n",
      "Iteration 2130: Loss = 0.2083, Accuracy = 0.8700 Test Loss = 0.2037, Test Accuracy = 0.8505\n",
      "Iteration 2131: Loss = 0.1925, Accuracy = 0.8400 Test Loss = 0.2038, Test Accuracy = 0.8492\n",
      "Iteration 2132: Loss = 0.2081, Accuracy = 0.8200 Test Loss = 0.2039, Test Accuracy = 0.8515\n",
      "Iteration 2133: Loss = 0.2094, Accuracy = 0.8500 Test Loss = 0.2036, Test Accuracy = 0.8502\n",
      "Iteration 2134: Loss = 0.1916, Accuracy = 0.8800 Test Loss = 0.2041, Test Accuracy = 0.8478\n",
      "Iteration 2135: Loss = 0.2498, Accuracy = 0.8100 Test Loss = 0.2037, Test Accuracy = 0.8519\n",
      "Iteration 2136: Loss = 0.2231, Accuracy = 0.8100 Test Loss = 0.2041, Test Accuracy = 0.8474\n",
      "Iteration 2137: Loss = 0.2186, Accuracy = 0.8400 Test Loss = 0.2036, Test Accuracy = 0.8516\n",
      "Iteration 2138: Loss = 0.1941, Accuracy = 0.8500 Test Loss = 0.2033, Test Accuracy = 0.8519\n",
      "Iteration 2139: Loss = 0.2064, Accuracy = 0.8200 Test Loss = 0.2035, Test Accuracy = 0.8512\n",
      "Iteration 2140: Loss = 0.2150, Accuracy = 0.8500 Test Loss = 0.2035, Test Accuracy = 0.8494\n",
      "Iteration 2141: Loss = 0.1900, Accuracy = 0.8800 Test Loss = 0.2041, Test Accuracy = 0.8477\n",
      "Iteration 2142: Loss = 0.1976, Accuracy = 0.8900 Test Loss = 0.2037, Test Accuracy = 0.8521\n",
      "Iteration 2143: Loss = 0.2236, Accuracy = 0.8100 Test Loss = 0.2042, Test Accuracy = 0.8518\n",
      "Iteration 2144: Loss = 0.1938, Accuracy = 0.9000 Test Loss = 0.2046, Test Accuracy = 0.8517\n",
      "Iteration 2145: Loss = 0.2130, Accuracy = 0.8300 Test Loss = 0.2039, Test Accuracy = 0.8499\n",
      "Iteration 2146: Loss = 0.2007, Accuracy = 0.8600 Test Loss = 0.2038, Test Accuracy = 0.8491\n",
      "Iteration 2147: Loss = 0.1895, Accuracy = 0.8600 Test Loss = 0.2038, Test Accuracy = 0.8474\n",
      "Iteration 2148: Loss = 0.2044, Accuracy = 0.8300 Test Loss = 0.2036, Test Accuracy = 0.8538\n",
      "Iteration 2149: Loss = 0.1794, Accuracy = 0.8900 Test Loss = 0.2039, Test Accuracy = 0.8495\n",
      "Iteration 2150: Loss = 0.1868, Accuracy = 0.8400 Test Loss = 0.2040, Test Accuracy = 0.8494\n",
      "Iteration 2151: Loss = 0.1727, Accuracy = 0.8800 Test Loss = 0.2035, Test Accuracy = 0.8524\n",
      "Iteration 2152: Loss = 0.1906, Accuracy = 0.8800 Test Loss = 0.2034, Test Accuracy = 0.8507\n",
      "Iteration 2153: Loss = 0.1817, Accuracy = 0.8700 Test Loss = 0.2034, Test Accuracy = 0.8525\n",
      "Iteration 2154: Loss = 0.2348, Accuracy = 0.7700 Test Loss = 0.2035, Test Accuracy = 0.8538\n",
      "Iteration 2155: Loss = 0.2029, Accuracy = 0.8500 Test Loss = 0.2042, Test Accuracy = 0.8522\n",
      "Iteration 2156: Loss = 0.1833, Accuracy = 0.8700 Test Loss = 0.2040, Test Accuracy = 0.8501\n",
      "Iteration 2157: Loss = 0.2004, Accuracy = 0.8700 Test Loss = 0.2036, Test Accuracy = 0.8516\n",
      "Iteration 2158: Loss = 0.2051, Accuracy = 0.8600 Test Loss = 0.2038, Test Accuracy = 0.8507\n",
      "Iteration 2159: Loss = 0.2183, Accuracy = 0.8200 Test Loss = 0.2034, Test Accuracy = 0.8547\n",
      "Iteration 2160: Loss = 0.2183, Accuracy = 0.8500 Test Loss = 0.2036, Test Accuracy = 0.8498\n",
      "Iteration 2161: Loss = 0.2177, Accuracy = 0.8000 Test Loss = 0.2035, Test Accuracy = 0.8508\n",
      "Iteration 2162: Loss = 0.2230, Accuracy = 0.8000 Test Loss = 0.2040, Test Accuracy = 0.8516\n",
      "Iteration 2163: Loss = 0.2016, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8523\n",
      "Iteration 2164: Loss = 0.1890, Accuracy = 0.9000 Test Loss = 0.2040, Test Accuracy = 0.8496\n",
      "Iteration 2165: Loss = 0.1814, Accuracy = 0.8900 Test Loss = 0.2041, Test Accuracy = 0.8511\n",
      "Iteration 2166: Loss = 0.2331, Accuracy = 0.8000 Test Loss = 0.2044, Test Accuracy = 0.8512\n",
      "Iteration 2167: Loss = 0.2169, Accuracy = 0.7900 Test Loss = 0.2035, Test Accuracy = 0.8514\n",
      "Iteration 2168: Loss = 0.1912, Accuracy = 0.8200 Test Loss = 0.2041, Test Accuracy = 0.8512\n",
      "Iteration 2169: Loss = 0.1990, Accuracy = 0.8200 Test Loss = 0.2035, Test Accuracy = 0.8493\n",
      "Iteration 2170: Loss = 0.2167, Accuracy = 0.8000 Test Loss = 0.2037, Test Accuracy = 0.8504\n",
      "Iteration 2171: Loss = 0.2197, Accuracy = 0.8300 Test Loss = 0.2038, Test Accuracy = 0.8503\n",
      "Iteration 2172: Loss = 0.2434, Accuracy = 0.7100 Test Loss = 0.2039, Test Accuracy = 0.8532\n",
      "Iteration 2173: Loss = 0.2159, Accuracy = 0.8500 Test Loss = 0.2035, Test Accuracy = 0.8482\n",
      "Iteration 2174: Loss = 0.1924, Accuracy = 0.8500 Test Loss = 0.2036, Test Accuracy = 0.8524\n",
      "Iteration 2175: Loss = 0.1911, Accuracy = 0.8300 Test Loss = 0.2037, Test Accuracy = 0.8498\n",
      "Iteration 2176: Loss = 0.1990, Accuracy = 0.8100 Test Loss = 0.2035, Test Accuracy = 0.8545\n",
      "Iteration 2177: Loss = 0.1961, Accuracy = 0.8800 Test Loss = 0.2039, Test Accuracy = 0.8505\n",
      "Iteration 2178: Loss = 0.1798, Accuracy = 0.8800 Test Loss = 0.2034, Test Accuracy = 0.8511\n",
      "Iteration 2179: Loss = 0.1921, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8525\n",
      "Iteration 2180: Loss = 0.1824, Accuracy = 0.8600 Test Loss = 0.2038, Test Accuracy = 0.8506\n",
      "Iteration 2181: Loss = 0.1970, Accuracy = 0.8600 Test Loss = 0.2040, Test Accuracy = 0.8479\n",
      "Iteration 2182: Loss = 0.2030, Accuracy = 0.8700 Test Loss = 0.2038, Test Accuracy = 0.8477\n",
      "Iteration 2183: Loss = 0.2038, Accuracy = 0.8400 Test Loss = 0.2034, Test Accuracy = 0.8501\n",
      "Iteration 2184: Loss = 0.2245, Accuracy = 0.8300 Test Loss = 0.2033, Test Accuracy = 0.8516\n",
      "Iteration 2185: Loss = 0.2107, Accuracy = 0.8400 Test Loss = 0.2039, Test Accuracy = 0.8486\n",
      "Iteration 2186: Loss = 0.2240, Accuracy = 0.8500 Test Loss = 0.2034, Test Accuracy = 0.8539\n",
      "Iteration 2187: Loss = 0.1916, Accuracy = 0.9000 Test Loss = 0.2036, Test Accuracy = 0.8511\n",
      "Iteration 2188: Loss = 0.2112, Accuracy = 0.8200 Test Loss = 0.2034, Test Accuracy = 0.8539\n",
      "Iteration 2189: Loss = 0.2148, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8530\n",
      "Iteration 2190: Loss = 0.1910, Accuracy = 0.9000 Test Loss = 0.2035, Test Accuracy = 0.8493\n",
      "Iteration 2191: Loss = 0.1858, Accuracy = 0.9000 Test Loss = 0.2033, Test Accuracy = 0.8488\n",
      "Iteration 2192: Loss = 0.2190, Accuracy = 0.8300 Test Loss = 0.2030, Test Accuracy = 0.8502\n",
      "Iteration 2193: Loss = 0.2063, Accuracy = 0.9300 Test Loss = 0.2034, Test Accuracy = 0.8514\n",
      "Iteration 2194: Loss = 0.1909, Accuracy = 0.8400 Test Loss = 0.2039, Test Accuracy = 0.8508\n",
      "Iteration 2195: Loss = 0.1967, Accuracy = 0.8800 Test Loss = 0.2038, Test Accuracy = 0.8539\n",
      "Iteration 2196: Loss = 0.2036, Accuracy = 0.8400 Test Loss = 0.2034, Test Accuracy = 0.8501\n",
      "Iteration 2197: Loss = 0.1852, Accuracy = 0.8600 Test Loss = 0.2037, Test Accuracy = 0.8513\n",
      "Iteration 2198: Loss = 0.1983, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8502\n",
      "Iteration 2199: Loss = 0.2231, Accuracy = 0.8100 Test Loss = 0.2040, Test Accuracy = 0.8491\n",
      "Iteration 2200: Loss = 0.1872, Accuracy = 0.9300 Test Loss = 0.2034, Test Accuracy = 0.8504\n",
      "Iteration 2201: Loss = 0.2000, Accuracy = 0.8600 Test Loss = 0.2035, Test Accuracy = 0.8498\n",
      "Iteration 2202: Loss = 0.1803, Accuracy = 0.8400 Test Loss = 0.2037, Test Accuracy = 0.8479\n",
      "Iteration 2203: Loss = 0.2015, Accuracy = 0.8200 Test Loss = 0.2035, Test Accuracy = 0.8488\n",
      "Iteration 2204: Loss = 0.2182, Accuracy = 0.8400 Test Loss = 0.2033, Test Accuracy = 0.8509\n",
      "Iteration 2205: Loss = 0.2106, Accuracy = 0.8000 Test Loss = 0.2032, Test Accuracy = 0.8533\n",
      "Iteration 2206: Loss = 0.1953, Accuracy = 0.8600 Test Loss = 0.2045, Test Accuracy = 0.8518\n",
      "Iteration 2207: Loss = 0.1877, Accuracy = 0.9100 Test Loss = 0.2036, Test Accuracy = 0.8541\n",
      "Iteration 2208: Loss = 0.2118, Accuracy = 0.8000 Test Loss = 0.2032, Test Accuracy = 0.8498\n",
      "Iteration 2209: Loss = 0.2199, Accuracy = 0.7600 Test Loss = 0.2034, Test Accuracy = 0.8494\n",
      "Iteration 2210: Loss = 0.1992, Accuracy = 0.8300 Test Loss = 0.2038, Test Accuracy = 0.8522\n",
      "Iteration 2211: Loss = 0.1854, Accuracy = 0.8800 Test Loss = 0.2037, Test Accuracy = 0.8536\n",
      "Iteration 2212: Loss = 0.2235, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8529\n",
      "Iteration 2213: Loss = 0.2183, Accuracy = 0.8100 Test Loss = 0.2035, Test Accuracy = 0.8536\n",
      "Iteration 2214: Loss = 0.2355, Accuracy = 0.7900 Test Loss = 0.2032, Test Accuracy = 0.8527\n",
      "Iteration 2215: Loss = 0.2096, Accuracy = 0.8300 Test Loss = 0.2033, Test Accuracy = 0.8507\n",
      "Iteration 2216: Loss = 0.1689, Accuracy = 0.9000 Test Loss = 0.2037, Test Accuracy = 0.8534\n",
      "Iteration 2217: Loss = 0.2251, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8518\n",
      "Iteration 2218: Loss = 0.1966, Accuracy = 0.8800 Test Loss = 0.2037, Test Accuracy = 0.8514\n",
      "Iteration 2219: Loss = 0.1971, Accuracy = 0.8500 Test Loss = 0.2038, Test Accuracy = 0.8479\n",
      "Iteration 2220: Loss = 0.2003, Accuracy = 0.8200 Test Loss = 0.2033, Test Accuracy = 0.8559\n",
      "Iteration 2221: Loss = 0.1826, Accuracy = 0.9000 Test Loss = 0.2035, Test Accuracy = 0.8531\n",
      "Iteration 2222: Loss = 0.1788, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8517\n",
      "Iteration 2223: Loss = 0.2040, Accuracy = 0.8500 Test Loss = 0.2035, Test Accuracy = 0.8487\n",
      "Iteration 2224: Loss = 0.1820, Accuracy = 0.8800 Test Loss = 0.2032, Test Accuracy = 0.8500\n",
      "Iteration 2225: Loss = 0.1934, Accuracy = 0.8700 Test Loss = 0.2034, Test Accuracy = 0.8499\n",
      "Iteration 2226: Loss = 0.2005, Accuracy = 0.8400 Test Loss = 0.2037, Test Accuracy = 0.8494\n",
      "Iteration 2227: Loss = 0.1970, Accuracy = 0.8600 Test Loss = 0.2035, Test Accuracy = 0.8507\n",
      "Iteration 2228: Loss = 0.2048, Accuracy = 0.8200 Test Loss = 0.2030, Test Accuracy = 0.8521\n",
      "Iteration 2229: Loss = 0.2164, Accuracy = 0.8100 Test Loss = 0.2036, Test Accuracy = 0.8548\n",
      "Iteration 2230: Loss = 0.2206, Accuracy = 0.7900 Test Loss = 0.2038, Test Accuracy = 0.8512\n",
      "Iteration 2231: Loss = 0.1885, Accuracy = 0.8700 Test Loss = 0.2034, Test Accuracy = 0.8493\n",
      "Iteration 2232: Loss = 0.2195, Accuracy = 0.8300 Test Loss = 0.2038, Test Accuracy = 0.8529\n",
      "Iteration 2233: Loss = 0.2237, Accuracy = 0.8500 Test Loss = 0.2041, Test Accuracy = 0.8467\n",
      "Iteration 2234: Loss = 0.2398, Accuracy = 0.7900 Test Loss = 0.2038, Test Accuracy = 0.8521\n",
      "Iteration 2235: Loss = 0.2139, Accuracy = 0.8300 Test Loss = 0.2031, Test Accuracy = 0.8534\n",
      "Iteration 2236: Loss = 0.2021, Accuracy = 0.7900 Test Loss = 0.2032, Test Accuracy = 0.8500\n",
      "Iteration 2237: Loss = 0.2082, Accuracy = 0.8500 Test Loss = 0.2034, Test Accuracy = 0.8512\n",
      "Iteration 2238: Loss = 0.1928, Accuracy = 0.8900 Test Loss = 0.2036, Test Accuracy = 0.8515\n",
      "Iteration 2239: Loss = 0.2052, Accuracy = 0.8300 Test Loss = 0.2038, Test Accuracy = 0.8509\n",
      "Iteration 2240: Loss = 0.2243, Accuracy = 0.7800 Test Loss = 0.2034, Test Accuracy = 0.8498\n",
      "Iteration 2241: Loss = 0.1853, Accuracy = 0.8800 Test Loss = 0.2035, Test Accuracy = 0.8543\n",
      "Iteration 2242: Loss = 0.1786, Accuracy = 0.8900 Test Loss = 0.2035, Test Accuracy = 0.8530\n",
      "Iteration 2243: Loss = 0.1786, Accuracy = 0.9000 Test Loss = 0.2035, Test Accuracy = 0.8528\n",
      "Iteration 2244: Loss = 0.2208, Accuracy = 0.8000 Test Loss = 0.2037, Test Accuracy = 0.8521\n",
      "Iteration 2245: Loss = 0.1886, Accuracy = 0.8700 Test Loss = 0.2038, Test Accuracy = 0.8526\n",
      "Iteration 2246: Loss = 0.1995, Accuracy = 0.8600 Test Loss = 0.2036, Test Accuracy = 0.8558\n",
      "Iteration 2247: Loss = 0.2080, Accuracy = 0.8800 Test Loss = 0.2032, Test Accuracy = 0.8528\n",
      "Iteration 2248: Loss = 0.2040, Accuracy = 0.8400 Test Loss = 0.2030, Test Accuracy = 0.8496\n",
      "Iteration 2249: Loss = 0.2376, Accuracy = 0.8300 Test Loss = 0.2031, Test Accuracy = 0.8527\n",
      "Iteration 2250: Loss = 0.1985, Accuracy = 0.8000 Test Loss = 0.2036, Test Accuracy = 0.8495\n",
      "Iteration 2251: Loss = 0.2071, Accuracy = 0.8700 Test Loss = 0.2032, Test Accuracy = 0.8558\n",
      "Iteration 2252: Loss = 0.2154, Accuracy = 0.8100 Test Loss = 0.2041, Test Accuracy = 0.8471\n",
      "Iteration 2253: Loss = 0.2115, Accuracy = 0.8400 Test Loss = 0.2033, Test Accuracy = 0.8499\n",
      "Iteration 2254: Loss = 0.1996, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8501\n",
      "Iteration 2255: Loss = 0.2109, Accuracy = 0.8100 Test Loss = 0.2035, Test Accuracy = 0.8548\n",
      "Iteration 2256: Loss = 0.2093, Accuracy = 0.8200 Test Loss = 0.2034, Test Accuracy = 0.8538\n",
      "Iteration 2257: Loss = 0.1639, Accuracy = 0.8900 Test Loss = 0.2034, Test Accuracy = 0.8511\n",
      "Iteration 2258: Loss = 0.1808, Accuracy = 0.8700 Test Loss = 0.2038, Test Accuracy = 0.8501\n",
      "Iteration 2259: Loss = 0.2216, Accuracy = 0.7900 Test Loss = 0.2033, Test Accuracy = 0.8536\n",
      "Iteration 2260: Loss = 0.2332, Accuracy = 0.8400 Test Loss = 0.2034, Test Accuracy = 0.8527\n",
      "Iteration 2261: Loss = 0.2269, Accuracy = 0.8000 Test Loss = 0.2037, Test Accuracy = 0.8490\n",
      "Iteration 2262: Loss = 0.2069, Accuracy = 0.8400 Test Loss = 0.2034, Test Accuracy = 0.8539\n",
      "Iteration 2263: Loss = 0.1939, Accuracy = 0.8600 Test Loss = 0.2031, Test Accuracy = 0.8521\n",
      "Iteration 2264: Loss = 0.1842, Accuracy = 0.8600 Test Loss = 0.2042, Test Accuracy = 0.8516\n",
      "Iteration 2265: Loss = 0.1932, Accuracy = 0.8600 Test Loss = 0.2033, Test Accuracy = 0.8522\n",
      "Iteration 2266: Loss = 0.1943, Accuracy = 0.8400 Test Loss = 0.2033, Test Accuracy = 0.8509\n",
      "Iteration 2267: Loss = 0.1973, Accuracy = 0.8400 Test Loss = 0.2029, Test Accuracy = 0.8505\n",
      "Iteration 2268: Loss = 0.1996, Accuracy = 0.8000 Test Loss = 0.2033, Test Accuracy = 0.8476\n",
      "Iteration 2269: Loss = 0.1728, Accuracy = 0.8600 Test Loss = 0.2033, Test Accuracy = 0.8515\n",
      "Iteration 2270: Loss = 0.2008, Accuracy = 0.8700 Test Loss = 0.2032, Test Accuracy = 0.8486\n",
      "Iteration 2271: Loss = 0.2110, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8513\n",
      "Iteration 2272: Loss = 0.2250, Accuracy = 0.8200 Test Loss = 0.2033, Test Accuracy = 0.8476\n",
      "Iteration 2273: Loss = 0.1766, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8485\n",
      "Iteration 2274: Loss = 0.2266, Accuracy = 0.8200 Test Loss = 0.2035, Test Accuracy = 0.8524\n",
      "Iteration 2275: Loss = 0.1988, Accuracy = 0.8400 Test Loss = 0.2031, Test Accuracy = 0.8491\n",
      "Iteration 2276: Loss = 0.1878, Accuracy = 0.8600 Test Loss = 0.2032, Test Accuracy = 0.8554\n",
      "Iteration 2277: Loss = 0.2125, Accuracy = 0.8400 Test Loss = 0.2036, Test Accuracy = 0.8515\n",
      "Iteration 2278: Loss = 0.1993, Accuracy = 0.8900 Test Loss = 0.2035, Test Accuracy = 0.8469\n",
      "Iteration 2279: Loss = 0.2041, Accuracy = 0.8200 Test Loss = 0.2032, Test Accuracy = 0.8478\n",
      "Iteration 2280: Loss = 0.2108, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8513\n",
      "Iteration 2281: Loss = 0.1751, Accuracy = 0.9000 Test Loss = 0.2032, Test Accuracy = 0.8473\n",
      "Iteration 2282: Loss = 0.1622, Accuracy = 0.9000 Test Loss = 0.2032, Test Accuracy = 0.8538\n",
      "Iteration 2283: Loss = 0.2145, Accuracy = 0.7900 Test Loss = 0.2032, Test Accuracy = 0.8531\n",
      "Iteration 2284: Loss = 0.1934, Accuracy = 0.8500 Test Loss = 0.2034, Test Accuracy = 0.8500\n",
      "Iteration 2285: Loss = 0.2150, Accuracy = 0.8400 Test Loss = 0.2034, Test Accuracy = 0.8529\n",
      "Iteration 2286: Loss = 0.2153, Accuracy = 0.8900 Test Loss = 0.2032, Test Accuracy = 0.8504\n",
      "Iteration 2287: Loss = 0.1896, Accuracy = 0.8800 Test Loss = 0.2031, Test Accuracy = 0.8495\n",
      "Iteration 2288: Loss = 0.2192, Accuracy = 0.8100 Test Loss = 0.2035, Test Accuracy = 0.8510\n",
      "Iteration 2289: Loss = 0.1877, Accuracy = 0.8200 Test Loss = 0.2031, Test Accuracy = 0.8520\n",
      "Iteration 2290: Loss = 0.1949, Accuracy = 0.8600 Test Loss = 0.2033, Test Accuracy = 0.8510\n",
      "Iteration 2291: Loss = 0.1889, Accuracy = 0.8600 Test Loss = 0.2032, Test Accuracy = 0.8490\n",
      "Iteration 2292: Loss = 0.2087, Accuracy = 0.8200 Test Loss = 0.2030, Test Accuracy = 0.8544\n",
      "Iteration 2293: Loss = 0.1934, Accuracy = 0.8600 Test Loss = 0.2041, Test Accuracy = 0.8460\n",
      "Iteration 2294: Loss = 0.2501, Accuracy = 0.7900 Test Loss = 0.2037, Test Accuracy = 0.8520\n",
      "Iteration 2295: Loss = 0.1808, Accuracy = 0.9000 Test Loss = 0.2031, Test Accuracy = 0.8493\n",
      "Iteration 2296: Loss = 0.2120, Accuracy = 0.8700 Test Loss = 0.2035, Test Accuracy = 0.8526\n",
      "Iteration 2297: Loss = 0.1995, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8567\n",
      "Iteration 2298: Loss = 0.2177, Accuracy = 0.8400 Test Loss = 0.2031, Test Accuracy = 0.8521\n",
      "Iteration 2299: Loss = 0.1806, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8488\n",
      "Iteration 2300: Loss = 0.1992, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8500\n",
      "Iteration 2301: Loss = 0.1718, Accuracy = 0.9100 Test Loss = 0.2035, Test Accuracy = 0.8467\n",
      "Iteration 2302: Loss = 0.2165, Accuracy = 0.8200 Test Loss = 0.2031, Test Accuracy = 0.8510\n",
      "Iteration 2303: Loss = 0.2115, Accuracy = 0.8200 Test Loss = 0.2033, Test Accuracy = 0.8485\n",
      "Iteration 2304: Loss = 0.1852, Accuracy = 0.8900 Test Loss = 0.2036, Test Accuracy = 0.8532\n",
      "Iteration 2305: Loss = 0.1916, Accuracy = 0.8200 Test Loss = 0.2032, Test Accuracy = 0.8520\n",
      "Iteration 2306: Loss = 0.2063, Accuracy = 0.8200 Test Loss = 0.2032, Test Accuracy = 0.8519\n",
      "Iteration 2307: Loss = 0.2394, Accuracy = 0.7400 Test Loss = 0.2032, Test Accuracy = 0.8532\n",
      "Iteration 2308: Loss = 0.1916, Accuracy = 0.8400 Test Loss = 0.2030, Test Accuracy = 0.8488\n",
      "Iteration 2309: Loss = 0.2138, Accuracy = 0.8200 Test Loss = 0.2030, Test Accuracy = 0.8538\n",
      "Iteration 2310: Loss = 0.2020, Accuracy = 0.8300 Test Loss = 0.2030, Test Accuracy = 0.8525\n",
      "Iteration 2311: Loss = 0.1932, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8522\n",
      "Iteration 2312: Loss = 0.1916, Accuracy = 0.9000 Test Loss = 0.2034, Test Accuracy = 0.8533\n",
      "Iteration 2313: Loss = 0.1946, Accuracy = 0.8900 Test Loss = 0.2032, Test Accuracy = 0.8501\n",
      "Iteration 2314: Loss = 0.1930, Accuracy = 0.8800 Test Loss = 0.2034, Test Accuracy = 0.8510\n",
      "Iteration 2315: Loss = 0.1834, Accuracy = 0.8700 Test Loss = 0.2030, Test Accuracy = 0.8527\n",
      "Iteration 2316: Loss = 0.1996, Accuracy = 0.8500 Test Loss = 0.2034, Test Accuracy = 0.8531\n",
      "Iteration 2317: Loss = 0.1539, Accuracy = 0.9000 Test Loss = 0.2038, Test Accuracy = 0.8451\n",
      "Iteration 2318: Loss = 0.1807, Accuracy = 0.9000 Test Loss = 0.2032, Test Accuracy = 0.8535\n",
      "Iteration 2319: Loss = 0.2056, Accuracy = 0.8300 Test Loss = 0.2038, Test Accuracy = 0.8480\n",
      "Iteration 2320: Loss = 0.1880, Accuracy = 0.8700 Test Loss = 0.2040, Test Accuracy = 0.8496\n",
      "Iteration 2321: Loss = 0.1924, Accuracy = 0.8900 Test Loss = 0.2029, Test Accuracy = 0.8511\n",
      "Iteration 2322: Loss = 0.2012, Accuracy = 0.8500 Test Loss = 0.2030, Test Accuracy = 0.8498\n",
      "Iteration 2323: Loss = 0.2055, Accuracy = 0.8700 Test Loss = 0.2031, Test Accuracy = 0.8509\n",
      "Iteration 2324: Loss = 0.2056, Accuracy = 0.8100 Test Loss = 0.2030, Test Accuracy = 0.8544\n",
      "Iteration 2325: Loss = 0.2069, Accuracy = 0.8100 Test Loss = 0.2033, Test Accuracy = 0.8460\n",
      "Iteration 2326: Loss = 0.2120, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8516\n",
      "Iteration 2327: Loss = 0.1816, Accuracy = 0.8700 Test Loss = 0.2039, Test Accuracy = 0.8550\n",
      "Iteration 2328: Loss = 0.2234, Accuracy = 0.9000 Test Loss = 0.2035, Test Accuracy = 0.8505\n",
      "Iteration 2329: Loss = 0.2142, Accuracy = 0.8100 Test Loss = 0.2035, Test Accuracy = 0.8474\n",
      "Iteration 2330: Loss = 0.2424, Accuracy = 0.8000 Test Loss = 0.2029, Test Accuracy = 0.8530\n",
      "Iteration 2331: Loss = 0.2223, Accuracy = 0.7900 Test Loss = 0.2043, Test Accuracy = 0.8538\n",
      "Iteration 2332: Loss = 0.2237, Accuracy = 0.7600 Test Loss = 0.2038, Test Accuracy = 0.8551\n",
      "Iteration 2333: Loss = 0.1892, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8531\n",
      "Iteration 2334: Loss = 0.1730, Accuracy = 0.8800 Test Loss = 0.2029, Test Accuracy = 0.8515\n",
      "Iteration 2335: Loss = 0.2002, Accuracy = 0.8700 Test Loss = 0.2031, Test Accuracy = 0.8500\n",
      "Iteration 2336: Loss = 0.1964, Accuracy = 0.8500 Test Loss = 0.2036, Test Accuracy = 0.8516\n",
      "Iteration 2337: Loss = 0.1985, Accuracy = 0.8200 Test Loss = 0.2034, Test Accuracy = 0.8527\n",
      "Iteration 2338: Loss = 0.1831, Accuracy = 0.8700 Test Loss = 0.2030, Test Accuracy = 0.8534\n",
      "Iteration 2339: Loss = 0.1822, Accuracy = 0.8900 Test Loss = 0.2036, Test Accuracy = 0.8452\n",
      "Iteration 2340: Loss = 0.1590, Accuracy = 0.9400 Test Loss = 0.2036, Test Accuracy = 0.8497\n",
      "Iteration 2341: Loss = 0.2074, Accuracy = 0.8400 Test Loss = 0.2036, Test Accuracy = 0.8543\n",
      "Iteration 2342: Loss = 0.2202, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8488\n",
      "Iteration 2343: Loss = 0.2019, Accuracy = 0.8600 Test Loss = 0.2031, Test Accuracy = 0.8497\n",
      "Iteration 2344: Loss = 0.2161, Accuracy = 0.8000 Test Loss = 0.2035, Test Accuracy = 0.8518\n",
      "Iteration 2345: Loss = 0.2127, Accuracy = 0.8000 Test Loss = 0.2033, Test Accuracy = 0.8502\n",
      "Iteration 2346: Loss = 0.2064, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8523\n",
      "Iteration 2347: Loss = 0.1758, Accuracy = 0.9100 Test Loss = 0.2029, Test Accuracy = 0.8491\n",
      "Iteration 2348: Loss = 0.1863, Accuracy = 0.8500 Test Loss = 0.2029, Test Accuracy = 0.8510\n",
      "Iteration 2349: Loss = 0.2040, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8527\n",
      "Iteration 2350: Loss = 0.1866, Accuracy = 0.8700 Test Loss = 0.2030, Test Accuracy = 0.8536\n",
      "Iteration 2351: Loss = 0.2048, Accuracy = 0.8200 Test Loss = 0.2031, Test Accuracy = 0.8497\n",
      "Iteration 2352: Loss = 0.2040, Accuracy = 0.8300 Test Loss = 0.2035, Test Accuracy = 0.8501\n",
      "Iteration 2353: Loss = 0.2054, Accuracy = 0.8300 Test Loss = 0.2031, Test Accuracy = 0.8532\n",
      "Iteration 2354: Loss = 0.1734, Accuracy = 0.8700 Test Loss = 0.2034, Test Accuracy = 0.8505\n",
      "Iteration 2355: Loss = 0.2049, Accuracy = 0.8300 Test Loss = 0.2033, Test Accuracy = 0.8502\n",
      "Iteration 2356: Loss = 0.1669, Accuracy = 0.8900 Test Loss = 0.2034, Test Accuracy = 0.8560\n",
      "Iteration 2357: Loss = 0.1841, Accuracy = 0.9100 Test Loss = 0.2030, Test Accuracy = 0.8540\n",
      "Iteration 2358: Loss = 0.2019, Accuracy = 0.8600 Test Loss = 0.2031, Test Accuracy = 0.8512\n",
      "Iteration 2359: Loss = 0.2183, Accuracy = 0.7500 Test Loss = 0.2031, Test Accuracy = 0.8516\n",
      "Iteration 2360: Loss = 0.1882, Accuracy = 0.8700 Test Loss = 0.2031, Test Accuracy = 0.8529\n",
      "Iteration 2361: Loss = 0.2309, Accuracy = 0.8700 Test Loss = 0.2030, Test Accuracy = 0.8504\n",
      "Iteration 2362: Loss = 0.1950, Accuracy = 0.8600 Test Loss = 0.2035, Test Accuracy = 0.8513\n",
      "Iteration 2363: Loss = 0.1951, Accuracy = 0.8500 Test Loss = 0.2036, Test Accuracy = 0.8514\n",
      "Iteration 2364: Loss = 0.2282, Accuracy = 0.8500 Test Loss = 0.2035, Test Accuracy = 0.8529\n",
      "Iteration 2365: Loss = 0.2114, Accuracy = 0.8200 Test Loss = 0.2028, Test Accuracy = 0.8520\n",
      "Iteration 2366: Loss = 0.1739, Accuracy = 0.9000 Test Loss = 0.2029, Test Accuracy = 0.8501\n",
      "Iteration 2367: Loss = 0.2005, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8549\n",
      "Iteration 2368: Loss = 0.2100, Accuracy = 0.8400 Test Loss = 0.2030, Test Accuracy = 0.8502\n",
      "Iteration 2369: Loss = 0.2061, Accuracy = 0.8100 Test Loss = 0.2031, Test Accuracy = 0.8495\n",
      "Iteration 2370: Loss = 0.2240, Accuracy = 0.8200 Test Loss = 0.2031, Test Accuracy = 0.8523\n",
      "Iteration 2371: Loss = 0.1935, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8480\n",
      "Iteration 2372: Loss = 0.2085, Accuracy = 0.7900 Test Loss = 0.2030, Test Accuracy = 0.8501\n",
      "Iteration 2373: Loss = 0.1980, Accuracy = 0.8200 Test Loss = 0.2028, Test Accuracy = 0.8529\n",
      "Iteration 2374: Loss = 0.1838, Accuracy = 0.9000 Test Loss = 0.2040, Test Accuracy = 0.8467\n",
      "Iteration 2375: Loss = 0.1964, Accuracy = 0.8200 Test Loss = 0.2030, Test Accuracy = 0.8526\n",
      "Iteration 2376: Loss = 0.1927, Accuracy = 0.8600 Test Loss = 0.2031, Test Accuracy = 0.8485\n",
      "Iteration 2377: Loss = 0.2171, Accuracy = 0.8200 Test Loss = 0.2030, Test Accuracy = 0.8481\n",
      "Iteration 2378: Loss = 0.2028, Accuracy = 0.8100 Test Loss = 0.2033, Test Accuracy = 0.8505\n",
      "Iteration 2379: Loss = 0.1983, Accuracy = 0.8600 Test Loss = 0.2031, Test Accuracy = 0.8507\n",
      "Iteration 2380: Loss = 0.2096, Accuracy = 0.8300 Test Loss = 0.2028, Test Accuracy = 0.8543\n",
      "Iteration 2381: Loss = 0.1780, Accuracy = 0.8900 Test Loss = 0.2039, Test Accuracy = 0.8462\n",
      "Iteration 2382: Loss = 0.2208, Accuracy = 0.7900 Test Loss = 0.2034, Test Accuracy = 0.8552\n",
      "Iteration 2383: Loss = 0.2035, Accuracy = 0.8700 Test Loss = 0.2031, Test Accuracy = 0.8490\n",
      "Iteration 2384: Loss = 0.2108, Accuracy = 0.8200 Test Loss = 0.2030, Test Accuracy = 0.8541\n",
      "Iteration 2385: Loss = 0.1876, Accuracy = 0.8900 Test Loss = 0.2032, Test Accuracy = 0.8504\n",
      "Iteration 2386: Loss = 0.1988, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8503\n",
      "Iteration 2387: Loss = 0.1956, Accuracy = 0.8500 Test Loss = 0.2026, Test Accuracy = 0.8508\n",
      "Iteration 2388: Loss = 0.2201, Accuracy = 0.8400 Test Loss = 0.2030, Test Accuracy = 0.8518\n",
      "Iteration 2389: Loss = 0.2140, Accuracy = 0.8400 Test Loss = 0.2029, Test Accuracy = 0.8503\n",
      "Iteration 2390: Loss = 0.2123, Accuracy = 0.8300 Test Loss = 0.2035, Test Accuracy = 0.8493\n",
      "Iteration 2391: Loss = 0.2123, Accuracy = 0.8100 Test Loss = 0.2029, Test Accuracy = 0.8506\n",
      "Iteration 2392: Loss = 0.1743, Accuracy = 0.8800 Test Loss = 0.2032, Test Accuracy = 0.8510\n",
      "Iteration 2393: Loss = 0.1960, Accuracy = 0.8700 Test Loss = 0.2029, Test Accuracy = 0.8495\n",
      "Iteration 2394: Loss = 0.1902, Accuracy = 0.8200 Test Loss = 0.2033, Test Accuracy = 0.8482\n",
      "Iteration 2395: Loss = 0.2242, Accuracy = 0.8000 Test Loss = 0.2029, Test Accuracy = 0.8514\n",
      "Iteration 2396: Loss = 0.2026, Accuracy = 0.8300 Test Loss = 0.2027, Test Accuracy = 0.8547\n",
      "Iteration 2397: Loss = 0.1807, Accuracy = 0.8900 Test Loss = 0.2033, Test Accuracy = 0.8532\n",
      "Iteration 2398: Loss = 0.2048, Accuracy = 0.8900 Test Loss = 0.2030, Test Accuracy = 0.8511\n",
      "Iteration 2399: Loss = 0.1876, Accuracy = 0.8600 Test Loss = 0.2030, Test Accuracy = 0.8538\n",
      "Iteration 2400: Loss = 0.1813, Accuracy = 0.8800 Test Loss = 0.2031, Test Accuracy = 0.8502\n",
      "Iteration 2401: Loss = 0.1852, Accuracy = 0.8600 Test Loss = 0.2036, Test Accuracy = 0.8502\n",
      "Iteration 2402: Loss = 0.1874, Accuracy = 0.8900 Test Loss = 0.2028, Test Accuracy = 0.8507\n",
      "Iteration 2403: Loss = 0.2177, Accuracy = 0.8300 Test Loss = 0.2033, Test Accuracy = 0.8523\n",
      "Iteration 2404: Loss = 0.1781, Accuracy = 0.9000 Test Loss = 0.2030, Test Accuracy = 0.8525\n",
      "Iteration 2405: Loss = 0.2168, Accuracy = 0.8200 Test Loss = 0.2027, Test Accuracy = 0.8542\n",
      "Iteration 2406: Loss = 0.2216, Accuracy = 0.8100 Test Loss = 0.2030, Test Accuracy = 0.8510\n",
      "Iteration 2407: Loss = 0.2072, Accuracy = 0.8500 Test Loss = 0.2034, Test Accuracy = 0.8513\n",
      "Iteration 2408: Loss = 0.1949, Accuracy = 0.8900 Test Loss = 0.2034, Test Accuracy = 0.8532\n",
      "Iteration 2409: Loss = 0.2039, Accuracy = 0.8000 Test Loss = 0.2029, Test Accuracy = 0.8515\n",
      "Iteration 2410: Loss = 0.2079, Accuracy = 0.8600 Test Loss = 0.2029, Test Accuracy = 0.8518\n",
      "Iteration 2411: Loss = 0.2106, Accuracy = 0.8400 Test Loss = 0.2026, Test Accuracy = 0.8529\n",
      "Iteration 2412: Loss = 0.1734, Accuracy = 0.9200 Test Loss = 0.2026, Test Accuracy = 0.8503\n",
      "Iteration 2413: Loss = 0.2100, Accuracy = 0.8600 Test Loss = 0.2028, Test Accuracy = 0.8559\n",
      "Iteration 2414: Loss = 0.1996, Accuracy = 0.8500 Test Loss = 0.2029, Test Accuracy = 0.8536\n",
      "Iteration 2415: Loss = 0.1863, Accuracy = 0.8700 Test Loss = 0.2035, Test Accuracy = 0.8504\n",
      "Iteration 2416: Loss = 0.1884, Accuracy = 0.8900 Test Loss = 0.2030, Test Accuracy = 0.8492\n",
      "Iteration 2417: Loss = 0.1748, Accuracy = 0.8800 Test Loss = 0.2029, Test Accuracy = 0.8535\n",
      "Iteration 2418: Loss = 0.2185, Accuracy = 0.7900 Test Loss = 0.2032, Test Accuracy = 0.8491\n",
      "Iteration 2419: Loss = 0.1753, Accuracy = 0.8700 Test Loss = 0.2029, Test Accuracy = 0.8552\n",
      "Iteration 2420: Loss = 0.1977, Accuracy = 0.8500 Test Loss = 0.2030, Test Accuracy = 0.8523\n",
      "Iteration 2421: Loss = 0.1939, Accuracy = 0.8400 Test Loss = 0.2027, Test Accuracy = 0.8509\n",
      "Iteration 2422: Loss = 0.2088, Accuracy = 0.8500 Test Loss = 0.2032, Test Accuracy = 0.8471\n",
      "Iteration 2423: Loss = 0.1981, Accuracy = 0.8400 Test Loss = 0.2030, Test Accuracy = 0.8526\n",
      "Iteration 2424: Loss = 0.2211, Accuracy = 0.8300 Test Loss = 0.2031, Test Accuracy = 0.8508\n",
      "Iteration 2425: Loss = 0.2007, Accuracy = 0.8100 Test Loss = 0.2027, Test Accuracy = 0.8489\n",
      "Iteration 2426: Loss = 0.1852, Accuracy = 0.8300 Test Loss = 0.2029, Test Accuracy = 0.8504\n",
      "Iteration 2427: Loss = 0.2219, Accuracy = 0.7900 Test Loss = 0.2027, Test Accuracy = 0.8547\n",
      "Iteration 2428: Loss = 0.2073, Accuracy = 0.8800 Test Loss = 0.2037, Test Accuracy = 0.8555\n",
      "Iteration 2429: Loss = 0.2017, Accuracy = 0.8600 Test Loss = 0.2031, Test Accuracy = 0.8504\n",
      "Iteration 2430: Loss = 0.2153, Accuracy = 0.8700 Test Loss = 0.2030, Test Accuracy = 0.8508\n",
      "Iteration 2431: Loss = 0.2048, Accuracy = 0.8600 Test Loss = 0.2026, Test Accuracy = 0.8522\n",
      "Iteration 2432: Loss = 0.2066, Accuracy = 0.8500 Test Loss = 0.2032, Test Accuracy = 0.8519\n",
      "Iteration 2433: Loss = 0.1821, Accuracy = 0.8800 Test Loss = 0.2030, Test Accuracy = 0.8577\n",
      "Iteration 2434: Loss = 0.2033, Accuracy = 0.8400 Test Loss = 0.2035, Test Accuracy = 0.8520\n",
      "Iteration 2435: Loss = 0.1760, Accuracy = 0.8900 Test Loss = 0.2027, Test Accuracy = 0.8523\n",
      "Iteration 2436: Loss = 0.1906, Accuracy = 0.8700 Test Loss = 0.2033, Test Accuracy = 0.8482\n",
      "Iteration 2437: Loss = 0.2054, Accuracy = 0.8900 Test Loss = 0.2025, Test Accuracy = 0.8540\n",
      "Iteration 2438: Loss = 0.1983, Accuracy = 0.8300 Test Loss = 0.2029, Test Accuracy = 0.8509\n",
      "Iteration 2439: Loss = 0.1966, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8488\n",
      "Iteration 2440: Loss = 0.2240, Accuracy = 0.7900 Test Loss = 0.2034, Test Accuracy = 0.8516\n",
      "Iteration 2441: Loss = 0.1881, Accuracy = 0.8800 Test Loss = 0.2028, Test Accuracy = 0.8503\n",
      "Iteration 2442: Loss = 0.1880, Accuracy = 0.8600 Test Loss = 0.2037, Test Accuracy = 0.8484\n",
      "Iteration 2443: Loss = 0.1723, Accuracy = 0.9300 Test Loss = 0.2038, Test Accuracy = 0.8500\n",
      "Iteration 2444: Loss = 0.1830, Accuracy = 0.9000 Test Loss = 0.2029, Test Accuracy = 0.8531\n",
      "Iteration 2445: Loss = 0.1830, Accuracy = 0.8900 Test Loss = 0.2031, Test Accuracy = 0.8534\n",
      "Iteration 2446: Loss = 0.2010, Accuracy = 0.8600 Test Loss = 0.2029, Test Accuracy = 0.8512\n",
      "Iteration 2447: Loss = 0.1849, Accuracy = 0.8700 Test Loss = 0.2034, Test Accuracy = 0.8513\n",
      "Iteration 2448: Loss = 0.2122, Accuracy = 0.8000 Test Loss = 0.2044, Test Accuracy = 0.8467\n",
      "Iteration 2449: Loss = 0.2188, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8500\n",
      "Iteration 2450: Loss = 0.2019, Accuracy = 0.8500 Test Loss = 0.2033, Test Accuracy = 0.8529\n",
      "Iteration 2451: Loss = 0.2225, Accuracy = 0.8500 Test Loss = 0.2035, Test Accuracy = 0.8510\n",
      "Iteration 2452: Loss = 0.1928, Accuracy = 0.8800 Test Loss = 0.2026, Test Accuracy = 0.8515\n",
      "Iteration 2453: Loss = 0.2091, Accuracy = 0.8000 Test Loss = 0.2032, Test Accuracy = 0.8512\n",
      "Iteration 2454: Loss = 0.1984, Accuracy = 0.8200 Test Loss = 0.2028, Test Accuracy = 0.8510\n",
      "Iteration 2455: Loss = 0.2052, Accuracy = 0.8900 Test Loss = 0.2028, Test Accuracy = 0.8508\n",
      "Iteration 2456: Loss = 0.1926, Accuracy = 0.8900 Test Loss = 0.2034, Test Accuracy = 0.8491\n",
      "Iteration 2457: Loss = 0.1754, Accuracy = 0.8600 Test Loss = 0.2032, Test Accuracy = 0.8494\n",
      "Iteration 2458: Loss = 0.1795, Accuracy = 0.9100 Test Loss = 0.2026, Test Accuracy = 0.8510\n",
      "Iteration 2459: Loss = 0.2005, Accuracy = 0.8700 Test Loss = 0.2037, Test Accuracy = 0.8454\n",
      "Iteration 2460: Loss = 0.1916, Accuracy = 0.9100 Test Loss = 0.2029, Test Accuracy = 0.8565\n",
      "Iteration 2461: Loss = 0.2164, Accuracy = 0.8400 Test Loss = 0.2025, Test Accuracy = 0.8527\n",
      "Iteration 2462: Loss = 0.2039, Accuracy = 0.8500 Test Loss = 0.2027, Test Accuracy = 0.8531\n",
      "Iteration 2463: Loss = 0.2018, Accuracy = 0.8500 Test Loss = 0.2026, Test Accuracy = 0.8513\n",
      "Iteration 2464: Loss = 0.2186, Accuracy = 0.7900 Test Loss = 0.2027, Test Accuracy = 0.8511\n",
      "Iteration 2465: Loss = 0.1994, Accuracy = 0.8800 Test Loss = 0.2027, Test Accuracy = 0.8519\n",
      "Iteration 2466: Loss = 0.2064, Accuracy = 0.8300 Test Loss = 0.2028, Test Accuracy = 0.8507\n",
      "Iteration 2467: Loss = 0.1842, Accuracy = 0.8900 Test Loss = 0.2036, Test Accuracy = 0.8514\n",
      "Iteration 2468: Loss = 0.1854, Accuracy = 0.8900 Test Loss = 0.2026, Test Accuracy = 0.8497\n",
      "Iteration 2469: Loss = 0.2041, Accuracy = 0.8500 Test Loss = 0.2034, Test Accuracy = 0.8472\n",
      "Iteration 2470: Loss = 0.2181, Accuracy = 0.8300 Test Loss = 0.2027, Test Accuracy = 0.8554\n",
      "Iteration 2471: Loss = 0.2062, Accuracy = 0.8700 Test Loss = 0.2035, Test Accuracy = 0.8508\n",
      "Iteration 2472: Loss = 0.2225, Accuracy = 0.8200 Test Loss = 0.2027, Test Accuracy = 0.8514\n",
      "Iteration 2473: Loss = 0.2026, Accuracy = 0.8000 Test Loss = 0.2032, Test Accuracy = 0.8529\n",
      "Iteration 2474: Loss = 0.2120, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8527\n",
      "Iteration 2475: Loss = 0.2116, Accuracy = 0.8600 Test Loss = 0.2032, Test Accuracy = 0.8515\n",
      "Iteration 2476: Loss = 0.1496, Accuracy = 0.9100 Test Loss = 0.2031, Test Accuracy = 0.8500\n",
      "Iteration 2477: Loss = 0.2006, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8496\n",
      "Iteration 2478: Loss = 0.2125, Accuracy = 0.8500 Test Loss = 0.2031, Test Accuracy = 0.8552\n",
      "Iteration 2479: Loss = 0.1999, Accuracy = 0.8800 Test Loss = 0.2026, Test Accuracy = 0.8516\n",
      "Iteration 2480: Loss = 0.2100, Accuracy = 0.8800 Test Loss = 0.2026, Test Accuracy = 0.8494\n",
      "Iteration 2481: Loss = 0.2047, Accuracy = 0.8400 Test Loss = 0.2033, Test Accuracy = 0.8453\n",
      "Iteration 2482: Loss = 0.1837, Accuracy = 0.8600 Test Loss = 0.2027, Test Accuracy = 0.8526\n",
      "Iteration 2483: Loss = 0.1919, Accuracy = 0.9000 Test Loss = 0.2028, Test Accuracy = 0.8516\n",
      "Iteration 2484: Loss = 0.2266, Accuracy = 0.7900 Test Loss = 0.2025, Test Accuracy = 0.8546\n",
      "Iteration 2485: Loss = 0.1975, Accuracy = 0.9000 Test Loss = 0.2030, Test Accuracy = 0.8529\n",
      "Iteration 2486: Loss = 0.2148, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8522\n",
      "Iteration 2487: Loss = 0.1662, Accuracy = 0.9100 Test Loss = 0.2027, Test Accuracy = 0.8503\n",
      "Iteration 2488: Loss = 0.1850, Accuracy = 0.8800 Test Loss = 0.2027, Test Accuracy = 0.8478\n",
      "Iteration 2489: Loss = 0.1904, Accuracy = 0.8900 Test Loss = 0.2026, Test Accuracy = 0.8491\n",
      "Iteration 2490: Loss = 0.2113, Accuracy = 0.8200 Test Loss = 0.2032, Test Accuracy = 0.8513\n",
      "Iteration 2491: Loss = 0.1828, Accuracy = 0.9000 Test Loss = 0.2024, Test Accuracy = 0.8522\n",
      "Iteration 2492: Loss = 0.2119, Accuracy = 0.8200 Test Loss = 0.2028, Test Accuracy = 0.8516\n",
      "Iteration 2493: Loss = 0.1985, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8540\n",
      "Iteration 2494: Loss = 0.1952, Accuracy = 0.8400 Test Loss = 0.2028, Test Accuracy = 0.8526\n",
      "Iteration 2495: Loss = 0.1962, Accuracy = 0.8800 Test Loss = 0.2027, Test Accuracy = 0.8527\n",
      "Iteration 2496: Loss = 0.1918, Accuracy = 0.8500 Test Loss = 0.2027, Test Accuracy = 0.8526\n",
      "Iteration 2497: Loss = 0.2049, Accuracy = 0.8400 Test Loss = 0.2028, Test Accuracy = 0.8545\n",
      "Iteration 2498: Loss = 0.1978, Accuracy = 0.8800 Test Loss = 0.2035, Test Accuracy = 0.8470\n",
      "Iteration 2499: Loss = 0.1779, Accuracy = 0.9000 Test Loss = 0.2032, Test Accuracy = 0.8503\n",
      "Iteration 2500: Loss = 0.1867, Accuracy = 0.8800 Test Loss = 0.2023, Test Accuracy = 0.8508\n",
      "Iteration 2501: Loss = 0.1841, Accuracy = 0.8800 Test Loss = 0.2029, Test Accuracy = 0.8466\n",
      "Iteration 2502: Loss = 0.2098, Accuracy = 0.8200 Test Loss = 0.2024, Test Accuracy = 0.8541\n",
      "Iteration 2503: Loss = 0.2060, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8524\n",
      "Iteration 2504: Loss = 0.1937, Accuracy = 0.8600 Test Loss = 0.2026, Test Accuracy = 0.8527\n",
      "Iteration 2505: Loss = 0.1834, Accuracy = 0.9200 Test Loss = 0.2030, Test Accuracy = 0.8527\n",
      "Iteration 2506: Loss = 0.2214, Accuracy = 0.8300 Test Loss = 0.2030, Test Accuracy = 0.8553\n",
      "Iteration 2507: Loss = 0.2073, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8520\n",
      "Iteration 2508: Loss = 0.2272, Accuracy = 0.7900 Test Loss = 0.2025, Test Accuracy = 0.8530\n",
      "Iteration 2509: Loss = 0.1664, Accuracy = 0.9000 Test Loss = 0.2026, Test Accuracy = 0.8499\n",
      "Iteration 2510: Loss = 0.2238, Accuracy = 0.8000 Test Loss = 0.2025, Test Accuracy = 0.8506\n",
      "Iteration 2511: Loss = 0.2021, Accuracy = 0.8700 Test Loss = 0.2032, Test Accuracy = 0.8543\n",
      "Iteration 2512: Loss = 0.1965, Accuracy = 0.8400 Test Loss = 0.2024, Test Accuracy = 0.8531\n",
      "Iteration 2513: Loss = 0.1977, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8497\n",
      "Iteration 2514: Loss = 0.2252, Accuracy = 0.8100 Test Loss = 0.2029, Test Accuracy = 0.8513\n",
      "Iteration 2515: Loss = 0.1966, Accuracy = 0.8600 Test Loss = 0.2029, Test Accuracy = 0.8541\n",
      "Iteration 2516: Loss = 0.2207, Accuracy = 0.8200 Test Loss = 0.2024, Test Accuracy = 0.8521\n",
      "Iteration 2517: Loss = 0.1867, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8499\n",
      "Iteration 2518: Loss = 0.2400, Accuracy = 0.8500 Test Loss = 0.2026, Test Accuracy = 0.8519\n",
      "Iteration 2519: Loss = 0.1894, Accuracy = 0.8700 Test Loss = 0.2031, Test Accuracy = 0.8555\n",
      "Iteration 2520: Loss = 0.1904, Accuracy = 0.8400 Test Loss = 0.2025, Test Accuracy = 0.8471\n",
      "Iteration 2521: Loss = 0.2151, Accuracy = 0.8200 Test Loss = 0.2026, Test Accuracy = 0.8504\n",
      "Iteration 2522: Loss = 0.1909, Accuracy = 0.8300 Test Loss = 0.2027, Test Accuracy = 0.8533\n",
      "Iteration 2523: Loss = 0.2035, Accuracy = 0.8500 Test Loss = 0.2032, Test Accuracy = 0.8507\n",
      "Iteration 2524: Loss = 0.2019, Accuracy = 0.8500 Test Loss = 0.2029, Test Accuracy = 0.8488\n",
      "Iteration 2525: Loss = 0.2154, Accuracy = 0.8700 Test Loss = 0.2032, Test Accuracy = 0.8534\n",
      "Iteration 2526: Loss = 0.1901, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8542\n",
      "Iteration 2527: Loss = 0.1966, Accuracy = 0.8500 Test Loss = 0.2026, Test Accuracy = 0.8493\n",
      "Iteration 2528: Loss = 0.1974, Accuracy = 0.8400 Test Loss = 0.2030, Test Accuracy = 0.8505\n",
      "Iteration 2529: Loss = 0.2195, Accuracy = 0.8400 Test Loss = 0.2030, Test Accuracy = 0.8521\n",
      "Iteration 2530: Loss = 0.2188, Accuracy = 0.7800 Test Loss = 0.2034, Test Accuracy = 0.8534\n",
      "Iteration 2531: Loss = 0.1739, Accuracy = 0.8700 Test Loss = 0.2036, Test Accuracy = 0.8497\n",
      "Iteration 2532: Loss = 0.1911, Accuracy = 0.9500 Test Loss = 0.2032, Test Accuracy = 0.8470\n",
      "Iteration 2533: Loss = 0.1969, Accuracy = 0.8600 Test Loss = 0.2027, Test Accuracy = 0.8487\n",
      "Iteration 2534: Loss = 0.1923, Accuracy = 0.8900 Test Loss = 0.2027, Test Accuracy = 0.8504\n",
      "Iteration 2535: Loss = 0.1986, Accuracy = 0.8500 Test Loss = 0.2031, Test Accuracy = 0.8528\n",
      "Iteration 2536: Loss = 0.1993, Accuracy = 0.8000 Test Loss = 0.2028, Test Accuracy = 0.8504\n",
      "Iteration 2537: Loss = 0.1899, Accuracy = 0.8700 Test Loss = 0.2028, Test Accuracy = 0.8517\n",
      "Iteration 2538: Loss = 0.2008, Accuracy = 0.8400 Test Loss = 0.2026, Test Accuracy = 0.8539\n",
      "Iteration 2539: Loss = 0.2060, Accuracy = 0.8600 Test Loss = 0.2034, Test Accuracy = 0.8448\n",
      "Iteration 2540: Loss = 0.2033, Accuracy = 0.8300 Test Loss = 0.2023, Test Accuracy = 0.8529\n",
      "Iteration 2541: Loss = 0.2070, Accuracy = 0.8400 Test Loss = 0.2024, Test Accuracy = 0.8521\n",
      "Iteration 2542: Loss = 0.1939, Accuracy = 0.8400 Test Loss = 0.2029, Test Accuracy = 0.8530\n",
      "Iteration 2543: Loss = 0.1932, Accuracy = 0.8200 Test Loss = 0.2022, Test Accuracy = 0.8521\n",
      "Iteration 2544: Loss = 0.1969, Accuracy = 0.8400 Test Loss = 0.2026, Test Accuracy = 0.8496\n",
      "Iteration 2545: Loss = 0.2386, Accuracy = 0.7900 Test Loss = 0.2027, Test Accuracy = 0.8524\n",
      "Iteration 2546: Loss = 0.1989, Accuracy = 0.8600 Test Loss = 0.2027, Test Accuracy = 0.8487\n",
      "Iteration 2547: Loss = 0.1926, Accuracy = 0.8300 Test Loss = 0.2024, Test Accuracy = 0.8525\n",
      "Iteration 2548: Loss = 0.2052, Accuracy = 0.8400 Test Loss = 0.2037, Test Accuracy = 0.8455\n",
      "Iteration 2549: Loss = 0.1957, Accuracy = 0.8200 Test Loss = 0.2033, Test Accuracy = 0.8578\n",
      "Iteration 2550: Loss = 0.1883, Accuracy = 0.8700 Test Loss = 0.2028, Test Accuracy = 0.8531\n",
      "Iteration 2551: Loss = 0.1731, Accuracy = 0.9000 Test Loss = 0.2029, Test Accuracy = 0.8519\n",
      "Iteration 2552: Loss = 0.2036, Accuracy = 0.8300 Test Loss = 0.2024, Test Accuracy = 0.8552\n",
      "Iteration 2553: Loss = 0.2088, Accuracy = 0.8200 Test Loss = 0.2024, Test Accuracy = 0.8538\n",
      "Iteration 2554: Loss = 0.2054, Accuracy = 0.8900 Test Loss = 0.2030, Test Accuracy = 0.8504\n",
      "Iteration 2555: Loss = 0.1923, Accuracy = 0.8700 Test Loss = 0.2026, Test Accuracy = 0.8509\n",
      "Iteration 2556: Loss = 0.2120, Accuracy = 0.8100 Test Loss = 0.2030, Test Accuracy = 0.8500\n",
      "Iteration 2557: Loss = 0.1848, Accuracy = 0.9000 Test Loss = 0.2030, Test Accuracy = 0.8506\n",
      "Iteration 2558: Loss = 0.2122, Accuracy = 0.8100 Test Loss = 0.2024, Test Accuracy = 0.8507\n",
      "Iteration 2559: Loss = 0.2162, Accuracy = 0.8300 Test Loss = 0.2024, Test Accuracy = 0.8509\n",
      "Iteration 2560: Loss = 0.2064, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8498\n",
      "Iteration 2561: Loss = 0.2005, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8505\n",
      "Iteration 2562: Loss = 0.2078, Accuracy = 0.8300 Test Loss = 0.2024, Test Accuracy = 0.8505\n",
      "Iteration 2563: Loss = 0.1709, Accuracy = 0.9300 Test Loss = 0.2027, Test Accuracy = 0.8504\n",
      "Iteration 2564: Loss = 0.1807, Accuracy = 0.8700 Test Loss = 0.2025, Test Accuracy = 0.8527\n",
      "Iteration 2565: Loss = 0.2035, Accuracy = 0.8900 Test Loss = 0.2025, Test Accuracy = 0.8526\n",
      "Iteration 2566: Loss = 0.1916, Accuracy = 0.8800 Test Loss = 0.2029, Test Accuracy = 0.8491\n",
      "Iteration 2567: Loss = 0.1995, Accuracy = 0.8800 Test Loss = 0.2027, Test Accuracy = 0.8496\n",
      "Iteration 2568: Loss = 0.2035, Accuracy = 0.8100 Test Loss = 0.2025, Test Accuracy = 0.8527\n",
      "Iteration 2569: Loss = 0.1992, Accuracy = 0.8500 Test Loss = 0.2026, Test Accuracy = 0.8519\n",
      "Iteration 2570: Loss = 0.2043, Accuracy = 0.8200 Test Loss = 0.2028, Test Accuracy = 0.8487\n",
      "Iteration 2571: Loss = 0.2143, Accuracy = 0.8200 Test Loss = 0.2029, Test Accuracy = 0.8501\n",
      "Iteration 2572: Loss = 0.2160, Accuracy = 0.8200 Test Loss = 0.2026, Test Accuracy = 0.8493\n",
      "Iteration 2573: Loss = 0.2219, Accuracy = 0.8200 Test Loss = 0.2024, Test Accuracy = 0.8555\n",
      "Iteration 2574: Loss = 0.1863, Accuracy = 0.8900 Test Loss = 0.2025, Test Accuracy = 0.8542\n",
      "Iteration 2575: Loss = 0.2172, Accuracy = 0.8500 Test Loss = 0.2030, Test Accuracy = 0.8514\n",
      "Iteration 2576: Loss = 0.2111, Accuracy = 0.8300 Test Loss = 0.2032, Test Accuracy = 0.8519\n",
      "Iteration 2577: Loss = 0.2053, Accuracy = 0.8300 Test Loss = 0.2027, Test Accuracy = 0.8535\n",
      "Iteration 2578: Loss = 0.1946, Accuracy = 0.8400 Test Loss = 0.2024, Test Accuracy = 0.8535\n",
      "Iteration 2579: Loss = 0.1999, Accuracy = 0.8300 Test Loss = 0.2023, Test Accuracy = 0.8520\n",
      "Iteration 2580: Loss = 0.1881, Accuracy = 0.8900 Test Loss = 0.2025, Test Accuracy = 0.8529\n",
      "Iteration 2581: Loss = 0.1815, Accuracy = 0.9100 Test Loss = 0.2026, Test Accuracy = 0.8520\n",
      "Iteration 2582: Loss = 0.1943, Accuracy = 0.8500 Test Loss = 0.2027, Test Accuracy = 0.8496\n",
      "Iteration 2583: Loss = 0.2001, Accuracy = 0.8800 Test Loss = 0.2024, Test Accuracy = 0.8489\n",
      "Iteration 2584: Loss = 0.1708, Accuracy = 0.9000 Test Loss = 0.2031, Test Accuracy = 0.8480\n",
      "Iteration 2585: Loss = 0.2584, Accuracy = 0.7600 Test Loss = 0.2027, Test Accuracy = 0.8529\n",
      "Iteration 2586: Loss = 0.1997, Accuracy = 0.8200 Test Loss = 0.2028, Test Accuracy = 0.8540\n",
      "Iteration 2587: Loss = 0.2077, Accuracy = 0.8600 Test Loss = 0.2026, Test Accuracy = 0.8517\n",
      "Iteration 2588: Loss = 0.2079, Accuracy = 0.8100 Test Loss = 0.2026, Test Accuracy = 0.8534\n",
      "Iteration 2589: Loss = 0.1764, Accuracy = 0.8900 Test Loss = 0.2026, Test Accuracy = 0.8516\n",
      "Iteration 2590: Loss = 0.2173, Accuracy = 0.8200 Test Loss = 0.2035, Test Accuracy = 0.8523\n",
      "Iteration 2591: Loss = 0.2094, Accuracy = 0.8000 Test Loss = 0.2025, Test Accuracy = 0.8491\n",
      "Iteration 2592: Loss = 0.1965, Accuracy = 0.8700 Test Loss = 0.2026, Test Accuracy = 0.8485\n",
      "Iteration 2593: Loss = 0.2141, Accuracy = 0.8500 Test Loss = 0.2031, Test Accuracy = 0.8480\n",
      "Iteration 2594: Loss = 0.2217, Accuracy = 0.8200 Test Loss = 0.2029, Test Accuracy = 0.8519\n",
      "Iteration 2595: Loss = 0.1872, Accuracy = 0.8500 Test Loss = 0.2030, Test Accuracy = 0.8493\n",
      "Iteration 2596: Loss = 0.1913, Accuracy = 0.8500 Test Loss = 0.2029, Test Accuracy = 0.8482\n",
      "Iteration 2597: Loss = 0.2218, Accuracy = 0.8200 Test Loss = 0.2024, Test Accuracy = 0.8516\n",
      "Iteration 2598: Loss = 0.2099, Accuracy = 0.8400 Test Loss = 0.2027, Test Accuracy = 0.8529\n",
      "Iteration 2599: Loss = 0.1955, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8536\n",
      "Iteration 2600: Loss = 0.2044, Accuracy = 0.8100 Test Loss = 0.2030, Test Accuracy = 0.8500\n",
      "Iteration 2601: Loss = 0.1923, Accuracy = 0.9100 Test Loss = 0.2022, Test Accuracy = 0.8512\n",
      "Iteration 2602: Loss = 0.1740, Accuracy = 0.8900 Test Loss = 0.2026, Test Accuracy = 0.8512\n",
      "Iteration 2603: Loss = 0.1923, Accuracy = 0.8300 Test Loss = 0.2029, Test Accuracy = 0.8510\n",
      "Iteration 2604: Loss = 0.2071, Accuracy = 0.8500 Test Loss = 0.2023, Test Accuracy = 0.8530\n",
      "Iteration 2605: Loss = 0.2067, Accuracy = 0.8200 Test Loss = 0.2032, Test Accuracy = 0.8488\n",
      "Iteration 2606: Loss = 0.1707, Accuracy = 0.9100 Test Loss = 0.2026, Test Accuracy = 0.8502\n",
      "Iteration 2607: Loss = 0.1738, Accuracy = 0.9300 Test Loss = 0.2030, Test Accuracy = 0.8502\n",
      "Iteration 2608: Loss = 0.2342, Accuracy = 0.7700 Test Loss = 0.2027, Test Accuracy = 0.8539\n",
      "Iteration 2609: Loss = 0.1757, Accuracy = 0.8600 Test Loss = 0.2020, Test Accuracy = 0.8503\n",
      "Iteration 2610: Loss = 0.2267, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8497\n",
      "Iteration 2611: Loss = 0.2168, Accuracy = 0.8800 Test Loss = 0.2028, Test Accuracy = 0.8510\n",
      "Iteration 2612: Loss = 0.1814, Accuracy = 0.8700 Test Loss = 0.2024, Test Accuracy = 0.8518\n",
      "Iteration 2613: Loss = 0.2038, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8525\n",
      "Iteration 2614: Loss = 0.2050, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8506\n",
      "Iteration 2615: Loss = 0.2000, Accuracy = 0.8700 Test Loss = 0.2023, Test Accuracy = 0.8513\n",
      "Iteration 2616: Loss = 0.2035, Accuracy = 0.8600 Test Loss = 0.2022, Test Accuracy = 0.8536\n",
      "Iteration 2617: Loss = 0.1764, Accuracy = 0.9200 Test Loss = 0.2025, Test Accuracy = 0.8477\n",
      "Iteration 2618: Loss = 0.2217, Accuracy = 0.7900 Test Loss = 0.2028, Test Accuracy = 0.8492\n",
      "Iteration 2619: Loss = 0.2272, Accuracy = 0.8000 Test Loss = 0.2025, Test Accuracy = 0.8518\n",
      "Iteration 2620: Loss = 0.2029, Accuracy = 0.8600 Test Loss = 0.2024, Test Accuracy = 0.8522\n",
      "Iteration 2621: Loss = 0.2067, Accuracy = 0.8800 Test Loss = 0.2024, Test Accuracy = 0.8502\n",
      "Iteration 2622: Loss = 0.1979, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8521\n",
      "Iteration 2623: Loss = 0.2006, Accuracy = 0.8700 Test Loss = 0.2022, Test Accuracy = 0.8528\n",
      "Iteration 2624: Loss = 0.1969, Accuracy = 0.8500 Test Loss = 0.2031, Test Accuracy = 0.8521\n",
      "Iteration 2625: Loss = 0.1711, Accuracy = 0.9000 Test Loss = 0.2028, Test Accuracy = 0.8507\n",
      "Iteration 2626: Loss = 0.2027, Accuracy = 0.8500 Test Loss = 0.2027, Test Accuracy = 0.8552\n",
      "Iteration 2627: Loss = 0.2212, Accuracy = 0.8000 Test Loss = 0.2027, Test Accuracy = 0.8525\n",
      "Iteration 2628: Loss = 0.1790, Accuracy = 0.8800 Test Loss = 0.2026, Test Accuracy = 0.8496\n",
      "Iteration 2629: Loss = 0.1751, Accuracy = 0.8900 Test Loss = 0.2021, Test Accuracy = 0.8529\n",
      "Iteration 2630: Loss = 0.1870, Accuracy = 0.8500 Test Loss = 0.2025, Test Accuracy = 0.8474\n",
      "Iteration 2631: Loss = 0.2165, Accuracy = 0.7800 Test Loss = 0.2025, Test Accuracy = 0.8541\n",
      "Iteration 2632: Loss = 0.2065, Accuracy = 0.8700 Test Loss = 0.2027, Test Accuracy = 0.8487\n",
      "Iteration 2633: Loss = 0.1876, Accuracy = 0.8900 Test Loss = 0.2023, Test Accuracy = 0.8536\n",
      "Iteration 2634: Loss = 0.1971, Accuracy = 0.8600 Test Loss = 0.2028, Test Accuracy = 0.8525\n",
      "Iteration 2635: Loss = 0.1924, Accuracy = 0.8700 Test Loss = 0.2025, Test Accuracy = 0.8485\n",
      "Iteration 2636: Loss = 0.2205, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8502\n",
      "Iteration 2637: Loss = 0.2006, Accuracy = 0.8600 Test Loss = 0.2024, Test Accuracy = 0.8545\n",
      "Iteration 2638: Loss = 0.1867, Accuracy = 0.8600 Test Loss = 0.2024, Test Accuracy = 0.8544\n",
      "Iteration 2639: Loss = 0.2125, Accuracy = 0.8200 Test Loss = 0.2024, Test Accuracy = 0.8532\n",
      "Iteration 2640: Loss = 0.2130, Accuracy = 0.7900 Test Loss = 0.2022, Test Accuracy = 0.8522\n",
      "Iteration 2641: Loss = 0.2060, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8504\n",
      "Iteration 2642: Loss = 0.2318, Accuracy = 0.7800 Test Loss = 0.2025, Test Accuracy = 0.8540\n",
      "Iteration 2643: Loss = 0.1886, Accuracy = 0.8600 Test Loss = 0.2022, Test Accuracy = 0.8517\n",
      "Iteration 2644: Loss = 0.2046, Accuracy = 0.8800 Test Loss = 0.2022, Test Accuracy = 0.8532\n",
      "Iteration 2645: Loss = 0.1894, Accuracy = 0.8500 Test Loss = 0.2022, Test Accuracy = 0.8494\n",
      "Iteration 2646: Loss = 0.2028, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8479\n",
      "Iteration 2647: Loss = 0.2265, Accuracy = 0.8100 Test Loss = 0.2023, Test Accuracy = 0.8550\n",
      "Iteration 2648: Loss = 0.1949, Accuracy = 0.8700 Test Loss = 0.2027, Test Accuracy = 0.8492\n",
      "Iteration 2649: Loss = 0.2077, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8493\n",
      "Iteration 2650: Loss = 0.2084, Accuracy = 0.8600 Test Loss = 0.2025, Test Accuracy = 0.8541\n",
      "Iteration 2651: Loss = 0.2469, Accuracy = 0.7500 Test Loss = 0.2028, Test Accuracy = 0.8504\n",
      "Iteration 2652: Loss = 0.1832, Accuracy = 0.8900 Test Loss = 0.2024, Test Accuracy = 0.8505\n",
      "Iteration 2653: Loss = 0.1916, Accuracy = 0.8600 Test Loss = 0.2024, Test Accuracy = 0.8506\n",
      "Iteration 2654: Loss = 0.2034, Accuracy = 0.8000 Test Loss = 0.2022, Test Accuracy = 0.8532\n",
      "Iteration 2655: Loss = 0.1938, Accuracy = 0.8800 Test Loss = 0.2026, Test Accuracy = 0.8497\n",
      "Iteration 2656: Loss = 0.1775, Accuracy = 0.8800 Test Loss = 0.2023, Test Accuracy = 0.8483\n",
      "Iteration 2657: Loss = 0.2468, Accuracy = 0.8000 Test Loss = 0.2031, Test Accuracy = 0.8492\n",
      "Iteration 2658: Loss = 0.1904, Accuracy = 0.8800 Test Loss = 0.2025, Test Accuracy = 0.8533\n",
      "Iteration 2659: Loss = 0.1843, Accuracy = 0.8700 Test Loss = 0.2024, Test Accuracy = 0.8488\n",
      "Iteration 2660: Loss = 0.1759, Accuracy = 0.8900 Test Loss = 0.2020, Test Accuracy = 0.8497\n",
      "Iteration 2661: Loss = 0.2143, Accuracy = 0.7700 Test Loss = 0.2025, Test Accuracy = 0.8521\n",
      "Iteration 2662: Loss = 0.1856, Accuracy = 0.9200 Test Loss = 0.2021, Test Accuracy = 0.8518\n",
      "Iteration 2663: Loss = 0.2043, Accuracy = 0.8300 Test Loss = 0.2022, Test Accuracy = 0.8537\n",
      "Iteration 2664: Loss = 0.2024, Accuracy = 0.8700 Test Loss = 0.2024, Test Accuracy = 0.8543\n",
      "Iteration 2665: Loss = 0.2013, Accuracy = 0.8400 Test Loss = 0.2024, Test Accuracy = 0.8517\n",
      "Iteration 2666: Loss = 0.1953, Accuracy = 0.8600 Test Loss = 0.2024, Test Accuracy = 0.8491\n",
      "Iteration 2667: Loss = 0.2168, Accuracy = 0.8400 Test Loss = 0.2028, Test Accuracy = 0.8503\n",
      "Iteration 2668: Loss = 0.1927, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8518\n",
      "Iteration 2669: Loss = 0.2135, Accuracy = 0.8400 Test Loss = 0.2032, Test Accuracy = 0.8548\n",
      "Iteration 2670: Loss = 0.1801, Accuracy = 0.8900 Test Loss = 0.2023, Test Accuracy = 0.8546\n",
      "Iteration 2671: Loss = 0.1999, Accuracy = 0.8600 Test Loss = 0.2026, Test Accuracy = 0.8497\n",
      "Iteration 2672: Loss = 0.2137, Accuracy = 0.8500 Test Loss = 0.2021, Test Accuracy = 0.8540\n",
      "Iteration 2673: Loss = 0.2269, Accuracy = 0.8200 Test Loss = 0.2024, Test Accuracy = 0.8543\n",
      "Iteration 2674: Loss = 0.1935, Accuracy = 0.8500 Test Loss = 0.2023, Test Accuracy = 0.8559\n",
      "Iteration 2675: Loss = 0.1973, Accuracy = 0.8500 Test Loss = 0.2022, Test Accuracy = 0.8506\n",
      "Iteration 2676: Loss = 0.1893, Accuracy = 0.8400 Test Loss = 0.2022, Test Accuracy = 0.8529\n",
      "Iteration 2677: Loss = 0.1718, Accuracy = 0.8800 Test Loss = 0.2028, Test Accuracy = 0.8535\n",
      "Iteration 2678: Loss = 0.2019, Accuracy = 0.8900 Test Loss = 0.2026, Test Accuracy = 0.8542\n",
      "Iteration 2679: Loss = 0.1687, Accuracy = 0.9000 Test Loss = 0.2026, Test Accuracy = 0.8505\n",
      "Iteration 2680: Loss = 0.1838, Accuracy = 0.9000 Test Loss = 0.2022, Test Accuracy = 0.8484\n",
      "Iteration 2681: Loss = 0.1892, Accuracy = 0.8700 Test Loss = 0.2024, Test Accuracy = 0.8506\n",
      "Iteration 2682: Loss = 0.2111, Accuracy = 0.8700 Test Loss = 0.2029, Test Accuracy = 0.8472\n",
      "Iteration 2683: Loss = 0.2125, Accuracy = 0.7600 Test Loss = 0.2028, Test Accuracy = 0.8485\n",
      "Iteration 2684: Loss = 0.2043, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8540\n",
      "Iteration 2685: Loss = 0.2111, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8520\n",
      "Iteration 2686: Loss = 0.2087, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8504\n",
      "Iteration 2687: Loss = 0.1844, Accuracy = 0.9200 Test Loss = 0.2026, Test Accuracy = 0.8479\n",
      "Iteration 2688: Loss = 0.2152, Accuracy = 0.8100 Test Loss = 0.2021, Test Accuracy = 0.8504\n",
      "Iteration 2689: Loss = 0.1929, Accuracy = 0.8300 Test Loss = 0.2022, Test Accuracy = 0.8508\n",
      "Iteration 2690: Loss = 0.1856, Accuracy = 0.8700 Test Loss = 0.2026, Test Accuracy = 0.8484\n",
      "Iteration 2691: Loss = 0.1968, Accuracy = 0.8100 Test Loss = 0.2021, Test Accuracy = 0.8497\n",
      "Iteration 2692: Loss = 0.2143, Accuracy = 0.8400 Test Loss = 0.2021, Test Accuracy = 0.8529\n",
      "Iteration 2693: Loss = 0.2154, Accuracy = 0.8400 Test Loss = 0.2026, Test Accuracy = 0.8498\n",
      "Iteration 2694: Loss = 0.1970, Accuracy = 0.8800 Test Loss = 0.2024, Test Accuracy = 0.8521\n",
      "Iteration 2695: Loss = 0.1923, Accuracy = 0.8500 Test Loss = 0.2021, Test Accuracy = 0.8525\n",
      "Iteration 2696: Loss = 0.1798, Accuracy = 0.8900 Test Loss = 0.2023, Test Accuracy = 0.8528\n",
      "Iteration 2697: Loss = 0.1936, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8525\n",
      "Iteration 2698: Loss = 0.1974, Accuracy = 0.8500 Test Loss = 0.2025, Test Accuracy = 0.8521\n",
      "Iteration 2699: Loss = 0.2180, Accuracy = 0.7900 Test Loss = 0.2025, Test Accuracy = 0.8539\n",
      "Iteration 2700: Loss = 0.1825, Accuracy = 0.9300 Test Loss = 0.2025, Test Accuracy = 0.8509\n",
      "Iteration 2701: Loss = 0.2412, Accuracy = 0.7400 Test Loss = 0.2034, Test Accuracy = 0.8536\n",
      "Iteration 2702: Loss = 0.2355, Accuracy = 0.7800 Test Loss = 0.2020, Test Accuracy = 0.8530\n",
      "Iteration 2703: Loss = 0.1768, Accuracy = 0.9000 Test Loss = 0.2027, Test Accuracy = 0.8521\n",
      "Iteration 2704: Loss = 0.2098, Accuracy = 0.8000 Test Loss = 0.2026, Test Accuracy = 0.8521\n",
      "Iteration 2705: Loss = 0.1665, Accuracy = 0.9200 Test Loss = 0.2023, Test Accuracy = 0.8516\n",
      "Iteration 2706: Loss = 0.1958, Accuracy = 0.8300 Test Loss = 0.2030, Test Accuracy = 0.8502\n",
      "Iteration 2707: Loss = 0.2126, Accuracy = 0.8300 Test Loss = 0.2022, Test Accuracy = 0.8532\n",
      "Iteration 2708: Loss = 0.1831, Accuracy = 0.8500 Test Loss = 0.2023, Test Accuracy = 0.8512\n",
      "Iteration 2709: Loss = 0.2142, Accuracy = 0.8100 Test Loss = 0.2021, Test Accuracy = 0.8520\n",
      "Iteration 2710: Loss = 0.1860, Accuracy = 0.8500 Test Loss = 0.2025, Test Accuracy = 0.8497\n",
      "Iteration 2711: Loss = 0.2127, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8499\n",
      "Iteration 2712: Loss = 0.1798, Accuracy = 0.8900 Test Loss = 0.2021, Test Accuracy = 0.8519\n",
      "Iteration 2713: Loss = 0.1668, Accuracy = 0.9100 Test Loss = 0.2025, Test Accuracy = 0.8499\n",
      "Iteration 2714: Loss = 0.2253, Accuracy = 0.7900 Test Loss = 0.2023, Test Accuracy = 0.8512\n",
      "Iteration 2715: Loss = 0.1950, Accuracy = 0.8800 Test Loss = 0.2020, Test Accuracy = 0.8545\n",
      "Iteration 2716: Loss = 0.2083, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8524\n",
      "Iteration 2717: Loss = 0.2095, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8520\n",
      "Iteration 2718: Loss = 0.1823, Accuracy = 0.8500 Test Loss = 0.2024, Test Accuracy = 0.8497\n",
      "Iteration 2719: Loss = 0.2324, Accuracy = 0.8000 Test Loss = 0.2025, Test Accuracy = 0.8531\n",
      "Iteration 2720: Loss = 0.2000, Accuracy = 0.8800 Test Loss = 0.2024, Test Accuracy = 0.8505\n",
      "Iteration 2721: Loss = 0.2072, Accuracy = 0.8700 Test Loss = 0.2021, Test Accuracy = 0.8521\n",
      "Iteration 2722: Loss = 0.1835, Accuracy = 0.8600 Test Loss = 0.2019, Test Accuracy = 0.8536\n",
      "Iteration 2723: Loss = 0.2017, Accuracy = 0.8400 Test Loss = 0.2026, Test Accuracy = 0.8510\n",
      "Iteration 2724: Loss = 0.2003, Accuracy = 0.8400 Test Loss = 0.2028, Test Accuracy = 0.8529\n",
      "Iteration 2725: Loss = 0.1864, Accuracy = 0.9000 Test Loss = 0.2020, Test Accuracy = 0.8486\n",
      "Iteration 2726: Loss = 0.1826, Accuracy = 0.8900 Test Loss = 0.2026, Test Accuracy = 0.8537\n",
      "Iteration 2727: Loss = 0.2052, Accuracy = 0.8800 Test Loss = 0.2029, Test Accuracy = 0.8566\n",
      "Iteration 2728: Loss = 0.1995, Accuracy = 0.9000 Test Loss = 0.2026, Test Accuracy = 0.8499\n",
      "Iteration 2729: Loss = 0.1882, Accuracy = 0.8600 Test Loss = 0.2030, Test Accuracy = 0.8484\n",
      "Iteration 2730: Loss = 0.2085, Accuracy = 0.8300 Test Loss = 0.2026, Test Accuracy = 0.8523\n",
      "Iteration 2731: Loss = 0.1989, Accuracy = 0.8000 Test Loss = 0.2024, Test Accuracy = 0.8527\n",
      "Iteration 2732: Loss = 0.2291, Accuracy = 0.7800 Test Loss = 0.2024, Test Accuracy = 0.8510\n",
      "Iteration 2733: Loss = 0.2007, Accuracy = 0.8400 Test Loss = 0.2021, Test Accuracy = 0.8513\n",
      "Iteration 2734: Loss = 0.2183, Accuracy = 0.8000 Test Loss = 0.2024, Test Accuracy = 0.8472\n",
      "Iteration 2735: Loss = 0.2176, Accuracy = 0.8000 Test Loss = 0.2028, Test Accuracy = 0.8518\n",
      "Iteration 2736: Loss = 0.1752, Accuracy = 0.8300 Test Loss = 0.2023, Test Accuracy = 0.8513\n",
      "Iteration 2737: Loss = 0.1894, Accuracy = 0.8600 Test Loss = 0.2022, Test Accuracy = 0.8527\n",
      "Iteration 2738: Loss = 0.1883, Accuracy = 0.8800 Test Loss = 0.2031, Test Accuracy = 0.8515\n",
      "Iteration 2739: Loss = 0.1860, Accuracy = 0.8400 Test Loss = 0.2022, Test Accuracy = 0.8505\n",
      "Iteration 2740: Loss = 0.1984, Accuracy = 0.8200 Test Loss = 0.2033, Test Accuracy = 0.8494\n",
      "Iteration 2741: Loss = 0.1910, Accuracy = 0.8700 Test Loss = 0.2020, Test Accuracy = 0.8525\n",
      "Iteration 2742: Loss = 0.1991, Accuracy = 0.8700 Test Loss = 0.2027, Test Accuracy = 0.8520\n",
      "Iteration 2743: Loss = 0.1946, Accuracy = 0.8500 Test Loss = 0.2026, Test Accuracy = 0.8490\n",
      "Iteration 2744: Loss = 0.1876, Accuracy = 0.9200 Test Loss = 0.2021, Test Accuracy = 0.8489\n",
      "Iteration 2745: Loss = 0.1770, Accuracy = 0.8400 Test Loss = 0.2027, Test Accuracy = 0.8494\n",
      "Iteration 2746: Loss = 0.2320, Accuracy = 0.7900 Test Loss = 0.2024, Test Accuracy = 0.8529\n",
      "Iteration 2747: Loss = 0.2061, Accuracy = 0.8300 Test Loss = 0.2024, Test Accuracy = 0.8535\n",
      "Iteration 2748: Loss = 0.2187, Accuracy = 0.8300 Test Loss = 0.2020, Test Accuracy = 0.8494\n",
      "Iteration 2749: Loss = 0.1892, Accuracy = 0.8700 Test Loss = 0.2023, Test Accuracy = 0.8524\n",
      "Iteration 2750: Loss = 0.1659, Accuracy = 0.9400 Test Loss = 0.2025, Test Accuracy = 0.8515\n",
      "Iteration 2751: Loss = 0.2109, Accuracy = 0.8100 Test Loss = 0.2023, Test Accuracy = 0.8517\n",
      "Iteration 2752: Loss = 0.1873, Accuracy = 0.8900 Test Loss = 0.2021, Test Accuracy = 0.8529\n",
      "Iteration 2753: Loss = 0.2147, Accuracy = 0.8700 Test Loss = 0.2028, Test Accuracy = 0.8530\n",
      "Iteration 2754: Loss = 0.2250, Accuracy = 0.8000 Test Loss = 0.2033, Test Accuracy = 0.8491\n",
      "Iteration 2755: Loss = 0.1978, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8553\n",
      "Iteration 2756: Loss = 0.1764, Accuracy = 0.8900 Test Loss = 0.2020, Test Accuracy = 0.8538\n",
      "Iteration 2757: Loss = 0.2189, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8490\n",
      "Iteration 2758: Loss = 0.1839, Accuracy = 0.9000 Test Loss = 0.2021, Test Accuracy = 0.8537\n",
      "Iteration 2759: Loss = 0.2351, Accuracy = 0.7800 Test Loss = 0.2024, Test Accuracy = 0.8480\n",
      "Iteration 2760: Loss = 0.2127, Accuracy = 0.8400 Test Loss = 0.2028, Test Accuracy = 0.8497\n",
      "Iteration 2761: Loss = 0.1938, Accuracy = 0.9100 Test Loss = 0.2021, Test Accuracy = 0.8521\n",
      "Iteration 2762: Loss = 0.2021, Accuracy = 0.8700 Test Loss = 0.2024, Test Accuracy = 0.8512\n",
      "Iteration 2763: Loss = 0.2137, Accuracy = 0.8700 Test Loss = 0.2028, Test Accuracy = 0.8470\n",
      "Iteration 2764: Loss = 0.1980, Accuracy = 0.8600 Test Loss = 0.2023, Test Accuracy = 0.8502\n",
      "Iteration 2765: Loss = 0.1856, Accuracy = 0.8800 Test Loss = 0.2022, Test Accuracy = 0.8506\n",
      "Iteration 2766: Loss = 0.1945, Accuracy = 0.8900 Test Loss = 0.2025, Test Accuracy = 0.8519\n",
      "Iteration 2767: Loss = 0.2155, Accuracy = 0.8500 Test Loss = 0.2020, Test Accuracy = 0.8512\n",
      "Iteration 2768: Loss = 0.2133, Accuracy = 0.7800 Test Loss = 0.2025, Test Accuracy = 0.8540\n",
      "Iteration 2769: Loss = 0.1929, Accuracy = 0.9000 Test Loss = 0.2018, Test Accuracy = 0.8525\n",
      "Iteration 2770: Loss = 0.2150, Accuracy = 0.8000 Test Loss = 0.2022, Test Accuracy = 0.8553\n",
      "Iteration 2771: Loss = 0.1860, Accuracy = 0.8600 Test Loss = 0.2018, Test Accuracy = 0.8504\n",
      "Iteration 2772: Loss = 0.1663, Accuracy = 0.9000 Test Loss = 0.2033, Test Accuracy = 0.8448\n",
      "Iteration 2773: Loss = 0.1889, Accuracy = 0.8500 Test Loss = 0.2021, Test Accuracy = 0.8550\n",
      "Iteration 2774: Loss = 0.1707, Accuracy = 0.9300 Test Loss = 0.2024, Test Accuracy = 0.8509\n",
      "Iteration 2775: Loss = 0.2245, Accuracy = 0.7800 Test Loss = 0.2023, Test Accuracy = 0.8478\n",
      "Iteration 2776: Loss = 0.1841, Accuracy = 0.9000 Test Loss = 0.2019, Test Accuracy = 0.8533\n",
      "Iteration 2777: Loss = 0.1941, Accuracy = 0.8900 Test Loss = 0.2026, Test Accuracy = 0.8569\n",
      "Iteration 2778: Loss = 0.2212, Accuracy = 0.8000 Test Loss = 0.2024, Test Accuracy = 0.8539\n",
      "Iteration 2779: Loss = 0.1952, Accuracy = 0.8200 Test Loss = 0.2021, Test Accuracy = 0.8489\n",
      "Iteration 2780: Loss = 0.2237, Accuracy = 0.7900 Test Loss = 0.2023, Test Accuracy = 0.8530\n",
      "Iteration 2781: Loss = 0.1954, Accuracy = 0.8700 Test Loss = 0.2023, Test Accuracy = 0.8537\n",
      "Iteration 2782: Loss = 0.2132, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8546\n",
      "Iteration 2783: Loss = 0.1817, Accuracy = 0.9000 Test Loss = 0.2025, Test Accuracy = 0.8514\n",
      "Iteration 2784: Loss = 0.1967, Accuracy = 0.8800 Test Loss = 0.2020, Test Accuracy = 0.8511\n",
      "Iteration 2785: Loss = 0.2141, Accuracy = 0.8300 Test Loss = 0.2017, Test Accuracy = 0.8509\n",
      "Iteration 2786: Loss = 0.1955, Accuracy = 0.8700 Test Loss = 0.2027, Test Accuracy = 0.8510\n",
      "Iteration 2787: Loss = 0.1943, Accuracy = 0.8800 Test Loss = 0.2019, Test Accuracy = 0.8545\n",
      "Iteration 2788: Loss = 0.2268, Accuracy = 0.7900 Test Loss = 0.2018, Test Accuracy = 0.8528\n",
      "Iteration 2789: Loss = 0.2058, Accuracy = 0.8500 Test Loss = 0.2029, Test Accuracy = 0.8483\n",
      "Iteration 2790: Loss = 0.2017, Accuracy = 0.8600 Test Loss = 0.2022, Test Accuracy = 0.8528\n",
      "Iteration 2791: Loss = 0.2128, Accuracy = 0.7900 Test Loss = 0.2025, Test Accuracy = 0.8535\n",
      "Iteration 2792: Loss = 0.2115, Accuracy = 0.8600 Test Loss = 0.2020, Test Accuracy = 0.8549\n",
      "Iteration 2793: Loss = 0.1910, Accuracy = 0.8200 Test Loss = 0.2022, Test Accuracy = 0.8497\n",
      "Iteration 2794: Loss = 0.1793, Accuracy = 0.9200 Test Loss = 0.2023, Test Accuracy = 0.8467\n",
      "Iteration 2795: Loss = 0.2007, Accuracy = 0.8700 Test Loss = 0.2024, Test Accuracy = 0.8549\n",
      "Iteration 2796: Loss = 0.1872, Accuracy = 0.8800 Test Loss = 0.2026, Test Accuracy = 0.8503\n",
      "Iteration 2797: Loss = 0.1935, Accuracy = 0.8700 Test Loss = 0.2022, Test Accuracy = 0.8508\n",
      "Iteration 2798: Loss = 0.2201, Accuracy = 0.8300 Test Loss = 0.2022, Test Accuracy = 0.8530\n",
      "Iteration 2799: Loss = 0.1832, Accuracy = 0.8700 Test Loss = 0.2019, Test Accuracy = 0.8534\n",
      "Iteration 2800: Loss = 0.1973, Accuracy = 0.8600 Test Loss = 0.2021, Test Accuracy = 0.8517\n",
      "Iteration 2801: Loss = 0.2047, Accuracy = 0.8500 Test Loss = 0.2018, Test Accuracy = 0.8561\n",
      "Iteration 2802: Loss = 0.1821, Accuracy = 0.8600 Test Loss = 0.2028, Test Accuracy = 0.8522\n",
      "Iteration 2803: Loss = 0.2020, Accuracy = 0.8500 Test Loss = 0.2021, Test Accuracy = 0.8520\n",
      "Iteration 2804: Loss = 0.1976, Accuracy = 0.8600 Test Loss = 0.2021, Test Accuracy = 0.8516\n",
      "Iteration 2805: Loss = 0.1979, Accuracy = 0.8500 Test Loss = 0.2021, Test Accuracy = 0.8506\n",
      "Iteration 2806: Loss = 0.2108, Accuracy = 0.8100 Test Loss = 0.2022, Test Accuracy = 0.8483\n",
      "Iteration 2807: Loss = 0.1694, Accuracy = 0.8900 Test Loss = 0.2020, Test Accuracy = 0.8480\n",
      "Iteration 2808: Loss = 0.2285, Accuracy = 0.8900 Test Loss = 0.2019, Test Accuracy = 0.8539\n",
      "Iteration 2809: Loss = 0.2058, Accuracy = 0.8500 Test Loss = 0.2028, Test Accuracy = 0.8501\n",
      "Iteration 2810: Loss = 0.1998, Accuracy = 0.8600 Test Loss = 0.2031, Test Accuracy = 0.8503\n",
      "Iteration 2811: Loss = 0.1795, Accuracy = 0.9100 Test Loss = 0.2026, Test Accuracy = 0.8530\n",
      "Iteration 2812: Loss = 0.1722, Accuracy = 0.8300 Test Loss = 0.2023, Test Accuracy = 0.8545\n",
      "Iteration 2813: Loss = 0.1624, Accuracy = 0.9200 Test Loss = 0.2025, Test Accuracy = 0.8495\n",
      "Iteration 2814: Loss = 0.1926, Accuracy = 0.8600 Test Loss = 0.2022, Test Accuracy = 0.8516\n",
      "Iteration 2815: Loss = 0.1851, Accuracy = 0.8700 Test Loss = 0.2020, Test Accuracy = 0.8543\n",
      "Iteration 2816: Loss = 0.1960, Accuracy = 0.8000 Test Loss = 0.2019, Test Accuracy = 0.8525\n",
      "Iteration 2817: Loss = 0.1988, Accuracy = 0.8300 Test Loss = 0.2021, Test Accuracy = 0.8505\n",
      "Iteration 2818: Loss = 0.2079, Accuracy = 0.7800 Test Loss = 0.2020, Test Accuracy = 0.8532\n",
      "Iteration 2819: Loss = 0.1729, Accuracy = 0.8900 Test Loss = 0.2023, Test Accuracy = 0.8497\n",
      "Iteration 2820: Loss = 0.1819, Accuracy = 0.9000 Test Loss = 0.2022, Test Accuracy = 0.8549\n",
      "Iteration 2821: Loss = 0.2049, Accuracy = 0.8500 Test Loss = 0.2031, Test Accuracy = 0.8506\n",
      "Iteration 2822: Loss = 0.1822, Accuracy = 0.8900 Test Loss = 0.2020, Test Accuracy = 0.8525\n",
      "Iteration 2823: Loss = 0.1996, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8507\n",
      "Iteration 2824: Loss = 0.1942, Accuracy = 0.8700 Test Loss = 0.2019, Test Accuracy = 0.8525\n",
      "Iteration 2825: Loss = 0.2109, Accuracy = 0.8000 Test Loss = 0.2021, Test Accuracy = 0.8527\n",
      "Iteration 2826: Loss = 0.2019, Accuracy = 0.8300 Test Loss = 0.2023, Test Accuracy = 0.8491\n",
      "Iteration 2827: Loss = 0.2121, Accuracy = 0.8100 Test Loss = 0.2022, Test Accuracy = 0.8511\n",
      "Iteration 2828: Loss = 0.2019, Accuracy = 0.8400 Test Loss = 0.2022, Test Accuracy = 0.8501\n",
      "Iteration 2829: Loss = 0.1886, Accuracy = 0.8400 Test Loss = 0.2024, Test Accuracy = 0.8517\n",
      "Iteration 2830: Loss = 0.1900, Accuracy = 0.8800 Test Loss = 0.2022, Test Accuracy = 0.8537\n",
      "Iteration 2831: Loss = 0.2031, Accuracy = 0.8400 Test Loss = 0.2022, Test Accuracy = 0.8528\n",
      "Iteration 2832: Loss = 0.2236, Accuracy = 0.7700 Test Loss = 0.2025, Test Accuracy = 0.8491\n",
      "Iteration 2833: Loss = 0.2306, Accuracy = 0.7800 Test Loss = 0.2028, Test Accuracy = 0.8477\n",
      "Iteration 2834: Loss = 0.1924, Accuracy = 0.8800 Test Loss = 0.2024, Test Accuracy = 0.8542\n",
      "Iteration 2835: Loss = 0.1960, Accuracy = 0.8500 Test Loss = 0.2025, Test Accuracy = 0.8499\n",
      "Iteration 2836: Loss = 0.2021, Accuracy = 0.8400 Test Loss = 0.2021, Test Accuracy = 0.8492\n",
      "Iteration 2837: Loss = 0.1895, Accuracy = 0.9100 Test Loss = 0.2025, Test Accuracy = 0.8507\n",
      "Iteration 2838: Loss = 0.2025, Accuracy = 0.8500 Test Loss = 0.2022, Test Accuracy = 0.8496\n",
      "Iteration 2839: Loss = 0.2012, Accuracy = 0.8700 Test Loss = 0.2022, Test Accuracy = 0.8498\n",
      "Iteration 2840: Loss = 0.1971, Accuracy = 0.8700 Test Loss = 0.2022, Test Accuracy = 0.8516\n",
      "Iteration 2841: Loss = 0.2256, Accuracy = 0.7800 Test Loss = 0.2024, Test Accuracy = 0.8506\n",
      "Iteration 2842: Loss = 0.1953, Accuracy = 0.8900 Test Loss = 0.2024, Test Accuracy = 0.8517\n",
      "Iteration 2843: Loss = 0.1938, Accuracy = 0.8600 Test Loss = 0.2019, Test Accuracy = 0.8514\n",
      "Iteration 2844: Loss = 0.2275, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8557\n",
      "Iteration 2845: Loss = 0.1999, Accuracy = 0.8600 Test Loss = 0.2018, Test Accuracy = 0.8511\n",
      "Iteration 2846: Loss = 0.1763, Accuracy = 0.8800 Test Loss = 0.2019, Test Accuracy = 0.8489\n",
      "Iteration 2847: Loss = 0.1883, Accuracy = 0.8400 Test Loss = 0.2020, Test Accuracy = 0.8506\n",
      "Iteration 2848: Loss = 0.2448, Accuracy = 0.7700 Test Loss = 0.2024, Test Accuracy = 0.8499\n",
      "Iteration 2849: Loss = 0.2065, Accuracy = 0.8500 Test Loss = 0.2018, Test Accuracy = 0.8561\n",
      "Iteration 2850: Loss = 0.1948, Accuracy = 0.8500 Test Loss = 0.2024, Test Accuracy = 0.8513\n",
      "Iteration 2851: Loss = 0.2298, Accuracy = 0.8000 Test Loss = 0.2020, Test Accuracy = 0.8538\n",
      "Iteration 2852: Loss = 0.1830, Accuracy = 0.8900 Test Loss = 0.2020, Test Accuracy = 0.8505\n",
      "Iteration 2853: Loss = 0.2076, Accuracy = 0.8300 Test Loss = 0.2022, Test Accuracy = 0.8514\n",
      "Iteration 2854: Loss = 0.1713, Accuracy = 0.8900 Test Loss = 0.2020, Test Accuracy = 0.8547\n",
      "Iteration 2855: Loss = 0.2179, Accuracy = 0.8400 Test Loss = 0.2024, Test Accuracy = 0.8525\n",
      "Iteration 2856: Loss = 0.1851, Accuracy = 0.8600 Test Loss = 0.2026, Test Accuracy = 0.8513\n",
      "Iteration 2857: Loss = 0.2277, Accuracy = 0.7600 Test Loss = 0.2020, Test Accuracy = 0.8489\n",
      "Iteration 2858: Loss = 0.1806, Accuracy = 0.8300 Test Loss = 0.2017, Test Accuracy = 0.8523\n",
      "Iteration 2859: Loss = 0.1757, Accuracy = 0.8900 Test Loss = 0.2022, Test Accuracy = 0.8548\n",
      "Iteration 2860: Loss = 0.1896, Accuracy = 0.8900 Test Loss = 0.2019, Test Accuracy = 0.8496\n",
      "Iteration 2861: Loss = 0.2239, Accuracy = 0.8200 Test Loss = 0.2023, Test Accuracy = 0.8522\n",
      "Iteration 2862: Loss = 0.1943, Accuracy = 0.8300 Test Loss = 0.2016, Test Accuracy = 0.8520\n",
      "Iteration 2863: Loss = 0.1936, Accuracy = 0.8700 Test Loss = 0.2022, Test Accuracy = 0.8485\n",
      "Iteration 2864: Loss = 0.1816, Accuracy = 0.9000 Test Loss = 0.2020, Test Accuracy = 0.8541\n",
      "Iteration 2865: Loss = 0.1972, Accuracy = 0.8400 Test Loss = 0.2021, Test Accuracy = 0.8516\n",
      "Iteration 2866: Loss = 0.1995, Accuracy = 0.8700 Test Loss = 0.2023, Test Accuracy = 0.8531\n",
      "Iteration 2867: Loss = 0.1808, Accuracy = 0.8900 Test Loss = 0.2022, Test Accuracy = 0.8556\n",
      "Iteration 2868: Loss = 0.1977, Accuracy = 0.8200 Test Loss = 0.2020, Test Accuracy = 0.8514\n",
      "Iteration 2869: Loss = 0.2025, Accuracy = 0.8300 Test Loss = 0.2024, Test Accuracy = 0.8551\n",
      "Iteration 2870: Loss = 0.1860, Accuracy = 0.9200 Test Loss = 0.2020, Test Accuracy = 0.8516\n",
      "Iteration 2871: Loss = 0.1842, Accuracy = 0.8800 Test Loss = 0.2022, Test Accuracy = 0.8487\n",
      "Iteration 2872: Loss = 0.1987, Accuracy = 0.8800 Test Loss = 0.2025, Test Accuracy = 0.8485\n",
      "Iteration 2873: Loss = 0.2200, Accuracy = 0.8500 Test Loss = 0.2024, Test Accuracy = 0.8542\n",
      "Iteration 2874: Loss = 0.1876, Accuracy = 0.8700 Test Loss = 0.2019, Test Accuracy = 0.8542\n",
      "Iteration 2875: Loss = 0.2052, Accuracy = 0.8600 Test Loss = 0.2021, Test Accuracy = 0.8522\n",
      "Iteration 2876: Loss = 0.2028, Accuracy = 0.8600 Test Loss = 0.2024, Test Accuracy = 0.8527\n",
      "Iteration 2877: Loss = 0.1772, Accuracy = 0.8600 Test Loss = 0.2027, Test Accuracy = 0.8521\n",
      "Iteration 2878: Loss = 0.1860, Accuracy = 0.8400 Test Loss = 0.2018, Test Accuracy = 0.8515\n",
      "Iteration 2879: Loss = 0.2138, Accuracy = 0.8300 Test Loss = 0.2025, Test Accuracy = 0.8514\n",
      "Iteration 2880: Loss = 0.2089, Accuracy = 0.8800 Test Loss = 0.2022, Test Accuracy = 0.8544\n",
      "Iteration 2881: Loss = 0.1922, Accuracy = 0.8500 Test Loss = 0.2022, Test Accuracy = 0.8472\n",
      "Iteration 2882: Loss = 0.2350, Accuracy = 0.7700 Test Loss = 0.2019, Test Accuracy = 0.8546\n",
      "Iteration 2883: Loss = 0.2056, Accuracy = 0.8200 Test Loss = 0.2025, Test Accuracy = 0.8494\n",
      "Iteration 2884: Loss = 0.2215, Accuracy = 0.8100 Test Loss = 0.2022, Test Accuracy = 0.8546\n",
      "Iteration 2885: Loss = 0.1934, Accuracy = 0.8400 Test Loss = 0.2031, Test Accuracy = 0.8472\n",
      "Iteration 2886: Loss = 0.1935, Accuracy = 0.8800 Test Loss = 0.2020, Test Accuracy = 0.8512\n",
      "Iteration 2887: Loss = 0.2321, Accuracy = 0.8400 Test Loss = 0.2020, Test Accuracy = 0.8541\n",
      "Iteration 2888: Loss = 0.2026, Accuracy = 0.8200 Test Loss = 0.2018, Test Accuracy = 0.8516\n",
      "Iteration 2889: Loss = 0.2275, Accuracy = 0.8100 Test Loss = 0.2019, Test Accuracy = 0.8513\n",
      "Iteration 2890: Loss = 0.2110, Accuracy = 0.8400 Test Loss = 0.2025, Test Accuracy = 0.8514\n",
      "Iteration 2891: Loss = 0.1934, Accuracy = 0.8800 Test Loss = 0.2017, Test Accuracy = 0.8535\n",
      "Iteration 2892: Loss = 0.1972, Accuracy = 0.8900 Test Loss = 0.2035, Test Accuracy = 0.8467\n",
      "Iteration 2893: Loss = 0.2266, Accuracy = 0.7800 Test Loss = 0.2023, Test Accuracy = 0.8546\n",
      "Iteration 2894: Loss = 0.2018, Accuracy = 0.8200 Test Loss = 0.2021, Test Accuracy = 0.8547\n",
      "Iteration 2895: Loss = 0.1969, Accuracy = 0.8300 Test Loss = 0.2023, Test Accuracy = 0.8544\n",
      "Iteration 2896: Loss = 0.1952, Accuracy = 0.8300 Test Loss = 0.2022, Test Accuracy = 0.8505\n",
      "Iteration 2897: Loss = 0.2235, Accuracy = 0.7800 Test Loss = 0.2021, Test Accuracy = 0.8542\n",
      "Iteration 2898: Loss = 0.1727, Accuracy = 0.9200 Test Loss = 0.2016, Test Accuracy = 0.8519\n",
      "Iteration 2899: Loss = 0.1751, Accuracy = 0.8900 Test Loss = 0.2022, Test Accuracy = 0.8505\n",
      "Iteration 2900: Loss = 0.2038, Accuracy = 0.8600 Test Loss = 0.2020, Test Accuracy = 0.8508\n",
      "Iteration 2901: Loss = 0.2090, Accuracy = 0.8200 Test Loss = 0.2022, Test Accuracy = 0.8498\n",
      "Iteration 2902: Loss = 0.2066, Accuracy = 0.8600 Test Loss = 0.2017, Test Accuracy = 0.8529\n",
      "Iteration 2903: Loss = 0.2234, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8525\n",
      "Iteration 2904: Loss = 0.1765, Accuracy = 0.8900 Test Loss = 0.2021, Test Accuracy = 0.8495\n",
      "Iteration 2905: Loss = 0.2058, Accuracy = 0.8300 Test Loss = 0.2021, Test Accuracy = 0.8505\n",
      "Iteration 2906: Loss = 0.2067, Accuracy = 0.8700 Test Loss = 0.2019, Test Accuracy = 0.8545\n",
      "Iteration 2907: Loss = 0.1984, Accuracy = 0.8600 Test Loss = 0.2018, Test Accuracy = 0.8533\n",
      "Iteration 2908: Loss = 0.1743, Accuracy = 0.9200 Test Loss = 0.2019, Test Accuracy = 0.8486\n",
      "Iteration 2909: Loss = 0.1875, Accuracy = 0.8600 Test Loss = 0.2017, Test Accuracy = 0.8512\n",
      "Iteration 2910: Loss = 0.2141, Accuracy = 0.8300 Test Loss = 0.2016, Test Accuracy = 0.8540\n",
      "Iteration 2911: Loss = 0.2063, Accuracy = 0.8500 Test Loss = 0.2022, Test Accuracy = 0.8488\n",
      "Iteration 2912: Loss = 0.1906, Accuracy = 0.8400 Test Loss = 0.2021, Test Accuracy = 0.8505\n",
      "Iteration 2913: Loss = 0.2005, Accuracy = 0.8700 Test Loss = 0.2020, Test Accuracy = 0.8527\n",
      "Iteration 2914: Loss = 0.1948, Accuracy = 0.8300 Test Loss = 0.2020, Test Accuracy = 0.8538\n",
      "Iteration 2915: Loss = 0.1624, Accuracy = 0.9200 Test Loss = 0.2015, Test Accuracy = 0.8546\n",
      "Iteration 2916: Loss = 0.1717, Accuracy = 0.9200 Test Loss = 0.2020, Test Accuracy = 0.8515\n",
      "Iteration 2917: Loss = 0.2151, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8494\n",
      "Iteration 2918: Loss = 0.1988, Accuracy = 0.8200 Test Loss = 0.2017, Test Accuracy = 0.8528\n",
      "Iteration 2919: Loss = 0.2223, Accuracy = 0.7900 Test Loss = 0.2024, Test Accuracy = 0.8530\n",
      "Iteration 2920: Loss = 0.1941, Accuracy = 0.8500 Test Loss = 0.2023, Test Accuracy = 0.8527\n",
      "Iteration 2921: Loss = 0.1977, Accuracy = 0.8600 Test Loss = 0.2026, Test Accuracy = 0.8549\n",
      "Iteration 2922: Loss = 0.2457, Accuracy = 0.7900 Test Loss = 0.2022, Test Accuracy = 0.8526\n",
      "Iteration 2923: Loss = 0.1969, Accuracy = 0.8400 Test Loss = 0.2019, Test Accuracy = 0.8516\n",
      "Iteration 2924: Loss = 0.2326, Accuracy = 0.7300 Test Loss = 0.2018, Test Accuracy = 0.8541\n",
      "Iteration 2925: Loss = 0.2257, Accuracy = 0.8600 Test Loss = 0.2018, Test Accuracy = 0.8515\n",
      "Iteration 2926: Loss = 0.2053, Accuracy = 0.8600 Test Loss = 0.2021, Test Accuracy = 0.8502\n",
      "Iteration 2927: Loss = 0.2034, Accuracy = 0.8900 Test Loss = 0.2024, Test Accuracy = 0.8498\n",
      "Iteration 2928: Loss = 0.2038, Accuracy = 0.8900 Test Loss = 0.2018, Test Accuracy = 0.8545\n",
      "Iteration 2929: Loss = 0.2251, Accuracy = 0.8600 Test Loss = 0.2022, Test Accuracy = 0.8514\n",
      "Iteration 2930: Loss = 0.2478, Accuracy = 0.7400 Test Loss = 0.2019, Test Accuracy = 0.8518\n",
      "Iteration 2931: Loss = 0.2091, Accuracy = 0.8200 Test Loss = 0.2019, Test Accuracy = 0.8509\n",
      "Iteration 2932: Loss = 0.2302, Accuracy = 0.8600 Test Loss = 0.2023, Test Accuracy = 0.8519\n",
      "Iteration 2933: Loss = 0.2174, Accuracy = 0.8400 Test Loss = 0.2023, Test Accuracy = 0.8486\n",
      "Iteration 2934: Loss = 0.2321, Accuracy = 0.8700 Test Loss = 0.2018, Test Accuracy = 0.8542\n",
      "Iteration 2935: Loss = 0.2152, Accuracy = 0.8300 Test Loss = 0.2020, Test Accuracy = 0.8522\n",
      "Iteration 2936: Loss = 0.2222, Accuracy = 0.7800 Test Loss = 0.2019, Test Accuracy = 0.8491\n",
      "Iteration 2937: Loss = 0.1970, Accuracy = 0.8300 Test Loss = 0.2021, Test Accuracy = 0.8556\n",
      "Iteration 2938: Loss = 0.2003, Accuracy = 0.8600 Test Loss = 0.2017, Test Accuracy = 0.8526\n",
      "Iteration 2939: Loss = 0.1982, Accuracy = 0.8800 Test Loss = 0.2022, Test Accuracy = 0.8516\n",
      "Iteration 2940: Loss = 0.2158, Accuracy = 0.8000 Test Loss = 0.2020, Test Accuracy = 0.8513\n",
      "Iteration 2941: Loss = 0.1827, Accuracy = 0.8600 Test Loss = 0.2018, Test Accuracy = 0.8531\n",
      "Iteration 2942: Loss = 0.1861, Accuracy = 0.8500 Test Loss = 0.2019, Test Accuracy = 0.8526\n",
      "Iteration 2943: Loss = 0.1823, Accuracy = 0.8400 Test Loss = 0.2022, Test Accuracy = 0.8503\n",
      "Iteration 2944: Loss = 0.2031, Accuracy = 0.8500 Test Loss = 0.2024, Test Accuracy = 0.8506\n",
      "Iteration 2945: Loss = 0.2043, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8518\n",
      "Iteration 2946: Loss = 0.2283, Accuracy = 0.7800 Test Loss = 0.2024, Test Accuracy = 0.8527\n",
      "Iteration 2947: Loss = 0.2025, Accuracy = 0.8500 Test Loss = 0.2015, Test Accuracy = 0.8546\n",
      "Iteration 2948: Loss = 0.2484, Accuracy = 0.7700 Test Loss = 0.2026, Test Accuracy = 0.8552\n",
      "Iteration 2949: Loss = 0.1845, Accuracy = 0.8900 Test Loss = 0.2027, Test Accuracy = 0.8535\n",
      "Iteration 2950: Loss = 0.2083, Accuracy = 0.8300 Test Loss = 0.2021, Test Accuracy = 0.8513\n",
      "Iteration 2951: Loss = 0.2356, Accuracy = 0.7500 Test Loss = 0.2024, Test Accuracy = 0.8513\n",
      "Iteration 2952: Loss = 0.1784, Accuracy = 0.8500 Test Loss = 0.2020, Test Accuracy = 0.8523\n",
      "Iteration 2953: Loss = 0.1882, Accuracy = 0.9100 Test Loss = 0.2017, Test Accuracy = 0.8500\n",
      "Iteration 2954: Loss = 0.1764, Accuracy = 0.9400 Test Loss = 0.2022, Test Accuracy = 0.8465\n",
      "Iteration 2955: Loss = 0.2219, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8535\n",
      "Iteration 2956: Loss = 0.2094, Accuracy = 0.8300 Test Loss = 0.2018, Test Accuracy = 0.8552\n",
      "Iteration 2957: Loss = 0.2180, Accuracy = 0.8800 Test Loss = 0.2017, Test Accuracy = 0.8508\n",
      "Iteration 2958: Loss = 0.1901, Accuracy = 0.8900 Test Loss = 0.2019, Test Accuracy = 0.8513\n",
      "Iteration 2959: Loss = 0.2018, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8525\n",
      "Iteration 2960: Loss = 0.1992, Accuracy = 0.8500 Test Loss = 0.2019, Test Accuracy = 0.8519\n",
      "Iteration 2961: Loss = 0.1576, Accuracy = 0.9100 Test Loss = 0.2022, Test Accuracy = 0.8521\n",
      "Iteration 2962: Loss = 0.1818, Accuracy = 0.8700 Test Loss = 0.2024, Test Accuracy = 0.8503\n",
      "Iteration 2963: Loss = 0.1998, Accuracy = 0.8700 Test Loss = 0.2022, Test Accuracy = 0.8490\n",
      "Iteration 2964: Loss = 0.1988, Accuracy = 0.8500 Test Loss = 0.2017, Test Accuracy = 0.8546\n",
      "Iteration 2965: Loss = 0.2014, Accuracy = 0.8800 Test Loss = 0.2018, Test Accuracy = 0.8543\n",
      "Iteration 2966: Loss = 0.2247, Accuracy = 0.7800 Test Loss = 0.2017, Test Accuracy = 0.8529\n",
      "Iteration 2967: Loss = 0.1801, Accuracy = 0.9200 Test Loss = 0.2019, Test Accuracy = 0.8509\n",
      "Iteration 2968: Loss = 0.2252, Accuracy = 0.8000 Test Loss = 0.2020, Test Accuracy = 0.8520\n",
      "Iteration 2969: Loss = 0.2131, Accuracy = 0.8400 Test Loss = 0.2020, Test Accuracy = 0.8534\n",
      "Iteration 2970: Loss = 0.1878, Accuracy = 0.8700 Test Loss = 0.2025, Test Accuracy = 0.8448\n",
      "Iteration 2971: Loss = 0.2161, Accuracy = 0.8100 Test Loss = 0.2020, Test Accuracy = 0.8502\n",
      "Iteration 2972: Loss = 0.1847, Accuracy = 0.8700 Test Loss = 0.2026, Test Accuracy = 0.8500\n",
      "Iteration 2973: Loss = 0.1951, Accuracy = 0.8500 Test Loss = 0.2021, Test Accuracy = 0.8542\n",
      "Iteration 2974: Loss = 0.1847, Accuracy = 0.8500 Test Loss = 0.2021, Test Accuracy = 0.8512\n",
      "Iteration 2975: Loss = 0.1789, Accuracy = 0.8900 Test Loss = 0.2018, Test Accuracy = 0.8507\n",
      "Iteration 2976: Loss = 0.1894, Accuracy = 0.8600 Test Loss = 0.2020, Test Accuracy = 0.8492\n",
      "Iteration 2977: Loss = 0.1608, Accuracy = 0.9200 Test Loss = 0.2020, Test Accuracy = 0.8510\n",
      "Iteration 2978: Loss = 0.1923, Accuracy = 0.8300 Test Loss = 0.2019, Test Accuracy = 0.8521\n",
      "Iteration 2979: Loss = 0.1919, Accuracy = 0.8300 Test Loss = 0.2020, Test Accuracy = 0.8494\n",
      "Iteration 2980: Loss = 0.2362, Accuracy = 0.8000 Test Loss = 0.2023, Test Accuracy = 0.8539\n",
      "Iteration 2981: Loss = 0.2422, Accuracy = 0.7700 Test Loss = 0.2019, Test Accuracy = 0.8530\n",
      "Iteration 2982: Loss = 0.2227, Accuracy = 0.8400 Test Loss = 0.2021, Test Accuracy = 0.8545\n",
      "Iteration 2983: Loss = 0.1765, Accuracy = 0.8800 Test Loss = 0.2021, Test Accuracy = 0.8526\n",
      "Iteration 2984: Loss = 0.1785, Accuracy = 0.8900 Test Loss = 0.2021, Test Accuracy = 0.8512\n",
      "Iteration 2985: Loss = 0.1970, Accuracy = 0.8500 Test Loss = 0.2015, Test Accuracy = 0.8503\n",
      "Iteration 2986: Loss = 0.2666, Accuracy = 0.7300 Test Loss = 0.2017, Test Accuracy = 0.8540\n",
      "Iteration 2987: Loss = 0.1984, Accuracy = 0.8700 Test Loss = 0.2022, Test Accuracy = 0.8486\n",
      "Iteration 2988: Loss = 0.2071, Accuracy = 0.8500 Test Loss = 0.2019, Test Accuracy = 0.8479\n",
      "Iteration 2989: Loss = 0.1698, Accuracy = 0.8700 Test Loss = 0.2020, Test Accuracy = 0.8503\n",
      "Iteration 2990: Loss = 0.1878, Accuracy = 0.8700 Test Loss = 0.2030, Test Accuracy = 0.8547\n",
      "Iteration 2991: Loss = 0.1939, Accuracy = 0.8800 Test Loss = 0.2019, Test Accuracy = 0.8490\n",
      "Iteration 2992: Loss = 0.1866, Accuracy = 0.8300 Test Loss = 0.2030, Test Accuracy = 0.8486\n",
      "Iteration 2993: Loss = 0.2136, Accuracy = 0.8400 Test Loss = 0.2017, Test Accuracy = 0.8509\n",
      "Iteration 2994: Loss = 0.1938, Accuracy = 0.8400 Test Loss = 0.2018, Test Accuracy = 0.8495\n",
      "Iteration 2995: Loss = 0.1938, Accuracy = 0.8200 Test Loss = 0.2018, Test Accuracy = 0.8520\n",
      "Iteration 2996: Loss = 0.2005, Accuracy = 0.8400 Test Loss = 0.2018, Test Accuracy = 0.8508\n",
      "Iteration 2997: Loss = 0.2197, Accuracy = 0.7900 Test Loss = 0.2018, Test Accuracy = 0.8508\n",
      "Iteration 2998: Loss = 0.2063, Accuracy = 0.8300 Test Loss = 0.2016, Test Accuracy = 0.8489\n",
      "Iteration 2999: Loss = 0.2270, Accuracy = 0.7400 Test Loss = 0.2025, Test Accuracy = 0.8500\n",
      "Total training time: 380.83s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history3 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=3000, B = 100)\n",
    "plot_history(history3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used 3000 epochs. Becasue, I tried with 4000 epochs previously and the line does not improve over the iterations. It converges early. \n",
    "That is why when I am running the models again for the final time, I am using less number of iterations. \n",
    "\n",
    "`Total training time`: 380.83s for 3000 epochs. `0.13`s per epoch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`B=1000`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 98.6488, Accuracy = 0.0950 Test Loss = 94.5800, Test Accuracy = 0.1004\n",
      "Iteration 1: Loss = 66.1937, Accuracy = 0.1250 Test Loss = 65.8526, Test Accuracy = 0.1151\n",
      "Iteration 2: Loss = 53.9449, Accuracy = 0.1270 Test Loss = 52.5421, Test Accuracy = 0.1255\n",
      "Iteration 3: Loss = 44.5077, Accuracy = 0.1590 Test Loss = 44.4828, Test Accuracy = 0.1314\n",
      "Iteration 4: Loss = 39.9347, Accuracy = 0.1420 Test Loss = 39.0079, Test Accuracy = 0.1360\n",
      "Iteration 5: Loss = 34.8321, Accuracy = 0.1300 Test Loss = 34.9644, Test Accuracy = 0.1410\n",
      "Iteration 6: Loss = 32.7338, Accuracy = 0.1540 Test Loss = 31.8262, Test Accuracy = 0.1455\n",
      "Iteration 7: Loss = 29.9426, Accuracy = 0.1540 Test Loss = 29.3044, Test Accuracy = 0.1470\n",
      "Iteration 8: Loss = 28.0403, Accuracy = 0.1460 Test Loss = 27.2040, Test Accuracy = 0.1488\n",
      "Iteration 9: Loss = 25.3490, Accuracy = 0.1550 Test Loss = 25.4495, Test Accuracy = 0.1534\n",
      "Iteration 10: Loss = 25.1376, Accuracy = 0.1590 Test Loss = 23.9367, Test Accuracy = 0.1530\n",
      "Iteration 11: Loss = 22.4417, Accuracy = 0.1520 Test Loss = 22.6154, Test Accuracy = 0.1547\n",
      "Iteration 12: Loss = 21.8826, Accuracy = 0.1790 Test Loss = 21.4607, Test Accuracy = 0.1569\n",
      "Iteration 13: Loss = 21.2449, Accuracy = 0.1540 Test Loss = 20.4308, Test Accuracy = 0.1610\n",
      "Iteration 14: Loss = 20.4372, Accuracy = 0.1680 Test Loss = 19.5087, Test Accuracy = 0.1622\n",
      "Iteration 15: Loss = 19.0790, Accuracy = 0.1650 Test Loss = 18.6847, Test Accuracy = 0.1626\n",
      "Iteration 16: Loss = 17.4470, Accuracy = 0.1700 Test Loss = 17.9323, Test Accuracy = 0.1636\n",
      "Iteration 17: Loss = 17.6723, Accuracy = 0.1580 Test Loss = 17.2510, Test Accuracy = 0.1652\n",
      "Iteration 18: Loss = 16.5810, Accuracy = 0.1610 Test Loss = 16.6186, Test Accuracy = 0.1646\n",
      "Iteration 19: Loss = 16.8986, Accuracy = 0.1610 Test Loss = 16.0423, Test Accuracy = 0.1645\n",
      "Iteration 20: Loss = 16.2495, Accuracy = 0.1530 Test Loss = 15.5079, Test Accuracy = 0.1656\n",
      "Iteration 21: Loss = 15.5308, Accuracy = 0.1690 Test Loss = 15.0127, Test Accuracy = 0.1668\n",
      "Iteration 22: Loss = 14.5122, Accuracy = 0.1810 Test Loss = 14.5482, Test Accuracy = 0.1684\n",
      "Iteration 23: Loss = 14.5312, Accuracy = 0.1950 Test Loss = 14.1146, Test Accuracy = 0.1687\n",
      "Iteration 24: Loss = 13.8458, Accuracy = 0.1890 Test Loss = 13.7130, Test Accuracy = 0.1721\n",
      "Iteration 25: Loss = 13.9724, Accuracy = 0.1610 Test Loss = 13.3315, Test Accuracy = 0.1735\n",
      "Iteration 26: Loss = 13.0753, Accuracy = 0.1760 Test Loss = 12.9731, Test Accuracy = 0.1734\n",
      "Iteration 27: Loss = 12.3897, Accuracy = 0.1940 Test Loss = 12.6356, Test Accuracy = 0.1757\n",
      "Iteration 28: Loss = 12.5898, Accuracy = 0.1770 Test Loss = 12.3132, Test Accuracy = 0.1755\n",
      "Iteration 29: Loss = 12.8214, Accuracy = 0.1880 Test Loss = 12.0106, Test Accuracy = 0.1761\n",
      "Iteration 30: Loss = 11.9533, Accuracy = 0.1710 Test Loss = 11.7270, Test Accuracy = 0.1783\n",
      "Iteration 31: Loss = 11.3217, Accuracy = 0.1750 Test Loss = 11.4530, Test Accuracy = 0.1787\n",
      "Iteration 32: Loss = 11.3455, Accuracy = 0.1690 Test Loss = 11.1894, Test Accuracy = 0.1805\n",
      "Iteration 33: Loss = 11.0630, Accuracy = 0.1760 Test Loss = 10.9405, Test Accuracy = 0.1811\n",
      "Iteration 34: Loss = 10.8579, Accuracy = 0.1890 Test Loss = 10.7031, Test Accuracy = 0.1810\n",
      "Iteration 35: Loss = 10.6209, Accuracy = 0.1890 Test Loss = 10.4790, Test Accuracy = 0.1830\n",
      "Iteration 36: Loss = 10.1529, Accuracy = 0.1820 Test Loss = 10.2573, Test Accuracy = 0.1834\n",
      "Iteration 37: Loss = 9.9087, Accuracy = 0.1910 Test Loss = 10.0462, Test Accuracy = 0.1836\n",
      "Iteration 38: Loss = 10.0895, Accuracy = 0.1770 Test Loss = 9.8476, Test Accuracy = 0.1847\n",
      "Iteration 39: Loss = 9.7998, Accuracy = 0.1770 Test Loss = 9.6537, Test Accuracy = 0.1854\n",
      "Iteration 40: Loss = 10.0497, Accuracy = 0.1870 Test Loss = 9.4683, Test Accuracy = 0.1861\n",
      "Iteration 41: Loss = 9.3651, Accuracy = 0.1950 Test Loss = 9.2909, Test Accuracy = 0.1885\n",
      "Iteration 42: Loss = 9.4450, Accuracy = 0.1880 Test Loss = 9.1158, Test Accuracy = 0.1888\n",
      "Iteration 43: Loss = 8.9496, Accuracy = 0.1970 Test Loss = 8.9524, Test Accuracy = 0.1889\n",
      "Iteration 44: Loss = 8.7378, Accuracy = 0.1990 Test Loss = 8.7915, Test Accuracy = 0.1914\n",
      "Iteration 45: Loss = 8.8614, Accuracy = 0.2010 Test Loss = 8.6388, Test Accuracy = 0.1926\n",
      "Iteration 46: Loss = 8.7644, Accuracy = 0.2100 Test Loss = 8.4878, Test Accuracy = 0.1949\n",
      "Iteration 47: Loss = 8.6587, Accuracy = 0.1880 Test Loss = 8.3402, Test Accuracy = 0.1936\n",
      "Iteration 48: Loss = 8.1430, Accuracy = 0.2010 Test Loss = 8.2008, Test Accuracy = 0.1950\n",
      "Iteration 49: Loss = 8.0259, Accuracy = 0.2000 Test Loss = 8.0660, Test Accuracy = 0.1955\n",
      "Iteration 50: Loss = 8.0259, Accuracy = 0.1700 Test Loss = 7.9327, Test Accuracy = 0.1963\n",
      "Iteration 51: Loss = 7.8533, Accuracy = 0.2020 Test Loss = 7.8041, Test Accuracy = 0.1983\n",
      "Iteration 52: Loss = 7.9258, Accuracy = 0.2250 Test Loss = 7.6823, Test Accuracy = 0.1996\n",
      "Iteration 53: Loss = 7.5280, Accuracy = 0.2120 Test Loss = 7.5613, Test Accuracy = 0.2013\n",
      "Iteration 54: Loss = 7.3558, Accuracy = 0.2030 Test Loss = 7.4437, Test Accuracy = 0.2029\n",
      "Iteration 55: Loss = 7.3962, Accuracy = 0.1880 Test Loss = 7.3322, Test Accuracy = 0.2038\n",
      "Iteration 56: Loss = 7.1049, Accuracy = 0.2030 Test Loss = 7.2202, Test Accuracy = 0.2033\n",
      "Iteration 57: Loss = 7.3490, Accuracy = 0.2380 Test Loss = 7.1141, Test Accuracy = 0.2042\n",
      "Iteration 58: Loss = 7.1634, Accuracy = 0.2060 Test Loss = 7.0085, Test Accuracy = 0.2082\n",
      "Iteration 59: Loss = 7.0190, Accuracy = 0.1940 Test Loss = 6.9069, Test Accuracy = 0.2079\n",
      "Iteration 60: Loss = 6.7203, Accuracy = 0.1760 Test Loss = 6.8068, Test Accuracy = 0.2098\n",
      "Iteration 61: Loss = 6.6104, Accuracy = 0.2030 Test Loss = 6.7117, Test Accuracy = 0.2108\n",
      "Iteration 62: Loss = 6.8242, Accuracy = 0.2280 Test Loss = 6.6184, Test Accuracy = 0.2122\n",
      "Iteration 63: Loss = 6.7352, Accuracy = 0.2140 Test Loss = 6.5264, Test Accuracy = 0.2133\n",
      "Iteration 64: Loss = 6.3923, Accuracy = 0.2180 Test Loss = 6.4369, Test Accuracy = 0.2148\n",
      "Iteration 65: Loss = 6.2162, Accuracy = 0.2410 Test Loss = 6.3508, Test Accuracy = 0.2148\n",
      "Iteration 66: Loss = 6.6705, Accuracy = 0.2160 Test Loss = 6.2655, Test Accuracy = 0.2169\n",
      "Iteration 67: Loss = 6.2584, Accuracy = 0.2210 Test Loss = 6.1830, Test Accuracy = 0.2163\n",
      "Iteration 68: Loss = 6.1488, Accuracy = 0.2140 Test Loss = 6.1005, Test Accuracy = 0.2179\n",
      "Iteration 69: Loss = 6.0140, Accuracy = 0.2390 Test Loss = 6.0214, Test Accuracy = 0.2203\n",
      "Iteration 70: Loss = 6.1617, Accuracy = 0.2170 Test Loss = 5.9441, Test Accuracy = 0.2192\n",
      "Iteration 71: Loss = 6.0701, Accuracy = 0.2360 Test Loss = 5.8682, Test Accuracy = 0.2229\n",
      "Iteration 72: Loss = 5.7920, Accuracy = 0.2380 Test Loss = 5.7951, Test Accuracy = 0.2226\n",
      "Iteration 73: Loss = 5.8255, Accuracy = 0.2360 Test Loss = 5.7233, Test Accuracy = 0.2240\n",
      "Iteration 74: Loss = 5.7040, Accuracy = 0.2180 Test Loss = 5.6531, Test Accuracy = 0.2238\n",
      "Iteration 75: Loss = 5.4890, Accuracy = 0.2090 Test Loss = 5.5840, Test Accuracy = 0.2252\n",
      "Iteration 76: Loss = 5.5899, Accuracy = 0.1910 Test Loss = 5.5164, Test Accuracy = 0.2265\n",
      "Iteration 77: Loss = 5.5681, Accuracy = 0.2230 Test Loss = 5.4493, Test Accuracy = 0.2276\n",
      "Iteration 78: Loss = 5.2941, Accuracy = 0.2430 Test Loss = 5.3854, Test Accuracy = 0.2298\n",
      "Iteration 79: Loss = 5.3667, Accuracy = 0.2450 Test Loss = 5.3221, Test Accuracy = 0.2294\n",
      "Iteration 80: Loss = 5.3888, Accuracy = 0.2360 Test Loss = 5.2594, Test Accuracy = 0.2301\n",
      "Iteration 81: Loss = 4.9741, Accuracy = 0.2280 Test Loss = 5.1991, Test Accuracy = 0.2311\n",
      "Iteration 82: Loss = 5.2026, Accuracy = 0.2330 Test Loss = 5.1393, Test Accuracy = 0.2325\n",
      "Iteration 83: Loss = 4.8439, Accuracy = 0.2390 Test Loss = 5.0826, Test Accuracy = 0.2323\n",
      "Iteration 84: Loss = 4.9944, Accuracy = 0.2400 Test Loss = 5.0233, Test Accuracy = 0.2339\n",
      "Iteration 85: Loss = 5.2268, Accuracy = 0.2310 Test Loss = 4.9671, Test Accuracy = 0.2343\n",
      "Iteration 86: Loss = 5.1587, Accuracy = 0.2610 Test Loss = 4.9126, Test Accuracy = 0.2374\n",
      "Iteration 87: Loss = 5.1921, Accuracy = 0.2400 Test Loss = 4.8594, Test Accuracy = 0.2383\n",
      "Iteration 88: Loss = 4.8116, Accuracy = 0.2520 Test Loss = 4.8052, Test Accuracy = 0.2369\n",
      "Iteration 89: Loss = 4.8669, Accuracy = 0.2420 Test Loss = 4.7538, Test Accuracy = 0.2406\n",
      "Iteration 90: Loss = 4.8470, Accuracy = 0.2340 Test Loss = 4.7035, Test Accuracy = 0.2396\n",
      "Iteration 91: Loss = 4.6691, Accuracy = 0.2450 Test Loss = 4.6534, Test Accuracy = 0.2415\n",
      "Iteration 92: Loss = 4.8049, Accuracy = 0.2670 Test Loss = 4.6044, Test Accuracy = 0.2439\n",
      "Iteration 93: Loss = 4.7590, Accuracy = 0.2450 Test Loss = 4.5561, Test Accuracy = 0.2441\n",
      "Iteration 94: Loss = 4.5926, Accuracy = 0.2300 Test Loss = 4.5090, Test Accuracy = 0.2449\n",
      "Iteration 95: Loss = 4.5989, Accuracy = 0.2390 Test Loss = 4.4635, Test Accuracy = 0.2453\n",
      "Iteration 96: Loss = 4.6240, Accuracy = 0.2550 Test Loss = 4.4176, Test Accuracy = 0.2476\n",
      "Iteration 97: Loss = 4.5925, Accuracy = 0.2500 Test Loss = 4.3722, Test Accuracy = 0.2480\n",
      "Iteration 98: Loss = 4.2380, Accuracy = 0.2630 Test Loss = 4.3286, Test Accuracy = 0.2515\n",
      "Iteration 99: Loss = 4.4883, Accuracy = 0.2760 Test Loss = 4.2858, Test Accuracy = 0.2524\n",
      "Iteration 100: Loss = 4.2839, Accuracy = 0.2540 Test Loss = 4.2433, Test Accuracy = 0.2532\n",
      "Iteration 101: Loss = 4.3672, Accuracy = 0.2560 Test Loss = 4.2013, Test Accuracy = 0.2545\n",
      "Iteration 102: Loss = 4.1659, Accuracy = 0.2650 Test Loss = 4.1596, Test Accuracy = 0.2550\n",
      "Iteration 103: Loss = 4.2394, Accuracy = 0.2740 Test Loss = 4.1197, Test Accuracy = 0.2556\n",
      "Iteration 104: Loss = 4.0257, Accuracy = 0.2630 Test Loss = 4.0811, Test Accuracy = 0.2581\n",
      "Iteration 105: Loss = 4.1776, Accuracy = 0.2690 Test Loss = 4.0414, Test Accuracy = 0.2596\n",
      "Iteration 106: Loss = 3.9030, Accuracy = 0.2780 Test Loss = 4.0021, Test Accuracy = 0.2618\n",
      "Iteration 107: Loss = 4.0854, Accuracy = 0.2700 Test Loss = 3.9643, Test Accuracy = 0.2625\n",
      "Iteration 108: Loss = 3.9408, Accuracy = 0.2760 Test Loss = 3.9274, Test Accuracy = 0.2631\n",
      "Iteration 109: Loss = 4.0676, Accuracy = 0.2430 Test Loss = 3.8912, Test Accuracy = 0.2638\n",
      "Iteration 110: Loss = 3.9365, Accuracy = 0.2580 Test Loss = 3.8550, Test Accuracy = 0.2651\n",
      "Iteration 111: Loss = 3.9268, Accuracy = 0.2720 Test Loss = 3.8210, Test Accuracy = 0.2657\n",
      "Iteration 112: Loss = 3.8908, Accuracy = 0.2650 Test Loss = 3.7855, Test Accuracy = 0.2678\n",
      "Iteration 113: Loss = 3.7444, Accuracy = 0.2740 Test Loss = 3.7525, Test Accuracy = 0.2666\n",
      "Iteration 114: Loss = 3.9141, Accuracy = 0.2550 Test Loss = 3.7174, Test Accuracy = 0.2699\n",
      "Iteration 115: Loss = 3.6556, Accuracy = 0.2670 Test Loss = 3.6851, Test Accuracy = 0.2698\n",
      "Iteration 116: Loss = 3.6663, Accuracy = 0.2820 Test Loss = 3.6524, Test Accuracy = 0.2720\n",
      "Iteration 117: Loss = 3.4903, Accuracy = 0.3030 Test Loss = 3.6196, Test Accuracy = 0.2736\n",
      "Iteration 118: Loss = 3.7067, Accuracy = 0.2680 Test Loss = 3.5879, Test Accuracy = 0.2738\n",
      "Iteration 119: Loss = 3.7114, Accuracy = 0.2690 Test Loss = 3.5578, Test Accuracy = 0.2737\n",
      "Iteration 120: Loss = 3.5351, Accuracy = 0.2810 Test Loss = 3.5263, Test Accuracy = 0.2780\n",
      "Iteration 121: Loss = 3.5531, Accuracy = 0.2740 Test Loss = 3.4963, Test Accuracy = 0.2781\n",
      "Iteration 122: Loss = 3.3584, Accuracy = 0.2650 Test Loss = 3.4656, Test Accuracy = 0.2785\n",
      "Iteration 123: Loss = 3.3312, Accuracy = 0.2990 Test Loss = 3.4368, Test Accuracy = 0.2782\n",
      "Iteration 124: Loss = 3.3198, Accuracy = 0.2970 Test Loss = 3.4072, Test Accuracy = 0.2810\n",
      "Iteration 125: Loss = 3.2677, Accuracy = 0.2690 Test Loss = 3.3796, Test Accuracy = 0.2827\n",
      "Iteration 126: Loss = 3.3395, Accuracy = 0.2650 Test Loss = 3.3519, Test Accuracy = 0.2842\n",
      "Iteration 127: Loss = 3.3806, Accuracy = 0.2870 Test Loss = 3.3235, Test Accuracy = 0.2845\n",
      "Iteration 128: Loss = 3.2310, Accuracy = 0.2860 Test Loss = 3.2957, Test Accuracy = 0.2855\n",
      "Iteration 129: Loss = 3.3039, Accuracy = 0.2750 Test Loss = 3.2707, Test Accuracy = 0.2857\n",
      "Iteration 130: Loss = 3.2996, Accuracy = 0.2970 Test Loss = 3.2427, Test Accuracy = 0.2878\n",
      "Iteration 131: Loss = 3.2079, Accuracy = 0.2860 Test Loss = 3.2167, Test Accuracy = 0.2892\n",
      "Iteration 132: Loss = 3.1051, Accuracy = 0.3010 Test Loss = 3.1912, Test Accuracy = 0.2916\n",
      "Iteration 133: Loss = 3.1871, Accuracy = 0.3070 Test Loss = 3.1661, Test Accuracy = 0.2926\n",
      "Iteration 134: Loss = 3.1448, Accuracy = 0.2860 Test Loss = 3.1410, Test Accuracy = 0.2916\n",
      "Iteration 135: Loss = 3.2447, Accuracy = 0.2820 Test Loss = 3.1168, Test Accuracy = 0.2933\n",
      "Iteration 136: Loss = 3.2261, Accuracy = 0.2780 Test Loss = 3.0921, Test Accuracy = 0.2943\n",
      "Iteration 137: Loss = 3.0652, Accuracy = 0.2910 Test Loss = 3.0673, Test Accuracy = 0.2967\n",
      "Iteration 138: Loss = 3.0888, Accuracy = 0.2860 Test Loss = 3.0431, Test Accuracy = 0.2974\n",
      "Iteration 139: Loss = 2.9171, Accuracy = 0.2980 Test Loss = 3.0208, Test Accuracy = 0.3003\n",
      "Iteration 140: Loss = 2.9307, Accuracy = 0.3160 Test Loss = 2.9973, Test Accuracy = 0.3000\n",
      "Iteration 141: Loss = 3.0238, Accuracy = 0.2950 Test Loss = 2.9736, Test Accuracy = 0.3007\n",
      "Iteration 142: Loss = 3.0109, Accuracy = 0.2940 Test Loss = 2.9516, Test Accuracy = 0.3029\n",
      "Iteration 143: Loss = 2.8918, Accuracy = 0.2980 Test Loss = 2.9306, Test Accuracy = 0.3022\n",
      "Iteration 144: Loss = 2.8325, Accuracy = 0.2880 Test Loss = 2.9073, Test Accuracy = 0.3049\n",
      "Iteration 145: Loss = 2.7915, Accuracy = 0.3300 Test Loss = 2.8861, Test Accuracy = 0.3046\n",
      "Iteration 146: Loss = 2.9207, Accuracy = 0.3220 Test Loss = 2.8647, Test Accuracy = 0.3070\n",
      "Iteration 147: Loss = 2.8086, Accuracy = 0.3230 Test Loss = 2.8437, Test Accuracy = 0.3091\n",
      "Iteration 148: Loss = 2.9624, Accuracy = 0.3030 Test Loss = 2.8226, Test Accuracy = 0.3087\n",
      "Iteration 149: Loss = 2.9761, Accuracy = 0.3120 Test Loss = 2.8021, Test Accuracy = 0.3114\n",
      "Iteration 150: Loss = 2.8340, Accuracy = 0.3040 Test Loss = 2.7821, Test Accuracy = 0.3097\n",
      "Iteration 151: Loss = 2.7913, Accuracy = 0.3250 Test Loss = 2.7620, Test Accuracy = 0.3123\n",
      "Iteration 152: Loss = 2.7172, Accuracy = 0.3060 Test Loss = 2.7425, Test Accuracy = 0.3144\n",
      "Iteration 153: Loss = 2.6932, Accuracy = 0.3140 Test Loss = 2.7229, Test Accuracy = 0.3150\n",
      "Iteration 154: Loss = 2.8004, Accuracy = 0.3240 Test Loss = 2.7039, Test Accuracy = 0.3165\n",
      "Iteration 155: Loss = 2.7052, Accuracy = 0.3180 Test Loss = 2.6846, Test Accuracy = 0.3167\n",
      "Iteration 156: Loss = 2.6544, Accuracy = 0.2990 Test Loss = 2.6662, Test Accuracy = 0.3168\n",
      "Iteration 157: Loss = 2.4645, Accuracy = 0.3420 Test Loss = 2.6476, Test Accuracy = 0.3186\n",
      "Iteration 158: Loss = 2.6697, Accuracy = 0.3120 Test Loss = 2.6289, Test Accuracy = 0.3209\n",
      "Iteration 159: Loss = 2.6459, Accuracy = 0.3020 Test Loss = 2.6109, Test Accuracy = 0.3186\n",
      "Iteration 160: Loss = 2.5940, Accuracy = 0.3580 Test Loss = 2.5931, Test Accuracy = 0.3220\n",
      "Iteration 161: Loss = 2.6176, Accuracy = 0.3190 Test Loss = 2.5745, Test Accuracy = 0.3224\n",
      "Iteration 162: Loss = 2.6182, Accuracy = 0.3180 Test Loss = 2.5574, Test Accuracy = 0.3256\n",
      "Iteration 163: Loss = 2.4992, Accuracy = 0.3480 Test Loss = 2.5399, Test Accuracy = 0.3262\n",
      "Iteration 164: Loss = 2.4384, Accuracy = 0.3180 Test Loss = 2.5229, Test Accuracy = 0.3271\n",
      "Iteration 165: Loss = 2.6594, Accuracy = 0.2840 Test Loss = 2.5061, Test Accuracy = 0.3277\n",
      "Iteration 166: Loss = 2.5281, Accuracy = 0.3400 Test Loss = 2.4894, Test Accuracy = 0.3313\n",
      "Iteration 167: Loss = 2.4793, Accuracy = 0.3400 Test Loss = 2.4729, Test Accuracy = 0.3303\n",
      "Iteration 168: Loss = 2.3196, Accuracy = 0.3620 Test Loss = 2.4572, Test Accuracy = 0.3331\n",
      "Iteration 169: Loss = 2.5048, Accuracy = 0.3320 Test Loss = 2.4406, Test Accuracy = 0.3343\n",
      "Iteration 170: Loss = 2.4184, Accuracy = 0.3470 Test Loss = 2.4250, Test Accuracy = 0.3351\n",
      "Iteration 171: Loss = 2.4859, Accuracy = 0.3350 Test Loss = 2.4095, Test Accuracy = 0.3366\n",
      "Iteration 172: Loss = 2.4207, Accuracy = 0.3150 Test Loss = 2.3940, Test Accuracy = 0.3381\n",
      "Iteration 173: Loss = 2.4257, Accuracy = 0.3260 Test Loss = 2.3786, Test Accuracy = 0.3380\n",
      "Iteration 174: Loss = 2.3570, Accuracy = 0.3460 Test Loss = 2.3632, Test Accuracy = 0.3393\n",
      "Iteration 175: Loss = 2.3610, Accuracy = 0.3360 Test Loss = 2.3488, Test Accuracy = 0.3413\n",
      "Iteration 176: Loss = 2.4025, Accuracy = 0.3230 Test Loss = 2.3332, Test Accuracy = 0.3405\n",
      "Iteration 177: Loss = 2.3498, Accuracy = 0.3560 Test Loss = 2.3189, Test Accuracy = 0.3431\n",
      "Iteration 178: Loss = 2.2783, Accuracy = 0.3500 Test Loss = 2.3043, Test Accuracy = 0.3429\n",
      "Iteration 179: Loss = 2.3103, Accuracy = 0.3490 Test Loss = 2.2902, Test Accuracy = 0.3449\n",
      "Iteration 180: Loss = 2.4344, Accuracy = 0.3410 Test Loss = 2.2766, Test Accuracy = 0.3463\n",
      "Iteration 181: Loss = 2.2838, Accuracy = 0.3720 Test Loss = 2.2627, Test Accuracy = 0.3457\n",
      "Iteration 182: Loss = 2.3300, Accuracy = 0.3310 Test Loss = 2.2480, Test Accuracy = 0.3470\n",
      "Iteration 183: Loss = 2.2253, Accuracy = 0.3460 Test Loss = 2.2339, Test Accuracy = 0.3492\n",
      "Iteration 184: Loss = 2.1909, Accuracy = 0.3520 Test Loss = 2.2206, Test Accuracy = 0.3507\n",
      "Iteration 185: Loss = 2.2097, Accuracy = 0.3390 Test Loss = 2.2073, Test Accuracy = 0.3522\n",
      "Iteration 186: Loss = 2.2874, Accuracy = 0.3360 Test Loss = 2.1939, Test Accuracy = 0.3540\n",
      "Iteration 187: Loss = 2.2634, Accuracy = 0.3410 Test Loss = 2.1809, Test Accuracy = 0.3537\n",
      "Iteration 188: Loss = 2.1302, Accuracy = 0.3470 Test Loss = 2.1679, Test Accuracy = 0.3553\n",
      "Iteration 189: Loss = 2.1420, Accuracy = 0.3330 Test Loss = 2.1546, Test Accuracy = 0.3557\n",
      "Iteration 190: Loss = 2.0989, Accuracy = 0.3640 Test Loss = 2.1422, Test Accuracy = 0.3585\n",
      "Iteration 191: Loss = 2.2081, Accuracy = 0.3640 Test Loss = 2.1294, Test Accuracy = 0.3593\n",
      "Iteration 192: Loss = 2.1099, Accuracy = 0.3670 Test Loss = 2.1176, Test Accuracy = 0.3616\n",
      "Iteration 193: Loss = 2.1145, Accuracy = 0.3530 Test Loss = 2.1051, Test Accuracy = 0.3613\n",
      "Iteration 194: Loss = 2.1075, Accuracy = 0.3600 Test Loss = 2.0927, Test Accuracy = 0.3626\n",
      "Iteration 195: Loss = 2.0309, Accuracy = 0.4110 Test Loss = 2.0803, Test Accuracy = 0.3629\n",
      "Iteration 196: Loss = 2.2269, Accuracy = 0.3590 Test Loss = 2.0687, Test Accuracy = 0.3648\n",
      "Iteration 197: Loss = 2.1550, Accuracy = 0.3640 Test Loss = 2.0571, Test Accuracy = 0.3651\n",
      "Iteration 198: Loss = 2.0608, Accuracy = 0.3750 Test Loss = 2.0447, Test Accuracy = 0.3664\n",
      "Iteration 199: Loss = 2.0376, Accuracy = 0.3630 Test Loss = 2.0334, Test Accuracy = 0.3663\n",
      "Iteration 200: Loss = 2.1308, Accuracy = 0.3680 Test Loss = 2.0222, Test Accuracy = 0.3671\n",
      "Iteration 201: Loss = 1.9967, Accuracy = 0.3540 Test Loss = 2.0104, Test Accuracy = 0.3694\n",
      "Iteration 202: Loss = 2.0688, Accuracy = 0.3790 Test Loss = 1.9997, Test Accuracy = 0.3706\n",
      "Iteration 203: Loss = 2.0537, Accuracy = 0.3780 Test Loss = 1.9881, Test Accuracy = 0.3711\n",
      "Iteration 204: Loss = 2.0252, Accuracy = 0.4090 Test Loss = 1.9773, Test Accuracy = 0.3722\n",
      "Iteration 205: Loss = 1.8306, Accuracy = 0.3900 Test Loss = 1.9662, Test Accuracy = 0.3737\n",
      "Iteration 206: Loss = 2.0621, Accuracy = 0.3890 Test Loss = 1.9554, Test Accuracy = 0.3739\n",
      "Iteration 207: Loss = 2.0279, Accuracy = 0.3850 Test Loss = 1.9449, Test Accuracy = 0.3741\n",
      "Iteration 208: Loss = 1.9596, Accuracy = 0.3740 Test Loss = 1.9350, Test Accuracy = 0.3756\n",
      "Iteration 209: Loss = 1.8676, Accuracy = 0.3630 Test Loss = 1.9240, Test Accuracy = 0.3784\n",
      "Iteration 210: Loss = 1.8734, Accuracy = 0.3700 Test Loss = 1.9140, Test Accuracy = 0.3774\n",
      "Iteration 211: Loss = 1.8545, Accuracy = 0.3950 Test Loss = 1.9037, Test Accuracy = 0.3789\n",
      "Iteration 212: Loss = 1.8484, Accuracy = 0.4080 Test Loss = 1.8931, Test Accuracy = 0.3803\n",
      "Iteration 213: Loss = 1.8422, Accuracy = 0.3970 Test Loss = 1.8830, Test Accuracy = 0.3806\n",
      "Iteration 214: Loss = 1.8384, Accuracy = 0.3870 Test Loss = 1.8731, Test Accuracy = 0.3829\n",
      "Iteration 215: Loss = 1.8616, Accuracy = 0.3910 Test Loss = 1.8635, Test Accuracy = 0.3845\n",
      "Iteration 216: Loss = 1.9123, Accuracy = 0.4010 Test Loss = 1.8535, Test Accuracy = 0.3833\n",
      "Iteration 217: Loss = 1.8630, Accuracy = 0.3700 Test Loss = 1.8436, Test Accuracy = 0.3828\n",
      "Iteration 218: Loss = 1.8545, Accuracy = 0.4100 Test Loss = 1.8340, Test Accuracy = 0.3851\n",
      "Iteration 219: Loss = 1.9549, Accuracy = 0.3640 Test Loss = 1.8245, Test Accuracy = 0.3860\n",
      "Iteration 220: Loss = 1.7973, Accuracy = 0.3800 Test Loss = 1.8150, Test Accuracy = 0.3886\n",
      "Iteration 221: Loss = 1.8373, Accuracy = 0.3680 Test Loss = 1.8060, Test Accuracy = 0.3879\n",
      "Iteration 222: Loss = 1.7622, Accuracy = 0.3810 Test Loss = 1.7970, Test Accuracy = 0.3893\n",
      "Iteration 223: Loss = 1.8276, Accuracy = 0.3860 Test Loss = 1.7880, Test Accuracy = 0.3906\n",
      "Iteration 224: Loss = 1.7397, Accuracy = 0.4230 Test Loss = 1.7783, Test Accuracy = 0.3915\n",
      "Iteration 225: Loss = 1.8086, Accuracy = 0.3710 Test Loss = 1.7694, Test Accuracy = 0.3947\n",
      "Iteration 226: Loss = 1.7947, Accuracy = 0.3950 Test Loss = 1.7606, Test Accuracy = 0.3943\n",
      "Iteration 227: Loss = 1.7436, Accuracy = 0.3960 Test Loss = 1.7518, Test Accuracy = 0.3966\n",
      "Iteration 228: Loss = 1.8081, Accuracy = 0.3960 Test Loss = 1.7434, Test Accuracy = 0.3984\n",
      "Iteration 229: Loss = 1.7723, Accuracy = 0.4000 Test Loss = 1.7343, Test Accuracy = 0.3986\n",
      "Iteration 230: Loss = 1.8345, Accuracy = 0.3900 Test Loss = 1.7260, Test Accuracy = 0.4004\n",
      "Iteration 231: Loss = 1.7822, Accuracy = 0.3930 Test Loss = 1.7173, Test Accuracy = 0.4017\n",
      "Iteration 232: Loss = 1.7391, Accuracy = 0.4180 Test Loss = 1.7089, Test Accuracy = 0.4020\n",
      "Iteration 233: Loss = 1.7363, Accuracy = 0.3950 Test Loss = 1.7007, Test Accuracy = 0.4037\n",
      "Iteration 234: Loss = 1.6740, Accuracy = 0.4270 Test Loss = 1.6922, Test Accuracy = 0.4058\n",
      "Iteration 235: Loss = 1.7617, Accuracy = 0.3970 Test Loss = 1.6838, Test Accuracy = 0.4058\n",
      "Iteration 236: Loss = 1.7036, Accuracy = 0.4140 Test Loss = 1.6762, Test Accuracy = 0.4062\n",
      "Iteration 237: Loss = 1.6538, Accuracy = 0.4040 Test Loss = 1.6678, Test Accuracy = 0.4067\n",
      "Iteration 238: Loss = 1.6107, Accuracy = 0.4170 Test Loss = 1.6605, Test Accuracy = 0.4079\n",
      "Iteration 239: Loss = 1.6841, Accuracy = 0.4320 Test Loss = 1.6522, Test Accuracy = 0.4088\n",
      "Iteration 240: Loss = 1.6701, Accuracy = 0.4280 Test Loss = 1.6443, Test Accuracy = 0.4106\n",
      "Iteration 241: Loss = 1.6530, Accuracy = 0.4370 Test Loss = 1.6374, Test Accuracy = 0.4101\n",
      "Iteration 242: Loss = 1.6488, Accuracy = 0.3990 Test Loss = 1.6293, Test Accuracy = 0.4111\n",
      "Iteration 243: Loss = 1.6578, Accuracy = 0.4210 Test Loss = 1.6216, Test Accuracy = 0.4135\n",
      "Iteration 244: Loss = 1.6087, Accuracy = 0.4210 Test Loss = 1.6143, Test Accuracy = 0.4144\n",
      "Iteration 245: Loss = 1.5450, Accuracy = 0.4330 Test Loss = 1.6067, Test Accuracy = 0.4149\n",
      "Iteration 246: Loss = 1.5690, Accuracy = 0.4390 Test Loss = 1.5989, Test Accuracy = 0.4169\n",
      "Iteration 247: Loss = 1.6145, Accuracy = 0.4170 Test Loss = 1.5920, Test Accuracy = 0.4174\n",
      "Iteration 248: Loss = 1.5544, Accuracy = 0.4390 Test Loss = 1.5843, Test Accuracy = 0.4187\n",
      "Iteration 249: Loss = 1.5472, Accuracy = 0.3960 Test Loss = 1.5769, Test Accuracy = 0.4210\n",
      "Iteration 250: Loss = 1.5634, Accuracy = 0.4250 Test Loss = 1.5698, Test Accuracy = 0.4207\n",
      "Iteration 251: Loss = 1.5137, Accuracy = 0.4130 Test Loss = 1.5624, Test Accuracy = 0.4226\n",
      "Iteration 252: Loss = 1.6867, Accuracy = 0.4040 Test Loss = 1.5555, Test Accuracy = 0.4230\n",
      "Iteration 253: Loss = 1.5685, Accuracy = 0.4280 Test Loss = 1.5485, Test Accuracy = 0.4259\n",
      "Iteration 254: Loss = 1.4792, Accuracy = 0.4450 Test Loss = 1.5413, Test Accuracy = 0.4247\n",
      "Iteration 255: Loss = 1.4603, Accuracy = 0.4130 Test Loss = 1.5348, Test Accuracy = 0.4266\n",
      "Iteration 256: Loss = 1.4923, Accuracy = 0.4290 Test Loss = 1.5282, Test Accuracy = 0.4268\n",
      "Iteration 257: Loss = 1.5756, Accuracy = 0.4020 Test Loss = 1.5209, Test Accuracy = 0.4281\n",
      "Iteration 258: Loss = 1.5214, Accuracy = 0.4430 Test Loss = 1.5149, Test Accuracy = 0.4304\n",
      "Iteration 259: Loss = 1.4524, Accuracy = 0.4370 Test Loss = 1.5079, Test Accuracy = 0.4307\n",
      "Iteration 260: Loss = 1.5837, Accuracy = 0.4370 Test Loss = 1.5016, Test Accuracy = 0.4324\n",
      "Iteration 261: Loss = 1.4415, Accuracy = 0.4510 Test Loss = 1.4949, Test Accuracy = 0.4321\n",
      "Iteration 262: Loss = 1.4478, Accuracy = 0.4240 Test Loss = 1.4881, Test Accuracy = 0.4343\n",
      "Iteration 263: Loss = 1.4364, Accuracy = 0.4360 Test Loss = 1.4821, Test Accuracy = 0.4339\n",
      "Iteration 264: Loss = 1.4339, Accuracy = 0.4520 Test Loss = 1.4756, Test Accuracy = 0.4372\n",
      "Iteration 265: Loss = 1.5567, Accuracy = 0.4500 Test Loss = 1.4696, Test Accuracy = 0.4355\n",
      "Iteration 266: Loss = 1.4846, Accuracy = 0.4320 Test Loss = 1.4631, Test Accuracy = 0.4356\n",
      "Iteration 267: Loss = 1.4139, Accuracy = 0.4190 Test Loss = 1.4569, Test Accuracy = 0.4384\n",
      "Iteration 268: Loss = 1.5676, Accuracy = 0.4280 Test Loss = 1.4506, Test Accuracy = 0.4398\n",
      "Iteration 269: Loss = 1.5591, Accuracy = 0.4530 Test Loss = 1.4450, Test Accuracy = 0.4390\n",
      "Iteration 270: Loss = 1.4557, Accuracy = 0.4390 Test Loss = 1.4387, Test Accuracy = 0.4405\n",
      "Iteration 271: Loss = 1.4342, Accuracy = 0.4530 Test Loss = 1.4324, Test Accuracy = 0.4419\n",
      "Iteration 272: Loss = 1.4422, Accuracy = 0.4280 Test Loss = 1.4265, Test Accuracy = 0.4423\n",
      "Iteration 273: Loss = 1.4300, Accuracy = 0.4520 Test Loss = 1.4208, Test Accuracy = 0.4439\n",
      "Iteration 274: Loss = 1.3998, Accuracy = 0.4350 Test Loss = 1.4147, Test Accuracy = 0.4442\n",
      "Iteration 275: Loss = 1.4138, Accuracy = 0.4570 Test Loss = 1.4090, Test Accuracy = 0.4440\n",
      "Iteration 276: Loss = 1.4470, Accuracy = 0.4460 Test Loss = 1.4032, Test Accuracy = 0.4479\n",
      "Iteration 277: Loss = 1.3163, Accuracy = 0.4480 Test Loss = 1.3972, Test Accuracy = 0.4497\n",
      "Iteration 278: Loss = 1.4247, Accuracy = 0.4570 Test Loss = 1.3915, Test Accuracy = 0.4482\n",
      "Iteration 279: Loss = 1.3910, Accuracy = 0.4530 Test Loss = 1.3858, Test Accuracy = 0.4516\n",
      "Iteration 280: Loss = 1.3839, Accuracy = 0.4670 Test Loss = 1.3805, Test Accuracy = 0.4541\n",
      "Iteration 281: Loss = 1.4915, Accuracy = 0.4510 Test Loss = 1.3749, Test Accuracy = 0.4508\n",
      "Iteration 282: Loss = 1.3765, Accuracy = 0.4700 Test Loss = 1.3694, Test Accuracy = 0.4535\n",
      "Iteration 283: Loss = 1.3242, Accuracy = 0.4730 Test Loss = 1.3639, Test Accuracy = 0.4555\n",
      "Iteration 284: Loss = 1.3923, Accuracy = 0.4380 Test Loss = 1.3584, Test Accuracy = 0.4569\n",
      "Iteration 285: Loss = 1.3824, Accuracy = 0.4320 Test Loss = 1.3531, Test Accuracy = 0.4578\n",
      "Iteration 286: Loss = 1.4256, Accuracy = 0.4410 Test Loss = 1.3478, Test Accuracy = 0.4612\n",
      "Iteration 287: Loss = 1.4462, Accuracy = 0.4590 Test Loss = 1.3425, Test Accuracy = 0.4604\n",
      "Iteration 288: Loss = 1.3484, Accuracy = 0.4470 Test Loss = 1.3373, Test Accuracy = 0.4612\n",
      "Iteration 289: Loss = 1.3325, Accuracy = 0.4500 Test Loss = 1.3322, Test Accuracy = 0.4603\n",
      "Iteration 290: Loss = 1.3073, Accuracy = 0.4430 Test Loss = 1.3270, Test Accuracy = 0.4605\n",
      "Iteration 291: Loss = 1.2547, Accuracy = 0.4810 Test Loss = 1.3217, Test Accuracy = 0.4634\n",
      "Iteration 292: Loss = 1.3086, Accuracy = 0.4450 Test Loss = 1.3167, Test Accuracy = 0.4643\n",
      "Iteration 293: Loss = 1.3931, Accuracy = 0.4600 Test Loss = 1.3113, Test Accuracy = 0.4650\n",
      "Iteration 294: Loss = 1.2998, Accuracy = 0.4950 Test Loss = 1.3065, Test Accuracy = 0.4641\n",
      "Iteration 295: Loss = 1.3523, Accuracy = 0.4600 Test Loss = 1.3016, Test Accuracy = 0.4674\n",
      "Iteration 296: Loss = 1.2668, Accuracy = 0.4870 Test Loss = 1.2964, Test Accuracy = 0.4679\n",
      "Iteration 297: Loss = 1.3165, Accuracy = 0.4370 Test Loss = 1.2919, Test Accuracy = 0.4682\n",
      "Iteration 298: Loss = 1.3264, Accuracy = 0.4730 Test Loss = 1.2867, Test Accuracy = 0.4674\n",
      "Iteration 299: Loss = 1.2614, Accuracy = 0.4590 Test Loss = 1.2819, Test Accuracy = 0.4695\n",
      "Iteration 300: Loss = 1.2213, Accuracy = 0.4700 Test Loss = 1.2769, Test Accuracy = 0.4709\n",
      "Iteration 301: Loss = 1.3399, Accuracy = 0.4710 Test Loss = 1.2725, Test Accuracy = 0.4718\n",
      "Iteration 302: Loss = 1.2639, Accuracy = 0.4920 Test Loss = 1.2680, Test Accuracy = 0.4716\n",
      "Iteration 303: Loss = 1.1790, Accuracy = 0.4860 Test Loss = 1.2628, Test Accuracy = 0.4729\n",
      "Iteration 304: Loss = 1.3066, Accuracy = 0.4790 Test Loss = 1.2580, Test Accuracy = 0.4739\n",
      "Iteration 305: Loss = 1.2971, Accuracy = 0.4830 Test Loss = 1.2538, Test Accuracy = 0.4737\n",
      "Iteration 306: Loss = 1.2107, Accuracy = 0.4720 Test Loss = 1.2488, Test Accuracy = 0.4759\n",
      "Iteration 307: Loss = 1.2863, Accuracy = 0.4820 Test Loss = 1.2443, Test Accuracy = 0.4772\n",
      "Iteration 308: Loss = 1.1850, Accuracy = 0.4660 Test Loss = 1.2398, Test Accuracy = 0.4774\n",
      "Iteration 309: Loss = 1.2013, Accuracy = 0.4920 Test Loss = 1.2355, Test Accuracy = 0.4783\n",
      "Iteration 310: Loss = 1.2189, Accuracy = 0.4620 Test Loss = 1.2307, Test Accuracy = 0.4794\n",
      "Iteration 311: Loss = 1.3220, Accuracy = 0.4600 Test Loss = 1.2269, Test Accuracy = 0.4808\n",
      "Iteration 312: Loss = 1.2160, Accuracy = 0.4830 Test Loss = 1.2225, Test Accuracy = 0.4830\n",
      "Iteration 313: Loss = 1.2369, Accuracy = 0.4880 Test Loss = 1.2178, Test Accuracy = 0.4831\n",
      "Iteration 314: Loss = 1.2630, Accuracy = 0.4930 Test Loss = 1.2134, Test Accuracy = 0.4838\n",
      "Iteration 315: Loss = 1.2475, Accuracy = 0.4650 Test Loss = 1.2094, Test Accuracy = 0.4849\n",
      "Iteration 316: Loss = 1.1849, Accuracy = 0.4870 Test Loss = 1.2050, Test Accuracy = 0.4872\n",
      "Iteration 317: Loss = 1.1900, Accuracy = 0.4820 Test Loss = 1.2005, Test Accuracy = 0.4870\n",
      "Iteration 318: Loss = 1.1560, Accuracy = 0.5090 Test Loss = 1.1964, Test Accuracy = 0.4878\n",
      "Iteration 319: Loss = 1.2123, Accuracy = 0.4980 Test Loss = 1.1925, Test Accuracy = 0.4881\n",
      "Iteration 320: Loss = 1.2451, Accuracy = 0.4880 Test Loss = 1.1883, Test Accuracy = 0.4890\n",
      "Iteration 321: Loss = 1.1080, Accuracy = 0.5110 Test Loss = 1.1840, Test Accuracy = 0.4884\n",
      "Iteration 322: Loss = 1.2200, Accuracy = 0.4860 Test Loss = 1.1801, Test Accuracy = 0.4918\n",
      "Iteration 323: Loss = 1.2123, Accuracy = 0.4940 Test Loss = 1.1757, Test Accuracy = 0.4896\n",
      "Iteration 324: Loss = 1.1123, Accuracy = 0.5030 Test Loss = 1.1719, Test Accuracy = 0.4931\n",
      "Iteration 325: Loss = 1.1523, Accuracy = 0.5030 Test Loss = 1.1680, Test Accuracy = 0.4936\n",
      "Iteration 326: Loss = 1.1229, Accuracy = 0.5070 Test Loss = 1.1636, Test Accuracy = 0.4948\n",
      "Iteration 327: Loss = 1.1350, Accuracy = 0.4700 Test Loss = 1.1598, Test Accuracy = 0.4955\n",
      "Iteration 328: Loss = 1.2487, Accuracy = 0.4760 Test Loss = 1.1557, Test Accuracy = 0.4960\n",
      "Iteration 329: Loss = 1.1817, Accuracy = 0.4870 Test Loss = 1.1526, Test Accuracy = 0.4979\n",
      "Iteration 330: Loss = 1.2280, Accuracy = 0.4950 Test Loss = 1.1484, Test Accuracy = 0.4967\n",
      "Iteration 331: Loss = 1.2542, Accuracy = 0.4900 Test Loss = 1.1446, Test Accuracy = 0.4990\n",
      "Iteration 332: Loss = 1.2131, Accuracy = 0.4900 Test Loss = 1.1404, Test Accuracy = 0.5009\n",
      "Iteration 333: Loss = 1.1818, Accuracy = 0.5020 Test Loss = 1.1368, Test Accuracy = 0.5005\n",
      "Iteration 334: Loss = 1.1296, Accuracy = 0.5260 Test Loss = 1.1328, Test Accuracy = 0.5015\n",
      "Iteration 335: Loss = 1.1335, Accuracy = 0.5290 Test Loss = 1.1293, Test Accuracy = 0.5012\n",
      "Iteration 336: Loss = 1.1842, Accuracy = 0.5130 Test Loss = 1.1256, Test Accuracy = 0.5023\n",
      "Iteration 337: Loss = 1.1496, Accuracy = 0.4870 Test Loss = 1.1218, Test Accuracy = 0.5023\n",
      "Iteration 338: Loss = 1.1391, Accuracy = 0.5270 Test Loss = 1.1178, Test Accuracy = 0.5047\n",
      "Iteration 339: Loss = 1.1112, Accuracy = 0.5330 Test Loss = 1.1147, Test Accuracy = 0.5058\n",
      "Iteration 340: Loss = 1.1347, Accuracy = 0.5060 Test Loss = 1.1109, Test Accuracy = 0.5067\n",
      "Iteration 341: Loss = 1.1542, Accuracy = 0.5210 Test Loss = 1.1071, Test Accuracy = 0.5051\n",
      "Iteration 342: Loss = 1.0752, Accuracy = 0.5060 Test Loss = 1.1039, Test Accuracy = 0.5065\n",
      "Iteration 343: Loss = 1.0666, Accuracy = 0.5210 Test Loss = 1.1005, Test Accuracy = 0.5086\n",
      "Iteration 344: Loss = 1.1550, Accuracy = 0.4870 Test Loss = 1.0966, Test Accuracy = 0.5087\n",
      "Iteration 345: Loss = 1.0955, Accuracy = 0.5320 Test Loss = 1.0931, Test Accuracy = 0.5102\n",
      "Iteration 346: Loss = 1.1157, Accuracy = 0.5120 Test Loss = 1.0894, Test Accuracy = 0.5095\n",
      "Iteration 347: Loss = 1.0781, Accuracy = 0.5120 Test Loss = 1.0860, Test Accuracy = 0.5112\n",
      "Iteration 348: Loss = 1.1011, Accuracy = 0.5120 Test Loss = 1.0829, Test Accuracy = 0.5132\n",
      "Iteration 349: Loss = 1.2543, Accuracy = 0.4970 Test Loss = 1.0799, Test Accuracy = 0.5112\n",
      "Iteration 350: Loss = 1.0764, Accuracy = 0.5290 Test Loss = 1.0759, Test Accuracy = 0.5123\n",
      "Iteration 351: Loss = 1.0382, Accuracy = 0.5310 Test Loss = 1.0724, Test Accuracy = 0.5146\n",
      "Iteration 352: Loss = 1.1169, Accuracy = 0.5100 Test Loss = 1.0691, Test Accuracy = 0.5133\n",
      "Iteration 353: Loss = 1.0939, Accuracy = 0.5280 Test Loss = 1.0662, Test Accuracy = 0.5146\n",
      "Iteration 354: Loss = 1.0148, Accuracy = 0.4850 Test Loss = 1.0624, Test Accuracy = 0.5168\n",
      "Iteration 355: Loss = 1.0433, Accuracy = 0.5110 Test Loss = 1.0592, Test Accuracy = 0.5166\n",
      "Iteration 356: Loss = 1.0832, Accuracy = 0.4980 Test Loss = 1.0559, Test Accuracy = 0.5173\n",
      "Iteration 357: Loss = 0.9983, Accuracy = 0.5310 Test Loss = 1.0528, Test Accuracy = 0.5184\n",
      "Iteration 358: Loss = 1.1098, Accuracy = 0.5390 Test Loss = 1.0496, Test Accuracy = 0.5209\n",
      "Iteration 359: Loss = 1.1087, Accuracy = 0.5020 Test Loss = 1.0463, Test Accuracy = 0.5211\n",
      "Iteration 360: Loss = 1.0807, Accuracy = 0.5190 Test Loss = 1.0432, Test Accuracy = 0.5200\n",
      "Iteration 361: Loss = 1.0477, Accuracy = 0.5070 Test Loss = 1.0399, Test Accuracy = 0.5224\n",
      "Iteration 362: Loss = 1.0683, Accuracy = 0.5270 Test Loss = 1.0369, Test Accuracy = 0.5226\n",
      "Iteration 363: Loss = 0.9593, Accuracy = 0.5160 Test Loss = 1.0337, Test Accuracy = 0.5250\n",
      "Iteration 364: Loss = 1.1276, Accuracy = 0.5000 Test Loss = 1.0306, Test Accuracy = 0.5253\n",
      "Iteration 365: Loss = 1.0281, Accuracy = 0.5290 Test Loss = 1.0277, Test Accuracy = 0.5272\n",
      "Iteration 366: Loss = 1.0184, Accuracy = 0.5320 Test Loss = 1.0247, Test Accuracy = 0.5271\n",
      "Iteration 367: Loss = 1.0519, Accuracy = 0.5480 Test Loss = 1.0215, Test Accuracy = 0.5274\n",
      "Iteration 368: Loss = 1.1164, Accuracy = 0.5150 Test Loss = 1.0185, Test Accuracy = 0.5275\n",
      "Iteration 369: Loss = 1.0038, Accuracy = 0.5500 Test Loss = 1.0158, Test Accuracy = 0.5303\n",
      "Iteration 370: Loss = 1.0111, Accuracy = 0.5740 Test Loss = 1.0128, Test Accuracy = 0.5291\n",
      "Iteration 371: Loss = 1.0147, Accuracy = 0.5400 Test Loss = 1.0095, Test Accuracy = 0.5317\n",
      "Iteration 372: Loss = 1.0031, Accuracy = 0.5420 Test Loss = 1.0069, Test Accuracy = 0.5304\n",
      "Iteration 373: Loss = 1.0090, Accuracy = 0.5160 Test Loss = 1.0037, Test Accuracy = 0.5325\n",
      "Iteration 374: Loss = 0.9908, Accuracy = 0.5400 Test Loss = 1.0009, Test Accuracy = 0.5334\n",
      "Iteration 375: Loss = 0.9692, Accuracy = 0.5460 Test Loss = 0.9978, Test Accuracy = 0.5327\n",
      "Iteration 376: Loss = 0.9499, Accuracy = 0.5590 Test Loss = 0.9950, Test Accuracy = 0.5350\n",
      "Iteration 377: Loss = 1.0147, Accuracy = 0.5360 Test Loss = 0.9926, Test Accuracy = 0.5338\n",
      "Iteration 378: Loss = 0.9678, Accuracy = 0.5300 Test Loss = 0.9893, Test Accuracy = 0.5372\n",
      "Iteration 379: Loss = 1.0186, Accuracy = 0.5480 Test Loss = 0.9866, Test Accuracy = 0.5375\n",
      "Iteration 380: Loss = 0.9729, Accuracy = 0.5490 Test Loss = 0.9840, Test Accuracy = 0.5372\n",
      "Iteration 381: Loss = 0.9700, Accuracy = 0.5660 Test Loss = 0.9811, Test Accuracy = 0.5391\n",
      "Iteration 382: Loss = 0.9234, Accuracy = 0.5680 Test Loss = 0.9783, Test Accuracy = 0.5388\n",
      "Iteration 383: Loss = 1.0271, Accuracy = 0.5340 Test Loss = 0.9756, Test Accuracy = 0.5414\n",
      "Iteration 384: Loss = 1.0001, Accuracy = 0.5420 Test Loss = 0.9729, Test Accuracy = 0.5433\n",
      "Iteration 385: Loss = 1.0285, Accuracy = 0.5250 Test Loss = 0.9699, Test Accuracy = 0.5434\n",
      "Iteration 386: Loss = 1.0131, Accuracy = 0.5360 Test Loss = 0.9675, Test Accuracy = 0.5430\n",
      "Iteration 387: Loss = 0.9983, Accuracy = 0.5470 Test Loss = 0.9647, Test Accuracy = 0.5452\n",
      "Iteration 388: Loss = 1.0024, Accuracy = 0.5400 Test Loss = 0.9620, Test Accuracy = 0.5458\n",
      "Iteration 389: Loss = 0.9734, Accuracy = 0.5450 Test Loss = 0.9593, Test Accuracy = 0.5463\n",
      "Iteration 390: Loss = 0.9793, Accuracy = 0.5520 Test Loss = 0.9567, Test Accuracy = 0.5460\n",
      "Iteration 391: Loss = 1.0178, Accuracy = 0.5420 Test Loss = 0.9541, Test Accuracy = 0.5495\n",
      "Iteration 392: Loss = 0.9525, Accuracy = 0.5630 Test Loss = 0.9517, Test Accuracy = 0.5487\n",
      "Iteration 393: Loss = 0.9954, Accuracy = 0.5350 Test Loss = 0.9491, Test Accuracy = 0.5489\n",
      "Iteration 394: Loss = 0.8901, Accuracy = 0.5620 Test Loss = 0.9464, Test Accuracy = 0.5495\n",
      "Iteration 395: Loss = 0.9284, Accuracy = 0.5640 Test Loss = 0.9438, Test Accuracy = 0.5505\n",
      "Iteration 396: Loss = 0.8785, Accuracy = 0.5840 Test Loss = 0.9415, Test Accuracy = 0.5520\n",
      "Iteration 397: Loss = 0.9622, Accuracy = 0.5920 Test Loss = 0.9389, Test Accuracy = 0.5537\n",
      "Iteration 398: Loss = 0.9415, Accuracy = 0.5640 Test Loss = 0.9362, Test Accuracy = 0.5538\n",
      "Iteration 399: Loss = 0.9514, Accuracy = 0.5680 Test Loss = 0.9337, Test Accuracy = 0.5530\n",
      "Iteration 400: Loss = 0.8970, Accuracy = 0.5560 Test Loss = 0.9311, Test Accuracy = 0.5538\n",
      "Iteration 401: Loss = 0.8986, Accuracy = 0.5740 Test Loss = 0.9287, Test Accuracy = 0.5559\n",
      "Iteration 402: Loss = 0.9510, Accuracy = 0.5710 Test Loss = 0.9264, Test Accuracy = 0.5556\n",
      "Iteration 403: Loss = 0.9346, Accuracy = 0.5500 Test Loss = 0.9238, Test Accuracy = 0.5564\n",
      "Iteration 404: Loss = 0.9824, Accuracy = 0.5560 Test Loss = 0.9214, Test Accuracy = 0.5581\n",
      "Iteration 405: Loss = 0.9615, Accuracy = 0.5500 Test Loss = 0.9197, Test Accuracy = 0.5579\n",
      "Iteration 406: Loss = 0.9012, Accuracy = 0.5510 Test Loss = 0.9168, Test Accuracy = 0.5590\n",
      "Iteration 407: Loss = 0.9484, Accuracy = 0.5920 Test Loss = 0.9143, Test Accuracy = 0.5601\n",
      "Iteration 408: Loss = 0.9774, Accuracy = 0.5540 Test Loss = 0.9119, Test Accuracy = 0.5600\n",
      "Iteration 409: Loss = 0.8638, Accuracy = 0.5530 Test Loss = 0.9096, Test Accuracy = 0.5630\n",
      "Iteration 410: Loss = 0.8746, Accuracy = 0.5620 Test Loss = 0.9071, Test Accuracy = 0.5638\n",
      "Iteration 411: Loss = 0.8957, Accuracy = 0.5780 Test Loss = 0.9048, Test Accuracy = 0.5630\n",
      "Iteration 412: Loss = 0.8812, Accuracy = 0.5740 Test Loss = 0.9029, Test Accuracy = 0.5616\n",
      "Iteration 413: Loss = 0.9409, Accuracy = 0.5600 Test Loss = 0.9001, Test Accuracy = 0.5635\n",
      "Iteration 414: Loss = 0.9459, Accuracy = 0.5710 Test Loss = 0.8981, Test Accuracy = 0.5640\n",
      "Iteration 415: Loss = 0.9358, Accuracy = 0.5820 Test Loss = 0.8958, Test Accuracy = 0.5639\n",
      "Iteration 416: Loss = 0.8969, Accuracy = 0.5580 Test Loss = 0.8932, Test Accuracy = 0.5661\n",
      "Iteration 417: Loss = 0.8584, Accuracy = 0.5770 Test Loss = 0.8911, Test Accuracy = 0.5673\n",
      "Iteration 418: Loss = 0.8890, Accuracy = 0.5760 Test Loss = 0.8888, Test Accuracy = 0.5670\n",
      "Iteration 419: Loss = 0.8344, Accuracy = 0.5910 Test Loss = 0.8868, Test Accuracy = 0.5698\n",
      "Iteration 420: Loss = 0.8201, Accuracy = 0.5800 Test Loss = 0.8843, Test Accuracy = 0.5695\n",
      "Iteration 421: Loss = 0.9151, Accuracy = 0.5480 Test Loss = 0.8821, Test Accuracy = 0.5709\n",
      "Iteration 422: Loss = 0.9603, Accuracy = 0.5520 Test Loss = 0.8801, Test Accuracy = 0.5707\n",
      "Iteration 423: Loss = 0.8478, Accuracy = 0.5640 Test Loss = 0.8777, Test Accuracy = 0.5724\n",
      "Iteration 424: Loss = 0.8846, Accuracy = 0.5860 Test Loss = 0.8756, Test Accuracy = 0.5720\n",
      "Iteration 425: Loss = 0.9034, Accuracy = 0.5630 Test Loss = 0.8741, Test Accuracy = 0.5722\n",
      "Iteration 426: Loss = 0.8904, Accuracy = 0.6020 Test Loss = 0.8717, Test Accuracy = 0.5740\n",
      "Iteration 427: Loss = 0.9393, Accuracy = 0.5690 Test Loss = 0.8691, Test Accuracy = 0.5745\n",
      "Iteration 428: Loss = 0.8453, Accuracy = 0.5420 Test Loss = 0.8675, Test Accuracy = 0.5766\n",
      "Iteration 429: Loss = 0.8452, Accuracy = 0.5800 Test Loss = 0.8650, Test Accuracy = 0.5755\n",
      "Iteration 430: Loss = 0.9431, Accuracy = 0.5650 Test Loss = 0.8629, Test Accuracy = 0.5768\n",
      "Iteration 431: Loss = 0.8549, Accuracy = 0.5660 Test Loss = 0.8610, Test Accuracy = 0.5777\n",
      "Iteration 432: Loss = 0.8212, Accuracy = 0.5850 Test Loss = 0.8590, Test Accuracy = 0.5795\n",
      "Iteration 433: Loss = 0.8584, Accuracy = 0.5970 Test Loss = 0.8570, Test Accuracy = 0.5781\n",
      "Iteration 434: Loss = 0.8577, Accuracy = 0.5710 Test Loss = 0.8546, Test Accuracy = 0.5798\n",
      "Iteration 435: Loss = 0.8326, Accuracy = 0.5840 Test Loss = 0.8526, Test Accuracy = 0.5799\n",
      "Iteration 436: Loss = 0.8865, Accuracy = 0.5860 Test Loss = 0.8507, Test Accuracy = 0.5812\n",
      "Iteration 437: Loss = 0.8813, Accuracy = 0.5620 Test Loss = 0.8487, Test Accuracy = 0.5834\n",
      "Iteration 438: Loss = 0.8522, Accuracy = 0.5980 Test Loss = 0.8464, Test Accuracy = 0.5824\n",
      "Iteration 439: Loss = 0.7993, Accuracy = 0.6110 Test Loss = 0.8448, Test Accuracy = 0.5829\n",
      "Iteration 440: Loss = 0.7897, Accuracy = 0.6030 Test Loss = 0.8425, Test Accuracy = 0.5838\n",
      "Iteration 441: Loss = 0.8055, Accuracy = 0.5900 Test Loss = 0.8409, Test Accuracy = 0.5838\n",
      "Iteration 442: Loss = 0.8040, Accuracy = 0.6280 Test Loss = 0.8387, Test Accuracy = 0.5856\n",
      "Iteration 443: Loss = 0.8066, Accuracy = 0.5720 Test Loss = 0.8368, Test Accuracy = 0.5880\n",
      "Iteration 444: Loss = 0.8753, Accuracy = 0.5890 Test Loss = 0.8350, Test Accuracy = 0.5878\n",
      "Iteration 445: Loss = 0.8890, Accuracy = 0.5490 Test Loss = 0.8328, Test Accuracy = 0.5884\n",
      "Iteration 446: Loss = 0.8184, Accuracy = 0.6070 Test Loss = 0.8308, Test Accuracy = 0.5902\n",
      "Iteration 447: Loss = 0.8376, Accuracy = 0.5760 Test Loss = 0.8290, Test Accuracy = 0.5910\n",
      "Iteration 448: Loss = 0.8093, Accuracy = 0.5780 Test Loss = 0.8273, Test Accuracy = 0.5915\n",
      "Iteration 449: Loss = 0.8133, Accuracy = 0.5820 Test Loss = 0.8252, Test Accuracy = 0.5911\n",
      "Iteration 450: Loss = 0.7921, Accuracy = 0.5850 Test Loss = 0.8236, Test Accuracy = 0.5919\n",
      "Iteration 451: Loss = 0.8632, Accuracy = 0.5860 Test Loss = 0.8214, Test Accuracy = 0.5930\n",
      "Iteration 452: Loss = 0.8166, Accuracy = 0.6180 Test Loss = 0.8195, Test Accuracy = 0.5934\n",
      "Iteration 453: Loss = 0.8886, Accuracy = 0.6130 Test Loss = 0.8178, Test Accuracy = 0.5938\n",
      "Iteration 454: Loss = 0.8186, Accuracy = 0.5850 Test Loss = 0.8160, Test Accuracy = 0.5948\n",
      "Iteration 455: Loss = 0.8014, Accuracy = 0.5990 Test Loss = 0.8143, Test Accuracy = 0.5960\n",
      "Iteration 456: Loss = 0.7737, Accuracy = 0.5970 Test Loss = 0.8123, Test Accuracy = 0.5969\n",
      "Iteration 457: Loss = 0.8083, Accuracy = 0.5740 Test Loss = 0.8104, Test Accuracy = 0.5967\n",
      "Iteration 458: Loss = 0.7820, Accuracy = 0.5790 Test Loss = 0.8087, Test Accuracy = 0.5967\n",
      "Iteration 459: Loss = 0.8056, Accuracy = 0.6020 Test Loss = 0.8069, Test Accuracy = 0.5961\n",
      "Iteration 460: Loss = 0.7901, Accuracy = 0.6050 Test Loss = 0.8050, Test Accuracy = 0.5974\n",
      "Iteration 461: Loss = 0.8183, Accuracy = 0.5720 Test Loss = 0.8035, Test Accuracy = 0.5996\n",
      "Iteration 462: Loss = 0.8655, Accuracy = 0.5770 Test Loss = 0.8015, Test Accuracy = 0.5993\n",
      "Iteration 463: Loss = 0.8441, Accuracy = 0.6120 Test Loss = 0.7997, Test Accuracy = 0.5992\n",
      "Iteration 464: Loss = 0.7846, Accuracy = 0.6040 Test Loss = 0.7983, Test Accuracy = 0.6027\n",
      "Iteration 465: Loss = 0.7518, Accuracy = 0.6180 Test Loss = 0.7962, Test Accuracy = 0.6013\n",
      "Iteration 466: Loss = 0.7641, Accuracy = 0.5980 Test Loss = 0.7944, Test Accuracy = 0.6027\n",
      "Iteration 467: Loss = 0.7870, Accuracy = 0.6060 Test Loss = 0.7930, Test Accuracy = 0.6031\n",
      "Iteration 468: Loss = 0.8089, Accuracy = 0.6040 Test Loss = 0.7911, Test Accuracy = 0.6040\n",
      "Iteration 469: Loss = 0.7515, Accuracy = 0.6030 Test Loss = 0.7895, Test Accuracy = 0.6033\n",
      "Iteration 470: Loss = 0.7945, Accuracy = 0.5810 Test Loss = 0.7877, Test Accuracy = 0.6036\n",
      "Iteration 471: Loss = 0.8335, Accuracy = 0.5810 Test Loss = 0.7861, Test Accuracy = 0.6056\n",
      "Iteration 472: Loss = 0.7353, Accuracy = 0.6130 Test Loss = 0.7848, Test Accuracy = 0.6058\n",
      "Iteration 473: Loss = 0.8022, Accuracy = 0.5730 Test Loss = 0.7828, Test Accuracy = 0.6071\n",
      "Iteration 474: Loss = 0.7967, Accuracy = 0.6020 Test Loss = 0.7812, Test Accuracy = 0.6082\n",
      "Iteration 475: Loss = 0.7896, Accuracy = 0.6110 Test Loss = 0.7794, Test Accuracy = 0.6073\n",
      "Iteration 476: Loss = 0.8102, Accuracy = 0.5880 Test Loss = 0.7777, Test Accuracy = 0.6078\n",
      "Iteration 477: Loss = 0.7800, Accuracy = 0.6190 Test Loss = 0.7760, Test Accuracy = 0.6088\n",
      "Iteration 478: Loss = 0.7842, Accuracy = 0.6200 Test Loss = 0.7745, Test Accuracy = 0.6103\n",
      "Iteration 479: Loss = 0.7623, Accuracy = 0.6420 Test Loss = 0.7729, Test Accuracy = 0.6111\n",
      "Iteration 480: Loss = 0.7602, Accuracy = 0.6270 Test Loss = 0.7712, Test Accuracy = 0.6102\n",
      "Iteration 481: Loss = 0.7163, Accuracy = 0.6440 Test Loss = 0.7697, Test Accuracy = 0.6119\n",
      "Iteration 482: Loss = 0.7907, Accuracy = 0.6160 Test Loss = 0.7680, Test Accuracy = 0.6116\n",
      "Iteration 483: Loss = 0.8044, Accuracy = 0.6130 Test Loss = 0.7664, Test Accuracy = 0.6139\n",
      "Iteration 484: Loss = 0.8102, Accuracy = 0.6140 Test Loss = 0.7649, Test Accuracy = 0.6122\n",
      "Iteration 485: Loss = 0.7544, Accuracy = 0.6330 Test Loss = 0.7633, Test Accuracy = 0.6137\n",
      "Iteration 486: Loss = 0.8031, Accuracy = 0.6120 Test Loss = 0.7617, Test Accuracy = 0.6145\n",
      "Iteration 487: Loss = 0.7987, Accuracy = 0.5960 Test Loss = 0.7602, Test Accuracy = 0.6132\n",
      "Iteration 488: Loss = 0.7846, Accuracy = 0.6310 Test Loss = 0.7586, Test Accuracy = 0.6168\n",
      "Iteration 489: Loss = 0.7680, Accuracy = 0.5680 Test Loss = 0.7570, Test Accuracy = 0.6169\n",
      "Iteration 490: Loss = 0.8008, Accuracy = 0.6200 Test Loss = 0.7555, Test Accuracy = 0.6175\n",
      "Iteration 491: Loss = 0.7424, Accuracy = 0.6010 Test Loss = 0.7538, Test Accuracy = 0.6178\n",
      "Iteration 492: Loss = 0.7553, Accuracy = 0.6200 Test Loss = 0.7527, Test Accuracy = 0.6193\n",
      "Iteration 493: Loss = 0.7941, Accuracy = 0.6230 Test Loss = 0.7511, Test Accuracy = 0.6187\n",
      "Iteration 494: Loss = 0.7603, Accuracy = 0.6290 Test Loss = 0.7496, Test Accuracy = 0.6180\n",
      "Iteration 495: Loss = 0.7316, Accuracy = 0.6390 Test Loss = 0.7480, Test Accuracy = 0.6204\n",
      "Iteration 496: Loss = 0.7827, Accuracy = 0.5950 Test Loss = 0.7465, Test Accuracy = 0.6204\n",
      "Iteration 497: Loss = 0.8313, Accuracy = 0.6160 Test Loss = 0.7451, Test Accuracy = 0.6211\n",
      "Iteration 498: Loss = 0.7008, Accuracy = 0.6310 Test Loss = 0.7435, Test Accuracy = 0.6207\n",
      "Iteration 499: Loss = 0.7601, Accuracy = 0.6050 Test Loss = 0.7422, Test Accuracy = 0.6216\n",
      "Iteration 500: Loss = 0.7569, Accuracy = 0.6190 Test Loss = 0.7406, Test Accuracy = 0.6235\n",
      "Iteration 501: Loss = 0.6973, Accuracy = 0.6280 Test Loss = 0.7390, Test Accuracy = 0.6236\n",
      "Iteration 502: Loss = 0.7466, Accuracy = 0.6290 Test Loss = 0.7378, Test Accuracy = 0.6234\n",
      "Iteration 503: Loss = 0.6950, Accuracy = 0.6510 Test Loss = 0.7363, Test Accuracy = 0.6258\n",
      "Iteration 504: Loss = 0.8020, Accuracy = 0.6120 Test Loss = 0.7349, Test Accuracy = 0.6262\n",
      "Iteration 505: Loss = 0.7406, Accuracy = 0.6090 Test Loss = 0.7334, Test Accuracy = 0.6253\n",
      "Iteration 506: Loss = 0.7003, Accuracy = 0.6360 Test Loss = 0.7321, Test Accuracy = 0.6271\n",
      "Iteration 507: Loss = 0.7329, Accuracy = 0.6310 Test Loss = 0.7305, Test Accuracy = 0.6275\n",
      "Iteration 508: Loss = 0.7481, Accuracy = 0.6210 Test Loss = 0.7289, Test Accuracy = 0.6282\n",
      "Iteration 509: Loss = 0.7394, Accuracy = 0.6060 Test Loss = 0.7275, Test Accuracy = 0.6287\n",
      "Iteration 510: Loss = 0.7477, Accuracy = 0.6330 Test Loss = 0.7262, Test Accuracy = 0.6280\n",
      "Iteration 511: Loss = 0.7312, Accuracy = 0.6560 Test Loss = 0.7249, Test Accuracy = 0.6303\n",
      "Iteration 512: Loss = 0.6912, Accuracy = 0.6250 Test Loss = 0.7236, Test Accuracy = 0.6296\n",
      "Iteration 513: Loss = 0.6863, Accuracy = 0.6370 Test Loss = 0.7221, Test Accuracy = 0.6314\n",
      "Iteration 514: Loss = 0.7202, Accuracy = 0.6080 Test Loss = 0.7207, Test Accuracy = 0.6315\n",
      "Iteration 515: Loss = 0.7588, Accuracy = 0.6210 Test Loss = 0.7196, Test Accuracy = 0.6308\n",
      "Iteration 516: Loss = 0.7496, Accuracy = 0.6010 Test Loss = 0.7181, Test Accuracy = 0.6317\n",
      "Iteration 517: Loss = 0.7195, Accuracy = 0.6120 Test Loss = 0.7165, Test Accuracy = 0.6328\n",
      "Iteration 518: Loss = 0.7117, Accuracy = 0.6530 Test Loss = 0.7156, Test Accuracy = 0.6340\n",
      "Iteration 519: Loss = 0.6758, Accuracy = 0.6480 Test Loss = 0.7143, Test Accuracy = 0.6344\n",
      "Iteration 520: Loss = 0.6877, Accuracy = 0.6360 Test Loss = 0.7127, Test Accuracy = 0.6359\n",
      "Iteration 521: Loss = 0.7639, Accuracy = 0.6040 Test Loss = 0.7113, Test Accuracy = 0.6353\n",
      "Iteration 522: Loss = 0.6622, Accuracy = 0.6370 Test Loss = 0.7102, Test Accuracy = 0.6362\n",
      "Iteration 523: Loss = 0.6691, Accuracy = 0.6380 Test Loss = 0.7091, Test Accuracy = 0.6366\n",
      "Iteration 524: Loss = 0.7611, Accuracy = 0.6210 Test Loss = 0.7074, Test Accuracy = 0.6356\n",
      "Iteration 525: Loss = 0.7107, Accuracy = 0.6170 Test Loss = 0.7063, Test Accuracy = 0.6378\n",
      "Iteration 526: Loss = 0.7240, Accuracy = 0.6240 Test Loss = 0.7049, Test Accuracy = 0.6387\n",
      "Iteration 527: Loss = 0.6903, Accuracy = 0.6340 Test Loss = 0.7040, Test Accuracy = 0.6388\n",
      "Iteration 528: Loss = 0.7384, Accuracy = 0.6250 Test Loss = 0.7023, Test Accuracy = 0.6389\n",
      "Iteration 529: Loss = 0.6932, Accuracy = 0.6350 Test Loss = 0.7010, Test Accuracy = 0.6391\n",
      "Iteration 530: Loss = 0.6974, Accuracy = 0.6320 Test Loss = 0.6997, Test Accuracy = 0.6417\n",
      "Iteration 531: Loss = 0.6738, Accuracy = 0.6470 Test Loss = 0.6986, Test Accuracy = 0.6405\n",
      "Iteration 532: Loss = 0.7388, Accuracy = 0.6310 Test Loss = 0.6973, Test Accuracy = 0.6379\n",
      "Iteration 533: Loss = 0.6758, Accuracy = 0.6340 Test Loss = 0.6960, Test Accuracy = 0.6416\n",
      "Iteration 534: Loss = 0.7125, Accuracy = 0.6220 Test Loss = 0.6948, Test Accuracy = 0.6419\n",
      "Iteration 535: Loss = 0.7348, Accuracy = 0.6260 Test Loss = 0.6934, Test Accuracy = 0.6418\n",
      "Iteration 536: Loss = 0.7034, Accuracy = 0.6400 Test Loss = 0.6923, Test Accuracy = 0.6414\n",
      "Iteration 537: Loss = 0.7140, Accuracy = 0.6380 Test Loss = 0.6909, Test Accuracy = 0.6435\n",
      "Iteration 538: Loss = 0.6990, Accuracy = 0.6350 Test Loss = 0.6898, Test Accuracy = 0.6444\n",
      "Iteration 539: Loss = 0.6328, Accuracy = 0.6340 Test Loss = 0.6885, Test Accuracy = 0.6437\n",
      "Iteration 540: Loss = 0.6408, Accuracy = 0.6570 Test Loss = 0.6872, Test Accuracy = 0.6437\n",
      "Iteration 541: Loss = 0.6835, Accuracy = 0.6540 Test Loss = 0.6860, Test Accuracy = 0.6436\n",
      "Iteration 542: Loss = 0.6943, Accuracy = 0.6180 Test Loss = 0.6850, Test Accuracy = 0.6453\n",
      "Iteration 543: Loss = 0.7934, Accuracy = 0.6360 Test Loss = 0.6836, Test Accuracy = 0.6445\n",
      "Iteration 544: Loss = 0.6991, Accuracy = 0.6500 Test Loss = 0.6823, Test Accuracy = 0.6440\n",
      "Iteration 545: Loss = 0.7112, Accuracy = 0.6460 Test Loss = 0.6814, Test Accuracy = 0.6468\n",
      "Iteration 546: Loss = 0.6968, Accuracy = 0.6590 Test Loss = 0.6803, Test Accuracy = 0.6457\n",
      "Iteration 547: Loss = 0.7113, Accuracy = 0.6310 Test Loss = 0.6789, Test Accuracy = 0.6465\n",
      "Iteration 548: Loss = 0.7301, Accuracy = 0.6260 Test Loss = 0.6778, Test Accuracy = 0.6474\n",
      "Iteration 549: Loss = 0.6818, Accuracy = 0.6590 Test Loss = 0.6765, Test Accuracy = 0.6489\n",
      "Iteration 550: Loss = 0.6925, Accuracy = 0.6490 Test Loss = 0.6754, Test Accuracy = 0.6480\n",
      "Iteration 551: Loss = 0.7147, Accuracy = 0.6110 Test Loss = 0.6743, Test Accuracy = 0.6486\n",
      "Iteration 552: Loss = 0.6992, Accuracy = 0.6430 Test Loss = 0.6730, Test Accuracy = 0.6505\n",
      "Iteration 553: Loss = 0.6672, Accuracy = 0.6550 Test Loss = 0.6719, Test Accuracy = 0.6507\n",
      "Iteration 554: Loss = 0.6754, Accuracy = 0.6370 Test Loss = 0.6708, Test Accuracy = 0.6513\n",
      "Iteration 555: Loss = 0.6609, Accuracy = 0.6400 Test Loss = 0.6696, Test Accuracy = 0.6530\n",
      "Iteration 556: Loss = 0.7151, Accuracy = 0.6370 Test Loss = 0.6686, Test Accuracy = 0.6521\n",
      "Iteration 557: Loss = 0.6996, Accuracy = 0.6200 Test Loss = 0.6675, Test Accuracy = 0.6529\n",
      "Iteration 558: Loss = 0.7329, Accuracy = 0.6210 Test Loss = 0.6663, Test Accuracy = 0.6534\n",
      "Iteration 559: Loss = 0.6553, Accuracy = 0.6550 Test Loss = 0.6650, Test Accuracy = 0.6532\n",
      "Iteration 560: Loss = 0.6258, Accuracy = 0.6420 Test Loss = 0.6641, Test Accuracy = 0.6542\n",
      "Iteration 561: Loss = 0.6117, Accuracy = 0.6510 Test Loss = 0.6628, Test Accuracy = 0.6551\n",
      "Iteration 562: Loss = 0.7478, Accuracy = 0.6310 Test Loss = 0.6618, Test Accuracy = 0.6534\n",
      "Iteration 563: Loss = 0.6862, Accuracy = 0.6590 Test Loss = 0.6606, Test Accuracy = 0.6561\n",
      "Iteration 564: Loss = 0.6365, Accuracy = 0.6720 Test Loss = 0.6595, Test Accuracy = 0.6556\n",
      "Iteration 565: Loss = 0.6661, Accuracy = 0.6270 Test Loss = 0.6587, Test Accuracy = 0.6573\n",
      "Iteration 566: Loss = 0.6658, Accuracy = 0.6310 Test Loss = 0.6574, Test Accuracy = 0.6573\n",
      "Iteration 567: Loss = 0.6689, Accuracy = 0.6640 Test Loss = 0.6563, Test Accuracy = 0.6583\n",
      "Iteration 568: Loss = 0.6667, Accuracy = 0.6390 Test Loss = 0.6553, Test Accuracy = 0.6589\n",
      "Iteration 569: Loss = 0.6575, Accuracy = 0.6640 Test Loss = 0.6543, Test Accuracy = 0.6579\n",
      "Iteration 570: Loss = 0.7117, Accuracy = 0.6260 Test Loss = 0.6531, Test Accuracy = 0.6598\n",
      "Iteration 571: Loss = 0.6665, Accuracy = 0.6470 Test Loss = 0.6519, Test Accuracy = 0.6593\n",
      "Iteration 572: Loss = 0.6948, Accuracy = 0.6440 Test Loss = 0.6511, Test Accuracy = 0.6581\n",
      "Iteration 573: Loss = 0.6828, Accuracy = 0.6410 Test Loss = 0.6499, Test Accuracy = 0.6595\n",
      "Iteration 574: Loss = 0.6912, Accuracy = 0.6300 Test Loss = 0.6489, Test Accuracy = 0.6603\n",
      "Iteration 575: Loss = 0.6406, Accuracy = 0.6300 Test Loss = 0.6478, Test Accuracy = 0.6610\n",
      "Iteration 576: Loss = 0.6625, Accuracy = 0.6430 Test Loss = 0.6468, Test Accuracy = 0.6606\n",
      "Iteration 577: Loss = 0.6758, Accuracy = 0.6510 Test Loss = 0.6456, Test Accuracy = 0.6600\n",
      "Iteration 578: Loss = 0.6501, Accuracy = 0.6560 Test Loss = 0.6447, Test Accuracy = 0.6615\n",
      "Iteration 579: Loss = 0.6663, Accuracy = 0.6490 Test Loss = 0.6437, Test Accuracy = 0.6623\n",
      "Iteration 580: Loss = 0.6583, Accuracy = 0.6450 Test Loss = 0.6426, Test Accuracy = 0.6629\n",
      "Iteration 581: Loss = 0.6496, Accuracy = 0.6480 Test Loss = 0.6417, Test Accuracy = 0.6633\n",
      "Iteration 582: Loss = 0.6340, Accuracy = 0.6770 Test Loss = 0.6406, Test Accuracy = 0.6631\n",
      "Iteration 583: Loss = 0.6487, Accuracy = 0.6730 Test Loss = 0.6396, Test Accuracy = 0.6649\n",
      "Iteration 584: Loss = 0.6255, Accuracy = 0.6560 Test Loss = 0.6388, Test Accuracy = 0.6657\n",
      "Iteration 585: Loss = 0.6730, Accuracy = 0.6430 Test Loss = 0.6379, Test Accuracy = 0.6652\n",
      "Iteration 586: Loss = 0.6254, Accuracy = 0.6550 Test Loss = 0.6366, Test Accuracy = 0.6663\n",
      "Iteration 587: Loss = 0.6334, Accuracy = 0.6720 Test Loss = 0.6358, Test Accuracy = 0.6638\n",
      "Iteration 588: Loss = 0.5839, Accuracy = 0.6790 Test Loss = 0.6346, Test Accuracy = 0.6659\n",
      "Iteration 589: Loss = 0.6471, Accuracy = 0.6700 Test Loss = 0.6337, Test Accuracy = 0.6659\n",
      "Iteration 590: Loss = 0.6633, Accuracy = 0.6820 Test Loss = 0.6326, Test Accuracy = 0.6658\n",
      "Iteration 591: Loss = 0.6576, Accuracy = 0.6670 Test Loss = 0.6317, Test Accuracy = 0.6663\n",
      "Iteration 592: Loss = 0.6608, Accuracy = 0.6560 Test Loss = 0.6307, Test Accuracy = 0.6683\n",
      "Iteration 593: Loss = 0.6827, Accuracy = 0.6540 Test Loss = 0.6298, Test Accuracy = 0.6684\n",
      "Iteration 594: Loss = 0.6133, Accuracy = 0.6890 Test Loss = 0.6288, Test Accuracy = 0.6673\n",
      "Iteration 595: Loss = 0.6216, Accuracy = 0.6500 Test Loss = 0.6279, Test Accuracy = 0.6686\n",
      "Iteration 596: Loss = 0.6850, Accuracy = 0.6480 Test Loss = 0.6270, Test Accuracy = 0.6686\n",
      "Iteration 597: Loss = 0.6368, Accuracy = 0.6610 Test Loss = 0.6259, Test Accuracy = 0.6682\n",
      "Iteration 598: Loss = 0.6771, Accuracy = 0.6310 Test Loss = 0.6251, Test Accuracy = 0.6699\n",
      "Iteration 599: Loss = 0.6194, Accuracy = 0.6480 Test Loss = 0.6240, Test Accuracy = 0.6706\n",
      "Iteration 600: Loss = 0.5775, Accuracy = 0.6870 Test Loss = 0.6232, Test Accuracy = 0.6716\n",
      "Iteration 601: Loss = 0.6208, Accuracy = 0.6590 Test Loss = 0.6221, Test Accuracy = 0.6689\n",
      "Iteration 602: Loss = 0.6437, Accuracy = 0.6600 Test Loss = 0.6210, Test Accuracy = 0.6714\n",
      "Iteration 603: Loss = 0.6315, Accuracy = 0.7010 Test Loss = 0.6203, Test Accuracy = 0.6711\n",
      "Iteration 604: Loss = 0.6705, Accuracy = 0.6540 Test Loss = 0.6193, Test Accuracy = 0.6717\n",
      "Iteration 605: Loss = 0.6289, Accuracy = 0.6720 Test Loss = 0.6184, Test Accuracy = 0.6714\n",
      "Iteration 606: Loss = 0.6394, Accuracy = 0.6510 Test Loss = 0.6173, Test Accuracy = 0.6729\n",
      "Iteration 607: Loss = 0.6543, Accuracy = 0.6600 Test Loss = 0.6165, Test Accuracy = 0.6718\n",
      "Iteration 608: Loss = 0.5870, Accuracy = 0.6670 Test Loss = 0.6157, Test Accuracy = 0.6729\n",
      "Iteration 609: Loss = 0.6151, Accuracy = 0.6700 Test Loss = 0.6146, Test Accuracy = 0.6745\n",
      "Iteration 610: Loss = 0.5857, Accuracy = 0.6840 Test Loss = 0.6137, Test Accuracy = 0.6721\n",
      "Iteration 611: Loss = 0.6038, Accuracy = 0.6810 Test Loss = 0.6131, Test Accuracy = 0.6739\n",
      "Iteration 612: Loss = 0.5882, Accuracy = 0.6810 Test Loss = 0.6120, Test Accuracy = 0.6736\n",
      "Iteration 613: Loss = 0.5864, Accuracy = 0.6670 Test Loss = 0.6112, Test Accuracy = 0.6761\n",
      "Iteration 614: Loss = 0.6035, Accuracy = 0.6730 Test Loss = 0.6101, Test Accuracy = 0.6750\n",
      "Iteration 615: Loss = 0.6320, Accuracy = 0.6610 Test Loss = 0.6097, Test Accuracy = 0.6772\n",
      "Iteration 616: Loss = 0.5870, Accuracy = 0.7050 Test Loss = 0.6085, Test Accuracy = 0.6761\n",
      "Iteration 617: Loss = 0.6470, Accuracy = 0.6730 Test Loss = 0.6075, Test Accuracy = 0.6749\n",
      "Iteration 618: Loss = 0.6224, Accuracy = 0.6800 Test Loss = 0.6066, Test Accuracy = 0.6748\n",
      "Iteration 619: Loss = 0.6516, Accuracy = 0.6750 Test Loss = 0.6060, Test Accuracy = 0.6781\n",
      "Iteration 620: Loss = 0.6634, Accuracy = 0.6710 Test Loss = 0.6049, Test Accuracy = 0.6773\n",
      "Iteration 621: Loss = 0.6081, Accuracy = 0.6810 Test Loss = 0.6041, Test Accuracy = 0.6774\n",
      "Iteration 622: Loss = 0.5936, Accuracy = 0.6970 Test Loss = 0.6033, Test Accuracy = 0.6786\n",
      "Iteration 623: Loss = 0.6001, Accuracy = 0.6900 Test Loss = 0.6026, Test Accuracy = 0.6785\n",
      "Iteration 624: Loss = 0.6120, Accuracy = 0.6770 Test Loss = 0.6015, Test Accuracy = 0.6790\n",
      "Iteration 625: Loss = 0.6294, Accuracy = 0.6720 Test Loss = 0.6006, Test Accuracy = 0.6792\n",
      "Iteration 626: Loss = 0.5661, Accuracy = 0.6880 Test Loss = 0.5998, Test Accuracy = 0.6798\n",
      "Iteration 627: Loss = 0.5568, Accuracy = 0.6830 Test Loss = 0.5989, Test Accuracy = 0.6801\n",
      "Iteration 628: Loss = 0.6268, Accuracy = 0.6650 Test Loss = 0.5981, Test Accuracy = 0.6802\n",
      "Iteration 629: Loss = 0.6069, Accuracy = 0.6630 Test Loss = 0.5972, Test Accuracy = 0.6802\n",
      "Iteration 630: Loss = 0.6404, Accuracy = 0.6590 Test Loss = 0.5965, Test Accuracy = 0.6819\n",
      "Iteration 631: Loss = 0.5636, Accuracy = 0.7240 Test Loss = 0.5957, Test Accuracy = 0.6793\n",
      "Iteration 632: Loss = 0.6098, Accuracy = 0.6610 Test Loss = 0.5947, Test Accuracy = 0.6810\n",
      "Iteration 633: Loss = 0.6183, Accuracy = 0.6840 Test Loss = 0.5938, Test Accuracy = 0.6819\n",
      "Iteration 634: Loss = 0.6308, Accuracy = 0.6800 Test Loss = 0.5932, Test Accuracy = 0.6824\n",
      "Iteration 635: Loss = 0.5149, Accuracy = 0.6900 Test Loss = 0.5923, Test Accuracy = 0.6819\n",
      "Iteration 636: Loss = 0.6115, Accuracy = 0.6830 Test Loss = 0.5914, Test Accuracy = 0.6846\n",
      "Iteration 637: Loss = 0.5898, Accuracy = 0.6830 Test Loss = 0.5906, Test Accuracy = 0.6831\n",
      "Iteration 638: Loss = 0.5755, Accuracy = 0.6940 Test Loss = 0.5900, Test Accuracy = 0.6836\n",
      "Iteration 639: Loss = 0.5788, Accuracy = 0.6680 Test Loss = 0.5891, Test Accuracy = 0.6839\n",
      "Iteration 640: Loss = 0.6020, Accuracy = 0.6940 Test Loss = 0.5880, Test Accuracy = 0.6838\n",
      "Iteration 641: Loss = 0.6388, Accuracy = 0.6680 Test Loss = 0.5875, Test Accuracy = 0.6853\n",
      "Iteration 642: Loss = 0.5761, Accuracy = 0.6620 Test Loss = 0.5867, Test Accuracy = 0.6839\n",
      "Iteration 643: Loss = 0.6047, Accuracy = 0.6680 Test Loss = 0.5857, Test Accuracy = 0.6853\n",
      "Iteration 644: Loss = 0.5885, Accuracy = 0.6850 Test Loss = 0.5851, Test Accuracy = 0.6875\n",
      "Iteration 645: Loss = 0.6063, Accuracy = 0.6900 Test Loss = 0.5843, Test Accuracy = 0.6865\n",
      "Iteration 646: Loss = 0.6220, Accuracy = 0.6780 Test Loss = 0.5834, Test Accuracy = 0.6876\n",
      "Iteration 647: Loss = 0.6029, Accuracy = 0.6720 Test Loss = 0.5825, Test Accuracy = 0.6863\n",
      "Iteration 648: Loss = 0.5404, Accuracy = 0.6900 Test Loss = 0.5818, Test Accuracy = 0.6860\n",
      "Iteration 649: Loss = 0.5607, Accuracy = 0.6820 Test Loss = 0.5811, Test Accuracy = 0.6877\n",
      "Iteration 650: Loss = 0.5802, Accuracy = 0.6480 Test Loss = 0.5804, Test Accuracy = 0.6877\n",
      "Iteration 651: Loss = 0.5902, Accuracy = 0.6980 Test Loss = 0.5796, Test Accuracy = 0.6868\n",
      "Iteration 652: Loss = 0.5401, Accuracy = 0.6850 Test Loss = 0.5788, Test Accuracy = 0.6880\n",
      "Iteration 653: Loss = 0.5932, Accuracy = 0.6960 Test Loss = 0.5779, Test Accuracy = 0.6880\n",
      "Iteration 654: Loss = 0.5552, Accuracy = 0.6830 Test Loss = 0.5771, Test Accuracy = 0.6886\n",
      "Iteration 655: Loss = 0.6039, Accuracy = 0.6840 Test Loss = 0.5763, Test Accuracy = 0.6891\n",
      "Iteration 656: Loss = 0.5629, Accuracy = 0.6970 Test Loss = 0.5758, Test Accuracy = 0.6894\n",
      "Iteration 657: Loss = 0.6529, Accuracy = 0.6810 Test Loss = 0.5750, Test Accuracy = 0.6895\n",
      "Iteration 658: Loss = 0.5515, Accuracy = 0.6930 Test Loss = 0.5742, Test Accuracy = 0.6902\n",
      "Iteration 659: Loss = 0.5849, Accuracy = 0.6850 Test Loss = 0.5736, Test Accuracy = 0.6904\n",
      "Iteration 660: Loss = 0.6575, Accuracy = 0.6690 Test Loss = 0.5726, Test Accuracy = 0.6904\n",
      "Iteration 661: Loss = 0.5887, Accuracy = 0.6430 Test Loss = 0.5722, Test Accuracy = 0.6921\n",
      "Iteration 662: Loss = 0.6213, Accuracy = 0.6660 Test Loss = 0.5712, Test Accuracy = 0.6919\n",
      "Iteration 663: Loss = 0.5173, Accuracy = 0.7270 Test Loss = 0.5705, Test Accuracy = 0.6912\n",
      "Iteration 664: Loss = 0.5859, Accuracy = 0.6870 Test Loss = 0.5697, Test Accuracy = 0.6938\n",
      "Iteration 665: Loss = 0.6152, Accuracy = 0.6510 Test Loss = 0.5689, Test Accuracy = 0.6923\n",
      "Iteration 666: Loss = 0.5805, Accuracy = 0.6990 Test Loss = 0.5682, Test Accuracy = 0.6938\n",
      "Iteration 667: Loss = 0.6014, Accuracy = 0.6800 Test Loss = 0.5675, Test Accuracy = 0.6935\n",
      "Iteration 668: Loss = 0.5513, Accuracy = 0.6970 Test Loss = 0.5668, Test Accuracy = 0.6936\n",
      "Iteration 669: Loss = 0.5399, Accuracy = 0.6970 Test Loss = 0.5661, Test Accuracy = 0.6944\n",
      "Iteration 670: Loss = 0.5734, Accuracy = 0.6950 Test Loss = 0.5653, Test Accuracy = 0.6938\n",
      "Iteration 671: Loss = 0.5654, Accuracy = 0.7060 Test Loss = 0.5651, Test Accuracy = 0.6934\n",
      "Iteration 672: Loss = 0.5424, Accuracy = 0.6740 Test Loss = 0.5640, Test Accuracy = 0.6947\n",
      "Iteration 673: Loss = 0.5774, Accuracy = 0.6890 Test Loss = 0.5632, Test Accuracy = 0.6945\n",
      "Iteration 674: Loss = 0.5613, Accuracy = 0.6930 Test Loss = 0.5624, Test Accuracy = 0.6963\n",
      "Iteration 675: Loss = 0.6215, Accuracy = 0.6720 Test Loss = 0.5618, Test Accuracy = 0.6958\n",
      "Iteration 676: Loss = 0.5654, Accuracy = 0.6790 Test Loss = 0.5611, Test Accuracy = 0.6964\n",
      "Iteration 677: Loss = 0.5890, Accuracy = 0.6690 Test Loss = 0.5602, Test Accuracy = 0.6961\n",
      "Iteration 678: Loss = 0.5401, Accuracy = 0.7070 Test Loss = 0.5596, Test Accuracy = 0.6965\n",
      "Iteration 679: Loss = 0.5905, Accuracy = 0.6700 Test Loss = 0.5590, Test Accuracy = 0.6973\n",
      "Iteration 680: Loss = 0.5213, Accuracy = 0.7060 Test Loss = 0.5583, Test Accuracy = 0.6976\n",
      "Iteration 681: Loss = 0.5574, Accuracy = 0.7010 Test Loss = 0.5574, Test Accuracy = 0.6975\n",
      "Iteration 682: Loss = 0.5451, Accuracy = 0.6880 Test Loss = 0.5568, Test Accuracy = 0.6979\n",
      "Iteration 683: Loss = 0.5844, Accuracy = 0.6930 Test Loss = 0.5561, Test Accuracy = 0.6977\n",
      "Iteration 684: Loss = 0.5513, Accuracy = 0.7000 Test Loss = 0.5555, Test Accuracy = 0.6971\n",
      "Iteration 685: Loss = 0.5778, Accuracy = 0.6700 Test Loss = 0.5546, Test Accuracy = 0.6987\n",
      "Iteration 686: Loss = 0.5617, Accuracy = 0.6940 Test Loss = 0.5542, Test Accuracy = 0.6992\n",
      "Iteration 687: Loss = 0.5088, Accuracy = 0.7150 Test Loss = 0.5533, Test Accuracy = 0.6997\n",
      "Iteration 688: Loss = 0.5280, Accuracy = 0.7020 Test Loss = 0.5528, Test Accuracy = 0.7004\n",
      "Iteration 689: Loss = 0.5432, Accuracy = 0.6790 Test Loss = 0.5520, Test Accuracy = 0.7008\n",
      "Iteration 690: Loss = 0.5397, Accuracy = 0.7180 Test Loss = 0.5513, Test Accuracy = 0.7001\n",
      "Iteration 691: Loss = 0.5730, Accuracy = 0.6880 Test Loss = 0.5507, Test Accuracy = 0.7012\n",
      "Iteration 692: Loss = 0.5866, Accuracy = 0.6810 Test Loss = 0.5501, Test Accuracy = 0.7011\n",
      "Iteration 693: Loss = 0.5418, Accuracy = 0.6860 Test Loss = 0.5494, Test Accuracy = 0.7017\n",
      "Iteration 694: Loss = 0.5517, Accuracy = 0.6790 Test Loss = 0.5486, Test Accuracy = 0.7005\n",
      "Iteration 695: Loss = 0.5351, Accuracy = 0.7060 Test Loss = 0.5480, Test Accuracy = 0.7012\n",
      "Iteration 696: Loss = 0.5257, Accuracy = 0.6940 Test Loss = 0.5474, Test Accuracy = 0.7016\n",
      "Iteration 697: Loss = 0.5372, Accuracy = 0.7030 Test Loss = 0.5466, Test Accuracy = 0.7020\n",
      "Iteration 698: Loss = 0.5633, Accuracy = 0.6750 Test Loss = 0.5461, Test Accuracy = 0.7022\n",
      "Iteration 699: Loss = 0.5871, Accuracy = 0.6970 Test Loss = 0.5453, Test Accuracy = 0.7021\n",
      "Iteration 700: Loss = 0.5357, Accuracy = 0.7210 Test Loss = 0.5448, Test Accuracy = 0.7034\n",
      "Iteration 701: Loss = 0.5336, Accuracy = 0.7110 Test Loss = 0.5442, Test Accuracy = 0.7026\n",
      "Iteration 702: Loss = 0.5572, Accuracy = 0.7200 Test Loss = 0.5436, Test Accuracy = 0.7034\n",
      "Iteration 703: Loss = 0.5286, Accuracy = 0.7100 Test Loss = 0.5427, Test Accuracy = 0.7040\n",
      "Iteration 704: Loss = 0.5643, Accuracy = 0.6800 Test Loss = 0.5422, Test Accuracy = 0.7043\n",
      "Iteration 705: Loss = 0.5419, Accuracy = 0.7080 Test Loss = 0.5416, Test Accuracy = 0.7048\n",
      "Iteration 706: Loss = 0.5558, Accuracy = 0.6810 Test Loss = 0.5412, Test Accuracy = 0.7046\n",
      "Iteration 707: Loss = 0.5050, Accuracy = 0.7160 Test Loss = 0.5404, Test Accuracy = 0.7056\n",
      "Iteration 708: Loss = 0.5525, Accuracy = 0.7110 Test Loss = 0.5397, Test Accuracy = 0.7060\n",
      "Iteration 709: Loss = 0.4843, Accuracy = 0.7130 Test Loss = 0.5389, Test Accuracy = 0.7051\n",
      "Iteration 710: Loss = 0.5813, Accuracy = 0.6810 Test Loss = 0.5384, Test Accuracy = 0.7060\n",
      "Iteration 711: Loss = 0.5661, Accuracy = 0.6890 Test Loss = 0.5378, Test Accuracy = 0.7061\n",
      "Iteration 712: Loss = 0.5425, Accuracy = 0.7110 Test Loss = 0.5372, Test Accuracy = 0.7070\n",
      "Iteration 713: Loss = 0.5430, Accuracy = 0.7080 Test Loss = 0.5365, Test Accuracy = 0.7070\n",
      "Iteration 714: Loss = 0.5327, Accuracy = 0.7200 Test Loss = 0.5360, Test Accuracy = 0.7065\n",
      "Iteration 715: Loss = 0.5114, Accuracy = 0.7400 Test Loss = 0.5352, Test Accuracy = 0.7072\n",
      "Iteration 716: Loss = 0.5237, Accuracy = 0.7040 Test Loss = 0.5346, Test Accuracy = 0.7075\n",
      "Iteration 717: Loss = 0.5265, Accuracy = 0.7110 Test Loss = 0.5339, Test Accuracy = 0.7084\n",
      "Iteration 718: Loss = 0.5500, Accuracy = 0.6880 Test Loss = 0.5334, Test Accuracy = 0.7093\n",
      "Iteration 719: Loss = 0.5508, Accuracy = 0.7070 Test Loss = 0.5328, Test Accuracy = 0.7093\n",
      "Iteration 720: Loss = 0.5107, Accuracy = 0.6800 Test Loss = 0.5321, Test Accuracy = 0.7089\n",
      "Iteration 721: Loss = 0.5665, Accuracy = 0.6880 Test Loss = 0.5317, Test Accuracy = 0.7095\n",
      "Iteration 722: Loss = 0.5644, Accuracy = 0.7060 Test Loss = 0.5310, Test Accuracy = 0.7097\n",
      "Iteration 723: Loss = 0.5060, Accuracy = 0.7200 Test Loss = 0.5303, Test Accuracy = 0.7101\n",
      "Iteration 724: Loss = 0.5433, Accuracy = 0.7140 Test Loss = 0.5296, Test Accuracy = 0.7104\n",
      "Iteration 725: Loss = 0.5095, Accuracy = 0.6970 Test Loss = 0.5291, Test Accuracy = 0.7099\n",
      "Iteration 726: Loss = 0.4991, Accuracy = 0.7060 Test Loss = 0.5287, Test Accuracy = 0.7104\n",
      "Iteration 727: Loss = 0.5071, Accuracy = 0.7180 Test Loss = 0.5281, Test Accuracy = 0.7102\n",
      "Iteration 728: Loss = 0.5035, Accuracy = 0.6850 Test Loss = 0.5277, Test Accuracy = 0.7112\n",
      "Iteration 729: Loss = 0.5432, Accuracy = 0.7160 Test Loss = 0.5269, Test Accuracy = 0.7114\n",
      "Iteration 730: Loss = 0.5507, Accuracy = 0.7190 Test Loss = 0.5262, Test Accuracy = 0.7123\n",
      "Iteration 731: Loss = 0.5006, Accuracy = 0.7380 Test Loss = 0.5256, Test Accuracy = 0.7122\n",
      "Iteration 732: Loss = 0.5116, Accuracy = 0.7080 Test Loss = 0.5250, Test Accuracy = 0.7125\n",
      "Iteration 733: Loss = 0.5006, Accuracy = 0.7020 Test Loss = 0.5246, Test Accuracy = 0.7121\n",
      "Iteration 734: Loss = 0.5164, Accuracy = 0.7300 Test Loss = 0.5240, Test Accuracy = 0.7133\n",
      "Iteration 735: Loss = 0.5593, Accuracy = 0.6950 Test Loss = 0.5235, Test Accuracy = 0.7128\n",
      "Iteration 736: Loss = 0.5043, Accuracy = 0.7220 Test Loss = 0.5227, Test Accuracy = 0.7133\n",
      "Iteration 737: Loss = 0.4993, Accuracy = 0.7210 Test Loss = 0.5220, Test Accuracy = 0.7130\n",
      "Iteration 738: Loss = 0.5076, Accuracy = 0.7080 Test Loss = 0.5217, Test Accuracy = 0.7129\n",
      "Iteration 739: Loss = 0.5201, Accuracy = 0.7110 Test Loss = 0.5211, Test Accuracy = 0.7137\n",
      "Iteration 740: Loss = 0.5642, Accuracy = 0.7050 Test Loss = 0.5203, Test Accuracy = 0.7139\n",
      "Iteration 741: Loss = 0.5112, Accuracy = 0.7130 Test Loss = 0.5199, Test Accuracy = 0.7149\n",
      "Iteration 742: Loss = 0.5358, Accuracy = 0.7000 Test Loss = 0.5192, Test Accuracy = 0.7145\n",
      "Iteration 743: Loss = 0.4921, Accuracy = 0.6960 Test Loss = 0.5189, Test Accuracy = 0.7144\n",
      "Iteration 744: Loss = 0.5356, Accuracy = 0.7070 Test Loss = 0.5182, Test Accuracy = 0.7153\n",
      "Iteration 745: Loss = 0.4796, Accuracy = 0.7440 Test Loss = 0.5176, Test Accuracy = 0.7152\n",
      "Iteration 746: Loss = 0.5610, Accuracy = 0.7080 Test Loss = 0.5172, Test Accuracy = 0.7160\n",
      "Iteration 747: Loss = 0.5552, Accuracy = 0.7060 Test Loss = 0.5166, Test Accuracy = 0.7160\n",
      "Iteration 748: Loss = 0.5856, Accuracy = 0.6990 Test Loss = 0.5162, Test Accuracy = 0.7147\n",
      "Iteration 749: Loss = 0.5247, Accuracy = 0.7080 Test Loss = 0.5155, Test Accuracy = 0.7157\n",
      "Iteration 750: Loss = 0.5203, Accuracy = 0.6960 Test Loss = 0.5147, Test Accuracy = 0.7172\n",
      "Iteration 751: Loss = 0.5302, Accuracy = 0.7010 Test Loss = 0.5143, Test Accuracy = 0.7172\n",
      "Iteration 752: Loss = 0.5357, Accuracy = 0.7030 Test Loss = 0.5137, Test Accuracy = 0.7180\n",
      "Iteration 753: Loss = 0.4945, Accuracy = 0.7060 Test Loss = 0.5131, Test Accuracy = 0.7181\n",
      "Iteration 754: Loss = 0.4862, Accuracy = 0.6990 Test Loss = 0.5127, Test Accuracy = 0.7175\n",
      "Iteration 755: Loss = 0.4898, Accuracy = 0.6990 Test Loss = 0.5121, Test Accuracy = 0.7192\n",
      "Iteration 756: Loss = 0.4997, Accuracy = 0.6930 Test Loss = 0.5116, Test Accuracy = 0.7175\n",
      "Iteration 757: Loss = 0.4714, Accuracy = 0.7250 Test Loss = 0.5110, Test Accuracy = 0.7183\n",
      "Iteration 758: Loss = 0.5099, Accuracy = 0.7160 Test Loss = 0.5105, Test Accuracy = 0.7180\n",
      "Iteration 759: Loss = 0.5166, Accuracy = 0.7100 Test Loss = 0.5100, Test Accuracy = 0.7183\n",
      "Iteration 760: Loss = 0.4822, Accuracy = 0.7230 Test Loss = 0.5095, Test Accuracy = 0.7188\n",
      "Iteration 761: Loss = 0.5473, Accuracy = 0.7130 Test Loss = 0.5090, Test Accuracy = 0.7188\n",
      "Iteration 762: Loss = 0.5030, Accuracy = 0.7250 Test Loss = 0.5083, Test Accuracy = 0.7195\n",
      "Iteration 763: Loss = 0.5348, Accuracy = 0.7020 Test Loss = 0.5079, Test Accuracy = 0.7185\n",
      "Iteration 764: Loss = 0.5255, Accuracy = 0.7080 Test Loss = 0.5074, Test Accuracy = 0.7186\n",
      "Iteration 765: Loss = 0.5105, Accuracy = 0.6990 Test Loss = 0.5067, Test Accuracy = 0.7204\n",
      "Iteration 766: Loss = 0.4860, Accuracy = 0.7310 Test Loss = 0.5062, Test Accuracy = 0.7207\n",
      "Iteration 767: Loss = 0.4735, Accuracy = 0.7360 Test Loss = 0.5057, Test Accuracy = 0.7198\n",
      "Iteration 768: Loss = 0.5236, Accuracy = 0.7060 Test Loss = 0.5053, Test Accuracy = 0.7207\n",
      "Iteration 769: Loss = 0.5503, Accuracy = 0.6980 Test Loss = 0.5047, Test Accuracy = 0.7201\n",
      "Iteration 770: Loss = 0.4763, Accuracy = 0.7360 Test Loss = 0.5041, Test Accuracy = 0.7209\n",
      "Iteration 771: Loss = 0.5103, Accuracy = 0.7160 Test Loss = 0.5036, Test Accuracy = 0.7211\n",
      "Iteration 772: Loss = 0.5040, Accuracy = 0.7260 Test Loss = 0.5032, Test Accuracy = 0.7215\n",
      "Iteration 773: Loss = 0.4994, Accuracy = 0.7220 Test Loss = 0.5028, Test Accuracy = 0.7212\n",
      "Iteration 774: Loss = 0.5201, Accuracy = 0.7220 Test Loss = 0.5021, Test Accuracy = 0.7209\n",
      "Iteration 775: Loss = 0.4720, Accuracy = 0.7330 Test Loss = 0.5017, Test Accuracy = 0.7219\n",
      "Iteration 776: Loss = 0.4922, Accuracy = 0.7030 Test Loss = 0.5012, Test Accuracy = 0.7228\n",
      "Iteration 777: Loss = 0.5006, Accuracy = 0.7140 Test Loss = 0.5005, Test Accuracy = 0.7219\n",
      "Iteration 778: Loss = 0.5136, Accuracy = 0.7390 Test Loss = 0.5001, Test Accuracy = 0.7222\n",
      "Iteration 779: Loss = 0.5179, Accuracy = 0.7120 Test Loss = 0.4997, Test Accuracy = 0.7226\n",
      "Iteration 780: Loss = 0.4967, Accuracy = 0.7190 Test Loss = 0.4991, Test Accuracy = 0.7229\n",
      "Iteration 781: Loss = 0.4905, Accuracy = 0.7200 Test Loss = 0.4986, Test Accuracy = 0.7220\n",
      "Iteration 782: Loss = 0.5591, Accuracy = 0.7060 Test Loss = 0.4983, Test Accuracy = 0.7227\n",
      "Iteration 783: Loss = 0.4975, Accuracy = 0.7420 Test Loss = 0.4977, Test Accuracy = 0.7235\n",
      "Iteration 784: Loss = 0.4843, Accuracy = 0.7280 Test Loss = 0.4973, Test Accuracy = 0.7233\n",
      "Iteration 785: Loss = 0.5552, Accuracy = 0.7080 Test Loss = 0.4967, Test Accuracy = 0.7244\n",
      "Iteration 786: Loss = 0.5063, Accuracy = 0.6940 Test Loss = 0.4963, Test Accuracy = 0.7242\n",
      "Iteration 787: Loss = 0.5058, Accuracy = 0.7040 Test Loss = 0.4957, Test Accuracy = 0.7243\n",
      "Iteration 788: Loss = 0.5023, Accuracy = 0.7260 Test Loss = 0.4953, Test Accuracy = 0.7242\n",
      "Iteration 789: Loss = 0.4601, Accuracy = 0.7280 Test Loss = 0.4948, Test Accuracy = 0.7262\n",
      "Iteration 790: Loss = 0.5000, Accuracy = 0.7220 Test Loss = 0.4943, Test Accuracy = 0.7245\n",
      "Iteration 791: Loss = 0.4924, Accuracy = 0.7230 Test Loss = 0.4937, Test Accuracy = 0.7256\n",
      "Iteration 792: Loss = 0.5477, Accuracy = 0.7230 Test Loss = 0.4933, Test Accuracy = 0.7254\n",
      "Iteration 793: Loss = 0.5253, Accuracy = 0.7260 Test Loss = 0.4927, Test Accuracy = 0.7249\n",
      "Iteration 794: Loss = 0.4706, Accuracy = 0.7290 Test Loss = 0.4922, Test Accuracy = 0.7255\n",
      "Iteration 795: Loss = 0.4830, Accuracy = 0.7080 Test Loss = 0.4919, Test Accuracy = 0.7263\n",
      "Iteration 796: Loss = 0.5012, Accuracy = 0.7430 Test Loss = 0.4913, Test Accuracy = 0.7251\n",
      "Iteration 797: Loss = 0.5399, Accuracy = 0.6780 Test Loss = 0.4908, Test Accuracy = 0.7262\n",
      "Iteration 798: Loss = 0.4703, Accuracy = 0.7310 Test Loss = 0.4904, Test Accuracy = 0.7266\n",
      "Iteration 799: Loss = 0.5253, Accuracy = 0.7380 Test Loss = 0.4900, Test Accuracy = 0.7257\n",
      "Iteration 800: Loss = 0.5014, Accuracy = 0.7130 Test Loss = 0.4893, Test Accuracy = 0.7277\n",
      "Iteration 801: Loss = 0.4655, Accuracy = 0.7320 Test Loss = 0.4890, Test Accuracy = 0.7288\n",
      "Iteration 802: Loss = 0.4966, Accuracy = 0.7200 Test Loss = 0.4886, Test Accuracy = 0.7279\n",
      "Iteration 803: Loss = 0.5124, Accuracy = 0.7420 Test Loss = 0.4881, Test Accuracy = 0.7277\n",
      "Iteration 804: Loss = 0.4551, Accuracy = 0.7380 Test Loss = 0.4878, Test Accuracy = 0.7285\n",
      "Iteration 805: Loss = 0.5036, Accuracy = 0.7340 Test Loss = 0.4874, Test Accuracy = 0.7282\n",
      "Iteration 806: Loss = 0.4496, Accuracy = 0.7500 Test Loss = 0.4866, Test Accuracy = 0.7289\n",
      "Iteration 807: Loss = 0.4584, Accuracy = 0.7250 Test Loss = 0.4863, Test Accuracy = 0.7286\n",
      "Iteration 808: Loss = 0.5150, Accuracy = 0.7230 Test Loss = 0.4857, Test Accuracy = 0.7276\n",
      "Iteration 809: Loss = 0.4900, Accuracy = 0.7250 Test Loss = 0.4853, Test Accuracy = 0.7286\n",
      "Iteration 810: Loss = 0.4706, Accuracy = 0.7390 Test Loss = 0.4848, Test Accuracy = 0.7294\n",
      "Iteration 811: Loss = 0.4940, Accuracy = 0.7170 Test Loss = 0.4844, Test Accuracy = 0.7296\n",
      "Iteration 812: Loss = 0.5100, Accuracy = 0.7180 Test Loss = 0.4838, Test Accuracy = 0.7284\n",
      "Iteration 813: Loss = 0.5064, Accuracy = 0.7230 Test Loss = 0.4833, Test Accuracy = 0.7304\n",
      "Iteration 814: Loss = 0.4603, Accuracy = 0.7450 Test Loss = 0.4829, Test Accuracy = 0.7304\n",
      "Iteration 815: Loss = 0.4674, Accuracy = 0.7310 Test Loss = 0.4824, Test Accuracy = 0.7302\n",
      "Iteration 816: Loss = 0.4727, Accuracy = 0.7430 Test Loss = 0.4820, Test Accuracy = 0.7301\n",
      "Iteration 817: Loss = 0.5224, Accuracy = 0.7340 Test Loss = 0.4815, Test Accuracy = 0.7314\n",
      "Iteration 818: Loss = 0.5056, Accuracy = 0.7120 Test Loss = 0.4810, Test Accuracy = 0.7301\n",
      "Iteration 819: Loss = 0.4957, Accuracy = 0.7040 Test Loss = 0.4809, Test Accuracy = 0.7300\n",
      "Iteration 820: Loss = 0.4684, Accuracy = 0.7220 Test Loss = 0.4803, Test Accuracy = 0.7314\n",
      "Iteration 821: Loss = 0.4904, Accuracy = 0.7500 Test Loss = 0.4797, Test Accuracy = 0.7320\n",
      "Iteration 822: Loss = 0.4620, Accuracy = 0.7490 Test Loss = 0.4794, Test Accuracy = 0.7323\n",
      "Iteration 823: Loss = 0.4561, Accuracy = 0.7350 Test Loss = 0.4790, Test Accuracy = 0.7327\n",
      "Iteration 824: Loss = 0.4878, Accuracy = 0.7220 Test Loss = 0.4785, Test Accuracy = 0.7312\n",
      "Iteration 825: Loss = 0.4792, Accuracy = 0.7260 Test Loss = 0.4784, Test Accuracy = 0.7314\n",
      "Iteration 826: Loss = 0.4894, Accuracy = 0.7380 Test Loss = 0.4778, Test Accuracy = 0.7310\n",
      "Iteration 827: Loss = 0.4535, Accuracy = 0.7420 Test Loss = 0.4773, Test Accuracy = 0.7315\n",
      "Iteration 828: Loss = 0.4847, Accuracy = 0.7130 Test Loss = 0.4767, Test Accuracy = 0.7346\n",
      "Iteration 829: Loss = 0.5016, Accuracy = 0.7260 Test Loss = 0.4763, Test Accuracy = 0.7336\n",
      "Iteration 830: Loss = 0.4883, Accuracy = 0.7140 Test Loss = 0.4757, Test Accuracy = 0.7339\n",
      "Iteration 831: Loss = 0.4606, Accuracy = 0.7280 Test Loss = 0.4753, Test Accuracy = 0.7329\n",
      "Iteration 832: Loss = 0.4970, Accuracy = 0.7320 Test Loss = 0.4750, Test Accuracy = 0.7335\n",
      "Iteration 833: Loss = 0.5032, Accuracy = 0.7090 Test Loss = 0.4746, Test Accuracy = 0.7340\n",
      "Iteration 834: Loss = 0.4399, Accuracy = 0.7360 Test Loss = 0.4741, Test Accuracy = 0.7335\n",
      "Iteration 835: Loss = 0.4944, Accuracy = 0.7330 Test Loss = 0.4739, Test Accuracy = 0.7325\n",
      "Iteration 836: Loss = 0.4728, Accuracy = 0.7420 Test Loss = 0.4734, Test Accuracy = 0.7343\n",
      "Iteration 837: Loss = 0.4838, Accuracy = 0.7280 Test Loss = 0.4729, Test Accuracy = 0.7326\n",
      "Iteration 838: Loss = 0.4600, Accuracy = 0.7350 Test Loss = 0.4725, Test Accuracy = 0.7353\n",
      "Iteration 839: Loss = 0.4841, Accuracy = 0.7420 Test Loss = 0.4720, Test Accuracy = 0.7342\n",
      "Iteration 840: Loss = 0.4624, Accuracy = 0.7150 Test Loss = 0.4716, Test Accuracy = 0.7350\n",
      "Iteration 841: Loss = 0.4694, Accuracy = 0.7290 Test Loss = 0.4711, Test Accuracy = 0.7366\n",
      "Iteration 842: Loss = 0.4831, Accuracy = 0.7140 Test Loss = 0.4707, Test Accuracy = 0.7353\n",
      "Iteration 843: Loss = 0.4836, Accuracy = 0.7030 Test Loss = 0.4704, Test Accuracy = 0.7382\n",
      "Iteration 844: Loss = 0.4704, Accuracy = 0.7310 Test Loss = 0.4698, Test Accuracy = 0.7368\n",
      "Iteration 845: Loss = 0.4658, Accuracy = 0.7370 Test Loss = 0.4695, Test Accuracy = 0.7369\n",
      "Iteration 846: Loss = 0.4721, Accuracy = 0.7430 Test Loss = 0.4694, Test Accuracy = 0.7365\n",
      "Iteration 847: Loss = 0.4665, Accuracy = 0.7370 Test Loss = 0.4688, Test Accuracy = 0.7377\n",
      "Iteration 848: Loss = 0.4466, Accuracy = 0.7380 Test Loss = 0.4683, Test Accuracy = 0.7377\n",
      "Iteration 849: Loss = 0.4632, Accuracy = 0.7640 Test Loss = 0.4678, Test Accuracy = 0.7372\n",
      "Iteration 850: Loss = 0.4596, Accuracy = 0.7360 Test Loss = 0.4674, Test Accuracy = 0.7370\n",
      "Iteration 851: Loss = 0.4541, Accuracy = 0.7290 Test Loss = 0.4671, Test Accuracy = 0.7385\n",
      "Iteration 852: Loss = 0.4785, Accuracy = 0.7340 Test Loss = 0.4666, Test Accuracy = 0.7393\n",
      "Iteration 853: Loss = 0.4736, Accuracy = 0.7440 Test Loss = 0.4663, Test Accuracy = 0.7381\n",
      "Iteration 854: Loss = 0.4669, Accuracy = 0.7420 Test Loss = 0.4660, Test Accuracy = 0.7376\n",
      "Iteration 855: Loss = 0.4507, Accuracy = 0.7270 Test Loss = 0.4655, Test Accuracy = 0.7389\n",
      "Iteration 856: Loss = 0.4906, Accuracy = 0.7320 Test Loss = 0.4651, Test Accuracy = 0.7395\n",
      "Iteration 857: Loss = 0.4426, Accuracy = 0.7410 Test Loss = 0.4647, Test Accuracy = 0.7393\n",
      "Iteration 858: Loss = 0.4640, Accuracy = 0.7370 Test Loss = 0.4642, Test Accuracy = 0.7398\n",
      "Iteration 859: Loss = 0.5201, Accuracy = 0.7210 Test Loss = 0.4640, Test Accuracy = 0.7402\n",
      "Iteration 860: Loss = 0.4294, Accuracy = 0.7310 Test Loss = 0.4634, Test Accuracy = 0.7399\n",
      "Iteration 861: Loss = 0.4460, Accuracy = 0.7590 Test Loss = 0.4632, Test Accuracy = 0.7410\n",
      "Iteration 862: Loss = 0.4904, Accuracy = 0.7400 Test Loss = 0.4627, Test Accuracy = 0.7401\n",
      "Iteration 863: Loss = 0.4894, Accuracy = 0.7250 Test Loss = 0.4622, Test Accuracy = 0.7417\n",
      "Iteration 864: Loss = 0.4612, Accuracy = 0.7150 Test Loss = 0.4619, Test Accuracy = 0.7417\n",
      "Iteration 865: Loss = 0.4436, Accuracy = 0.7360 Test Loss = 0.4614, Test Accuracy = 0.7400\n",
      "Iteration 866: Loss = 0.4567, Accuracy = 0.7460 Test Loss = 0.4611, Test Accuracy = 0.7410\n",
      "Iteration 867: Loss = 0.4779, Accuracy = 0.7330 Test Loss = 0.4609, Test Accuracy = 0.7422\n",
      "Iteration 868: Loss = 0.4513, Accuracy = 0.7450 Test Loss = 0.4602, Test Accuracy = 0.7410\n",
      "Iteration 869: Loss = 0.4801, Accuracy = 0.7310 Test Loss = 0.4600, Test Accuracy = 0.7417\n",
      "Iteration 870: Loss = 0.4637, Accuracy = 0.7440 Test Loss = 0.4595, Test Accuracy = 0.7416\n",
      "Iteration 871: Loss = 0.4594, Accuracy = 0.7390 Test Loss = 0.4592, Test Accuracy = 0.7433\n",
      "Iteration 872: Loss = 0.4741, Accuracy = 0.7490 Test Loss = 0.4590, Test Accuracy = 0.7427\n",
      "Iteration 873: Loss = 0.4625, Accuracy = 0.7270 Test Loss = 0.4585, Test Accuracy = 0.7409\n",
      "Iteration 874: Loss = 0.4399, Accuracy = 0.7250 Test Loss = 0.4580, Test Accuracy = 0.7406\n",
      "Iteration 875: Loss = 0.4683, Accuracy = 0.7160 Test Loss = 0.4577, Test Accuracy = 0.7410\n",
      "Iteration 876: Loss = 0.4363, Accuracy = 0.7620 Test Loss = 0.4574, Test Accuracy = 0.7433\n",
      "Iteration 877: Loss = 0.4417, Accuracy = 0.7320 Test Loss = 0.4569, Test Accuracy = 0.7429\n",
      "Iteration 878: Loss = 0.4563, Accuracy = 0.7160 Test Loss = 0.4565, Test Accuracy = 0.7426\n",
      "Iteration 879: Loss = 0.4497, Accuracy = 0.7420 Test Loss = 0.4560, Test Accuracy = 0.7439\n",
      "Iteration 880: Loss = 0.4494, Accuracy = 0.7530 Test Loss = 0.4560, Test Accuracy = 0.7439\n",
      "Iteration 881: Loss = 0.4658, Accuracy = 0.7510 Test Loss = 0.4555, Test Accuracy = 0.7435\n",
      "Iteration 882: Loss = 0.4565, Accuracy = 0.7530 Test Loss = 0.4551, Test Accuracy = 0.7435\n",
      "Iteration 883: Loss = 0.4538, Accuracy = 0.7430 Test Loss = 0.4546, Test Accuracy = 0.7437\n",
      "Iteration 884: Loss = 0.4872, Accuracy = 0.7400 Test Loss = 0.4542, Test Accuracy = 0.7443\n",
      "Iteration 885: Loss = 0.4197, Accuracy = 0.7290 Test Loss = 0.4540, Test Accuracy = 0.7439\n",
      "Iteration 886: Loss = 0.4538, Accuracy = 0.7420 Test Loss = 0.4535, Test Accuracy = 0.7444\n",
      "Iteration 887: Loss = 0.4516, Accuracy = 0.7450 Test Loss = 0.4532, Test Accuracy = 0.7454\n",
      "Iteration 888: Loss = 0.4482, Accuracy = 0.7390 Test Loss = 0.4527, Test Accuracy = 0.7443\n",
      "Iteration 889: Loss = 0.5019, Accuracy = 0.7360 Test Loss = 0.4526, Test Accuracy = 0.7439\n",
      "Iteration 890: Loss = 0.4477, Accuracy = 0.7710 Test Loss = 0.4521, Test Accuracy = 0.7437\n",
      "Iteration 891: Loss = 0.4438, Accuracy = 0.7360 Test Loss = 0.4517, Test Accuracy = 0.7447\n",
      "Iteration 892: Loss = 0.4996, Accuracy = 0.7250 Test Loss = 0.4513, Test Accuracy = 0.7448\n",
      "Iteration 893: Loss = 0.4926, Accuracy = 0.7060 Test Loss = 0.4511, Test Accuracy = 0.7456\n",
      "Iteration 894: Loss = 0.4566, Accuracy = 0.7520 Test Loss = 0.4505, Test Accuracy = 0.7454\n",
      "Iteration 895: Loss = 0.4831, Accuracy = 0.7310 Test Loss = 0.4502, Test Accuracy = 0.7457\n",
      "Iteration 896: Loss = 0.4799, Accuracy = 0.7500 Test Loss = 0.4499, Test Accuracy = 0.7458\n",
      "Iteration 897: Loss = 0.4289, Accuracy = 0.7310 Test Loss = 0.4495, Test Accuracy = 0.7455\n",
      "Iteration 898: Loss = 0.4476, Accuracy = 0.7350 Test Loss = 0.4493, Test Accuracy = 0.7464\n",
      "Iteration 899: Loss = 0.4573, Accuracy = 0.7570 Test Loss = 0.4489, Test Accuracy = 0.7444\n",
      "Iteration 900: Loss = 0.4256, Accuracy = 0.7660 Test Loss = 0.4484, Test Accuracy = 0.7463\n",
      "Iteration 901: Loss = 0.4716, Accuracy = 0.7290 Test Loss = 0.4482, Test Accuracy = 0.7458\n",
      "Iteration 902: Loss = 0.4158, Accuracy = 0.7730 Test Loss = 0.4476, Test Accuracy = 0.7466\n",
      "Iteration 903: Loss = 0.4561, Accuracy = 0.7430 Test Loss = 0.4475, Test Accuracy = 0.7478\n",
      "Iteration 904: Loss = 0.4462, Accuracy = 0.7470 Test Loss = 0.4470, Test Accuracy = 0.7472\n",
      "Iteration 905: Loss = 0.4562, Accuracy = 0.7380 Test Loss = 0.4466, Test Accuracy = 0.7467\n",
      "Iteration 906: Loss = 0.4565, Accuracy = 0.7510 Test Loss = 0.4463, Test Accuracy = 0.7472\n",
      "Iteration 907: Loss = 0.4381, Accuracy = 0.7570 Test Loss = 0.4460, Test Accuracy = 0.7467\n",
      "Iteration 908: Loss = 0.4504, Accuracy = 0.7440 Test Loss = 0.4456, Test Accuracy = 0.7480\n",
      "Iteration 909: Loss = 0.4233, Accuracy = 0.7740 Test Loss = 0.4454, Test Accuracy = 0.7470\n",
      "Iteration 910: Loss = 0.4765, Accuracy = 0.7350 Test Loss = 0.4449, Test Accuracy = 0.7462\n",
      "Iteration 911: Loss = 0.4338, Accuracy = 0.7510 Test Loss = 0.4446, Test Accuracy = 0.7481\n",
      "Iteration 912: Loss = 0.4351, Accuracy = 0.7510 Test Loss = 0.4443, Test Accuracy = 0.7489\n",
      "Iteration 913: Loss = 0.4521, Accuracy = 0.7310 Test Loss = 0.4439, Test Accuracy = 0.7488\n",
      "Iteration 914: Loss = 0.4335, Accuracy = 0.7330 Test Loss = 0.4437, Test Accuracy = 0.7487\n",
      "Iteration 915: Loss = 0.4327, Accuracy = 0.7590 Test Loss = 0.4432, Test Accuracy = 0.7480\n",
      "Iteration 916: Loss = 0.4614, Accuracy = 0.7420 Test Loss = 0.4429, Test Accuracy = 0.7491\n",
      "Iteration 917: Loss = 0.4589, Accuracy = 0.7150 Test Loss = 0.4425, Test Accuracy = 0.7489\n",
      "Iteration 918: Loss = 0.4702, Accuracy = 0.7320 Test Loss = 0.4423, Test Accuracy = 0.7490\n",
      "Iteration 919: Loss = 0.4257, Accuracy = 0.7360 Test Loss = 0.4419, Test Accuracy = 0.7487\n",
      "Iteration 920: Loss = 0.4515, Accuracy = 0.7400 Test Loss = 0.4415, Test Accuracy = 0.7504\n",
      "Iteration 921: Loss = 0.4395, Accuracy = 0.7530 Test Loss = 0.4411, Test Accuracy = 0.7480\n",
      "Iteration 922: Loss = 0.4256, Accuracy = 0.7350 Test Loss = 0.4408, Test Accuracy = 0.7495\n",
      "Iteration 923: Loss = 0.4520, Accuracy = 0.7100 Test Loss = 0.4407, Test Accuracy = 0.7483\n",
      "Iteration 924: Loss = 0.4601, Accuracy = 0.7500 Test Loss = 0.4402, Test Accuracy = 0.7501\n",
      "Iteration 925: Loss = 0.4473, Accuracy = 0.7170 Test Loss = 0.4398, Test Accuracy = 0.7494\n",
      "Iteration 926: Loss = 0.4505, Accuracy = 0.7630 Test Loss = 0.4396, Test Accuracy = 0.7498\n",
      "Iteration 927: Loss = 0.4321, Accuracy = 0.7420 Test Loss = 0.4394, Test Accuracy = 0.7497\n",
      "Iteration 928: Loss = 0.4510, Accuracy = 0.7330 Test Loss = 0.4389, Test Accuracy = 0.7511\n",
      "Iteration 929: Loss = 0.4332, Accuracy = 0.7370 Test Loss = 0.4385, Test Accuracy = 0.7504\n",
      "Iteration 930: Loss = 0.4138, Accuracy = 0.7620 Test Loss = 0.4382, Test Accuracy = 0.7515\n",
      "Iteration 931: Loss = 0.4631, Accuracy = 0.7230 Test Loss = 0.4379, Test Accuracy = 0.7504\n",
      "Iteration 932: Loss = 0.4514, Accuracy = 0.7400 Test Loss = 0.4376, Test Accuracy = 0.7512\n",
      "Iteration 933: Loss = 0.4204, Accuracy = 0.7460 Test Loss = 0.4373, Test Accuracy = 0.7518\n",
      "Iteration 934: Loss = 0.4488, Accuracy = 0.7580 Test Loss = 0.4368, Test Accuracy = 0.7516\n",
      "Iteration 935: Loss = 0.4296, Accuracy = 0.7480 Test Loss = 0.4365, Test Accuracy = 0.7511\n",
      "Iteration 936: Loss = 0.4184, Accuracy = 0.7400 Test Loss = 0.4363, Test Accuracy = 0.7510\n",
      "Iteration 937: Loss = 0.4303, Accuracy = 0.7600 Test Loss = 0.4359, Test Accuracy = 0.7514\n",
      "Iteration 938: Loss = 0.4480, Accuracy = 0.7540 Test Loss = 0.4357, Test Accuracy = 0.7522\n",
      "Iteration 939: Loss = 0.4737, Accuracy = 0.7430 Test Loss = 0.4352, Test Accuracy = 0.7515\n",
      "Iteration 940: Loss = 0.4639, Accuracy = 0.7640 Test Loss = 0.4351, Test Accuracy = 0.7519\n",
      "Iteration 941: Loss = 0.4238, Accuracy = 0.7670 Test Loss = 0.4346, Test Accuracy = 0.7522\n",
      "Iteration 942: Loss = 0.4280, Accuracy = 0.7500 Test Loss = 0.4343, Test Accuracy = 0.7529\n",
      "Iteration 943: Loss = 0.4116, Accuracy = 0.7630 Test Loss = 0.4339, Test Accuracy = 0.7539\n",
      "Iteration 944: Loss = 0.4341, Accuracy = 0.7270 Test Loss = 0.4336, Test Accuracy = 0.7532\n",
      "Iteration 945: Loss = 0.4686, Accuracy = 0.7270 Test Loss = 0.4335, Test Accuracy = 0.7519\n",
      "Iteration 946: Loss = 0.3888, Accuracy = 0.7680 Test Loss = 0.4330, Test Accuracy = 0.7532\n",
      "Iteration 947: Loss = 0.4439, Accuracy = 0.7350 Test Loss = 0.4328, Test Accuracy = 0.7519\n",
      "Iteration 948: Loss = 0.4905, Accuracy = 0.7420 Test Loss = 0.4323, Test Accuracy = 0.7545\n",
      "Iteration 949: Loss = 0.4302, Accuracy = 0.7560 Test Loss = 0.4321, Test Accuracy = 0.7530\n",
      "Iteration 950: Loss = 0.4128, Accuracy = 0.7610 Test Loss = 0.4318, Test Accuracy = 0.7529\n",
      "Iteration 951: Loss = 0.3973, Accuracy = 0.7640 Test Loss = 0.4314, Test Accuracy = 0.7527\n",
      "Iteration 952: Loss = 0.4541, Accuracy = 0.7550 Test Loss = 0.4312, Test Accuracy = 0.7522\n",
      "Iteration 953: Loss = 0.4407, Accuracy = 0.7550 Test Loss = 0.4308, Test Accuracy = 0.7530\n",
      "Iteration 954: Loss = 0.4438, Accuracy = 0.7340 Test Loss = 0.4306, Test Accuracy = 0.7538\n",
      "Iteration 955: Loss = 0.3970, Accuracy = 0.7520 Test Loss = 0.4303, Test Accuracy = 0.7546\n",
      "Iteration 956: Loss = 0.4248, Accuracy = 0.7560 Test Loss = 0.4298, Test Accuracy = 0.7533\n",
      "Iteration 957: Loss = 0.4801, Accuracy = 0.7490 Test Loss = 0.4295, Test Accuracy = 0.7543\n",
      "Iteration 958: Loss = 0.4384, Accuracy = 0.7370 Test Loss = 0.4293, Test Accuracy = 0.7542\n",
      "Iteration 959: Loss = 0.4002, Accuracy = 0.7710 Test Loss = 0.4291, Test Accuracy = 0.7547\n",
      "Iteration 960: Loss = 0.3903, Accuracy = 0.7670 Test Loss = 0.4288, Test Accuracy = 0.7547\n",
      "Iteration 961: Loss = 0.4138, Accuracy = 0.7830 Test Loss = 0.4284, Test Accuracy = 0.7546\n",
      "Iteration 962: Loss = 0.4372, Accuracy = 0.7410 Test Loss = 0.4280, Test Accuracy = 0.7541\n",
      "Iteration 963: Loss = 0.3946, Accuracy = 0.7410 Test Loss = 0.4277, Test Accuracy = 0.7548\n",
      "Iteration 964: Loss = 0.4419, Accuracy = 0.7580 Test Loss = 0.4274, Test Accuracy = 0.7550\n",
      "Iteration 965: Loss = 0.4539, Accuracy = 0.7670 Test Loss = 0.4272, Test Accuracy = 0.7535\n",
      "Iteration 966: Loss = 0.4355, Accuracy = 0.7420 Test Loss = 0.4269, Test Accuracy = 0.7552\n",
      "Iteration 967: Loss = 0.4434, Accuracy = 0.7490 Test Loss = 0.4266, Test Accuracy = 0.7554\n",
      "Iteration 968: Loss = 0.4135, Accuracy = 0.7600 Test Loss = 0.4262, Test Accuracy = 0.7561\n",
      "Iteration 969: Loss = 0.4541, Accuracy = 0.7430 Test Loss = 0.4260, Test Accuracy = 0.7553\n",
      "Iteration 970: Loss = 0.4195, Accuracy = 0.7580 Test Loss = 0.4256, Test Accuracy = 0.7557\n",
      "Iteration 971: Loss = 0.4249, Accuracy = 0.7500 Test Loss = 0.4254, Test Accuracy = 0.7563\n",
      "Iteration 972: Loss = 0.3973, Accuracy = 0.7570 Test Loss = 0.4251, Test Accuracy = 0.7569\n",
      "Iteration 973: Loss = 0.4333, Accuracy = 0.7340 Test Loss = 0.4248, Test Accuracy = 0.7558\n",
      "Iteration 974: Loss = 0.4443, Accuracy = 0.7510 Test Loss = 0.4246, Test Accuracy = 0.7561\n",
      "Iteration 975: Loss = 0.4795, Accuracy = 0.7250 Test Loss = 0.4243, Test Accuracy = 0.7566\n",
      "Iteration 976: Loss = 0.4170, Accuracy = 0.7340 Test Loss = 0.4241, Test Accuracy = 0.7577\n",
      "Iteration 977: Loss = 0.4822, Accuracy = 0.7330 Test Loss = 0.4236, Test Accuracy = 0.7561\n",
      "Iteration 978: Loss = 0.4057, Accuracy = 0.7660 Test Loss = 0.4233, Test Accuracy = 0.7564\n",
      "Iteration 979: Loss = 0.4175, Accuracy = 0.7450 Test Loss = 0.4231, Test Accuracy = 0.7582\n",
      "Iteration 980: Loss = 0.4232, Accuracy = 0.7690 Test Loss = 0.4227, Test Accuracy = 0.7574\n",
      "Iteration 981: Loss = 0.4065, Accuracy = 0.7510 Test Loss = 0.4225, Test Accuracy = 0.7571\n",
      "Iteration 982: Loss = 0.4299, Accuracy = 0.7720 Test Loss = 0.4223, Test Accuracy = 0.7583\n",
      "Iteration 983: Loss = 0.4578, Accuracy = 0.7580 Test Loss = 0.4219, Test Accuracy = 0.7575\n",
      "Iteration 984: Loss = 0.4107, Accuracy = 0.7420 Test Loss = 0.4216, Test Accuracy = 0.7577\n",
      "Iteration 985: Loss = 0.4462, Accuracy = 0.7490 Test Loss = 0.4212, Test Accuracy = 0.7569\n",
      "Iteration 986: Loss = 0.4048, Accuracy = 0.7520 Test Loss = 0.4211, Test Accuracy = 0.7569\n",
      "Iteration 987: Loss = 0.4109, Accuracy = 0.7680 Test Loss = 0.4208, Test Accuracy = 0.7587\n",
      "Iteration 988: Loss = 0.4018, Accuracy = 0.7710 Test Loss = 0.4204, Test Accuracy = 0.7587\n",
      "Iteration 989: Loss = 0.4142, Accuracy = 0.7610 Test Loss = 0.4201, Test Accuracy = 0.7579\n",
      "Iteration 990: Loss = 0.4206, Accuracy = 0.7420 Test Loss = 0.4199, Test Accuracy = 0.7583\n",
      "Iteration 991: Loss = 0.4235, Accuracy = 0.7470 Test Loss = 0.4196, Test Accuracy = 0.7583\n",
      "Iteration 992: Loss = 0.3984, Accuracy = 0.7720 Test Loss = 0.4192, Test Accuracy = 0.7589\n",
      "Iteration 993: Loss = 0.4154, Accuracy = 0.7630 Test Loss = 0.4189, Test Accuracy = 0.7587\n",
      "Iteration 994: Loss = 0.4323, Accuracy = 0.7540 Test Loss = 0.4188, Test Accuracy = 0.7589\n",
      "Iteration 995: Loss = 0.4090, Accuracy = 0.7560 Test Loss = 0.4184, Test Accuracy = 0.7604\n",
      "Iteration 996: Loss = 0.3843, Accuracy = 0.7940 Test Loss = 0.4182, Test Accuracy = 0.7589\n",
      "Iteration 997: Loss = 0.4037, Accuracy = 0.7760 Test Loss = 0.4180, Test Accuracy = 0.7598\n",
      "Iteration 998: Loss = 0.4154, Accuracy = 0.7530 Test Loss = 0.4177, Test Accuracy = 0.7585\n",
      "Iteration 999: Loss = 0.4218, Accuracy = 0.7680 Test Loss = 0.4174, Test Accuracy = 0.7597\n",
      "Iteration 1000: Loss = 0.4039, Accuracy = 0.7640 Test Loss = 0.4169, Test Accuracy = 0.7607\n",
      "Iteration 1001: Loss = 0.4037, Accuracy = 0.7620 Test Loss = 0.4167, Test Accuracy = 0.7606\n",
      "Iteration 1002: Loss = 0.4083, Accuracy = 0.7710 Test Loss = 0.4165, Test Accuracy = 0.7594\n",
      "Iteration 1003: Loss = 0.4114, Accuracy = 0.7180 Test Loss = 0.4164, Test Accuracy = 0.7615\n",
      "Iteration 1004: Loss = 0.4166, Accuracy = 0.7720 Test Loss = 0.4160, Test Accuracy = 0.7605\n",
      "Iteration 1005: Loss = 0.4296, Accuracy = 0.7620 Test Loss = 0.4156, Test Accuracy = 0.7598\n",
      "Iteration 1006: Loss = 0.4208, Accuracy = 0.7610 Test Loss = 0.4154, Test Accuracy = 0.7605\n",
      "Iteration 1007: Loss = 0.4016, Accuracy = 0.7670 Test Loss = 0.4151, Test Accuracy = 0.7610\n",
      "Iteration 1008: Loss = 0.3990, Accuracy = 0.7730 Test Loss = 0.4148, Test Accuracy = 0.7597\n",
      "Iteration 1009: Loss = 0.4056, Accuracy = 0.7490 Test Loss = 0.4145, Test Accuracy = 0.7616\n",
      "Iteration 1010: Loss = 0.4121, Accuracy = 0.7460 Test Loss = 0.4145, Test Accuracy = 0.7594\n",
      "Iteration 1011: Loss = 0.4264, Accuracy = 0.7560 Test Loss = 0.4141, Test Accuracy = 0.7613\n",
      "Iteration 1012: Loss = 0.4061, Accuracy = 0.7720 Test Loss = 0.4138, Test Accuracy = 0.7604\n",
      "Iteration 1013: Loss = 0.4193, Accuracy = 0.7430 Test Loss = 0.4136, Test Accuracy = 0.7612\n",
      "Iteration 1014: Loss = 0.4008, Accuracy = 0.7650 Test Loss = 0.4132, Test Accuracy = 0.7617\n",
      "Iteration 1015: Loss = 0.4043, Accuracy = 0.7720 Test Loss = 0.4130, Test Accuracy = 0.7635\n",
      "Iteration 1016: Loss = 0.4315, Accuracy = 0.7530 Test Loss = 0.4126, Test Accuracy = 0.7619\n",
      "Iteration 1017: Loss = 0.4493, Accuracy = 0.7300 Test Loss = 0.4123, Test Accuracy = 0.7625\n",
      "Iteration 1018: Loss = 0.4425, Accuracy = 0.7610 Test Loss = 0.4123, Test Accuracy = 0.7608\n",
      "Iteration 1019: Loss = 0.4050, Accuracy = 0.7640 Test Loss = 0.4119, Test Accuracy = 0.7601\n",
      "Iteration 1020: Loss = 0.3883, Accuracy = 0.7610 Test Loss = 0.4117, Test Accuracy = 0.7611\n",
      "Iteration 1021: Loss = 0.4005, Accuracy = 0.7580 Test Loss = 0.4113, Test Accuracy = 0.7632\n",
      "Iteration 1022: Loss = 0.4145, Accuracy = 0.7580 Test Loss = 0.4112, Test Accuracy = 0.7629\n",
      "Iteration 1023: Loss = 0.4069, Accuracy = 0.7510 Test Loss = 0.4109, Test Accuracy = 0.7630\n",
      "Iteration 1024: Loss = 0.4145, Accuracy = 0.7650 Test Loss = 0.4106, Test Accuracy = 0.7624\n",
      "Iteration 1025: Loss = 0.4090, Accuracy = 0.7580 Test Loss = 0.4102, Test Accuracy = 0.7630\n",
      "Iteration 1026: Loss = 0.3975, Accuracy = 0.7550 Test Loss = 0.4101, Test Accuracy = 0.7638\n",
      "Iteration 1027: Loss = 0.4325, Accuracy = 0.7650 Test Loss = 0.4098, Test Accuracy = 0.7631\n",
      "Iteration 1028: Loss = 0.3879, Accuracy = 0.7470 Test Loss = 0.4096, Test Accuracy = 0.7642\n",
      "Iteration 1029: Loss = 0.4424, Accuracy = 0.7420 Test Loss = 0.4093, Test Accuracy = 0.7650\n",
      "Iteration 1030: Loss = 0.4045, Accuracy = 0.7820 Test Loss = 0.4091, Test Accuracy = 0.7618\n",
      "Iteration 1031: Loss = 0.4081, Accuracy = 0.7590 Test Loss = 0.4088, Test Accuracy = 0.7636\n",
      "Iteration 1032: Loss = 0.4032, Accuracy = 0.7610 Test Loss = 0.4085, Test Accuracy = 0.7640\n",
      "Iteration 1033: Loss = 0.4131, Accuracy = 0.7320 Test Loss = 0.4082, Test Accuracy = 0.7641\n",
      "Iteration 1034: Loss = 0.4030, Accuracy = 0.7650 Test Loss = 0.4080, Test Accuracy = 0.7651\n",
      "Iteration 1035: Loss = 0.4204, Accuracy = 0.7600 Test Loss = 0.4078, Test Accuracy = 0.7636\n",
      "Iteration 1036: Loss = 0.4029, Accuracy = 0.7620 Test Loss = 0.4075, Test Accuracy = 0.7659\n",
      "Iteration 1037: Loss = 0.4122, Accuracy = 0.7440 Test Loss = 0.4073, Test Accuracy = 0.7664\n",
      "Iteration 1038: Loss = 0.4100, Accuracy = 0.7500 Test Loss = 0.4069, Test Accuracy = 0.7646\n",
      "Iteration 1039: Loss = 0.4137, Accuracy = 0.7420 Test Loss = 0.4068, Test Accuracy = 0.7662\n",
      "Iteration 1040: Loss = 0.4151, Accuracy = 0.7570 Test Loss = 0.4065, Test Accuracy = 0.7652\n",
      "Iteration 1041: Loss = 0.4101, Accuracy = 0.7640 Test Loss = 0.4063, Test Accuracy = 0.7645\n",
      "Iteration 1042: Loss = 0.4461, Accuracy = 0.7370 Test Loss = 0.4060, Test Accuracy = 0.7650\n",
      "Iteration 1043: Loss = 0.4191, Accuracy = 0.7500 Test Loss = 0.4057, Test Accuracy = 0.7653\n",
      "Iteration 1044: Loss = 0.4026, Accuracy = 0.7380 Test Loss = 0.4056, Test Accuracy = 0.7665\n",
      "Iteration 1045: Loss = 0.4064, Accuracy = 0.7720 Test Loss = 0.4053, Test Accuracy = 0.7649\n",
      "Iteration 1046: Loss = 0.4090, Accuracy = 0.7440 Test Loss = 0.4049, Test Accuracy = 0.7662\n",
      "Iteration 1047: Loss = 0.3789, Accuracy = 0.7670 Test Loss = 0.4048, Test Accuracy = 0.7662\n",
      "Iteration 1048: Loss = 0.4050, Accuracy = 0.7510 Test Loss = 0.4044, Test Accuracy = 0.7666\n",
      "Iteration 1049: Loss = 0.3903, Accuracy = 0.7800 Test Loss = 0.4044, Test Accuracy = 0.7635\n",
      "Iteration 1050: Loss = 0.4068, Accuracy = 0.7890 Test Loss = 0.4039, Test Accuracy = 0.7666\n",
      "Iteration 1051: Loss = 0.3868, Accuracy = 0.7680 Test Loss = 0.4036, Test Accuracy = 0.7675\n",
      "Iteration 1052: Loss = 0.3979, Accuracy = 0.7710 Test Loss = 0.4036, Test Accuracy = 0.7664\n",
      "Iteration 1053: Loss = 0.4269, Accuracy = 0.7620 Test Loss = 0.4033, Test Accuracy = 0.7671\n",
      "Iteration 1054: Loss = 0.4173, Accuracy = 0.7590 Test Loss = 0.4030, Test Accuracy = 0.7653\n",
      "Iteration 1055: Loss = 0.4468, Accuracy = 0.7400 Test Loss = 0.4028, Test Accuracy = 0.7678\n",
      "Iteration 1056: Loss = 0.4107, Accuracy = 0.7680 Test Loss = 0.4024, Test Accuracy = 0.7675\n",
      "Iteration 1057: Loss = 0.4042, Accuracy = 0.7570 Test Loss = 0.4023, Test Accuracy = 0.7669\n",
      "Iteration 1058: Loss = 0.4017, Accuracy = 0.7660 Test Loss = 0.4020, Test Accuracy = 0.7677\n",
      "Iteration 1059: Loss = 0.4186, Accuracy = 0.7700 Test Loss = 0.4020, Test Accuracy = 0.7675\n",
      "Iteration 1060: Loss = 0.4363, Accuracy = 0.7440 Test Loss = 0.4016, Test Accuracy = 0.7666\n",
      "Iteration 1061: Loss = 0.4210, Accuracy = 0.7600 Test Loss = 0.4013, Test Accuracy = 0.7695\n",
      "Iteration 1062: Loss = 0.4019, Accuracy = 0.7440 Test Loss = 0.4010, Test Accuracy = 0.7670\n",
      "Iteration 1063: Loss = 0.4021, Accuracy = 0.7710 Test Loss = 0.4007, Test Accuracy = 0.7689\n",
      "Iteration 1064: Loss = 0.3830, Accuracy = 0.7720 Test Loss = 0.4006, Test Accuracy = 0.7687\n",
      "Iteration 1065: Loss = 0.4092, Accuracy = 0.7580 Test Loss = 0.4003, Test Accuracy = 0.7673\n",
      "Iteration 1066: Loss = 0.4084, Accuracy = 0.7280 Test Loss = 0.4002, Test Accuracy = 0.7680\n",
      "Iteration 1067: Loss = 0.3892, Accuracy = 0.7740 Test Loss = 0.3998, Test Accuracy = 0.7678\n",
      "Iteration 1068: Loss = 0.3772, Accuracy = 0.7830 Test Loss = 0.3996, Test Accuracy = 0.7679\n",
      "Iteration 1069: Loss = 0.4105, Accuracy = 0.7400 Test Loss = 0.3993, Test Accuracy = 0.7685\n",
      "Iteration 1070: Loss = 0.4198, Accuracy = 0.7670 Test Loss = 0.3993, Test Accuracy = 0.7686\n",
      "Iteration 1071: Loss = 0.3914, Accuracy = 0.7670 Test Loss = 0.3989, Test Accuracy = 0.7688\n",
      "Iteration 1072: Loss = 0.4126, Accuracy = 0.7560 Test Loss = 0.3986, Test Accuracy = 0.7687\n",
      "Iteration 1073: Loss = 0.3800, Accuracy = 0.7730 Test Loss = 0.3984, Test Accuracy = 0.7675\n",
      "Iteration 1074: Loss = 0.4289, Accuracy = 0.7590 Test Loss = 0.3982, Test Accuracy = 0.7702\n",
      "Iteration 1075: Loss = 0.3797, Accuracy = 0.7960 Test Loss = 0.3981, Test Accuracy = 0.7700\n",
      "Iteration 1076: Loss = 0.3632, Accuracy = 0.7560 Test Loss = 0.3978, Test Accuracy = 0.7703\n",
      "Iteration 1077: Loss = 0.4143, Accuracy = 0.7590 Test Loss = 0.3975, Test Accuracy = 0.7691\n",
      "Iteration 1078: Loss = 0.4095, Accuracy = 0.7680 Test Loss = 0.3973, Test Accuracy = 0.7699\n",
      "Iteration 1079: Loss = 0.3940, Accuracy = 0.7370 Test Loss = 0.3972, Test Accuracy = 0.7702\n",
      "Iteration 1080: Loss = 0.4027, Accuracy = 0.7620 Test Loss = 0.3968, Test Accuracy = 0.7717\n",
      "Iteration 1081: Loss = 0.3864, Accuracy = 0.7410 Test Loss = 0.3967, Test Accuracy = 0.7707\n",
      "Iteration 1082: Loss = 0.4332, Accuracy = 0.7430 Test Loss = 0.3964, Test Accuracy = 0.7695\n",
      "Iteration 1083: Loss = 0.3803, Accuracy = 0.7790 Test Loss = 0.3962, Test Accuracy = 0.7696\n",
      "Iteration 1084: Loss = 0.3891, Accuracy = 0.7780 Test Loss = 0.3960, Test Accuracy = 0.7690\n",
      "Iteration 1085: Loss = 0.4108, Accuracy = 0.7430 Test Loss = 0.3957, Test Accuracy = 0.7714\n",
      "Iteration 1086: Loss = 0.4080, Accuracy = 0.7380 Test Loss = 0.3954, Test Accuracy = 0.7706\n",
      "Iteration 1087: Loss = 0.3543, Accuracy = 0.7840 Test Loss = 0.3951, Test Accuracy = 0.7716\n",
      "Iteration 1088: Loss = 0.3873, Accuracy = 0.7750 Test Loss = 0.3950, Test Accuracy = 0.7720\n",
      "Iteration 1089: Loss = 0.3845, Accuracy = 0.7880 Test Loss = 0.3948, Test Accuracy = 0.7719\n",
      "Iteration 1090: Loss = 0.4064, Accuracy = 0.7540 Test Loss = 0.3945, Test Accuracy = 0.7701\n",
      "Iteration 1091: Loss = 0.3920, Accuracy = 0.7770 Test Loss = 0.3944, Test Accuracy = 0.7697\n",
      "Iteration 1092: Loss = 0.4047, Accuracy = 0.7400 Test Loss = 0.3942, Test Accuracy = 0.7716\n",
      "Iteration 1093: Loss = 0.4403, Accuracy = 0.7620 Test Loss = 0.3939, Test Accuracy = 0.7709\n",
      "Iteration 1094: Loss = 0.4177, Accuracy = 0.7550 Test Loss = 0.3936, Test Accuracy = 0.7731\n",
      "Iteration 1095: Loss = 0.3974, Accuracy = 0.7700 Test Loss = 0.3933, Test Accuracy = 0.7727\n",
      "Iteration 1096: Loss = 0.4076, Accuracy = 0.7620 Test Loss = 0.3932, Test Accuracy = 0.7702\n",
      "Iteration 1097: Loss = 0.3671, Accuracy = 0.7640 Test Loss = 0.3929, Test Accuracy = 0.7714\n",
      "Iteration 1098: Loss = 0.3836, Accuracy = 0.7860 Test Loss = 0.3927, Test Accuracy = 0.7722\n",
      "Iteration 1099: Loss = 0.3797, Accuracy = 0.7780 Test Loss = 0.3926, Test Accuracy = 0.7725\n",
      "Iteration 1100: Loss = 0.3698, Accuracy = 0.7820 Test Loss = 0.3923, Test Accuracy = 0.7731\n",
      "Iteration 1101: Loss = 0.3903, Accuracy = 0.7610 Test Loss = 0.3920, Test Accuracy = 0.7719\n",
      "Iteration 1102: Loss = 0.4041, Accuracy = 0.7620 Test Loss = 0.3918, Test Accuracy = 0.7728\n",
      "Iteration 1103: Loss = 0.4037, Accuracy = 0.7600 Test Loss = 0.3915, Test Accuracy = 0.7713\n",
      "Iteration 1104: Loss = 0.4132, Accuracy = 0.7580 Test Loss = 0.3914, Test Accuracy = 0.7724\n",
      "Iteration 1105: Loss = 0.4265, Accuracy = 0.7610 Test Loss = 0.3913, Test Accuracy = 0.7733\n",
      "Iteration 1106: Loss = 0.3741, Accuracy = 0.7770 Test Loss = 0.3909, Test Accuracy = 0.7731\n",
      "Iteration 1107: Loss = 0.3873, Accuracy = 0.7800 Test Loss = 0.3908, Test Accuracy = 0.7736\n",
      "Iteration 1108: Loss = 0.3961, Accuracy = 0.7600 Test Loss = 0.3905, Test Accuracy = 0.7729\n",
      "Iteration 1109: Loss = 0.3728, Accuracy = 0.7560 Test Loss = 0.3903, Test Accuracy = 0.7715\n",
      "Iteration 1110: Loss = 0.3967, Accuracy = 0.7670 Test Loss = 0.3902, Test Accuracy = 0.7727\n",
      "Iteration 1111: Loss = 0.4050, Accuracy = 0.7500 Test Loss = 0.3900, Test Accuracy = 0.7725\n",
      "Iteration 1112: Loss = 0.4116, Accuracy = 0.7550 Test Loss = 0.3896, Test Accuracy = 0.7729\n",
      "Iteration 1113: Loss = 0.3675, Accuracy = 0.7670 Test Loss = 0.3895, Test Accuracy = 0.7733\n",
      "Iteration 1114: Loss = 0.3896, Accuracy = 0.7410 Test Loss = 0.3892, Test Accuracy = 0.7744\n",
      "Iteration 1115: Loss = 0.3679, Accuracy = 0.7930 Test Loss = 0.3890, Test Accuracy = 0.7737\n",
      "Iteration 1116: Loss = 0.3933, Accuracy = 0.7910 Test Loss = 0.3890, Test Accuracy = 0.7726\n",
      "Iteration 1117: Loss = 0.4125, Accuracy = 0.7760 Test Loss = 0.3886, Test Accuracy = 0.7722\n",
      "Iteration 1118: Loss = 0.3894, Accuracy = 0.7540 Test Loss = 0.3885, Test Accuracy = 0.7734\n",
      "Iteration 1119: Loss = 0.4040, Accuracy = 0.7690 Test Loss = 0.3881, Test Accuracy = 0.7733\n",
      "Iteration 1120: Loss = 0.4069, Accuracy = 0.7640 Test Loss = 0.3879, Test Accuracy = 0.7738\n",
      "Iteration 1121: Loss = 0.3836, Accuracy = 0.7850 Test Loss = 0.3877, Test Accuracy = 0.7738\n",
      "Iteration 1122: Loss = 0.3731, Accuracy = 0.7550 Test Loss = 0.3875, Test Accuracy = 0.7734\n",
      "Iteration 1123: Loss = 0.3906, Accuracy = 0.7750 Test Loss = 0.3872, Test Accuracy = 0.7743\n",
      "Iteration 1124: Loss = 0.3699, Accuracy = 0.7660 Test Loss = 0.3872, Test Accuracy = 0.7739\n",
      "Iteration 1125: Loss = 0.3767, Accuracy = 0.7660 Test Loss = 0.3869, Test Accuracy = 0.7765\n",
      "Iteration 1126: Loss = 0.4014, Accuracy = 0.7630 Test Loss = 0.3868, Test Accuracy = 0.7766\n",
      "Iteration 1127: Loss = 0.4000, Accuracy = 0.7660 Test Loss = 0.3865, Test Accuracy = 0.7743\n",
      "Iteration 1128: Loss = 0.3736, Accuracy = 0.7510 Test Loss = 0.3862, Test Accuracy = 0.7748\n",
      "Iteration 1129: Loss = 0.4081, Accuracy = 0.7670 Test Loss = 0.3859, Test Accuracy = 0.7750\n",
      "Iteration 1130: Loss = 0.4049, Accuracy = 0.7410 Test Loss = 0.3860, Test Accuracy = 0.7738\n",
      "Iteration 1131: Loss = 0.3997, Accuracy = 0.7710 Test Loss = 0.3856, Test Accuracy = 0.7759\n",
      "Iteration 1132: Loss = 0.3868, Accuracy = 0.7720 Test Loss = 0.3856, Test Accuracy = 0.7754\n",
      "Iteration 1133: Loss = 0.3714, Accuracy = 0.7730 Test Loss = 0.3852, Test Accuracy = 0.7738\n",
      "Iteration 1134: Loss = 0.3834, Accuracy = 0.7630 Test Loss = 0.3852, Test Accuracy = 0.7740\n",
      "Iteration 1135: Loss = 0.4016, Accuracy = 0.7780 Test Loss = 0.3849, Test Accuracy = 0.7754\n",
      "Iteration 1136: Loss = 0.3818, Accuracy = 0.7660 Test Loss = 0.3847, Test Accuracy = 0.7758\n",
      "Iteration 1137: Loss = 0.3985, Accuracy = 0.7830 Test Loss = 0.3844, Test Accuracy = 0.7743\n",
      "Iteration 1138: Loss = 0.3782, Accuracy = 0.7850 Test Loss = 0.3841, Test Accuracy = 0.7758\n",
      "Iteration 1139: Loss = 0.4154, Accuracy = 0.7460 Test Loss = 0.3841, Test Accuracy = 0.7763\n",
      "Iteration 1140: Loss = 0.3804, Accuracy = 0.7870 Test Loss = 0.3838, Test Accuracy = 0.7746\n",
      "Iteration 1141: Loss = 0.3927, Accuracy = 0.7840 Test Loss = 0.3836, Test Accuracy = 0.7750\n",
      "Iteration 1142: Loss = 0.3711, Accuracy = 0.7740 Test Loss = 0.3836, Test Accuracy = 0.7756\n",
      "Iteration 1143: Loss = 0.3894, Accuracy = 0.7750 Test Loss = 0.3831, Test Accuracy = 0.7769\n",
      "Iteration 1144: Loss = 0.3752, Accuracy = 0.7650 Test Loss = 0.3830, Test Accuracy = 0.7772\n",
      "Iteration 1145: Loss = 0.3556, Accuracy = 0.7810 Test Loss = 0.3827, Test Accuracy = 0.7764\n",
      "Iteration 1146: Loss = 0.3855, Accuracy = 0.7760 Test Loss = 0.3826, Test Accuracy = 0.7782\n",
      "Iteration 1147: Loss = 0.3883, Accuracy = 0.7960 Test Loss = 0.3823, Test Accuracy = 0.7774\n",
      "Iteration 1148: Loss = 0.3762, Accuracy = 0.7540 Test Loss = 0.3821, Test Accuracy = 0.7763\n",
      "Iteration 1149: Loss = 0.3889, Accuracy = 0.7640 Test Loss = 0.3820, Test Accuracy = 0.7770\n",
      "Iteration 1150: Loss = 0.3707, Accuracy = 0.7790 Test Loss = 0.3818, Test Accuracy = 0.7755\n",
      "Iteration 1151: Loss = 0.3590, Accuracy = 0.7710 Test Loss = 0.3815, Test Accuracy = 0.7758\n",
      "Iteration 1152: Loss = 0.3832, Accuracy = 0.7830 Test Loss = 0.3815, Test Accuracy = 0.7770\n",
      "Iteration 1153: Loss = 0.3955, Accuracy = 0.7720 Test Loss = 0.3812, Test Accuracy = 0.7770\n",
      "Iteration 1154: Loss = 0.3814, Accuracy = 0.7570 Test Loss = 0.3811, Test Accuracy = 0.7774\n",
      "Iteration 1155: Loss = 0.3629, Accuracy = 0.7720 Test Loss = 0.3809, Test Accuracy = 0.7777\n",
      "Iteration 1156: Loss = 0.3778, Accuracy = 0.7560 Test Loss = 0.3806, Test Accuracy = 0.7784\n",
      "Iteration 1157: Loss = 0.3809, Accuracy = 0.7910 Test Loss = 0.3805, Test Accuracy = 0.7766\n",
      "Iteration 1158: Loss = 0.3903, Accuracy = 0.7630 Test Loss = 0.3803, Test Accuracy = 0.7770\n",
      "Iteration 1159: Loss = 0.3887, Accuracy = 0.7550 Test Loss = 0.3800, Test Accuracy = 0.7773\n",
      "Iteration 1160: Loss = 0.3800, Accuracy = 0.7560 Test Loss = 0.3799, Test Accuracy = 0.7797\n",
      "Iteration 1161: Loss = 0.3791, Accuracy = 0.7580 Test Loss = 0.3795, Test Accuracy = 0.7782\n",
      "Iteration 1162: Loss = 0.3317, Accuracy = 0.7870 Test Loss = 0.3794, Test Accuracy = 0.7774\n",
      "Iteration 1163: Loss = 0.3653, Accuracy = 0.7780 Test Loss = 0.3791, Test Accuracy = 0.7793\n",
      "Iteration 1164: Loss = 0.3664, Accuracy = 0.8010 Test Loss = 0.3790, Test Accuracy = 0.7781\n",
      "Iteration 1165: Loss = 0.3643, Accuracy = 0.7630 Test Loss = 0.3788, Test Accuracy = 0.7792\n",
      "Iteration 1166: Loss = 0.3870, Accuracy = 0.7910 Test Loss = 0.3787, Test Accuracy = 0.7777\n",
      "Iteration 1167: Loss = 0.3738, Accuracy = 0.7640 Test Loss = 0.3785, Test Accuracy = 0.7784\n",
      "Iteration 1168: Loss = 0.3802, Accuracy = 0.7790 Test Loss = 0.3786, Test Accuracy = 0.7776\n",
      "Iteration 1169: Loss = 0.3664, Accuracy = 0.8040 Test Loss = 0.3780, Test Accuracy = 0.7785\n",
      "Iteration 1170: Loss = 0.3916, Accuracy = 0.7670 Test Loss = 0.3777, Test Accuracy = 0.7799\n",
      "Iteration 1171: Loss = 0.3934, Accuracy = 0.7670 Test Loss = 0.3776, Test Accuracy = 0.7800\n",
      "Iteration 1172: Loss = 0.3898, Accuracy = 0.8060 Test Loss = 0.3775, Test Accuracy = 0.7766\n",
      "Iteration 1173: Loss = 0.4166, Accuracy = 0.7710 Test Loss = 0.3772, Test Accuracy = 0.7793\n",
      "Iteration 1174: Loss = 0.3898, Accuracy = 0.7730 Test Loss = 0.3770, Test Accuracy = 0.7782\n",
      "Iteration 1175: Loss = 0.3442, Accuracy = 0.7780 Test Loss = 0.3770, Test Accuracy = 0.7801\n",
      "Iteration 1176: Loss = 0.3681, Accuracy = 0.7740 Test Loss = 0.3767, Test Accuracy = 0.7793\n",
      "Iteration 1177: Loss = 0.3868, Accuracy = 0.7690 Test Loss = 0.3765, Test Accuracy = 0.7790\n",
      "Iteration 1178: Loss = 0.3801, Accuracy = 0.7680 Test Loss = 0.3765, Test Accuracy = 0.7793\n",
      "Iteration 1179: Loss = 0.3835, Accuracy = 0.7940 Test Loss = 0.3761, Test Accuracy = 0.7793\n",
      "Iteration 1180: Loss = 0.3740, Accuracy = 0.7740 Test Loss = 0.3759, Test Accuracy = 0.7794\n",
      "Iteration 1181: Loss = 0.3901, Accuracy = 0.7750 Test Loss = 0.3759, Test Accuracy = 0.7816\n",
      "Iteration 1182: Loss = 0.3616, Accuracy = 0.7650 Test Loss = 0.3756, Test Accuracy = 0.7798\n",
      "Iteration 1183: Loss = 0.3611, Accuracy = 0.7690 Test Loss = 0.3753, Test Accuracy = 0.7809\n",
      "Iteration 1184: Loss = 0.3656, Accuracy = 0.7790 Test Loss = 0.3752, Test Accuracy = 0.7784\n",
      "Iteration 1185: Loss = 0.3748, Accuracy = 0.7830 Test Loss = 0.3750, Test Accuracy = 0.7808\n",
      "Iteration 1186: Loss = 0.3665, Accuracy = 0.7810 Test Loss = 0.3747, Test Accuracy = 0.7803\n",
      "Iteration 1187: Loss = 0.3479, Accuracy = 0.7910 Test Loss = 0.3747, Test Accuracy = 0.7797\n",
      "Iteration 1188: Loss = 0.3681, Accuracy = 0.7760 Test Loss = 0.3744, Test Accuracy = 0.7801\n",
      "Iteration 1189: Loss = 0.3620, Accuracy = 0.7750 Test Loss = 0.3742, Test Accuracy = 0.7799\n",
      "Iteration 1190: Loss = 0.3708, Accuracy = 0.7940 Test Loss = 0.3741, Test Accuracy = 0.7803\n",
      "Iteration 1191: Loss = 0.3679, Accuracy = 0.7650 Test Loss = 0.3739, Test Accuracy = 0.7803\n",
      "Iteration 1192: Loss = 0.3741, Accuracy = 0.7700 Test Loss = 0.3737, Test Accuracy = 0.7806\n",
      "Iteration 1193: Loss = 0.4035, Accuracy = 0.7630 Test Loss = 0.3735, Test Accuracy = 0.7795\n",
      "Iteration 1194: Loss = 0.3428, Accuracy = 0.7930 Test Loss = 0.3733, Test Accuracy = 0.7805\n",
      "Iteration 1195: Loss = 0.3398, Accuracy = 0.7910 Test Loss = 0.3732, Test Accuracy = 0.7806\n",
      "Iteration 1196: Loss = 0.3948, Accuracy = 0.7570 Test Loss = 0.3730, Test Accuracy = 0.7818\n",
      "Iteration 1197: Loss = 0.3708, Accuracy = 0.7890 Test Loss = 0.3727, Test Accuracy = 0.7812\n",
      "Iteration 1198: Loss = 0.3568, Accuracy = 0.7830 Test Loss = 0.3725, Test Accuracy = 0.7806\n",
      "Iteration 1199: Loss = 0.3823, Accuracy = 0.7800 Test Loss = 0.3725, Test Accuracy = 0.7806\n",
      "Iteration 1200: Loss = 0.3833, Accuracy = 0.7870 Test Loss = 0.3722, Test Accuracy = 0.7807\n",
      "Iteration 1201: Loss = 0.3551, Accuracy = 0.8010 Test Loss = 0.3720, Test Accuracy = 0.7800\n",
      "Iteration 1202: Loss = 0.3348, Accuracy = 0.8030 Test Loss = 0.3719, Test Accuracy = 0.7813\n",
      "Iteration 1203: Loss = 0.3903, Accuracy = 0.7790 Test Loss = 0.3716, Test Accuracy = 0.7810\n",
      "Iteration 1204: Loss = 0.3696, Accuracy = 0.7930 Test Loss = 0.3715, Test Accuracy = 0.7811\n",
      "Iteration 1205: Loss = 0.3780, Accuracy = 0.7870 Test Loss = 0.3713, Test Accuracy = 0.7813\n",
      "Iteration 1206: Loss = 0.4009, Accuracy = 0.7790 Test Loss = 0.3712, Test Accuracy = 0.7815\n",
      "Iteration 1207: Loss = 0.3849, Accuracy = 0.7830 Test Loss = 0.3710, Test Accuracy = 0.7814\n",
      "Iteration 1208: Loss = 0.3564, Accuracy = 0.7760 Test Loss = 0.3708, Test Accuracy = 0.7804\n",
      "Iteration 1209: Loss = 0.3542, Accuracy = 0.7670 Test Loss = 0.3707, Test Accuracy = 0.7807\n",
      "Iteration 1210: Loss = 0.3817, Accuracy = 0.7910 Test Loss = 0.3705, Test Accuracy = 0.7836\n",
      "Iteration 1211: Loss = 0.3584, Accuracy = 0.8030 Test Loss = 0.3703, Test Accuracy = 0.7805\n",
      "Iteration 1212: Loss = 0.3872, Accuracy = 0.7610 Test Loss = 0.3700, Test Accuracy = 0.7822\n",
      "Iteration 1213: Loss = 0.3886, Accuracy = 0.7860 Test Loss = 0.3699, Test Accuracy = 0.7827\n",
      "Iteration 1214: Loss = 0.3786, Accuracy = 0.7600 Test Loss = 0.3697, Test Accuracy = 0.7822\n",
      "Iteration 1215: Loss = 0.3852, Accuracy = 0.7640 Test Loss = 0.3695, Test Accuracy = 0.7815\n",
      "Iteration 1216: Loss = 0.3665, Accuracy = 0.7710 Test Loss = 0.3694, Test Accuracy = 0.7840\n",
      "Iteration 1217: Loss = 0.3528, Accuracy = 0.7750 Test Loss = 0.3692, Test Accuracy = 0.7821\n",
      "Iteration 1218: Loss = 0.3389, Accuracy = 0.7850 Test Loss = 0.3691, Test Accuracy = 0.7805\n",
      "Iteration 1219: Loss = 0.3791, Accuracy = 0.7580 Test Loss = 0.3688, Test Accuracy = 0.7809\n",
      "Iteration 1220: Loss = 0.3749, Accuracy = 0.7590 Test Loss = 0.3687, Test Accuracy = 0.7828\n",
      "Iteration 1221: Loss = 0.3614, Accuracy = 0.7710 Test Loss = 0.3685, Test Accuracy = 0.7827\n",
      "Iteration 1222: Loss = 0.3787, Accuracy = 0.7680 Test Loss = 0.3684, Test Accuracy = 0.7828\n",
      "Iteration 1223: Loss = 0.3688, Accuracy = 0.7650 Test Loss = 0.3682, Test Accuracy = 0.7832\n",
      "Iteration 1224: Loss = 0.3809, Accuracy = 0.7720 Test Loss = 0.3679, Test Accuracy = 0.7834\n",
      "Iteration 1225: Loss = 0.3703, Accuracy = 0.7520 Test Loss = 0.3678, Test Accuracy = 0.7837\n",
      "Iteration 1226: Loss = 0.3652, Accuracy = 0.7940 Test Loss = 0.3677, Test Accuracy = 0.7812\n",
      "Iteration 1227: Loss = 0.3821, Accuracy = 0.7730 Test Loss = 0.3676, Test Accuracy = 0.7838\n",
      "Iteration 1228: Loss = 0.3892, Accuracy = 0.7820 Test Loss = 0.3673, Test Accuracy = 0.7840\n",
      "Iteration 1229: Loss = 0.3830, Accuracy = 0.7630 Test Loss = 0.3672, Test Accuracy = 0.7836\n",
      "Iteration 1230: Loss = 0.3429, Accuracy = 0.7830 Test Loss = 0.3670, Test Accuracy = 0.7835\n",
      "Iteration 1231: Loss = 0.3805, Accuracy = 0.8000 Test Loss = 0.3668, Test Accuracy = 0.7833\n",
      "Iteration 1232: Loss = 0.3601, Accuracy = 0.7870 Test Loss = 0.3668, Test Accuracy = 0.7840\n",
      "Iteration 1233: Loss = 0.3525, Accuracy = 0.7990 Test Loss = 0.3665, Test Accuracy = 0.7831\n",
      "Iteration 1234: Loss = 0.3586, Accuracy = 0.7730 Test Loss = 0.3663, Test Accuracy = 0.7849\n",
      "Iteration 1235: Loss = 0.3344, Accuracy = 0.7910 Test Loss = 0.3661, Test Accuracy = 0.7848\n",
      "Iteration 1236: Loss = 0.3515, Accuracy = 0.7970 Test Loss = 0.3660, Test Accuracy = 0.7848\n",
      "Iteration 1237: Loss = 0.3765, Accuracy = 0.7550 Test Loss = 0.3657, Test Accuracy = 0.7841\n",
      "Iteration 1238: Loss = 0.3620, Accuracy = 0.7680 Test Loss = 0.3656, Test Accuracy = 0.7842\n",
      "Iteration 1239: Loss = 0.3536, Accuracy = 0.7830 Test Loss = 0.3655, Test Accuracy = 0.7850\n",
      "Iteration 1240: Loss = 0.3651, Accuracy = 0.7720 Test Loss = 0.3654, Test Accuracy = 0.7844\n",
      "Iteration 1241: Loss = 0.3606, Accuracy = 0.7720 Test Loss = 0.3651, Test Accuracy = 0.7841\n",
      "Iteration 1242: Loss = 0.3511, Accuracy = 0.7880 Test Loss = 0.3649, Test Accuracy = 0.7824\n",
      "Iteration 1243: Loss = 0.3537, Accuracy = 0.7940 Test Loss = 0.3647, Test Accuracy = 0.7850\n",
      "Iteration 1244: Loss = 0.3679, Accuracy = 0.7820 Test Loss = 0.3646, Test Accuracy = 0.7852\n",
      "Iteration 1245: Loss = 0.3994, Accuracy = 0.7530 Test Loss = 0.3643, Test Accuracy = 0.7847\n",
      "Iteration 1246: Loss = 0.3727, Accuracy = 0.7800 Test Loss = 0.3643, Test Accuracy = 0.7839\n",
      "Iteration 1247: Loss = 0.3544, Accuracy = 0.7740 Test Loss = 0.3642, Test Accuracy = 0.7838\n",
      "Iteration 1248: Loss = 0.4198, Accuracy = 0.7650 Test Loss = 0.3638, Test Accuracy = 0.7857\n",
      "Iteration 1249: Loss = 0.3821, Accuracy = 0.7930 Test Loss = 0.3639, Test Accuracy = 0.7844\n",
      "Iteration 1250: Loss = 0.4021, Accuracy = 0.7730 Test Loss = 0.3636, Test Accuracy = 0.7845\n",
      "Iteration 1251: Loss = 0.3746, Accuracy = 0.7600 Test Loss = 0.3634, Test Accuracy = 0.7853\n",
      "Iteration 1252: Loss = 0.3724, Accuracy = 0.7540 Test Loss = 0.3633, Test Accuracy = 0.7854\n",
      "Iteration 1253: Loss = 0.3567, Accuracy = 0.7510 Test Loss = 0.3632, Test Accuracy = 0.7848\n",
      "Iteration 1254: Loss = 0.3632, Accuracy = 0.7790 Test Loss = 0.3629, Test Accuracy = 0.7861\n",
      "Iteration 1255: Loss = 0.4041, Accuracy = 0.7740 Test Loss = 0.3628, Test Accuracy = 0.7835\n",
      "Iteration 1256: Loss = 0.3678, Accuracy = 0.7790 Test Loss = 0.3627, Test Accuracy = 0.7860\n",
      "Iteration 1257: Loss = 0.3611, Accuracy = 0.7870 Test Loss = 0.3625, Test Accuracy = 0.7844\n",
      "Iteration 1258: Loss = 0.3530, Accuracy = 0.7700 Test Loss = 0.3624, Test Accuracy = 0.7834\n",
      "Iteration 1259: Loss = 0.3666, Accuracy = 0.8060 Test Loss = 0.3621, Test Accuracy = 0.7856\n",
      "Iteration 1260: Loss = 0.3625, Accuracy = 0.7910 Test Loss = 0.3620, Test Accuracy = 0.7857\n",
      "Iteration 1261: Loss = 0.3579, Accuracy = 0.7880 Test Loss = 0.3618, Test Accuracy = 0.7869\n",
      "Iteration 1262: Loss = 0.3531, Accuracy = 0.7790 Test Loss = 0.3616, Test Accuracy = 0.7857\n",
      "Iteration 1263: Loss = 0.3409, Accuracy = 0.7950 Test Loss = 0.3616, Test Accuracy = 0.7863\n",
      "Iteration 1264: Loss = 0.3814, Accuracy = 0.7750 Test Loss = 0.3613, Test Accuracy = 0.7858\n",
      "Iteration 1265: Loss = 0.3765, Accuracy = 0.7590 Test Loss = 0.3612, Test Accuracy = 0.7882\n",
      "Iteration 1266: Loss = 0.3557, Accuracy = 0.7730 Test Loss = 0.3609, Test Accuracy = 0.7876\n",
      "Iteration 1267: Loss = 0.3725, Accuracy = 0.7730 Test Loss = 0.3609, Test Accuracy = 0.7859\n",
      "Iteration 1268: Loss = 0.3356, Accuracy = 0.7960 Test Loss = 0.3607, Test Accuracy = 0.7867\n",
      "Iteration 1269: Loss = 0.3716, Accuracy = 0.7880 Test Loss = 0.3605, Test Accuracy = 0.7865\n",
      "Iteration 1270: Loss = 0.3548, Accuracy = 0.7790 Test Loss = 0.3605, Test Accuracy = 0.7863\n",
      "Iteration 1271: Loss = 0.3515, Accuracy = 0.7850 Test Loss = 0.3603, Test Accuracy = 0.7866\n",
      "Iteration 1272: Loss = 0.3829, Accuracy = 0.7560 Test Loss = 0.3600, Test Accuracy = 0.7877\n",
      "Iteration 1273: Loss = 0.3626, Accuracy = 0.7940 Test Loss = 0.3599, Test Accuracy = 0.7864\n",
      "Iteration 1274: Loss = 0.3406, Accuracy = 0.7820 Test Loss = 0.3597, Test Accuracy = 0.7861\n",
      "Iteration 1275: Loss = 0.3616, Accuracy = 0.7790 Test Loss = 0.3595, Test Accuracy = 0.7870\n",
      "Iteration 1276: Loss = 0.3576, Accuracy = 0.7820 Test Loss = 0.3594, Test Accuracy = 0.7863\n",
      "Iteration 1277: Loss = 0.3428, Accuracy = 0.8170 Test Loss = 0.3593, Test Accuracy = 0.7865\n",
      "Iteration 1278: Loss = 0.3679, Accuracy = 0.7910 Test Loss = 0.3591, Test Accuracy = 0.7875\n",
      "Iteration 1279: Loss = 0.3694, Accuracy = 0.7920 Test Loss = 0.3590, Test Accuracy = 0.7880\n",
      "Iteration 1280: Loss = 0.3437, Accuracy = 0.7850 Test Loss = 0.3588, Test Accuracy = 0.7879\n",
      "Iteration 1281: Loss = 0.3558, Accuracy = 0.7760 Test Loss = 0.3587, Test Accuracy = 0.7859\n",
      "Iteration 1282: Loss = 0.3371, Accuracy = 0.8080 Test Loss = 0.3585, Test Accuracy = 0.7890\n",
      "Iteration 1283: Loss = 0.3577, Accuracy = 0.8000 Test Loss = 0.3583, Test Accuracy = 0.7868\n",
      "Iteration 1284: Loss = 0.3700, Accuracy = 0.7940 Test Loss = 0.3583, Test Accuracy = 0.7890\n",
      "Iteration 1285: Loss = 0.3615, Accuracy = 0.7880 Test Loss = 0.3581, Test Accuracy = 0.7880\n",
      "Iteration 1286: Loss = 0.3692, Accuracy = 0.8030 Test Loss = 0.3579, Test Accuracy = 0.7863\n",
      "Iteration 1287: Loss = 0.3647, Accuracy = 0.7700 Test Loss = 0.3577, Test Accuracy = 0.7889\n",
      "Iteration 1288: Loss = 0.3618, Accuracy = 0.7610 Test Loss = 0.3575, Test Accuracy = 0.7899\n",
      "Iteration 1289: Loss = 0.3497, Accuracy = 0.7980 Test Loss = 0.3574, Test Accuracy = 0.7898\n",
      "Iteration 1290: Loss = 0.3249, Accuracy = 0.7800 Test Loss = 0.3572, Test Accuracy = 0.7893\n",
      "Iteration 1291: Loss = 0.3959, Accuracy = 0.7600 Test Loss = 0.3571, Test Accuracy = 0.7883\n",
      "Iteration 1292: Loss = 0.3601, Accuracy = 0.7950 Test Loss = 0.3570, Test Accuracy = 0.7880\n",
      "Iteration 1293: Loss = 0.3772, Accuracy = 0.7930 Test Loss = 0.3569, Test Accuracy = 0.7870\n",
      "Iteration 1294: Loss = 0.3380, Accuracy = 0.7820 Test Loss = 0.3567, Test Accuracy = 0.7890\n",
      "Iteration 1295: Loss = 0.3526, Accuracy = 0.7860 Test Loss = 0.3565, Test Accuracy = 0.7896\n",
      "Iteration 1296: Loss = 0.3698, Accuracy = 0.7750 Test Loss = 0.3564, Test Accuracy = 0.7899\n",
      "Iteration 1297: Loss = 0.3537, Accuracy = 0.7880 Test Loss = 0.3561, Test Accuracy = 0.7874\n",
      "Iteration 1298: Loss = 0.3446, Accuracy = 0.7790 Test Loss = 0.3562, Test Accuracy = 0.7887\n",
      "Iteration 1299: Loss = 0.3734, Accuracy = 0.7810 Test Loss = 0.3559, Test Accuracy = 0.7896\n",
      "Iteration 1300: Loss = 0.3790, Accuracy = 0.7700 Test Loss = 0.3557, Test Accuracy = 0.7901\n",
      "Iteration 1301: Loss = 0.3698, Accuracy = 0.7910 Test Loss = 0.3555, Test Accuracy = 0.7884\n",
      "Iteration 1302: Loss = 0.3646, Accuracy = 0.7800 Test Loss = 0.3555, Test Accuracy = 0.7905\n",
      "Iteration 1303: Loss = 0.3632, Accuracy = 0.7830 Test Loss = 0.3553, Test Accuracy = 0.7904\n",
      "Iteration 1304: Loss = 0.3852, Accuracy = 0.7680 Test Loss = 0.3552, Test Accuracy = 0.7894\n",
      "Iteration 1305: Loss = 0.3359, Accuracy = 0.7810 Test Loss = 0.3551, Test Accuracy = 0.7891\n",
      "Iteration 1306: Loss = 0.3506, Accuracy = 0.7890 Test Loss = 0.3549, Test Accuracy = 0.7908\n",
      "Iteration 1307: Loss = 0.3670, Accuracy = 0.7730 Test Loss = 0.3547, Test Accuracy = 0.7899\n",
      "Iteration 1308: Loss = 0.3435, Accuracy = 0.7700 Test Loss = 0.3546, Test Accuracy = 0.7904\n",
      "Iteration 1309: Loss = 0.3537, Accuracy = 0.7900 Test Loss = 0.3544, Test Accuracy = 0.7905\n",
      "Iteration 1310: Loss = 0.3429, Accuracy = 0.7910 Test Loss = 0.3543, Test Accuracy = 0.7915\n",
      "Iteration 1311: Loss = 0.3442, Accuracy = 0.7690 Test Loss = 0.3541, Test Accuracy = 0.7914\n",
      "Iteration 1312: Loss = 0.3510, Accuracy = 0.7810 Test Loss = 0.3541, Test Accuracy = 0.7894\n",
      "Iteration 1313: Loss = 0.3494, Accuracy = 0.7870 Test Loss = 0.3538, Test Accuracy = 0.7906\n",
      "Iteration 1314: Loss = 0.3353, Accuracy = 0.7760 Test Loss = 0.3536, Test Accuracy = 0.7905\n",
      "Iteration 1315: Loss = 0.3290, Accuracy = 0.8060 Test Loss = 0.3536, Test Accuracy = 0.7907\n",
      "Iteration 1316: Loss = 0.3557, Accuracy = 0.7730 Test Loss = 0.3534, Test Accuracy = 0.7906\n",
      "Iteration 1317: Loss = 0.3640, Accuracy = 0.7870 Test Loss = 0.3534, Test Accuracy = 0.7889\n",
      "Iteration 1318: Loss = 0.3625, Accuracy = 0.7730 Test Loss = 0.3530, Test Accuracy = 0.7893\n",
      "Iteration 1319: Loss = 0.3591, Accuracy = 0.8020 Test Loss = 0.3529, Test Accuracy = 0.7912\n",
      "Iteration 1320: Loss = 0.3832, Accuracy = 0.7550 Test Loss = 0.3528, Test Accuracy = 0.7900\n",
      "Iteration 1321: Loss = 0.3671, Accuracy = 0.7710 Test Loss = 0.3526, Test Accuracy = 0.7902\n",
      "Iteration 1322: Loss = 0.3694, Accuracy = 0.7850 Test Loss = 0.3526, Test Accuracy = 0.7917\n",
      "Iteration 1323: Loss = 0.3519, Accuracy = 0.7670 Test Loss = 0.3525, Test Accuracy = 0.7914\n",
      "Iteration 1324: Loss = 0.3503, Accuracy = 0.7900 Test Loss = 0.3522, Test Accuracy = 0.7920\n",
      "Iteration 1325: Loss = 0.3478, Accuracy = 0.7830 Test Loss = 0.3521, Test Accuracy = 0.7900\n",
      "Iteration 1326: Loss = 0.3559, Accuracy = 0.8010 Test Loss = 0.3520, Test Accuracy = 0.7900\n",
      "Iteration 1327: Loss = 0.3725, Accuracy = 0.7970 Test Loss = 0.3518, Test Accuracy = 0.7915\n",
      "Iteration 1328: Loss = 0.3374, Accuracy = 0.8010 Test Loss = 0.3516, Test Accuracy = 0.7905\n",
      "Iteration 1329: Loss = 0.3270, Accuracy = 0.7810 Test Loss = 0.3516, Test Accuracy = 0.7914\n",
      "Iteration 1330: Loss = 0.3517, Accuracy = 0.7790 Test Loss = 0.3514, Test Accuracy = 0.7919\n",
      "Iteration 1331: Loss = 0.3489, Accuracy = 0.7930 Test Loss = 0.3512, Test Accuracy = 0.7905\n",
      "Iteration 1332: Loss = 0.3661, Accuracy = 0.7930 Test Loss = 0.3510, Test Accuracy = 0.7916\n",
      "Iteration 1333: Loss = 0.3617, Accuracy = 0.7840 Test Loss = 0.3509, Test Accuracy = 0.7919\n",
      "Iteration 1334: Loss = 0.3624, Accuracy = 0.7780 Test Loss = 0.3509, Test Accuracy = 0.7923\n",
      "Iteration 1335: Loss = 0.3797, Accuracy = 0.7560 Test Loss = 0.3507, Test Accuracy = 0.7909\n",
      "Iteration 1336: Loss = 0.3497, Accuracy = 0.7680 Test Loss = 0.3506, Test Accuracy = 0.7903\n",
      "Iteration 1337: Loss = 0.3620, Accuracy = 0.7820 Test Loss = 0.3504, Test Accuracy = 0.7921\n",
      "Iteration 1338: Loss = 0.3518, Accuracy = 0.7670 Test Loss = 0.3503, Test Accuracy = 0.7923\n",
      "Iteration 1339: Loss = 0.3410, Accuracy = 0.7920 Test Loss = 0.3501, Test Accuracy = 0.7929\n",
      "Iteration 1340: Loss = 0.3690, Accuracy = 0.7820 Test Loss = 0.3499, Test Accuracy = 0.7923\n",
      "Iteration 1341: Loss = 0.3343, Accuracy = 0.7950 Test Loss = 0.3498, Test Accuracy = 0.7921\n",
      "Iteration 1342: Loss = 0.3476, Accuracy = 0.7960 Test Loss = 0.3495, Test Accuracy = 0.7917\n",
      "Iteration 1343: Loss = 0.3454, Accuracy = 0.7810 Test Loss = 0.3495, Test Accuracy = 0.7937\n",
      "Iteration 1344: Loss = 0.3597, Accuracy = 0.7790 Test Loss = 0.3494, Test Accuracy = 0.7929\n",
      "Iteration 1345: Loss = 0.3350, Accuracy = 0.8020 Test Loss = 0.3492, Test Accuracy = 0.7923\n",
      "Iteration 1346: Loss = 0.3349, Accuracy = 0.7970 Test Loss = 0.3491, Test Accuracy = 0.7922\n",
      "Iteration 1347: Loss = 0.3611, Accuracy = 0.7830 Test Loss = 0.3488, Test Accuracy = 0.7926\n",
      "Iteration 1348: Loss = 0.3603, Accuracy = 0.7670 Test Loss = 0.3488, Test Accuracy = 0.7930\n",
      "Iteration 1349: Loss = 0.3466, Accuracy = 0.7840 Test Loss = 0.3487, Test Accuracy = 0.7915\n",
      "Iteration 1350: Loss = 0.3405, Accuracy = 0.7690 Test Loss = 0.3486, Test Accuracy = 0.7928\n",
      "Iteration 1351: Loss = 0.3435, Accuracy = 0.8100 Test Loss = 0.3484, Test Accuracy = 0.7934\n",
      "Iteration 1352: Loss = 0.3351, Accuracy = 0.8030 Test Loss = 0.3482, Test Accuracy = 0.7926\n",
      "Iteration 1353: Loss = 0.3616, Accuracy = 0.7800 Test Loss = 0.3481, Test Accuracy = 0.7926\n",
      "Iteration 1354: Loss = 0.3256, Accuracy = 0.7870 Test Loss = 0.3480, Test Accuracy = 0.7919\n",
      "Iteration 1355: Loss = 0.3391, Accuracy = 0.8040 Test Loss = 0.3478, Test Accuracy = 0.7919\n",
      "Iteration 1356: Loss = 0.3695, Accuracy = 0.7750 Test Loss = 0.3477, Test Accuracy = 0.7950\n",
      "Iteration 1357: Loss = 0.3519, Accuracy = 0.7920 Test Loss = 0.3475, Test Accuracy = 0.7944\n",
      "Iteration 1358: Loss = 0.3780, Accuracy = 0.7810 Test Loss = 0.3474, Test Accuracy = 0.7929\n",
      "Iteration 1359: Loss = 0.3425, Accuracy = 0.8020 Test Loss = 0.3473, Test Accuracy = 0.7935\n",
      "Iteration 1360: Loss = 0.3385, Accuracy = 0.7740 Test Loss = 0.3471, Test Accuracy = 0.7933\n",
      "Iteration 1361: Loss = 0.3286, Accuracy = 0.7810 Test Loss = 0.3470, Test Accuracy = 0.7945\n",
      "Iteration 1362: Loss = 0.3699, Accuracy = 0.7750 Test Loss = 0.3468, Test Accuracy = 0.7947\n",
      "Iteration 1363: Loss = 0.3488, Accuracy = 0.7770 Test Loss = 0.3469, Test Accuracy = 0.7948\n",
      "Iteration 1364: Loss = 0.3679, Accuracy = 0.7640 Test Loss = 0.3467, Test Accuracy = 0.7947\n",
      "Iteration 1365: Loss = 0.3475, Accuracy = 0.7850 Test Loss = 0.3465, Test Accuracy = 0.7949\n",
      "Iteration 1366: Loss = 0.3571, Accuracy = 0.7810 Test Loss = 0.3464, Test Accuracy = 0.7933\n",
      "Iteration 1367: Loss = 0.3460, Accuracy = 0.7820 Test Loss = 0.3462, Test Accuracy = 0.7936\n",
      "Iteration 1368: Loss = 0.3416, Accuracy = 0.7810 Test Loss = 0.3460, Test Accuracy = 0.7947\n",
      "Iteration 1369: Loss = 0.3393, Accuracy = 0.7940 Test Loss = 0.3459, Test Accuracy = 0.7945\n",
      "Iteration 1370: Loss = 0.3117, Accuracy = 0.8230 Test Loss = 0.3459, Test Accuracy = 0.7948\n",
      "Iteration 1371: Loss = 0.3549, Accuracy = 0.7660 Test Loss = 0.3457, Test Accuracy = 0.7943\n",
      "Iteration 1372: Loss = 0.3277, Accuracy = 0.7930 Test Loss = 0.3456, Test Accuracy = 0.7944\n",
      "Iteration 1373: Loss = 0.3460, Accuracy = 0.7910 Test Loss = 0.3454, Test Accuracy = 0.7950\n",
      "Iteration 1374: Loss = 0.3322, Accuracy = 0.8070 Test Loss = 0.3454, Test Accuracy = 0.7943\n",
      "Iteration 1375: Loss = 0.3493, Accuracy = 0.7830 Test Loss = 0.3451, Test Accuracy = 0.7944\n",
      "Iteration 1376: Loss = 0.3354, Accuracy = 0.8040 Test Loss = 0.3450, Test Accuracy = 0.7941\n",
      "Iteration 1377: Loss = 0.3383, Accuracy = 0.7790 Test Loss = 0.3449, Test Accuracy = 0.7945\n",
      "Iteration 1378: Loss = 0.3344, Accuracy = 0.7920 Test Loss = 0.3448, Test Accuracy = 0.7943\n",
      "Iteration 1379: Loss = 0.3295, Accuracy = 0.7900 Test Loss = 0.3446, Test Accuracy = 0.7944\n",
      "Iteration 1380: Loss = 0.3470, Accuracy = 0.7850 Test Loss = 0.3445, Test Accuracy = 0.7956\n",
      "Iteration 1381: Loss = 0.3444, Accuracy = 0.7970 Test Loss = 0.3444, Test Accuracy = 0.7956\n",
      "Iteration 1382: Loss = 0.3488, Accuracy = 0.8060 Test Loss = 0.3442, Test Accuracy = 0.7945\n",
      "Iteration 1383: Loss = 0.3300, Accuracy = 0.7900 Test Loss = 0.3443, Test Accuracy = 0.7941\n",
      "Iteration 1384: Loss = 0.3398, Accuracy = 0.7810 Test Loss = 0.3440, Test Accuracy = 0.7959\n",
      "Iteration 1385: Loss = 0.3394, Accuracy = 0.8000 Test Loss = 0.3439, Test Accuracy = 0.7951\n",
      "Iteration 1386: Loss = 0.3468, Accuracy = 0.7870 Test Loss = 0.3439, Test Accuracy = 0.7942\n",
      "Iteration 1387: Loss = 0.3165, Accuracy = 0.8050 Test Loss = 0.3436, Test Accuracy = 0.7956\n",
      "Iteration 1388: Loss = 0.3372, Accuracy = 0.7910 Test Loss = 0.3436, Test Accuracy = 0.7966\n",
      "Iteration 1389: Loss = 0.3271, Accuracy = 0.7780 Test Loss = 0.3433, Test Accuracy = 0.7951\n",
      "Iteration 1390: Loss = 0.3303, Accuracy = 0.7960 Test Loss = 0.3431, Test Accuracy = 0.7959\n",
      "Iteration 1391: Loss = 0.3680, Accuracy = 0.7850 Test Loss = 0.3431, Test Accuracy = 0.7946\n",
      "Iteration 1392: Loss = 0.3386, Accuracy = 0.7950 Test Loss = 0.3429, Test Accuracy = 0.7948\n",
      "Iteration 1393: Loss = 0.3427, Accuracy = 0.7960 Test Loss = 0.3427, Test Accuracy = 0.7961\n",
      "Iteration 1394: Loss = 0.3344, Accuracy = 0.8040 Test Loss = 0.3427, Test Accuracy = 0.7954\n",
      "Iteration 1395: Loss = 0.3255, Accuracy = 0.7860 Test Loss = 0.3425, Test Accuracy = 0.7970\n",
      "Iteration 1396: Loss = 0.3352, Accuracy = 0.8080 Test Loss = 0.3424, Test Accuracy = 0.7967\n",
      "Iteration 1397: Loss = 0.3459, Accuracy = 0.7820 Test Loss = 0.3423, Test Accuracy = 0.7959\n",
      "Iteration 1398: Loss = 0.3416, Accuracy = 0.8040 Test Loss = 0.3423, Test Accuracy = 0.7968\n",
      "Iteration 1399: Loss = 0.3885, Accuracy = 0.7830 Test Loss = 0.3420, Test Accuracy = 0.7963\n",
      "Iteration 1400: Loss = 0.3790, Accuracy = 0.7790 Test Loss = 0.3418, Test Accuracy = 0.7971\n",
      "Iteration 1401: Loss = 0.3495, Accuracy = 0.7950 Test Loss = 0.3418, Test Accuracy = 0.7971\n",
      "Iteration 1402: Loss = 0.3406, Accuracy = 0.8000 Test Loss = 0.3417, Test Accuracy = 0.7971\n",
      "Iteration 1403: Loss = 0.3459, Accuracy = 0.7880 Test Loss = 0.3416, Test Accuracy = 0.7967\n",
      "Iteration 1404: Loss = 0.3106, Accuracy = 0.8080 Test Loss = 0.3415, Test Accuracy = 0.7980\n",
      "Iteration 1405: Loss = 0.3268, Accuracy = 0.7980 Test Loss = 0.3412, Test Accuracy = 0.7984\n",
      "Iteration 1406: Loss = 0.3358, Accuracy = 0.7930 Test Loss = 0.3411, Test Accuracy = 0.7970\n",
      "Iteration 1407: Loss = 0.3238, Accuracy = 0.7840 Test Loss = 0.3410, Test Accuracy = 0.7962\n",
      "Iteration 1408: Loss = 0.3464, Accuracy = 0.7830 Test Loss = 0.3408, Test Accuracy = 0.7983\n",
      "Iteration 1409: Loss = 0.3246, Accuracy = 0.7900 Test Loss = 0.3408, Test Accuracy = 0.7975\n",
      "Iteration 1410: Loss = 0.3536, Accuracy = 0.7700 Test Loss = 0.3407, Test Accuracy = 0.7956\n",
      "Iteration 1411: Loss = 0.3408, Accuracy = 0.7760 Test Loss = 0.3406, Test Accuracy = 0.7975\n",
      "Iteration 1412: Loss = 0.3429, Accuracy = 0.7860 Test Loss = 0.3404, Test Accuracy = 0.7980\n",
      "Iteration 1413: Loss = 0.3192, Accuracy = 0.7950 Test Loss = 0.3404, Test Accuracy = 0.7960\n",
      "Iteration 1414: Loss = 0.3475, Accuracy = 0.7870 Test Loss = 0.3401, Test Accuracy = 0.7966\n",
      "Iteration 1415: Loss = 0.3419, Accuracy = 0.7910 Test Loss = 0.3401, Test Accuracy = 0.7974\n",
      "Iteration 1416: Loss = 0.3598, Accuracy = 0.7770 Test Loss = 0.3399, Test Accuracy = 0.7985\n",
      "Iteration 1417: Loss = 0.3421, Accuracy = 0.7850 Test Loss = 0.3397, Test Accuracy = 0.7989\n",
      "Iteration 1418: Loss = 0.3584, Accuracy = 0.7780 Test Loss = 0.3396, Test Accuracy = 0.7983\n",
      "Iteration 1419: Loss = 0.3096, Accuracy = 0.8020 Test Loss = 0.3397, Test Accuracy = 0.7972\n",
      "Iteration 1420: Loss = 0.3415, Accuracy = 0.7920 Test Loss = 0.3393, Test Accuracy = 0.7971\n",
      "Iteration 1421: Loss = 0.3399, Accuracy = 0.8070 Test Loss = 0.3392, Test Accuracy = 0.7970\n",
      "Iteration 1422: Loss = 0.3141, Accuracy = 0.8090 Test Loss = 0.3391, Test Accuracy = 0.7980\n",
      "Iteration 1423: Loss = 0.3536, Accuracy = 0.7680 Test Loss = 0.3390, Test Accuracy = 0.7977\n",
      "Iteration 1424: Loss = 0.3301, Accuracy = 0.7800 Test Loss = 0.3390, Test Accuracy = 0.7980\n",
      "Iteration 1425: Loss = 0.3033, Accuracy = 0.8120 Test Loss = 0.3388, Test Accuracy = 0.7970\n",
      "Iteration 1426: Loss = 0.3581, Accuracy = 0.7890 Test Loss = 0.3388, Test Accuracy = 0.7967\n",
      "Iteration 1427: Loss = 0.3414, Accuracy = 0.7940 Test Loss = 0.3386, Test Accuracy = 0.7985\n",
      "Iteration 1428: Loss = 0.3382, Accuracy = 0.7720 Test Loss = 0.3386, Test Accuracy = 0.8006\n",
      "Iteration 1429: Loss = 0.3246, Accuracy = 0.7920 Test Loss = 0.3384, Test Accuracy = 0.7981\n",
      "Iteration 1430: Loss = 0.3173, Accuracy = 0.7930 Test Loss = 0.3382, Test Accuracy = 0.7976\n",
      "Iteration 1431: Loss = 0.3484, Accuracy = 0.7960 Test Loss = 0.3381, Test Accuracy = 0.7988\n",
      "Iteration 1432: Loss = 0.3284, Accuracy = 0.7980 Test Loss = 0.3379, Test Accuracy = 0.7980\n",
      "Iteration 1433: Loss = 0.3204, Accuracy = 0.7920 Test Loss = 0.3379, Test Accuracy = 0.7983\n",
      "Iteration 1434: Loss = 0.3515, Accuracy = 0.8010 Test Loss = 0.3377, Test Accuracy = 0.7995\n",
      "Iteration 1435: Loss = 0.3480, Accuracy = 0.8010 Test Loss = 0.3375, Test Accuracy = 0.7989\n",
      "Iteration 1436: Loss = 0.3410, Accuracy = 0.7950 Test Loss = 0.3375, Test Accuracy = 0.7994\n",
      "Iteration 1437: Loss = 0.3492, Accuracy = 0.8090 Test Loss = 0.3373, Test Accuracy = 0.7985\n",
      "Iteration 1438: Loss = 0.3120, Accuracy = 0.8070 Test Loss = 0.3372, Test Accuracy = 0.7985\n",
      "Iteration 1439: Loss = 0.3590, Accuracy = 0.7880 Test Loss = 0.3371, Test Accuracy = 0.7983\n",
      "Iteration 1440: Loss = 0.3569, Accuracy = 0.7800 Test Loss = 0.3369, Test Accuracy = 0.7998\n",
      "Iteration 1441: Loss = 0.3274, Accuracy = 0.7850 Test Loss = 0.3369, Test Accuracy = 0.7993\n",
      "Iteration 1442: Loss = 0.3358, Accuracy = 0.7640 Test Loss = 0.3367, Test Accuracy = 0.7991\n",
      "Iteration 1443: Loss = 0.3194, Accuracy = 0.7920 Test Loss = 0.3367, Test Accuracy = 0.7985\n",
      "Iteration 1444: Loss = 0.3065, Accuracy = 0.7910 Test Loss = 0.3366, Test Accuracy = 0.7987\n",
      "Iteration 1445: Loss = 0.3346, Accuracy = 0.7940 Test Loss = 0.3363, Test Accuracy = 0.7992\n",
      "Iteration 1446: Loss = 0.3389, Accuracy = 0.8000 Test Loss = 0.3362, Test Accuracy = 0.7989\n",
      "Iteration 1447: Loss = 0.3414, Accuracy = 0.7960 Test Loss = 0.3362, Test Accuracy = 0.7992\n",
      "Iteration 1448: Loss = 0.3294, Accuracy = 0.7980 Test Loss = 0.3360, Test Accuracy = 0.7982\n",
      "Iteration 1449: Loss = 0.3210, Accuracy = 0.7840 Test Loss = 0.3360, Test Accuracy = 0.7994\n",
      "Iteration 1450: Loss = 0.3118, Accuracy = 0.8180 Test Loss = 0.3357, Test Accuracy = 0.7991\n",
      "Iteration 1451: Loss = 0.3755, Accuracy = 0.7690 Test Loss = 0.3357, Test Accuracy = 0.7998\n",
      "Iteration 1452: Loss = 0.3293, Accuracy = 0.8010 Test Loss = 0.3355, Test Accuracy = 0.7990\n",
      "Iteration 1453: Loss = 0.3363, Accuracy = 0.7960 Test Loss = 0.3354, Test Accuracy = 0.7998\n",
      "Iteration 1454: Loss = 0.3090, Accuracy = 0.8080 Test Loss = 0.3353, Test Accuracy = 0.8000\n",
      "Iteration 1455: Loss = 0.3358, Accuracy = 0.7870 Test Loss = 0.3352, Test Accuracy = 0.7991\n",
      "Iteration 1456: Loss = 0.3443, Accuracy = 0.8010 Test Loss = 0.3352, Test Accuracy = 0.7998\n",
      "Iteration 1457: Loss = 0.3520, Accuracy = 0.7760 Test Loss = 0.3351, Test Accuracy = 0.7997\n",
      "Iteration 1458: Loss = 0.3533, Accuracy = 0.7910 Test Loss = 0.3349, Test Accuracy = 0.8001\n",
      "Iteration 1459: Loss = 0.3260, Accuracy = 0.7890 Test Loss = 0.3348, Test Accuracy = 0.8006\n",
      "Iteration 1460: Loss = 0.3371, Accuracy = 0.7930 Test Loss = 0.3347, Test Accuracy = 0.7982\n",
      "Iteration 1461: Loss = 0.3288, Accuracy = 0.8010 Test Loss = 0.3345, Test Accuracy = 0.8011\n",
      "Iteration 1462: Loss = 0.3324, Accuracy = 0.7850 Test Loss = 0.3344, Test Accuracy = 0.8007\n",
      "Iteration 1463: Loss = 0.3420, Accuracy = 0.8170 Test Loss = 0.3343, Test Accuracy = 0.8002\n",
      "Iteration 1464: Loss = 0.3533, Accuracy = 0.7700 Test Loss = 0.3342, Test Accuracy = 0.7991\n",
      "Iteration 1465: Loss = 0.3401, Accuracy = 0.7900 Test Loss = 0.3341, Test Accuracy = 0.8008\n",
      "Iteration 1466: Loss = 0.3240, Accuracy = 0.7890 Test Loss = 0.3340, Test Accuracy = 0.8000\n",
      "Iteration 1467: Loss = 0.3495, Accuracy = 0.7870 Test Loss = 0.3339, Test Accuracy = 0.8000\n",
      "Iteration 1468: Loss = 0.3304, Accuracy = 0.8020 Test Loss = 0.3336, Test Accuracy = 0.8007\n",
      "Iteration 1469: Loss = 0.3355, Accuracy = 0.8170 Test Loss = 0.3336, Test Accuracy = 0.8001\n",
      "Iteration 1470: Loss = 0.3290, Accuracy = 0.7910 Test Loss = 0.3336, Test Accuracy = 0.8003\n",
      "Iteration 1471: Loss = 0.3562, Accuracy = 0.7960 Test Loss = 0.3334, Test Accuracy = 0.8015\n",
      "Iteration 1472: Loss = 0.3396, Accuracy = 0.7840 Test Loss = 0.3332, Test Accuracy = 0.8013\n",
      "Iteration 1473: Loss = 0.3351, Accuracy = 0.7800 Test Loss = 0.3331, Test Accuracy = 0.8001\n",
      "Iteration 1474: Loss = 0.3199, Accuracy = 0.7870 Test Loss = 0.3330, Test Accuracy = 0.8002\n",
      "Iteration 1475: Loss = 0.3489, Accuracy = 0.7940 Test Loss = 0.3328, Test Accuracy = 0.8005\n",
      "Iteration 1476: Loss = 0.3260, Accuracy = 0.7870 Test Loss = 0.3328, Test Accuracy = 0.8023\n",
      "Iteration 1477: Loss = 0.3444, Accuracy = 0.7920 Test Loss = 0.3328, Test Accuracy = 0.8009\n",
      "Iteration 1478: Loss = 0.3485, Accuracy = 0.7790 Test Loss = 0.3325, Test Accuracy = 0.8009\n",
      "Iteration 1479: Loss = 0.3498, Accuracy = 0.7840 Test Loss = 0.3324, Test Accuracy = 0.8007\n",
      "Iteration 1480: Loss = 0.3327, Accuracy = 0.7850 Test Loss = 0.3324, Test Accuracy = 0.8018\n",
      "Iteration 1481: Loss = 0.3184, Accuracy = 0.8110 Test Loss = 0.3322, Test Accuracy = 0.8017\n",
      "Iteration 1482: Loss = 0.3286, Accuracy = 0.7870 Test Loss = 0.3322, Test Accuracy = 0.8006\n",
      "Iteration 1483: Loss = 0.3657, Accuracy = 0.7880 Test Loss = 0.3322, Test Accuracy = 0.8013\n",
      "Iteration 1484: Loss = 0.3401, Accuracy = 0.7980 Test Loss = 0.3319, Test Accuracy = 0.8020\n",
      "Iteration 1485: Loss = 0.3149, Accuracy = 0.7750 Test Loss = 0.3318, Test Accuracy = 0.8013\n",
      "Iteration 1486: Loss = 0.3216, Accuracy = 0.7900 Test Loss = 0.3317, Test Accuracy = 0.8027\n",
      "Iteration 1487: Loss = 0.3293, Accuracy = 0.8050 Test Loss = 0.3316, Test Accuracy = 0.8030\n",
      "Iteration 1488: Loss = 0.3365, Accuracy = 0.7810 Test Loss = 0.3315, Test Accuracy = 0.8020\n",
      "Iteration 1489: Loss = 0.3267, Accuracy = 0.8000 Test Loss = 0.3313, Test Accuracy = 0.8011\n",
      "Iteration 1490: Loss = 0.3427, Accuracy = 0.7810 Test Loss = 0.3314, Test Accuracy = 0.7999\n",
      "Iteration 1491: Loss = 0.3304, Accuracy = 0.8000 Test Loss = 0.3311, Test Accuracy = 0.8021\n",
      "Iteration 1492: Loss = 0.3354, Accuracy = 0.7890 Test Loss = 0.3311, Test Accuracy = 0.8012\n",
      "Iteration 1493: Loss = 0.3423, Accuracy = 0.7810 Test Loss = 0.3309, Test Accuracy = 0.8003\n",
      "Iteration 1494: Loss = 0.3319, Accuracy = 0.7940 Test Loss = 0.3307, Test Accuracy = 0.8032\n",
      "Iteration 1495: Loss = 0.3536, Accuracy = 0.7980 Test Loss = 0.3308, Test Accuracy = 0.8001\n",
      "Iteration 1496: Loss = 0.3274, Accuracy = 0.7790 Test Loss = 0.3306, Test Accuracy = 0.8013\n",
      "Iteration 1497: Loss = 0.3533, Accuracy = 0.7850 Test Loss = 0.3304, Test Accuracy = 0.8022\n",
      "Iteration 1498: Loss = 0.3131, Accuracy = 0.7950 Test Loss = 0.3305, Test Accuracy = 0.8012\n",
      "Iteration 1499: Loss = 0.3334, Accuracy = 0.7940 Test Loss = 0.3302, Test Accuracy = 0.8019\n",
      "Iteration 1500: Loss = 0.3053, Accuracy = 0.7980 Test Loss = 0.3300, Test Accuracy = 0.8012\n",
      "Iteration 1501: Loss = 0.3098, Accuracy = 0.8000 Test Loss = 0.3300, Test Accuracy = 0.8012\n",
      "Iteration 1502: Loss = 0.3015, Accuracy = 0.8190 Test Loss = 0.3298, Test Accuracy = 0.8006\n",
      "Iteration 1503: Loss = 0.3209, Accuracy = 0.8060 Test Loss = 0.3299, Test Accuracy = 0.8041\n",
      "Iteration 1504: Loss = 0.3383, Accuracy = 0.7980 Test Loss = 0.3296, Test Accuracy = 0.8012\n",
      "Iteration 1505: Loss = 0.3605, Accuracy = 0.7730 Test Loss = 0.3296, Test Accuracy = 0.8009\n",
      "Iteration 1506: Loss = 0.3189, Accuracy = 0.7820 Test Loss = 0.3296, Test Accuracy = 0.8001\n",
      "Iteration 1507: Loss = 0.3097, Accuracy = 0.7860 Test Loss = 0.3293, Test Accuracy = 0.8023\n",
      "Iteration 1508: Loss = 0.3192, Accuracy = 0.8070 Test Loss = 0.3293, Test Accuracy = 0.8000\n",
      "Iteration 1509: Loss = 0.3306, Accuracy = 0.7650 Test Loss = 0.3291, Test Accuracy = 0.8022\n",
      "Iteration 1510: Loss = 0.3626, Accuracy = 0.7840 Test Loss = 0.3290, Test Accuracy = 0.8032\n",
      "Iteration 1511: Loss = 0.3103, Accuracy = 0.8110 Test Loss = 0.3290, Test Accuracy = 0.8023\n",
      "Iteration 1512: Loss = 0.3158, Accuracy = 0.8050 Test Loss = 0.3289, Test Accuracy = 0.8020\n",
      "Iteration 1513: Loss = 0.3278, Accuracy = 0.7900 Test Loss = 0.3287, Test Accuracy = 0.8019\n",
      "Iteration 1514: Loss = 0.3223, Accuracy = 0.7900 Test Loss = 0.3286, Test Accuracy = 0.8038\n",
      "Iteration 1515: Loss = 0.3147, Accuracy = 0.8110 Test Loss = 0.3285, Test Accuracy = 0.8031\n",
      "Iteration 1516: Loss = 0.3336, Accuracy = 0.8020 Test Loss = 0.3284, Test Accuracy = 0.8022\n",
      "Iteration 1517: Loss = 0.3210, Accuracy = 0.8070 Test Loss = 0.3283, Test Accuracy = 0.8029\n",
      "Iteration 1518: Loss = 0.2999, Accuracy = 0.8060 Test Loss = 0.3282, Test Accuracy = 0.8039\n",
      "Iteration 1519: Loss = 0.3297, Accuracy = 0.7950 Test Loss = 0.3281, Test Accuracy = 0.8032\n",
      "Iteration 1520: Loss = 0.3337, Accuracy = 0.8040 Test Loss = 0.3279, Test Accuracy = 0.8033\n",
      "Iteration 1521: Loss = 0.3596, Accuracy = 0.8020 Test Loss = 0.3279, Test Accuracy = 0.8029\n",
      "Iteration 1522: Loss = 0.3373, Accuracy = 0.7740 Test Loss = 0.3278, Test Accuracy = 0.8035\n",
      "Iteration 1523: Loss = 0.3117, Accuracy = 0.8080 Test Loss = 0.3277, Test Accuracy = 0.8040\n",
      "Iteration 1524: Loss = 0.3181, Accuracy = 0.7890 Test Loss = 0.3276, Test Accuracy = 0.8038\n",
      "Iteration 1525: Loss = 0.3276, Accuracy = 0.7840 Test Loss = 0.3275, Test Accuracy = 0.8041\n",
      "Iteration 1526: Loss = 0.3304, Accuracy = 0.8050 Test Loss = 0.3273, Test Accuracy = 0.8042\n",
      "Iteration 1527: Loss = 0.3198, Accuracy = 0.7920 Test Loss = 0.3273, Test Accuracy = 0.8033\n",
      "Iteration 1528: Loss = 0.3429, Accuracy = 0.7890 Test Loss = 0.3272, Test Accuracy = 0.8026\n",
      "Iteration 1529: Loss = 0.3313, Accuracy = 0.8020 Test Loss = 0.3270, Test Accuracy = 0.8041\n",
      "Iteration 1530: Loss = 0.3184, Accuracy = 0.7920 Test Loss = 0.3269, Test Accuracy = 0.8029\n",
      "Iteration 1531: Loss = 0.3313, Accuracy = 0.7820 Test Loss = 0.3269, Test Accuracy = 0.8037\n",
      "Iteration 1532: Loss = 0.3024, Accuracy = 0.7930 Test Loss = 0.3267, Test Accuracy = 0.8045\n",
      "Iteration 1533: Loss = 0.3410, Accuracy = 0.7860 Test Loss = 0.3266, Test Accuracy = 0.8040\n",
      "Iteration 1534: Loss = 0.3099, Accuracy = 0.7930 Test Loss = 0.3265, Test Accuracy = 0.8044\n",
      "Iteration 1535: Loss = 0.3066, Accuracy = 0.7990 Test Loss = 0.3264, Test Accuracy = 0.8034\n",
      "Iteration 1536: Loss = 0.3036, Accuracy = 0.8020 Test Loss = 0.3264, Test Accuracy = 0.8047\n",
      "Iteration 1537: Loss = 0.3028, Accuracy = 0.7880 Test Loss = 0.3262, Test Accuracy = 0.8055\n",
      "Iteration 1538: Loss = 0.3339, Accuracy = 0.7920 Test Loss = 0.3261, Test Accuracy = 0.8039\n",
      "Iteration 1539: Loss = 0.3348, Accuracy = 0.7860 Test Loss = 0.3259, Test Accuracy = 0.8034\n",
      "Iteration 1540: Loss = 0.3008, Accuracy = 0.8160 Test Loss = 0.3259, Test Accuracy = 0.8030\n",
      "Iteration 1541: Loss = 0.3511, Accuracy = 0.8050 Test Loss = 0.3259, Test Accuracy = 0.8033\n",
      "Iteration 1542: Loss = 0.3622, Accuracy = 0.7840 Test Loss = 0.3257, Test Accuracy = 0.8051\n",
      "Iteration 1543: Loss = 0.3048, Accuracy = 0.7920 Test Loss = 0.3256, Test Accuracy = 0.8038\n",
      "Iteration 1544: Loss = 0.3295, Accuracy = 0.7910 Test Loss = 0.3257, Test Accuracy = 0.8022\n",
      "Iteration 1545: Loss = 0.3122, Accuracy = 0.8010 Test Loss = 0.3255, Test Accuracy = 0.8018\n",
      "Iteration 1546: Loss = 0.3009, Accuracy = 0.8150 Test Loss = 0.3253, Test Accuracy = 0.8040\n",
      "Iteration 1547: Loss = 0.3008, Accuracy = 0.8130 Test Loss = 0.3251, Test Accuracy = 0.8041\n",
      "Iteration 1548: Loss = 0.3371, Accuracy = 0.7980 Test Loss = 0.3251, Test Accuracy = 0.8035\n",
      "Iteration 1549: Loss = 0.3400, Accuracy = 0.8290 Test Loss = 0.3249, Test Accuracy = 0.8045\n",
      "Iteration 1550: Loss = 0.3169, Accuracy = 0.8290 Test Loss = 0.3249, Test Accuracy = 0.8037\n",
      "Iteration 1551: Loss = 0.3109, Accuracy = 0.8100 Test Loss = 0.3247, Test Accuracy = 0.8044\n",
      "Iteration 1552: Loss = 0.3497, Accuracy = 0.7890 Test Loss = 0.3247, Test Accuracy = 0.8065\n",
      "Iteration 1553: Loss = 0.3122, Accuracy = 0.8170 Test Loss = 0.3247, Test Accuracy = 0.8047\n",
      "Iteration 1554: Loss = 0.3116, Accuracy = 0.7930 Test Loss = 0.3244, Test Accuracy = 0.8047\n",
      "Iteration 1555: Loss = 0.3023, Accuracy = 0.7960 Test Loss = 0.3244, Test Accuracy = 0.8034\n",
      "Iteration 1556: Loss = 0.3183, Accuracy = 0.7910 Test Loss = 0.3243, Test Accuracy = 0.8047\n",
      "Iteration 1557: Loss = 0.3256, Accuracy = 0.8190 Test Loss = 0.3241, Test Accuracy = 0.8051\n",
      "Iteration 1558: Loss = 0.3254, Accuracy = 0.7900 Test Loss = 0.3240, Test Accuracy = 0.8059\n",
      "Iteration 1559: Loss = 0.3268, Accuracy = 0.7980 Test Loss = 0.3239, Test Accuracy = 0.8043\n",
      "Iteration 1560: Loss = 0.3206, Accuracy = 0.8110 Test Loss = 0.3240, Test Accuracy = 0.8045\n",
      "Iteration 1561: Loss = 0.3222, Accuracy = 0.8200 Test Loss = 0.3239, Test Accuracy = 0.8052\n",
      "Iteration 1562: Loss = 0.3231, Accuracy = 0.7970 Test Loss = 0.3236, Test Accuracy = 0.8065\n",
      "Iteration 1563: Loss = 0.3124, Accuracy = 0.8020 Test Loss = 0.3236, Test Accuracy = 0.8047\n",
      "Iteration 1564: Loss = 0.3033, Accuracy = 0.7950 Test Loss = 0.3235, Test Accuracy = 0.8047\n",
      "Iteration 1565: Loss = 0.3426, Accuracy = 0.7860 Test Loss = 0.3234, Test Accuracy = 0.8035\n",
      "Iteration 1566: Loss = 0.3399, Accuracy = 0.7830 Test Loss = 0.3233, Test Accuracy = 0.8062\n",
      "Iteration 1567: Loss = 0.3250, Accuracy = 0.8140 Test Loss = 0.3233, Test Accuracy = 0.8039\n",
      "Iteration 1568: Loss = 0.3101, Accuracy = 0.8160 Test Loss = 0.3231, Test Accuracy = 0.8049\n",
      "Iteration 1569: Loss = 0.3149, Accuracy = 0.8050 Test Loss = 0.3230, Test Accuracy = 0.8061\n",
      "Iteration 1570: Loss = 0.3332, Accuracy = 0.7880 Test Loss = 0.3229, Test Accuracy = 0.8053\n",
      "Iteration 1571: Loss = 0.3147, Accuracy = 0.8210 Test Loss = 0.3230, Test Accuracy = 0.8043\n",
      "Iteration 1572: Loss = 0.3124, Accuracy = 0.8180 Test Loss = 0.3227, Test Accuracy = 0.8041\n",
      "Iteration 1573: Loss = 0.3020, Accuracy = 0.8220 Test Loss = 0.3226, Test Accuracy = 0.8056\n",
      "Iteration 1574: Loss = 0.3353, Accuracy = 0.8010 Test Loss = 0.3225, Test Accuracy = 0.8074\n",
      "Iteration 1575: Loss = 0.3292, Accuracy = 0.8050 Test Loss = 0.3224, Test Accuracy = 0.8066\n",
      "Iteration 1576: Loss = 0.3379, Accuracy = 0.7810 Test Loss = 0.3223, Test Accuracy = 0.8064\n",
      "Iteration 1577: Loss = 0.3234, Accuracy = 0.7850 Test Loss = 0.3223, Test Accuracy = 0.8062\n",
      "Iteration 1578: Loss = 0.3026, Accuracy = 0.7930 Test Loss = 0.3221, Test Accuracy = 0.8046\n",
      "Iteration 1579: Loss = 0.3353, Accuracy = 0.7870 Test Loss = 0.3220, Test Accuracy = 0.8055\n",
      "Iteration 1580: Loss = 0.3139, Accuracy = 0.8110 Test Loss = 0.3221, Test Accuracy = 0.8051\n",
      "Iteration 1581: Loss = 0.3180, Accuracy = 0.8280 Test Loss = 0.3218, Test Accuracy = 0.8066\n",
      "Iteration 1582: Loss = 0.3315, Accuracy = 0.8000 Test Loss = 0.3217, Test Accuracy = 0.8063\n",
      "Iteration 1583: Loss = 0.3432, Accuracy = 0.7980 Test Loss = 0.3217, Test Accuracy = 0.8045\n",
      "Iteration 1584: Loss = 0.3205, Accuracy = 0.7920 Test Loss = 0.3216, Test Accuracy = 0.8041\n",
      "Iteration 1585: Loss = 0.3231, Accuracy = 0.7840 Test Loss = 0.3214, Test Accuracy = 0.8069\n",
      "Iteration 1586: Loss = 0.3199, Accuracy = 0.7960 Test Loss = 0.3213, Test Accuracy = 0.8077\n",
      "Iteration 1587: Loss = 0.3399, Accuracy = 0.8120 Test Loss = 0.3212, Test Accuracy = 0.8054\n",
      "Iteration 1588: Loss = 0.3346, Accuracy = 0.8260 Test Loss = 0.3212, Test Accuracy = 0.8066\n",
      "Iteration 1589: Loss = 0.3084, Accuracy = 0.7890 Test Loss = 0.3210, Test Accuracy = 0.8063\n",
      "Iteration 1590: Loss = 0.3155, Accuracy = 0.8000 Test Loss = 0.3211, Test Accuracy = 0.8052\n",
      "Iteration 1591: Loss = 0.3103, Accuracy = 0.7810 Test Loss = 0.3208, Test Accuracy = 0.8068\n",
      "Iteration 1592: Loss = 0.3224, Accuracy = 0.7990 Test Loss = 0.3207, Test Accuracy = 0.8057\n",
      "Iteration 1593: Loss = 0.3118, Accuracy = 0.7890 Test Loss = 0.3207, Test Accuracy = 0.8068\n",
      "Iteration 1594: Loss = 0.3048, Accuracy = 0.7990 Test Loss = 0.3206, Test Accuracy = 0.8063\n",
      "Iteration 1595: Loss = 0.3113, Accuracy = 0.8100 Test Loss = 0.3205, Test Accuracy = 0.8073\n",
      "Iteration 1596: Loss = 0.3137, Accuracy = 0.8050 Test Loss = 0.3204, Test Accuracy = 0.8061\n",
      "Iteration 1597: Loss = 0.3133, Accuracy = 0.8030 Test Loss = 0.3202, Test Accuracy = 0.8069\n",
      "Iteration 1598: Loss = 0.3092, Accuracy = 0.8020 Test Loss = 0.3202, Test Accuracy = 0.8064\n",
      "Iteration 1599: Loss = 0.3437, Accuracy = 0.7900 Test Loss = 0.3201, Test Accuracy = 0.8055\n",
      "Iteration 1600: Loss = 0.3089, Accuracy = 0.8050 Test Loss = 0.3200, Test Accuracy = 0.8067\n",
      "Iteration 1601: Loss = 0.3104, Accuracy = 0.7870 Test Loss = 0.3199, Test Accuracy = 0.8069\n",
      "Iteration 1602: Loss = 0.3202, Accuracy = 0.7790 Test Loss = 0.3198, Test Accuracy = 0.8074\n",
      "Iteration 1603: Loss = 0.3195, Accuracy = 0.8210 Test Loss = 0.3197, Test Accuracy = 0.8078\n",
      "Iteration 1604: Loss = 0.3288, Accuracy = 0.7780 Test Loss = 0.3196, Test Accuracy = 0.8071\n",
      "Iteration 1605: Loss = 0.3009, Accuracy = 0.8070 Test Loss = 0.3195, Test Accuracy = 0.8078\n",
      "Iteration 1606: Loss = 0.3058, Accuracy = 0.7860 Test Loss = 0.3195, Test Accuracy = 0.8057\n",
      "Iteration 1607: Loss = 0.3209, Accuracy = 0.7990 Test Loss = 0.3194, Test Accuracy = 0.8068\n",
      "Iteration 1608: Loss = 0.3071, Accuracy = 0.7820 Test Loss = 0.3193, Test Accuracy = 0.8060\n",
      "Iteration 1609: Loss = 0.2891, Accuracy = 0.8110 Test Loss = 0.3191, Test Accuracy = 0.8073\n",
      "Iteration 1610: Loss = 0.3007, Accuracy = 0.8100 Test Loss = 0.3191, Test Accuracy = 0.8067\n",
      "Iteration 1611: Loss = 0.3501, Accuracy = 0.7970 Test Loss = 0.3190, Test Accuracy = 0.8066\n",
      "Iteration 1612: Loss = 0.3033, Accuracy = 0.8140 Test Loss = 0.3190, Test Accuracy = 0.8088\n",
      "Iteration 1613: Loss = 0.3199, Accuracy = 0.8190 Test Loss = 0.3188, Test Accuracy = 0.8065\n",
      "Iteration 1614: Loss = 0.3138, Accuracy = 0.7910 Test Loss = 0.3188, Test Accuracy = 0.8063\n",
      "Iteration 1615: Loss = 0.3273, Accuracy = 0.7880 Test Loss = 0.3186, Test Accuracy = 0.8076\n",
      "Iteration 1616: Loss = 0.3159, Accuracy = 0.8110 Test Loss = 0.3186, Test Accuracy = 0.8068\n",
      "Iteration 1617: Loss = 0.3144, Accuracy = 0.8040 Test Loss = 0.3186, Test Accuracy = 0.8055\n",
      "Iteration 1618: Loss = 0.2918, Accuracy = 0.8190 Test Loss = 0.3183, Test Accuracy = 0.8078\n",
      "Iteration 1619: Loss = 0.3225, Accuracy = 0.7910 Test Loss = 0.3183, Test Accuracy = 0.8068\n",
      "Iteration 1620: Loss = 0.3103, Accuracy = 0.7970 Test Loss = 0.3182, Test Accuracy = 0.8056\n",
      "Iteration 1621: Loss = 0.3106, Accuracy = 0.8120 Test Loss = 0.3181, Test Accuracy = 0.8072\n",
      "Iteration 1622: Loss = 0.3325, Accuracy = 0.8130 Test Loss = 0.3180, Test Accuracy = 0.8072\n",
      "Iteration 1623: Loss = 0.2810, Accuracy = 0.8160 Test Loss = 0.3180, Test Accuracy = 0.8066\n",
      "Iteration 1624: Loss = 0.3318, Accuracy = 0.7750 Test Loss = 0.3178, Test Accuracy = 0.8077\n",
      "Iteration 1625: Loss = 0.3226, Accuracy = 0.7950 Test Loss = 0.3178, Test Accuracy = 0.8083\n",
      "Iteration 1626: Loss = 0.3275, Accuracy = 0.8020 Test Loss = 0.3177, Test Accuracy = 0.8069\n",
      "Iteration 1627: Loss = 0.3366, Accuracy = 0.7790 Test Loss = 0.3175, Test Accuracy = 0.8087\n",
      "Iteration 1628: Loss = 0.3213, Accuracy = 0.7760 Test Loss = 0.3174, Test Accuracy = 0.8090\n",
      "Iteration 1629: Loss = 0.3537, Accuracy = 0.7970 Test Loss = 0.3173, Test Accuracy = 0.8076\n",
      "Iteration 1630: Loss = 0.2984, Accuracy = 0.8040 Test Loss = 0.3172, Test Accuracy = 0.8077\n",
      "Iteration 1631: Loss = 0.3021, Accuracy = 0.8000 Test Loss = 0.3172, Test Accuracy = 0.8067\n",
      "Iteration 1632: Loss = 0.3248, Accuracy = 0.8050 Test Loss = 0.3171, Test Accuracy = 0.8068\n",
      "Iteration 1633: Loss = 0.3305, Accuracy = 0.7890 Test Loss = 0.3170, Test Accuracy = 0.8076\n",
      "Iteration 1634: Loss = 0.3300, Accuracy = 0.7990 Test Loss = 0.3169, Test Accuracy = 0.8088\n",
      "Iteration 1635: Loss = 0.3161, Accuracy = 0.7980 Test Loss = 0.3168, Test Accuracy = 0.8075\n",
      "Iteration 1636: Loss = 0.2998, Accuracy = 0.7930 Test Loss = 0.3168, Test Accuracy = 0.8089\n",
      "Iteration 1637: Loss = 0.2798, Accuracy = 0.8260 Test Loss = 0.3167, Test Accuracy = 0.8065\n",
      "Iteration 1638: Loss = 0.3316, Accuracy = 0.7920 Test Loss = 0.3166, Test Accuracy = 0.8077\n",
      "Iteration 1639: Loss = 0.3296, Accuracy = 0.8020 Test Loss = 0.3164, Test Accuracy = 0.8077\n",
      "Iteration 1640: Loss = 0.3047, Accuracy = 0.7940 Test Loss = 0.3164, Test Accuracy = 0.8087\n",
      "Iteration 1641: Loss = 0.3059, Accuracy = 0.8040 Test Loss = 0.3163, Test Accuracy = 0.8069\n",
      "Iteration 1642: Loss = 0.2891, Accuracy = 0.8010 Test Loss = 0.3162, Test Accuracy = 0.8090\n",
      "Iteration 1643: Loss = 0.2933, Accuracy = 0.8330 Test Loss = 0.3160, Test Accuracy = 0.8076\n",
      "Iteration 1644: Loss = 0.3098, Accuracy = 0.8010 Test Loss = 0.3161, Test Accuracy = 0.8069\n",
      "Iteration 1645: Loss = 0.2913, Accuracy = 0.8080 Test Loss = 0.3160, Test Accuracy = 0.8081\n",
      "Iteration 1646: Loss = 0.3105, Accuracy = 0.8280 Test Loss = 0.3159, Test Accuracy = 0.8077\n",
      "Iteration 1647: Loss = 0.3161, Accuracy = 0.8070 Test Loss = 0.3157, Test Accuracy = 0.8080\n",
      "Iteration 1648: Loss = 0.3019, Accuracy = 0.8090 Test Loss = 0.3156, Test Accuracy = 0.8074\n",
      "Iteration 1649: Loss = 0.3088, Accuracy = 0.8040 Test Loss = 0.3156, Test Accuracy = 0.8085\n",
      "Iteration 1650: Loss = 0.3312, Accuracy = 0.7880 Test Loss = 0.3154, Test Accuracy = 0.8088\n",
      "Iteration 1651: Loss = 0.3055, Accuracy = 0.8060 Test Loss = 0.3153, Test Accuracy = 0.8084\n",
      "Iteration 1652: Loss = 0.3107, Accuracy = 0.7960 Test Loss = 0.3154, Test Accuracy = 0.8093\n",
      "Iteration 1653: Loss = 0.2953, Accuracy = 0.8050 Test Loss = 0.3154, Test Accuracy = 0.8069\n",
      "Iteration 1654: Loss = 0.2929, Accuracy = 0.8050 Test Loss = 0.3151, Test Accuracy = 0.8093\n",
      "Iteration 1655: Loss = 0.3129, Accuracy = 0.8020 Test Loss = 0.3151, Test Accuracy = 0.8081\n",
      "Iteration 1656: Loss = 0.3145, Accuracy = 0.8010 Test Loss = 0.3149, Test Accuracy = 0.8084\n",
      "Iteration 1657: Loss = 0.3181, Accuracy = 0.7950 Test Loss = 0.3148, Test Accuracy = 0.8076\n",
      "Iteration 1658: Loss = 0.3175, Accuracy = 0.8010 Test Loss = 0.3148, Test Accuracy = 0.8089\n",
      "Iteration 1659: Loss = 0.3217, Accuracy = 0.7930 Test Loss = 0.3146, Test Accuracy = 0.8099\n",
      "Iteration 1660: Loss = 0.3090, Accuracy = 0.8060 Test Loss = 0.3146, Test Accuracy = 0.8079\n",
      "Iteration 1661: Loss = 0.3153, Accuracy = 0.7920 Test Loss = 0.3145, Test Accuracy = 0.8089\n",
      "Iteration 1662: Loss = 0.3213, Accuracy = 0.7940 Test Loss = 0.3145, Test Accuracy = 0.8100\n",
      "Iteration 1663: Loss = 0.3152, Accuracy = 0.8130 Test Loss = 0.3143, Test Accuracy = 0.8090\n",
      "Iteration 1664: Loss = 0.3020, Accuracy = 0.8060 Test Loss = 0.3144, Test Accuracy = 0.8060\n",
      "Iteration 1665: Loss = 0.3070, Accuracy = 0.8080 Test Loss = 0.3141, Test Accuracy = 0.8083\n",
      "Iteration 1666: Loss = 0.3325, Accuracy = 0.7910 Test Loss = 0.3140, Test Accuracy = 0.8099\n",
      "Iteration 1667: Loss = 0.3255, Accuracy = 0.7920 Test Loss = 0.3139, Test Accuracy = 0.8089\n",
      "Iteration 1668: Loss = 0.3034, Accuracy = 0.8050 Test Loss = 0.3139, Test Accuracy = 0.8084\n",
      "Iteration 1669: Loss = 0.3446, Accuracy = 0.7950 Test Loss = 0.3138, Test Accuracy = 0.8083\n",
      "Iteration 1670: Loss = 0.2922, Accuracy = 0.8060 Test Loss = 0.3137, Test Accuracy = 0.8099\n",
      "Iteration 1671: Loss = 0.2911, Accuracy = 0.8210 Test Loss = 0.3137, Test Accuracy = 0.8105\n",
      "Iteration 1672: Loss = 0.3057, Accuracy = 0.7860 Test Loss = 0.3135, Test Accuracy = 0.8092\n",
      "Iteration 1673: Loss = 0.3167, Accuracy = 0.7920 Test Loss = 0.3136, Test Accuracy = 0.8099\n",
      "Iteration 1674: Loss = 0.3271, Accuracy = 0.7920 Test Loss = 0.3133, Test Accuracy = 0.8094\n",
      "Iteration 1675: Loss = 0.2869, Accuracy = 0.8070 Test Loss = 0.3134, Test Accuracy = 0.8101\n",
      "Iteration 1676: Loss = 0.3362, Accuracy = 0.7880 Test Loss = 0.3133, Test Accuracy = 0.8083\n",
      "Iteration 1677: Loss = 0.3022, Accuracy = 0.8140 Test Loss = 0.3131, Test Accuracy = 0.8097\n",
      "Iteration 1678: Loss = 0.3199, Accuracy = 0.8000 Test Loss = 0.3132, Test Accuracy = 0.8098\n",
      "Iteration 1679: Loss = 0.3159, Accuracy = 0.7780 Test Loss = 0.3130, Test Accuracy = 0.8076\n",
      "Iteration 1680: Loss = 0.3360, Accuracy = 0.8020 Test Loss = 0.3128, Test Accuracy = 0.8078\n",
      "Iteration 1681: Loss = 0.3236, Accuracy = 0.8000 Test Loss = 0.3127, Test Accuracy = 0.8088\n",
      "Iteration 1682: Loss = 0.3029, Accuracy = 0.7960 Test Loss = 0.3127, Test Accuracy = 0.8109\n",
      "Iteration 1683: Loss = 0.2899, Accuracy = 0.7830 Test Loss = 0.3126, Test Accuracy = 0.8086\n",
      "Iteration 1684: Loss = 0.2978, Accuracy = 0.8210 Test Loss = 0.3125, Test Accuracy = 0.8100\n",
      "Iteration 1685: Loss = 0.3246, Accuracy = 0.8000 Test Loss = 0.3124, Test Accuracy = 0.8078\n",
      "Iteration 1686: Loss = 0.3319, Accuracy = 0.8050 Test Loss = 0.3124, Test Accuracy = 0.8091\n",
      "Iteration 1687: Loss = 0.3078, Accuracy = 0.8110 Test Loss = 0.3123, Test Accuracy = 0.8112\n",
      "Iteration 1688: Loss = 0.2944, Accuracy = 0.7990 Test Loss = 0.3123, Test Accuracy = 0.8098\n",
      "Iteration 1689: Loss = 0.3122, Accuracy = 0.8050 Test Loss = 0.3122, Test Accuracy = 0.8113\n",
      "Iteration 1690: Loss = 0.3156, Accuracy = 0.7970 Test Loss = 0.3120, Test Accuracy = 0.8104\n",
      "Iteration 1691: Loss = 0.3313, Accuracy = 0.8090 Test Loss = 0.3119, Test Accuracy = 0.8090\n",
      "Iteration 1692: Loss = 0.3148, Accuracy = 0.8200 Test Loss = 0.3119, Test Accuracy = 0.8098\n",
      "Iteration 1693: Loss = 0.3051, Accuracy = 0.7980 Test Loss = 0.3118, Test Accuracy = 0.8096\n",
      "Iteration 1694: Loss = 0.3144, Accuracy = 0.7860 Test Loss = 0.3119, Test Accuracy = 0.8100\n",
      "Iteration 1695: Loss = 0.3304, Accuracy = 0.7930 Test Loss = 0.3117, Test Accuracy = 0.8102\n",
      "Iteration 1696: Loss = 0.3082, Accuracy = 0.8050 Test Loss = 0.3115, Test Accuracy = 0.8103\n",
      "Iteration 1697: Loss = 0.3152, Accuracy = 0.8070 Test Loss = 0.3114, Test Accuracy = 0.8108\n",
      "Iteration 1698: Loss = 0.3330, Accuracy = 0.7750 Test Loss = 0.3114, Test Accuracy = 0.8086\n",
      "Iteration 1699: Loss = 0.2991, Accuracy = 0.8230 Test Loss = 0.3112, Test Accuracy = 0.8105\n",
      "Iteration 1700: Loss = 0.2947, Accuracy = 0.8100 Test Loss = 0.3113, Test Accuracy = 0.8093\n",
      "Iteration 1701: Loss = 0.2912, Accuracy = 0.8300 Test Loss = 0.3112, Test Accuracy = 0.8088\n",
      "Iteration 1702: Loss = 0.2992, Accuracy = 0.8180 Test Loss = 0.3112, Test Accuracy = 0.8083\n",
      "Iteration 1703: Loss = 0.3222, Accuracy = 0.7950 Test Loss = 0.3109, Test Accuracy = 0.8093\n",
      "Iteration 1704: Loss = 0.3173, Accuracy = 0.8310 Test Loss = 0.3109, Test Accuracy = 0.8117\n",
      "Iteration 1705: Loss = 0.3363, Accuracy = 0.7810 Test Loss = 0.3108, Test Accuracy = 0.8087\n",
      "Iteration 1706: Loss = 0.2984, Accuracy = 0.8120 Test Loss = 0.3106, Test Accuracy = 0.8115\n",
      "Iteration 1707: Loss = 0.3026, Accuracy = 0.8120 Test Loss = 0.3107, Test Accuracy = 0.8101\n",
      "Iteration 1708: Loss = 0.3097, Accuracy = 0.7880 Test Loss = 0.3106, Test Accuracy = 0.8102\n",
      "Iteration 1709: Loss = 0.3089, Accuracy = 0.8020 Test Loss = 0.3107, Test Accuracy = 0.8105\n",
      "Iteration 1710: Loss = 0.3001, Accuracy = 0.8120 Test Loss = 0.3105, Test Accuracy = 0.8101\n",
      "Iteration 1711: Loss = 0.3032, Accuracy = 0.7990 Test Loss = 0.3103, Test Accuracy = 0.8112\n",
      "Iteration 1712: Loss = 0.3012, Accuracy = 0.8050 Test Loss = 0.3102, Test Accuracy = 0.8104\n",
      "Iteration 1713: Loss = 0.3048, Accuracy = 0.8130 Test Loss = 0.3101, Test Accuracy = 0.8093\n",
      "Iteration 1714: Loss = 0.3173, Accuracy = 0.8070 Test Loss = 0.3100, Test Accuracy = 0.8110\n",
      "Iteration 1715: Loss = 0.3136, Accuracy = 0.7930 Test Loss = 0.3100, Test Accuracy = 0.8114\n",
      "Iteration 1716: Loss = 0.3451, Accuracy = 0.7800 Test Loss = 0.3099, Test Accuracy = 0.8111\n",
      "Iteration 1717: Loss = 0.3116, Accuracy = 0.8090 Test Loss = 0.3098, Test Accuracy = 0.8122\n",
      "Iteration 1718: Loss = 0.3228, Accuracy = 0.7890 Test Loss = 0.3098, Test Accuracy = 0.8110\n",
      "Iteration 1719: Loss = 0.3089, Accuracy = 0.8160 Test Loss = 0.3098, Test Accuracy = 0.8103\n",
      "Iteration 1720: Loss = 0.3443, Accuracy = 0.8060 Test Loss = 0.3096, Test Accuracy = 0.8106\n",
      "Iteration 1721: Loss = 0.3082, Accuracy = 0.8230 Test Loss = 0.3095, Test Accuracy = 0.8115\n",
      "Iteration 1722: Loss = 0.2887, Accuracy = 0.8140 Test Loss = 0.3095, Test Accuracy = 0.8102\n",
      "Iteration 1723: Loss = 0.3100, Accuracy = 0.7960 Test Loss = 0.3094, Test Accuracy = 0.8117\n",
      "Iteration 1724: Loss = 0.2903, Accuracy = 0.8090 Test Loss = 0.3094, Test Accuracy = 0.8109\n",
      "Iteration 1725: Loss = 0.3315, Accuracy = 0.7980 Test Loss = 0.3091, Test Accuracy = 0.8114\n",
      "Iteration 1726: Loss = 0.3073, Accuracy = 0.7950 Test Loss = 0.3091, Test Accuracy = 0.8118\n",
      "Iteration 1727: Loss = 0.2871, Accuracy = 0.8210 Test Loss = 0.3091, Test Accuracy = 0.8107\n",
      "Iteration 1728: Loss = 0.3482, Accuracy = 0.8220 Test Loss = 0.3090, Test Accuracy = 0.8119\n",
      "Iteration 1729: Loss = 0.2940, Accuracy = 0.8010 Test Loss = 0.3088, Test Accuracy = 0.8116\n",
      "Iteration 1730: Loss = 0.2956, Accuracy = 0.7980 Test Loss = 0.3089, Test Accuracy = 0.8100\n",
      "Iteration 1731: Loss = 0.3167, Accuracy = 0.7930 Test Loss = 0.3088, Test Accuracy = 0.8104\n",
      "Iteration 1732: Loss = 0.2739, Accuracy = 0.8360 Test Loss = 0.3087, Test Accuracy = 0.8112\n",
      "Iteration 1733: Loss = 0.3043, Accuracy = 0.7790 Test Loss = 0.3086, Test Accuracy = 0.8109\n",
      "Iteration 1734: Loss = 0.3066, Accuracy = 0.8210 Test Loss = 0.3085, Test Accuracy = 0.8120\n",
      "Iteration 1735: Loss = 0.3080, Accuracy = 0.8090 Test Loss = 0.3083, Test Accuracy = 0.8125\n",
      "Iteration 1736: Loss = 0.3201, Accuracy = 0.7970 Test Loss = 0.3084, Test Accuracy = 0.8086\n",
      "Iteration 1737: Loss = 0.3035, Accuracy = 0.8040 Test Loss = 0.3082, Test Accuracy = 0.8124\n",
      "Iteration 1738: Loss = 0.3109, Accuracy = 0.8240 Test Loss = 0.3083, Test Accuracy = 0.8097\n",
      "Iteration 1739: Loss = 0.3223, Accuracy = 0.7830 Test Loss = 0.3081, Test Accuracy = 0.8108\n",
      "Iteration 1740: Loss = 0.2986, Accuracy = 0.8140 Test Loss = 0.3080, Test Accuracy = 0.8121\n",
      "Iteration 1741: Loss = 0.3130, Accuracy = 0.8030 Test Loss = 0.3079, Test Accuracy = 0.8121\n",
      "Iteration 1742: Loss = 0.3056, Accuracy = 0.8140 Test Loss = 0.3079, Test Accuracy = 0.8118\n",
      "Iteration 1743: Loss = 0.3120, Accuracy = 0.8020 Test Loss = 0.3078, Test Accuracy = 0.8128\n",
      "Iteration 1744: Loss = 0.3257, Accuracy = 0.8000 Test Loss = 0.3077, Test Accuracy = 0.8120\n",
      "Iteration 1745: Loss = 0.3056, Accuracy = 0.8230 Test Loss = 0.3077, Test Accuracy = 0.8126\n",
      "Iteration 1746: Loss = 0.3083, Accuracy = 0.8180 Test Loss = 0.3075, Test Accuracy = 0.8119\n",
      "Iteration 1747: Loss = 0.2893, Accuracy = 0.7980 Test Loss = 0.3075, Test Accuracy = 0.8120\n",
      "Iteration 1748: Loss = 0.3200, Accuracy = 0.7690 Test Loss = 0.3073, Test Accuracy = 0.8107\n",
      "Iteration 1749: Loss = 0.3081, Accuracy = 0.8230 Test Loss = 0.3074, Test Accuracy = 0.8122\n",
      "Iteration 1750: Loss = 0.2954, Accuracy = 0.8000 Test Loss = 0.3072, Test Accuracy = 0.8109\n",
      "Iteration 1751: Loss = 0.2983, Accuracy = 0.8160 Test Loss = 0.3072, Test Accuracy = 0.8127\n",
      "Iteration 1752: Loss = 0.3247, Accuracy = 0.7880 Test Loss = 0.3072, Test Accuracy = 0.8119\n",
      "Iteration 1753: Loss = 0.3183, Accuracy = 0.7850 Test Loss = 0.3070, Test Accuracy = 0.8126\n",
      "Iteration 1754: Loss = 0.3086, Accuracy = 0.8050 Test Loss = 0.3071, Test Accuracy = 0.8101\n",
      "Iteration 1755: Loss = 0.2936, Accuracy = 0.8180 Test Loss = 0.3070, Test Accuracy = 0.8104\n",
      "Iteration 1756: Loss = 0.2838, Accuracy = 0.8120 Test Loss = 0.3068, Test Accuracy = 0.8110\n",
      "Iteration 1757: Loss = 0.3278, Accuracy = 0.8080 Test Loss = 0.3067, Test Accuracy = 0.8114\n",
      "Iteration 1758: Loss = 0.2986, Accuracy = 0.8030 Test Loss = 0.3066, Test Accuracy = 0.8121\n",
      "Iteration 1759: Loss = 0.2855, Accuracy = 0.8120 Test Loss = 0.3066, Test Accuracy = 0.8123\n",
      "Iteration 1760: Loss = 0.2947, Accuracy = 0.8240 Test Loss = 0.3065, Test Accuracy = 0.8129\n",
      "Iteration 1761: Loss = 0.2918, Accuracy = 0.8230 Test Loss = 0.3065, Test Accuracy = 0.8127\n",
      "Iteration 1762: Loss = 0.2876, Accuracy = 0.8330 Test Loss = 0.3064, Test Accuracy = 0.8119\n",
      "Iteration 1763: Loss = 0.2982, Accuracy = 0.8170 Test Loss = 0.3062, Test Accuracy = 0.8109\n",
      "Iteration 1764: Loss = 0.3039, Accuracy = 0.8140 Test Loss = 0.3062, Test Accuracy = 0.8106\n",
      "Iteration 1765: Loss = 0.2957, Accuracy = 0.8240 Test Loss = 0.3060, Test Accuracy = 0.8132\n",
      "Iteration 1766: Loss = 0.2867, Accuracy = 0.8230 Test Loss = 0.3060, Test Accuracy = 0.8115\n",
      "Iteration 1767: Loss = 0.3045, Accuracy = 0.7960 Test Loss = 0.3060, Test Accuracy = 0.8123\n",
      "Iteration 1768: Loss = 0.2961, Accuracy = 0.8010 Test Loss = 0.3059, Test Accuracy = 0.8120\n",
      "Iteration 1769: Loss = 0.2930, Accuracy = 0.8270 Test Loss = 0.3058, Test Accuracy = 0.8116\n",
      "Iteration 1770: Loss = 0.3234, Accuracy = 0.8110 Test Loss = 0.3058, Test Accuracy = 0.8114\n",
      "Iteration 1771: Loss = 0.3201, Accuracy = 0.8120 Test Loss = 0.3057, Test Accuracy = 0.8120\n",
      "Iteration 1772: Loss = 0.3311, Accuracy = 0.8080 Test Loss = 0.3055, Test Accuracy = 0.8120\n",
      "Iteration 1773: Loss = 0.3322, Accuracy = 0.7950 Test Loss = 0.3056, Test Accuracy = 0.8122\n",
      "Iteration 1774: Loss = 0.3051, Accuracy = 0.8260 Test Loss = 0.3054, Test Accuracy = 0.8131\n",
      "Iteration 1775: Loss = 0.2927, Accuracy = 0.7940 Test Loss = 0.3054, Test Accuracy = 0.8125\n",
      "Iteration 1776: Loss = 0.3299, Accuracy = 0.8020 Test Loss = 0.3053, Test Accuracy = 0.8108\n",
      "Iteration 1777: Loss = 0.2849, Accuracy = 0.8200 Test Loss = 0.3052, Test Accuracy = 0.8119\n",
      "Iteration 1778: Loss = 0.3110, Accuracy = 0.7980 Test Loss = 0.3051, Test Accuracy = 0.8129\n",
      "Iteration 1779: Loss = 0.2759, Accuracy = 0.8400 Test Loss = 0.3050, Test Accuracy = 0.8133\n",
      "Iteration 1780: Loss = 0.3126, Accuracy = 0.8110 Test Loss = 0.3050, Test Accuracy = 0.8136\n",
      "Iteration 1781: Loss = 0.3135, Accuracy = 0.8030 Test Loss = 0.3048, Test Accuracy = 0.8128\n",
      "Iteration 1782: Loss = 0.2973, Accuracy = 0.8010 Test Loss = 0.3048, Test Accuracy = 0.8117\n",
      "Iteration 1783: Loss = 0.2911, Accuracy = 0.8290 Test Loss = 0.3048, Test Accuracy = 0.8118\n",
      "Iteration 1784: Loss = 0.2845, Accuracy = 0.8190 Test Loss = 0.3046, Test Accuracy = 0.8128\n",
      "Iteration 1785: Loss = 0.2902, Accuracy = 0.8130 Test Loss = 0.3047, Test Accuracy = 0.8104\n",
      "Iteration 1786: Loss = 0.3059, Accuracy = 0.7830 Test Loss = 0.3045, Test Accuracy = 0.8131\n",
      "Iteration 1787: Loss = 0.3088, Accuracy = 0.8120 Test Loss = 0.3045, Test Accuracy = 0.8122\n",
      "Iteration 1788: Loss = 0.3067, Accuracy = 0.7810 Test Loss = 0.3044, Test Accuracy = 0.8122\n",
      "Iteration 1789: Loss = 0.2805, Accuracy = 0.8110 Test Loss = 0.3043, Test Accuracy = 0.8127\n",
      "Iteration 1790: Loss = 0.3026, Accuracy = 0.7720 Test Loss = 0.3042, Test Accuracy = 0.8139\n",
      "Iteration 1791: Loss = 0.2779, Accuracy = 0.8090 Test Loss = 0.3041, Test Accuracy = 0.8115\n",
      "Iteration 1792: Loss = 0.3133, Accuracy = 0.7970 Test Loss = 0.3041, Test Accuracy = 0.8114\n",
      "Iteration 1793: Loss = 0.3093, Accuracy = 0.8020 Test Loss = 0.3040, Test Accuracy = 0.8130\n",
      "Iteration 1794: Loss = 0.2944, Accuracy = 0.7940 Test Loss = 0.3040, Test Accuracy = 0.8120\n",
      "Iteration 1795: Loss = 0.3137, Accuracy = 0.8030 Test Loss = 0.3040, Test Accuracy = 0.8117\n",
      "Iteration 1796: Loss = 0.2944, Accuracy = 0.7990 Test Loss = 0.3038, Test Accuracy = 0.8124\n",
      "Iteration 1797: Loss = 0.2911, Accuracy = 0.8220 Test Loss = 0.3038, Test Accuracy = 0.8130\n",
      "Iteration 1798: Loss = 0.3321, Accuracy = 0.7800 Test Loss = 0.3037, Test Accuracy = 0.8123\n",
      "Iteration 1799: Loss = 0.2950, Accuracy = 0.8220 Test Loss = 0.3036, Test Accuracy = 0.8114\n",
      "Iteration 1800: Loss = 0.3061, Accuracy = 0.7960 Test Loss = 0.3035, Test Accuracy = 0.8134\n",
      "Iteration 1801: Loss = 0.3049, Accuracy = 0.8020 Test Loss = 0.3035, Test Accuracy = 0.8113\n",
      "Iteration 1802: Loss = 0.2904, Accuracy = 0.8440 Test Loss = 0.3033, Test Accuracy = 0.8137\n",
      "Iteration 1803: Loss = 0.3092, Accuracy = 0.8160 Test Loss = 0.3033, Test Accuracy = 0.8097\n",
      "Iteration 1804: Loss = 0.3068, Accuracy = 0.8100 Test Loss = 0.3032, Test Accuracy = 0.8131\n",
      "Iteration 1805: Loss = 0.3276, Accuracy = 0.8000 Test Loss = 0.3031, Test Accuracy = 0.8140\n",
      "Iteration 1806: Loss = 0.2991, Accuracy = 0.8170 Test Loss = 0.3033, Test Accuracy = 0.8116\n",
      "Iteration 1807: Loss = 0.3122, Accuracy = 0.8140 Test Loss = 0.3030, Test Accuracy = 0.8134\n",
      "Iteration 1808: Loss = 0.3119, Accuracy = 0.8030 Test Loss = 0.3029, Test Accuracy = 0.8151\n",
      "Iteration 1809: Loss = 0.3174, Accuracy = 0.8020 Test Loss = 0.3029, Test Accuracy = 0.8149\n",
      "Iteration 1810: Loss = 0.3251, Accuracy = 0.7920 Test Loss = 0.3028, Test Accuracy = 0.8132\n",
      "Iteration 1811: Loss = 0.3227, Accuracy = 0.7980 Test Loss = 0.3027, Test Accuracy = 0.8117\n",
      "Iteration 1812: Loss = 0.2893, Accuracy = 0.8150 Test Loss = 0.3026, Test Accuracy = 0.8137\n",
      "Iteration 1813: Loss = 0.3062, Accuracy = 0.8210 Test Loss = 0.3026, Test Accuracy = 0.8126\n",
      "Iteration 1814: Loss = 0.3120, Accuracy = 0.7850 Test Loss = 0.3026, Test Accuracy = 0.8126\n",
      "Iteration 1815: Loss = 0.2938, Accuracy = 0.8240 Test Loss = 0.3024, Test Accuracy = 0.8126\n",
      "Iteration 1816: Loss = 0.3111, Accuracy = 0.7960 Test Loss = 0.3023, Test Accuracy = 0.8142\n",
      "Iteration 1817: Loss = 0.3025, Accuracy = 0.8100 Test Loss = 0.3022, Test Accuracy = 0.8130\n",
      "Iteration 1818: Loss = 0.2988, Accuracy = 0.7990 Test Loss = 0.3023, Test Accuracy = 0.8124\n",
      "Iteration 1819: Loss = 0.3148, Accuracy = 0.7920 Test Loss = 0.3022, Test Accuracy = 0.8132\n",
      "Iteration 1820: Loss = 0.3024, Accuracy = 0.8170 Test Loss = 0.3021, Test Accuracy = 0.8113\n",
      "Iteration 1821: Loss = 0.3122, Accuracy = 0.8390 Test Loss = 0.3020, Test Accuracy = 0.8145\n",
      "Iteration 1822: Loss = 0.3039, Accuracy = 0.8070 Test Loss = 0.3019, Test Accuracy = 0.8139\n",
      "Iteration 1823: Loss = 0.2945, Accuracy = 0.8100 Test Loss = 0.3018, Test Accuracy = 0.8142\n",
      "Iteration 1824: Loss = 0.3027, Accuracy = 0.8130 Test Loss = 0.3019, Test Accuracy = 0.8115\n",
      "Iteration 1825: Loss = 0.2934, Accuracy = 0.8150 Test Loss = 0.3018, Test Accuracy = 0.8120\n",
      "Iteration 1826: Loss = 0.2868, Accuracy = 0.8220 Test Loss = 0.3018, Test Accuracy = 0.8137\n",
      "Iteration 1827: Loss = 0.2815, Accuracy = 0.8270 Test Loss = 0.3017, Test Accuracy = 0.8134\n",
      "Iteration 1828: Loss = 0.3255, Accuracy = 0.7870 Test Loss = 0.3016, Test Accuracy = 0.8151\n",
      "Iteration 1829: Loss = 0.3011, Accuracy = 0.8180 Test Loss = 0.3015, Test Accuracy = 0.8129\n",
      "Iteration 1830: Loss = 0.2732, Accuracy = 0.8230 Test Loss = 0.3014, Test Accuracy = 0.8136\n",
      "Iteration 1831: Loss = 0.3014, Accuracy = 0.8280 Test Loss = 0.3013, Test Accuracy = 0.8120\n",
      "Iteration 1832: Loss = 0.3032, Accuracy = 0.8050 Test Loss = 0.3012, Test Accuracy = 0.8153\n",
      "Iteration 1833: Loss = 0.3026, Accuracy = 0.8010 Test Loss = 0.3011, Test Accuracy = 0.8145\n",
      "Iteration 1834: Loss = 0.3136, Accuracy = 0.8090 Test Loss = 0.3011, Test Accuracy = 0.8130\n",
      "Iteration 1835: Loss = 0.2940, Accuracy = 0.8170 Test Loss = 0.3011, Test Accuracy = 0.8139\n",
      "Iteration 1836: Loss = 0.2878, Accuracy = 0.8340 Test Loss = 0.3010, Test Accuracy = 0.8148\n",
      "Iteration 1837: Loss = 0.2928, Accuracy = 0.8130 Test Loss = 0.3009, Test Accuracy = 0.8130\n",
      "Iteration 1838: Loss = 0.3002, Accuracy = 0.8100 Test Loss = 0.3009, Test Accuracy = 0.8128\n",
      "Iteration 1839: Loss = 0.3057, Accuracy = 0.8240 Test Loss = 0.3008, Test Accuracy = 0.8138\n",
      "Iteration 1840: Loss = 0.3091, Accuracy = 0.8160 Test Loss = 0.3007, Test Accuracy = 0.8139\n",
      "Iteration 1841: Loss = 0.3190, Accuracy = 0.7900 Test Loss = 0.3006, Test Accuracy = 0.8123\n",
      "Iteration 1842: Loss = 0.3113, Accuracy = 0.8150 Test Loss = 0.3005, Test Accuracy = 0.8132\n",
      "Iteration 1843: Loss = 0.2944, Accuracy = 0.8290 Test Loss = 0.3004, Test Accuracy = 0.8138\n",
      "Iteration 1844: Loss = 0.2977, Accuracy = 0.8270 Test Loss = 0.3005, Test Accuracy = 0.8137\n",
      "Iteration 1845: Loss = 0.2877, Accuracy = 0.8130 Test Loss = 0.3004, Test Accuracy = 0.8135\n",
      "Iteration 1846: Loss = 0.2833, Accuracy = 0.8180 Test Loss = 0.3003, Test Accuracy = 0.8129\n",
      "Iteration 1847: Loss = 0.2854, Accuracy = 0.8160 Test Loss = 0.3001, Test Accuracy = 0.8120\n",
      "Iteration 1848: Loss = 0.2843, Accuracy = 0.8100 Test Loss = 0.3001, Test Accuracy = 0.8150\n",
      "Iteration 1849: Loss = 0.3065, Accuracy = 0.7860 Test Loss = 0.3000, Test Accuracy = 0.8140\n",
      "Iteration 1850: Loss = 0.3070, Accuracy = 0.8050 Test Loss = 0.3000, Test Accuracy = 0.8156\n",
      "Iteration 1851: Loss = 0.2891, Accuracy = 0.7960 Test Loss = 0.3000, Test Accuracy = 0.8126\n",
      "Iteration 1852: Loss = 0.2944, Accuracy = 0.8070 Test Loss = 0.2998, Test Accuracy = 0.8144\n",
      "Iteration 1853: Loss = 0.2852, Accuracy = 0.8290 Test Loss = 0.2998, Test Accuracy = 0.8145\n",
      "Iteration 1854: Loss = 0.3166, Accuracy = 0.7850 Test Loss = 0.2998, Test Accuracy = 0.8151\n",
      "Iteration 1855: Loss = 0.2886, Accuracy = 0.8310 Test Loss = 0.2997, Test Accuracy = 0.8125\n",
      "Iteration 1856: Loss = 0.3072, Accuracy = 0.8020 Test Loss = 0.2996, Test Accuracy = 0.8137\n",
      "Iteration 1857: Loss = 0.3120, Accuracy = 0.7960 Test Loss = 0.2995, Test Accuracy = 0.8140\n",
      "Iteration 1858: Loss = 0.2791, Accuracy = 0.8150 Test Loss = 0.2995, Test Accuracy = 0.8146\n",
      "Iteration 1859: Loss = 0.3018, Accuracy = 0.8190 Test Loss = 0.2993, Test Accuracy = 0.8147\n",
      "Iteration 1860: Loss = 0.3263, Accuracy = 0.7790 Test Loss = 0.2993, Test Accuracy = 0.8147\n",
      "Iteration 1861: Loss = 0.3282, Accuracy = 0.7830 Test Loss = 0.2992, Test Accuracy = 0.8151\n",
      "Iteration 1862: Loss = 0.2994, Accuracy = 0.8110 Test Loss = 0.2993, Test Accuracy = 0.8128\n",
      "Iteration 1863: Loss = 0.3194, Accuracy = 0.8080 Test Loss = 0.2991, Test Accuracy = 0.8149\n",
      "Iteration 1864: Loss = 0.2980, Accuracy = 0.8000 Test Loss = 0.2990, Test Accuracy = 0.8149\n",
      "Iteration 1865: Loss = 0.3071, Accuracy = 0.8030 Test Loss = 0.2989, Test Accuracy = 0.8131\n",
      "Iteration 1866: Loss = 0.3161, Accuracy = 0.8040 Test Loss = 0.2990, Test Accuracy = 0.8121\n",
      "Iteration 1867: Loss = 0.3019, Accuracy = 0.8080 Test Loss = 0.2988, Test Accuracy = 0.8147\n",
      "Iteration 1868: Loss = 0.3094, Accuracy = 0.8140 Test Loss = 0.2988, Test Accuracy = 0.8143\n",
      "Iteration 1869: Loss = 0.2904, Accuracy = 0.8120 Test Loss = 0.2987, Test Accuracy = 0.8130\n",
      "Iteration 1870: Loss = 0.3003, Accuracy = 0.8160 Test Loss = 0.2987, Test Accuracy = 0.8147\n",
      "Iteration 1871: Loss = 0.2753, Accuracy = 0.8220 Test Loss = 0.2986, Test Accuracy = 0.8165\n",
      "Iteration 1872: Loss = 0.3008, Accuracy = 0.7970 Test Loss = 0.2986, Test Accuracy = 0.8149\n",
      "Iteration 1873: Loss = 0.3005, Accuracy = 0.7930 Test Loss = 0.2985, Test Accuracy = 0.8152\n",
      "Iteration 1874: Loss = 0.2807, Accuracy = 0.8260 Test Loss = 0.2984, Test Accuracy = 0.8146\n",
      "Iteration 1875: Loss = 0.2851, Accuracy = 0.8150 Test Loss = 0.2983, Test Accuracy = 0.8151\n",
      "Iteration 1876: Loss = 0.2875, Accuracy = 0.8080 Test Loss = 0.2982, Test Accuracy = 0.8161\n",
      "Iteration 1877: Loss = 0.2846, Accuracy = 0.8100 Test Loss = 0.2982, Test Accuracy = 0.8143\n",
      "Iteration 1878: Loss = 0.3336, Accuracy = 0.7850 Test Loss = 0.2982, Test Accuracy = 0.8138\n",
      "Iteration 1879: Loss = 0.2882, Accuracy = 0.8200 Test Loss = 0.2982, Test Accuracy = 0.8152\n",
      "Iteration 1880: Loss = 0.2829, Accuracy = 0.8030 Test Loss = 0.2980, Test Accuracy = 0.8148\n",
      "Iteration 1881: Loss = 0.3072, Accuracy = 0.8050 Test Loss = 0.2980, Test Accuracy = 0.8142\n",
      "Iteration 1882: Loss = 0.2933, Accuracy = 0.8040 Test Loss = 0.2979, Test Accuracy = 0.8149\n",
      "Iteration 1883: Loss = 0.2791, Accuracy = 0.8190 Test Loss = 0.2979, Test Accuracy = 0.8136\n",
      "Iteration 1884: Loss = 0.2896, Accuracy = 0.8320 Test Loss = 0.2978, Test Accuracy = 0.8142\n",
      "Iteration 1885: Loss = 0.3131, Accuracy = 0.7990 Test Loss = 0.2977, Test Accuracy = 0.8143\n",
      "Iteration 1886: Loss = 0.3069, Accuracy = 0.7920 Test Loss = 0.2976, Test Accuracy = 0.8139\n",
      "Iteration 1887: Loss = 0.2858, Accuracy = 0.8140 Test Loss = 0.2977, Test Accuracy = 0.8150\n",
      "Iteration 1888: Loss = 0.3290, Accuracy = 0.8020 Test Loss = 0.2975, Test Accuracy = 0.8145\n",
      "Iteration 1889: Loss = 0.2799, Accuracy = 0.8240 Test Loss = 0.2974, Test Accuracy = 0.8161\n",
      "Iteration 1890: Loss = 0.2961, Accuracy = 0.8080 Test Loss = 0.2974, Test Accuracy = 0.8154\n",
      "Iteration 1891: Loss = 0.2949, Accuracy = 0.8230 Test Loss = 0.2973, Test Accuracy = 0.8135\n",
      "Iteration 1892: Loss = 0.3046, Accuracy = 0.8030 Test Loss = 0.2972, Test Accuracy = 0.8154\n",
      "Iteration 1893: Loss = 0.2815, Accuracy = 0.8250 Test Loss = 0.2971, Test Accuracy = 0.8152\n",
      "Iteration 1894: Loss = 0.2820, Accuracy = 0.8130 Test Loss = 0.2970, Test Accuracy = 0.8156\n",
      "Iteration 1895: Loss = 0.3071, Accuracy = 0.8150 Test Loss = 0.2972, Test Accuracy = 0.8141\n",
      "Iteration 1896: Loss = 0.3096, Accuracy = 0.8080 Test Loss = 0.2970, Test Accuracy = 0.8156\n",
      "Iteration 1897: Loss = 0.2863, Accuracy = 0.7920 Test Loss = 0.2969, Test Accuracy = 0.8141\n",
      "Iteration 1898: Loss = 0.2811, Accuracy = 0.8170 Test Loss = 0.2969, Test Accuracy = 0.8155\n",
      "Iteration 1899: Loss = 0.2923, Accuracy = 0.8120 Test Loss = 0.2967, Test Accuracy = 0.8155\n",
      "Iteration 1900: Loss = 0.2762, Accuracy = 0.8280 Test Loss = 0.2967, Test Accuracy = 0.8154\n",
      "Iteration 1901: Loss = 0.2856, Accuracy = 0.8080 Test Loss = 0.2966, Test Accuracy = 0.8154\n",
      "Iteration 1902: Loss = 0.2876, Accuracy = 0.8310 Test Loss = 0.2965, Test Accuracy = 0.8142\n",
      "Iteration 1903: Loss = 0.2935, Accuracy = 0.8260 Test Loss = 0.2965, Test Accuracy = 0.8175\n",
      "Iteration 1904: Loss = 0.3035, Accuracy = 0.8000 Test Loss = 0.2964, Test Accuracy = 0.8157\n",
      "Iteration 1905: Loss = 0.3081, Accuracy = 0.8020 Test Loss = 0.2963, Test Accuracy = 0.8159\n",
      "Iteration 1906: Loss = 0.3058, Accuracy = 0.7960 Test Loss = 0.2964, Test Accuracy = 0.8149\n",
      "Iteration 1907: Loss = 0.2988, Accuracy = 0.8050 Test Loss = 0.2962, Test Accuracy = 0.8160\n",
      "Iteration 1908: Loss = 0.2902, Accuracy = 0.8030 Test Loss = 0.2962, Test Accuracy = 0.8158\n",
      "Iteration 1909: Loss = 0.2944, Accuracy = 0.8040 Test Loss = 0.2962, Test Accuracy = 0.8165\n",
      "Iteration 1910: Loss = 0.3077, Accuracy = 0.7990 Test Loss = 0.2961, Test Accuracy = 0.8159\n",
      "Iteration 1911: Loss = 0.2924, Accuracy = 0.7940 Test Loss = 0.2961, Test Accuracy = 0.8160\n",
      "Iteration 1912: Loss = 0.2982, Accuracy = 0.8070 Test Loss = 0.2960, Test Accuracy = 0.8154\n",
      "Iteration 1913: Loss = 0.2866, Accuracy = 0.8160 Test Loss = 0.2958, Test Accuracy = 0.8157\n",
      "Iteration 1914: Loss = 0.3141, Accuracy = 0.7990 Test Loss = 0.2958, Test Accuracy = 0.8158\n",
      "Iteration 1915: Loss = 0.2839, Accuracy = 0.8250 Test Loss = 0.2957, Test Accuracy = 0.8162\n",
      "Iteration 1916: Loss = 0.2788, Accuracy = 0.8180 Test Loss = 0.2957, Test Accuracy = 0.8161\n",
      "Iteration 1917: Loss = 0.3078, Accuracy = 0.8150 Test Loss = 0.2956, Test Accuracy = 0.8158\n",
      "Iteration 1918: Loss = 0.2884, Accuracy = 0.8280 Test Loss = 0.2955, Test Accuracy = 0.8161\n",
      "Iteration 1919: Loss = 0.3061, Accuracy = 0.8190 Test Loss = 0.2954, Test Accuracy = 0.8137\n",
      "Iteration 1920: Loss = 0.2887, Accuracy = 0.8210 Test Loss = 0.2954, Test Accuracy = 0.8159\n",
      "Iteration 1921: Loss = 0.3054, Accuracy = 0.7990 Test Loss = 0.2954, Test Accuracy = 0.8157\n",
      "Iteration 1922: Loss = 0.2824, Accuracy = 0.8080 Test Loss = 0.2954, Test Accuracy = 0.8157\n",
      "Iteration 1923: Loss = 0.2972, Accuracy = 0.8140 Test Loss = 0.2952, Test Accuracy = 0.8152\n",
      "Iteration 1924: Loss = 0.2898, Accuracy = 0.7960 Test Loss = 0.2951, Test Accuracy = 0.8160\n",
      "Iteration 1925: Loss = 0.2984, Accuracy = 0.8020 Test Loss = 0.2951, Test Accuracy = 0.8162\n",
      "Iteration 1926: Loss = 0.2979, Accuracy = 0.8010 Test Loss = 0.2951, Test Accuracy = 0.8161\n",
      "Iteration 1927: Loss = 0.2879, Accuracy = 0.7980 Test Loss = 0.2950, Test Accuracy = 0.8149\n",
      "Iteration 1928: Loss = 0.2891, Accuracy = 0.8040 Test Loss = 0.2950, Test Accuracy = 0.8175\n",
      "Iteration 1929: Loss = 0.2921, Accuracy = 0.8380 Test Loss = 0.2948, Test Accuracy = 0.8157\n",
      "Iteration 1930: Loss = 0.2885, Accuracy = 0.8030 Test Loss = 0.2949, Test Accuracy = 0.8182\n",
      "Iteration 1931: Loss = 0.3050, Accuracy = 0.8170 Test Loss = 0.2947, Test Accuracy = 0.8167\n",
      "Iteration 1932: Loss = 0.2995, Accuracy = 0.8280 Test Loss = 0.2946, Test Accuracy = 0.8160\n",
      "Iteration 1933: Loss = 0.2861, Accuracy = 0.8080 Test Loss = 0.2946, Test Accuracy = 0.8161\n",
      "Iteration 1934: Loss = 0.3091, Accuracy = 0.8120 Test Loss = 0.2946, Test Accuracy = 0.8161\n",
      "Iteration 1935: Loss = 0.2867, Accuracy = 0.8240 Test Loss = 0.2945, Test Accuracy = 0.8171\n",
      "Iteration 1936: Loss = 0.2963, Accuracy = 0.8180 Test Loss = 0.2945, Test Accuracy = 0.8143\n",
      "Iteration 1937: Loss = 0.2959, Accuracy = 0.8340 Test Loss = 0.2944, Test Accuracy = 0.8145\n",
      "Iteration 1938: Loss = 0.3400, Accuracy = 0.7900 Test Loss = 0.2943, Test Accuracy = 0.8179\n",
      "Iteration 1939: Loss = 0.2733, Accuracy = 0.8150 Test Loss = 0.2943, Test Accuracy = 0.8178\n",
      "Iteration 1940: Loss = 0.2763, Accuracy = 0.8230 Test Loss = 0.2942, Test Accuracy = 0.8160\n",
      "Iteration 1941: Loss = 0.2665, Accuracy = 0.8260 Test Loss = 0.2941, Test Accuracy = 0.8165\n",
      "Iteration 1942: Loss = 0.2882, Accuracy = 0.8150 Test Loss = 0.2941, Test Accuracy = 0.8167\n",
      "Iteration 1943: Loss = 0.2835, Accuracy = 0.8210 Test Loss = 0.2940, Test Accuracy = 0.8156\n",
      "Iteration 1944: Loss = 0.3116, Accuracy = 0.7920 Test Loss = 0.2939, Test Accuracy = 0.8164\n",
      "Iteration 1945: Loss = 0.3152, Accuracy = 0.8070 Test Loss = 0.2939, Test Accuracy = 0.8160\n",
      "Iteration 1946: Loss = 0.2968, Accuracy = 0.8150 Test Loss = 0.2939, Test Accuracy = 0.8154\n",
      "Iteration 1947: Loss = 0.3136, Accuracy = 0.8290 Test Loss = 0.2938, Test Accuracy = 0.8178\n",
      "Iteration 1948: Loss = 0.2992, Accuracy = 0.8090 Test Loss = 0.2936, Test Accuracy = 0.8174\n",
      "Iteration 1949: Loss = 0.3004, Accuracy = 0.8040 Test Loss = 0.2937, Test Accuracy = 0.8157\n",
      "Iteration 1950: Loss = 0.2966, Accuracy = 0.8170 Test Loss = 0.2936, Test Accuracy = 0.8159\n",
      "Iteration 1951: Loss = 0.3022, Accuracy = 0.8040 Test Loss = 0.2935, Test Accuracy = 0.8163\n",
      "Iteration 1952: Loss = 0.3034, Accuracy = 0.8140 Test Loss = 0.2935, Test Accuracy = 0.8177\n",
      "Iteration 1953: Loss = 0.3351, Accuracy = 0.8010 Test Loss = 0.2934, Test Accuracy = 0.8157\n",
      "Iteration 1954: Loss = 0.3095, Accuracy = 0.7830 Test Loss = 0.2935, Test Accuracy = 0.8154\n",
      "Iteration 1955: Loss = 0.3037, Accuracy = 0.7980 Test Loss = 0.2933, Test Accuracy = 0.8168\n",
      "Iteration 1956: Loss = 0.3218, Accuracy = 0.8070 Test Loss = 0.2932, Test Accuracy = 0.8169\n",
      "Iteration 1957: Loss = 0.2850, Accuracy = 0.8090 Test Loss = 0.2931, Test Accuracy = 0.8174\n",
      "Iteration 1958: Loss = 0.2656, Accuracy = 0.8330 Test Loss = 0.2931, Test Accuracy = 0.8150\n",
      "Iteration 1959: Loss = 0.2765, Accuracy = 0.8080 Test Loss = 0.2931, Test Accuracy = 0.8163\n",
      "Iteration 1960: Loss = 0.2939, Accuracy = 0.7950 Test Loss = 0.2930, Test Accuracy = 0.8177\n",
      "Iteration 1961: Loss = 0.3196, Accuracy = 0.7980 Test Loss = 0.2928, Test Accuracy = 0.8163\n",
      "Iteration 1962: Loss = 0.3076, Accuracy = 0.8010 Test Loss = 0.2929, Test Accuracy = 0.8161\n",
      "Iteration 1963: Loss = 0.3024, Accuracy = 0.8190 Test Loss = 0.2928, Test Accuracy = 0.8161\n",
      "Iteration 1964: Loss = 0.2896, Accuracy = 0.8180 Test Loss = 0.2928, Test Accuracy = 0.8167\n",
      "Iteration 1965: Loss = 0.2814, Accuracy = 0.8170 Test Loss = 0.2927, Test Accuracy = 0.8175\n",
      "Iteration 1966: Loss = 0.2748, Accuracy = 0.8280 Test Loss = 0.2927, Test Accuracy = 0.8162\n",
      "Iteration 1967: Loss = 0.2993, Accuracy = 0.8160 Test Loss = 0.2926, Test Accuracy = 0.8157\n",
      "Iteration 1968: Loss = 0.3026, Accuracy = 0.8110 Test Loss = 0.2925, Test Accuracy = 0.8161\n",
      "Iteration 1969: Loss = 0.2800, Accuracy = 0.8160 Test Loss = 0.2924, Test Accuracy = 0.8167\n",
      "Iteration 1970: Loss = 0.3051, Accuracy = 0.7980 Test Loss = 0.2924, Test Accuracy = 0.8173\n",
      "Iteration 1971: Loss = 0.2991, Accuracy = 0.8080 Test Loss = 0.2923, Test Accuracy = 0.8180\n",
      "Iteration 1972: Loss = 0.2905, Accuracy = 0.7960 Test Loss = 0.2923, Test Accuracy = 0.8167\n",
      "Iteration 1973: Loss = 0.2872, Accuracy = 0.8260 Test Loss = 0.2923, Test Accuracy = 0.8161\n",
      "Iteration 1974: Loss = 0.3053, Accuracy = 0.8150 Test Loss = 0.2921, Test Accuracy = 0.8165\n",
      "Iteration 1975: Loss = 0.3011, Accuracy = 0.8110 Test Loss = 0.2921, Test Accuracy = 0.8178\n",
      "Iteration 1976: Loss = 0.3233, Accuracy = 0.8090 Test Loss = 0.2921, Test Accuracy = 0.8176\n",
      "Iteration 1977: Loss = 0.2880, Accuracy = 0.8060 Test Loss = 0.2920, Test Accuracy = 0.8161\n",
      "Iteration 1978: Loss = 0.2608, Accuracy = 0.8240 Test Loss = 0.2919, Test Accuracy = 0.8168\n",
      "Iteration 1979: Loss = 0.2860, Accuracy = 0.8370 Test Loss = 0.2919, Test Accuracy = 0.8167\n",
      "Iteration 1980: Loss = 0.2977, Accuracy = 0.8040 Test Loss = 0.2918, Test Accuracy = 0.8189\n",
      "Iteration 1981: Loss = 0.3002, Accuracy = 0.8230 Test Loss = 0.2917, Test Accuracy = 0.8165\n",
      "Iteration 1982: Loss = 0.3139, Accuracy = 0.7940 Test Loss = 0.2917, Test Accuracy = 0.8165\n",
      "Iteration 1983: Loss = 0.2918, Accuracy = 0.8060 Test Loss = 0.2916, Test Accuracy = 0.8162\n",
      "Iteration 1984: Loss = 0.2704, Accuracy = 0.8320 Test Loss = 0.2915, Test Accuracy = 0.8181\n",
      "Iteration 1985: Loss = 0.2739, Accuracy = 0.8050 Test Loss = 0.2915, Test Accuracy = 0.8183\n",
      "Iteration 1986: Loss = 0.3137, Accuracy = 0.8300 Test Loss = 0.2915, Test Accuracy = 0.8166\n",
      "Iteration 1987: Loss = 0.2944, Accuracy = 0.8040 Test Loss = 0.2914, Test Accuracy = 0.8159\n",
      "Iteration 1988: Loss = 0.3226, Accuracy = 0.8020 Test Loss = 0.2914, Test Accuracy = 0.8154\n",
      "Iteration 1989: Loss = 0.3001, Accuracy = 0.8130 Test Loss = 0.2914, Test Accuracy = 0.8185\n",
      "Iteration 1990: Loss = 0.2816, Accuracy = 0.8200 Test Loss = 0.2912, Test Accuracy = 0.8175\n",
      "Iteration 1991: Loss = 0.3078, Accuracy = 0.8060 Test Loss = 0.2912, Test Accuracy = 0.8175\n",
      "Iteration 1992: Loss = 0.2820, Accuracy = 0.8150 Test Loss = 0.2911, Test Accuracy = 0.8177\n",
      "Iteration 1993: Loss = 0.3194, Accuracy = 0.7870 Test Loss = 0.2911, Test Accuracy = 0.8175\n",
      "Iteration 1994: Loss = 0.2852, Accuracy = 0.8090 Test Loss = 0.2909, Test Accuracy = 0.8179\n",
      "Iteration 1995: Loss = 0.3056, Accuracy = 0.7930 Test Loss = 0.2910, Test Accuracy = 0.8170\n",
      "Iteration 1996: Loss = 0.2901, Accuracy = 0.8020 Test Loss = 0.2909, Test Accuracy = 0.8178\n",
      "Iteration 1997: Loss = 0.2832, Accuracy = 0.7990 Test Loss = 0.2908, Test Accuracy = 0.8173\n",
      "Iteration 1998: Loss = 0.2754, Accuracy = 0.8330 Test Loss = 0.2908, Test Accuracy = 0.8179\n",
      "Iteration 1999: Loss = 0.2939, Accuracy = 0.8050 Test Loss = 0.2907, Test Accuracy = 0.8185\n",
      "Iteration 2000: Loss = 0.2973, Accuracy = 0.8140 Test Loss = 0.2906, Test Accuracy = 0.8177\n",
      "Iteration 2001: Loss = 0.2762, Accuracy = 0.8240 Test Loss = 0.2905, Test Accuracy = 0.8173\n",
      "Iteration 2002: Loss = 0.3059, Accuracy = 0.8140 Test Loss = 0.2906, Test Accuracy = 0.8184\n",
      "Iteration 2003: Loss = 0.2839, Accuracy = 0.8180 Test Loss = 0.2905, Test Accuracy = 0.8183\n",
      "Iteration 2004: Loss = 0.2869, Accuracy = 0.8030 Test Loss = 0.2904, Test Accuracy = 0.8160\n",
      "Iteration 2005: Loss = 0.2686, Accuracy = 0.8030 Test Loss = 0.2904, Test Accuracy = 0.8177\n",
      "Iteration 2006: Loss = 0.3050, Accuracy = 0.7940 Test Loss = 0.2903, Test Accuracy = 0.8171\n",
      "Iteration 2007: Loss = 0.3009, Accuracy = 0.8110 Test Loss = 0.2903, Test Accuracy = 0.8183\n",
      "Iteration 2008: Loss = 0.2691, Accuracy = 0.8360 Test Loss = 0.2903, Test Accuracy = 0.8175\n",
      "Iteration 2009: Loss = 0.2807, Accuracy = 0.8080 Test Loss = 0.2902, Test Accuracy = 0.8180\n",
      "Iteration 2010: Loss = 0.2709, Accuracy = 0.8060 Test Loss = 0.2900, Test Accuracy = 0.8183\n",
      "Iteration 2011: Loss = 0.2903, Accuracy = 0.8210 Test Loss = 0.2901, Test Accuracy = 0.8171\n",
      "Iteration 2012: Loss = 0.2777, Accuracy = 0.8320 Test Loss = 0.2899, Test Accuracy = 0.8182\n",
      "Iteration 2013: Loss = 0.2813, Accuracy = 0.8140 Test Loss = 0.2899, Test Accuracy = 0.8171\n",
      "Iteration 2014: Loss = 0.2832, Accuracy = 0.7900 Test Loss = 0.2900, Test Accuracy = 0.8183\n",
      "Iteration 2015: Loss = 0.2892, Accuracy = 0.8120 Test Loss = 0.2898, Test Accuracy = 0.8184\n",
      "Iteration 2016: Loss = 0.2826, Accuracy = 0.8070 Test Loss = 0.2898, Test Accuracy = 0.8182\n",
      "Iteration 2017: Loss = 0.2716, Accuracy = 0.8290 Test Loss = 0.2897, Test Accuracy = 0.8170\n",
      "Iteration 2018: Loss = 0.2888, Accuracy = 0.8040 Test Loss = 0.2896, Test Accuracy = 0.8189\n",
      "Iteration 2019: Loss = 0.2907, Accuracy = 0.8210 Test Loss = 0.2896, Test Accuracy = 0.8188\n",
      "Iteration 2020: Loss = 0.2766, Accuracy = 0.8300 Test Loss = 0.2895, Test Accuracy = 0.8182\n",
      "Iteration 2021: Loss = 0.2830, Accuracy = 0.8080 Test Loss = 0.2895, Test Accuracy = 0.8163\n",
      "Iteration 2022: Loss = 0.3110, Accuracy = 0.8120 Test Loss = 0.2893, Test Accuracy = 0.8179\n",
      "Iteration 2023: Loss = 0.2638, Accuracy = 0.8390 Test Loss = 0.2894, Test Accuracy = 0.8191\n",
      "Iteration 2024: Loss = 0.2702, Accuracy = 0.8140 Test Loss = 0.2893, Test Accuracy = 0.8190\n",
      "Iteration 2025: Loss = 0.2767, Accuracy = 0.8100 Test Loss = 0.2894, Test Accuracy = 0.8179\n",
      "Iteration 2026: Loss = 0.3063, Accuracy = 0.8130 Test Loss = 0.2892, Test Accuracy = 0.8182\n",
      "Iteration 2027: Loss = 0.2696, Accuracy = 0.8520 Test Loss = 0.2891, Test Accuracy = 0.8198\n",
      "Iteration 2028: Loss = 0.2918, Accuracy = 0.8080 Test Loss = 0.2891, Test Accuracy = 0.8183\n",
      "Iteration 2029: Loss = 0.2744, Accuracy = 0.8330 Test Loss = 0.2890, Test Accuracy = 0.8191\n",
      "Iteration 2030: Loss = 0.2889, Accuracy = 0.8030 Test Loss = 0.2890, Test Accuracy = 0.8188\n",
      "Iteration 2031: Loss = 0.2921, Accuracy = 0.8110 Test Loss = 0.2890, Test Accuracy = 0.8182\n",
      "Iteration 2032: Loss = 0.2940, Accuracy = 0.8170 Test Loss = 0.2889, Test Accuracy = 0.8175\n",
      "Iteration 2033: Loss = 0.2888, Accuracy = 0.7960 Test Loss = 0.2889, Test Accuracy = 0.8186\n",
      "Iteration 2034: Loss = 0.2893, Accuracy = 0.7980 Test Loss = 0.2887, Test Accuracy = 0.8191\n",
      "Iteration 2035: Loss = 0.2867, Accuracy = 0.8340 Test Loss = 0.2888, Test Accuracy = 0.8185\n",
      "Iteration 2036: Loss = 0.2665, Accuracy = 0.8340 Test Loss = 0.2888, Test Accuracy = 0.8167\n",
      "Iteration 2037: Loss = 0.2720, Accuracy = 0.8310 Test Loss = 0.2886, Test Accuracy = 0.8190\n",
      "Iteration 2038: Loss = 0.2829, Accuracy = 0.8170 Test Loss = 0.2884, Test Accuracy = 0.8182\n",
      "Iteration 2039: Loss = 0.2905, Accuracy = 0.8230 Test Loss = 0.2885, Test Accuracy = 0.8184\n",
      "Iteration 2040: Loss = 0.2787, Accuracy = 0.8090 Test Loss = 0.2883, Test Accuracy = 0.8192\n",
      "Iteration 2041: Loss = 0.2946, Accuracy = 0.7990 Test Loss = 0.2884, Test Accuracy = 0.8184\n",
      "Iteration 2042: Loss = 0.2981, Accuracy = 0.8140 Test Loss = 0.2883, Test Accuracy = 0.8186\n",
      "Iteration 2043: Loss = 0.2952, Accuracy = 0.8120 Test Loss = 0.2884, Test Accuracy = 0.8185\n",
      "Iteration 2044: Loss = 0.2684, Accuracy = 0.8280 Test Loss = 0.2883, Test Accuracy = 0.8190\n",
      "Iteration 2045: Loss = 0.2805, Accuracy = 0.8180 Test Loss = 0.2881, Test Accuracy = 0.8191\n",
      "Iteration 2046: Loss = 0.2965, Accuracy = 0.8240 Test Loss = 0.2881, Test Accuracy = 0.8201\n",
      "Iteration 2047: Loss = 0.2950, Accuracy = 0.8000 Test Loss = 0.2881, Test Accuracy = 0.8188\n",
      "Iteration 2048: Loss = 0.2964, Accuracy = 0.8230 Test Loss = 0.2880, Test Accuracy = 0.8179\n",
      "Iteration 2049: Loss = 0.2887, Accuracy = 0.7990 Test Loss = 0.2879, Test Accuracy = 0.8202\n",
      "Iteration 2050: Loss = 0.2990, Accuracy = 0.8000 Test Loss = 0.2878, Test Accuracy = 0.8203\n",
      "Iteration 2051: Loss = 0.2909, Accuracy = 0.8280 Test Loss = 0.2877, Test Accuracy = 0.8188\n",
      "Iteration 2052: Loss = 0.2958, Accuracy = 0.8280 Test Loss = 0.2878, Test Accuracy = 0.8191\n",
      "Iteration 2053: Loss = 0.2877, Accuracy = 0.8040 Test Loss = 0.2877, Test Accuracy = 0.8198\n",
      "Iteration 2054: Loss = 0.3073, Accuracy = 0.8040 Test Loss = 0.2876, Test Accuracy = 0.8189\n",
      "Iteration 2055: Loss = 0.2856, Accuracy = 0.8160 Test Loss = 0.2877, Test Accuracy = 0.8202\n",
      "Iteration 2056: Loss = 0.2764, Accuracy = 0.8100 Test Loss = 0.2876, Test Accuracy = 0.8200\n",
      "Iteration 2057: Loss = 0.2791, Accuracy = 0.7990 Test Loss = 0.2876, Test Accuracy = 0.8191\n",
      "Iteration 2058: Loss = 0.2895, Accuracy = 0.8120 Test Loss = 0.2874, Test Accuracy = 0.8199\n",
      "Iteration 2059: Loss = 0.2894, Accuracy = 0.8070 Test Loss = 0.2874, Test Accuracy = 0.8203\n",
      "Iteration 2060: Loss = 0.2723, Accuracy = 0.8070 Test Loss = 0.2873, Test Accuracy = 0.8199\n",
      "Iteration 2061: Loss = 0.2991, Accuracy = 0.8040 Test Loss = 0.2874, Test Accuracy = 0.8187\n",
      "Iteration 2062: Loss = 0.2951, Accuracy = 0.8270 Test Loss = 0.2872, Test Accuracy = 0.8193\n",
      "Iteration 2063: Loss = 0.2835, Accuracy = 0.8140 Test Loss = 0.2871, Test Accuracy = 0.8213\n",
      "Iteration 2064: Loss = 0.3141, Accuracy = 0.7890 Test Loss = 0.2873, Test Accuracy = 0.8185\n",
      "Iteration 2065: Loss = 0.2895, Accuracy = 0.8370 Test Loss = 0.2871, Test Accuracy = 0.8199\n",
      "Iteration 2066: Loss = 0.2816, Accuracy = 0.8120 Test Loss = 0.2871, Test Accuracy = 0.8206\n",
      "Iteration 2067: Loss = 0.2847, Accuracy = 0.8040 Test Loss = 0.2869, Test Accuracy = 0.8201\n",
      "Iteration 2068: Loss = 0.2758, Accuracy = 0.8140 Test Loss = 0.2869, Test Accuracy = 0.8203\n",
      "Iteration 2069: Loss = 0.3075, Accuracy = 0.8060 Test Loss = 0.2868, Test Accuracy = 0.8188\n",
      "Iteration 2070: Loss = 0.3060, Accuracy = 0.8100 Test Loss = 0.2867, Test Accuracy = 0.8205\n",
      "Iteration 2071: Loss = 0.2872, Accuracy = 0.8290 Test Loss = 0.2867, Test Accuracy = 0.8190\n",
      "Iteration 2072: Loss = 0.2971, Accuracy = 0.8220 Test Loss = 0.2867, Test Accuracy = 0.8194\n",
      "Iteration 2073: Loss = 0.2831, Accuracy = 0.8040 Test Loss = 0.2866, Test Accuracy = 0.8199\n",
      "Iteration 2074: Loss = 0.2885, Accuracy = 0.8110 Test Loss = 0.2866, Test Accuracy = 0.8196\n",
      "Iteration 2075: Loss = 0.2885, Accuracy = 0.8120 Test Loss = 0.2865, Test Accuracy = 0.8210\n",
      "Iteration 2076: Loss = 0.2655, Accuracy = 0.8320 Test Loss = 0.2865, Test Accuracy = 0.8200\n",
      "Iteration 2077: Loss = 0.2862, Accuracy = 0.8070 Test Loss = 0.2865, Test Accuracy = 0.8197\n",
      "Iteration 2078: Loss = 0.2989, Accuracy = 0.8130 Test Loss = 0.2864, Test Accuracy = 0.8207\n",
      "Iteration 2079: Loss = 0.2866, Accuracy = 0.8260 Test Loss = 0.2864, Test Accuracy = 0.8205\n",
      "Iteration 2080: Loss = 0.2661, Accuracy = 0.8230 Test Loss = 0.2864, Test Accuracy = 0.8193\n",
      "Iteration 2081: Loss = 0.2768, Accuracy = 0.8170 Test Loss = 0.2862, Test Accuracy = 0.8200\n",
      "Iteration 2082: Loss = 0.2754, Accuracy = 0.8020 Test Loss = 0.2862, Test Accuracy = 0.8195\n",
      "Iteration 2083: Loss = 0.2689, Accuracy = 0.8120 Test Loss = 0.2862, Test Accuracy = 0.8194\n",
      "Iteration 2084: Loss = 0.2780, Accuracy = 0.7990 Test Loss = 0.2861, Test Accuracy = 0.8208\n",
      "Iteration 2085: Loss = 0.2977, Accuracy = 0.7910 Test Loss = 0.2860, Test Accuracy = 0.8206\n",
      "Iteration 2086: Loss = 0.2830, Accuracy = 0.8190 Test Loss = 0.2859, Test Accuracy = 0.8208\n",
      "Iteration 2087: Loss = 0.2795, Accuracy = 0.8060 Test Loss = 0.2859, Test Accuracy = 0.8212\n",
      "Iteration 2088: Loss = 0.3008, Accuracy = 0.8060 Test Loss = 0.2859, Test Accuracy = 0.8200\n",
      "Iteration 2089: Loss = 0.2853, Accuracy = 0.8040 Test Loss = 0.2859, Test Accuracy = 0.8202\n",
      "Iteration 2090: Loss = 0.2934, Accuracy = 0.8060 Test Loss = 0.2858, Test Accuracy = 0.8209\n",
      "Iteration 2091: Loss = 0.2774, Accuracy = 0.8090 Test Loss = 0.2856, Test Accuracy = 0.8209\n",
      "Iteration 2092: Loss = 0.2820, Accuracy = 0.8270 Test Loss = 0.2857, Test Accuracy = 0.8201\n",
      "Iteration 2093: Loss = 0.2799, Accuracy = 0.8050 Test Loss = 0.2856, Test Accuracy = 0.8201\n",
      "Iteration 2094: Loss = 0.2825, Accuracy = 0.8010 Test Loss = 0.2855, Test Accuracy = 0.8209\n",
      "Iteration 2095: Loss = 0.2581, Accuracy = 0.8230 Test Loss = 0.2855, Test Accuracy = 0.8202\n",
      "Iteration 2096: Loss = 0.2892, Accuracy = 0.8050 Test Loss = 0.2855, Test Accuracy = 0.8204\n",
      "Iteration 2097: Loss = 0.2687, Accuracy = 0.8230 Test Loss = 0.2854, Test Accuracy = 0.8191\n",
      "Iteration 2098: Loss = 0.2741, Accuracy = 0.8210 Test Loss = 0.2853, Test Accuracy = 0.8211\n",
      "Iteration 2099: Loss = 0.2654, Accuracy = 0.8220 Test Loss = 0.2853, Test Accuracy = 0.8208\n",
      "Iteration 2100: Loss = 0.2839, Accuracy = 0.8240 Test Loss = 0.2853, Test Accuracy = 0.8192\n",
      "Iteration 2101: Loss = 0.2791, Accuracy = 0.8270 Test Loss = 0.2852, Test Accuracy = 0.8209\n",
      "Iteration 2102: Loss = 0.2845, Accuracy = 0.8070 Test Loss = 0.2851, Test Accuracy = 0.8212\n",
      "Iteration 2103: Loss = 0.2958, Accuracy = 0.8060 Test Loss = 0.2850, Test Accuracy = 0.8207\n",
      "Iteration 2104: Loss = 0.2647, Accuracy = 0.8280 Test Loss = 0.2850, Test Accuracy = 0.8209\n",
      "Iteration 2105: Loss = 0.2853, Accuracy = 0.8200 Test Loss = 0.2850, Test Accuracy = 0.8219\n",
      "Iteration 2106: Loss = 0.2759, Accuracy = 0.8280 Test Loss = 0.2849, Test Accuracy = 0.8214\n",
      "Iteration 2107: Loss = 0.2797, Accuracy = 0.8100 Test Loss = 0.2848, Test Accuracy = 0.8209\n",
      "Iteration 2108: Loss = 0.2821, Accuracy = 0.7990 Test Loss = 0.2849, Test Accuracy = 0.8217\n",
      "Iteration 2109: Loss = 0.2941, Accuracy = 0.8140 Test Loss = 0.2848, Test Accuracy = 0.8215\n",
      "Iteration 2110: Loss = 0.2743, Accuracy = 0.8020 Test Loss = 0.2847, Test Accuracy = 0.8225\n",
      "Iteration 2111: Loss = 0.3144, Accuracy = 0.7850 Test Loss = 0.2846, Test Accuracy = 0.8220\n",
      "Iteration 2112: Loss = 0.2731, Accuracy = 0.8270 Test Loss = 0.2846, Test Accuracy = 0.8214\n",
      "Iteration 2113: Loss = 0.3143, Accuracy = 0.7990 Test Loss = 0.2847, Test Accuracy = 0.8212\n",
      "Iteration 2114: Loss = 0.2723, Accuracy = 0.8150 Test Loss = 0.2845, Test Accuracy = 0.8218\n",
      "Iteration 2115: Loss = 0.2753, Accuracy = 0.8010 Test Loss = 0.2846, Test Accuracy = 0.8212\n",
      "Iteration 2116: Loss = 0.2827, Accuracy = 0.8250 Test Loss = 0.2844, Test Accuracy = 0.8216\n",
      "Iteration 2117: Loss = 0.2900, Accuracy = 0.8360 Test Loss = 0.2844, Test Accuracy = 0.8210\n",
      "Iteration 2118: Loss = 0.2689, Accuracy = 0.8220 Test Loss = 0.2843, Test Accuracy = 0.8199\n",
      "Iteration 2119: Loss = 0.2952, Accuracy = 0.8050 Test Loss = 0.2843, Test Accuracy = 0.8210\n",
      "Iteration 2120: Loss = 0.2924, Accuracy = 0.8090 Test Loss = 0.2843, Test Accuracy = 0.8205\n",
      "Iteration 2121: Loss = 0.2990, Accuracy = 0.8160 Test Loss = 0.2842, Test Accuracy = 0.8225\n",
      "Iteration 2122: Loss = 0.2760, Accuracy = 0.8110 Test Loss = 0.2841, Test Accuracy = 0.8227\n",
      "Iteration 2123: Loss = 0.2747, Accuracy = 0.8280 Test Loss = 0.2840, Test Accuracy = 0.8214\n",
      "Iteration 2124: Loss = 0.2866, Accuracy = 0.8110 Test Loss = 0.2840, Test Accuracy = 0.8216\n",
      "Iteration 2125: Loss = 0.2626, Accuracy = 0.8230 Test Loss = 0.2840, Test Accuracy = 0.8219\n",
      "Iteration 2126: Loss = 0.2671, Accuracy = 0.8220 Test Loss = 0.2839, Test Accuracy = 0.8212\n",
      "Iteration 2127: Loss = 0.2959, Accuracy = 0.8160 Test Loss = 0.2839, Test Accuracy = 0.8198\n",
      "Iteration 2128: Loss = 0.2666, Accuracy = 0.8440 Test Loss = 0.2839, Test Accuracy = 0.8206\n",
      "Iteration 2129: Loss = 0.2598, Accuracy = 0.8200 Test Loss = 0.2837, Test Accuracy = 0.8226\n",
      "Iteration 2130: Loss = 0.2796, Accuracy = 0.8110 Test Loss = 0.2839, Test Accuracy = 0.8211\n",
      "Iteration 2131: Loss = 0.2742, Accuracy = 0.7940 Test Loss = 0.2837, Test Accuracy = 0.8215\n",
      "Iteration 2132: Loss = 0.2790, Accuracy = 0.8160 Test Loss = 0.2837, Test Accuracy = 0.8230\n",
      "Iteration 2133: Loss = 0.3022, Accuracy = 0.8000 Test Loss = 0.2836, Test Accuracy = 0.8230\n",
      "Iteration 2134: Loss = 0.3057, Accuracy = 0.7900 Test Loss = 0.2836, Test Accuracy = 0.8226\n",
      "Iteration 2135: Loss = 0.2653, Accuracy = 0.8240 Test Loss = 0.2835, Test Accuracy = 0.8211\n",
      "Iteration 2136: Loss = 0.2843, Accuracy = 0.8200 Test Loss = 0.2834, Test Accuracy = 0.8227\n",
      "Iteration 2137: Loss = 0.2832, Accuracy = 0.8370 Test Loss = 0.2834, Test Accuracy = 0.8208\n",
      "Iteration 2138: Loss = 0.2840, Accuracy = 0.8180 Test Loss = 0.2833, Test Accuracy = 0.8214\n",
      "Iteration 2139: Loss = 0.2669, Accuracy = 0.8490 Test Loss = 0.2833, Test Accuracy = 0.8220\n",
      "Iteration 2140: Loss = 0.3169, Accuracy = 0.8190 Test Loss = 0.2833, Test Accuracy = 0.8204\n",
      "Iteration 2141: Loss = 0.2625, Accuracy = 0.8330 Test Loss = 0.2831, Test Accuracy = 0.8207\n",
      "Iteration 2142: Loss = 0.2718, Accuracy = 0.8340 Test Loss = 0.2831, Test Accuracy = 0.8217\n",
      "Iteration 2143: Loss = 0.2689, Accuracy = 0.8320 Test Loss = 0.2831, Test Accuracy = 0.8219\n",
      "Iteration 2144: Loss = 0.2904, Accuracy = 0.8100 Test Loss = 0.2831, Test Accuracy = 0.8213\n",
      "Iteration 2145: Loss = 0.2897, Accuracy = 0.8140 Test Loss = 0.2831, Test Accuracy = 0.8208\n",
      "Iteration 2146: Loss = 0.2855, Accuracy = 0.8050 Test Loss = 0.2830, Test Accuracy = 0.8220\n",
      "Iteration 2147: Loss = 0.2872, Accuracy = 0.8150 Test Loss = 0.2829, Test Accuracy = 0.8223\n",
      "Iteration 2148: Loss = 0.3051, Accuracy = 0.8110 Test Loss = 0.2828, Test Accuracy = 0.8217\n",
      "Iteration 2149: Loss = 0.2690, Accuracy = 0.8270 Test Loss = 0.2828, Test Accuracy = 0.8225\n",
      "Iteration 2150: Loss = 0.2805, Accuracy = 0.8270 Test Loss = 0.2828, Test Accuracy = 0.8217\n",
      "Iteration 2151: Loss = 0.2934, Accuracy = 0.8180 Test Loss = 0.2827, Test Accuracy = 0.8221\n",
      "Iteration 2152: Loss = 0.3097, Accuracy = 0.8050 Test Loss = 0.2827, Test Accuracy = 0.8233\n",
      "Iteration 2153: Loss = 0.2875, Accuracy = 0.8130 Test Loss = 0.2826, Test Accuracy = 0.8208\n",
      "Iteration 2154: Loss = 0.2730, Accuracy = 0.8180 Test Loss = 0.2825, Test Accuracy = 0.8223\n",
      "Iteration 2155: Loss = 0.2687, Accuracy = 0.8230 Test Loss = 0.2824, Test Accuracy = 0.8233\n",
      "Iteration 2156: Loss = 0.2847, Accuracy = 0.7860 Test Loss = 0.2824, Test Accuracy = 0.8211\n",
      "Iteration 2157: Loss = 0.3074, Accuracy = 0.8030 Test Loss = 0.2825, Test Accuracy = 0.8224\n",
      "Iteration 2158: Loss = 0.2885, Accuracy = 0.8170 Test Loss = 0.2824, Test Accuracy = 0.8227\n",
      "Iteration 2159: Loss = 0.2765, Accuracy = 0.8240 Test Loss = 0.2823, Test Accuracy = 0.8230\n",
      "Iteration 2160: Loss = 0.2796, Accuracy = 0.8170 Test Loss = 0.2823, Test Accuracy = 0.8224\n",
      "Iteration 2161: Loss = 0.2574, Accuracy = 0.8170 Test Loss = 0.2822, Test Accuracy = 0.8233\n",
      "Iteration 2162: Loss = 0.2848, Accuracy = 0.8080 Test Loss = 0.2821, Test Accuracy = 0.8222\n",
      "Iteration 2163: Loss = 0.2863, Accuracy = 0.8080 Test Loss = 0.2822, Test Accuracy = 0.8214\n",
      "Iteration 2164: Loss = 0.2825, Accuracy = 0.8260 Test Loss = 0.2821, Test Accuracy = 0.8230\n",
      "Iteration 2165: Loss = 0.2972, Accuracy = 0.7890 Test Loss = 0.2820, Test Accuracy = 0.8227\n",
      "Iteration 2166: Loss = 0.2898, Accuracy = 0.8190 Test Loss = 0.2819, Test Accuracy = 0.8215\n",
      "Iteration 2167: Loss = 0.2779, Accuracy = 0.8120 Test Loss = 0.2819, Test Accuracy = 0.8225\n",
      "Iteration 2168: Loss = 0.2845, Accuracy = 0.8060 Test Loss = 0.2819, Test Accuracy = 0.8225\n",
      "Iteration 2169: Loss = 0.2938, Accuracy = 0.7960 Test Loss = 0.2818, Test Accuracy = 0.8227\n",
      "Iteration 2170: Loss = 0.3032, Accuracy = 0.8000 Test Loss = 0.2818, Test Accuracy = 0.8234\n",
      "Iteration 2171: Loss = 0.2537, Accuracy = 0.8340 Test Loss = 0.2817, Test Accuracy = 0.8232\n",
      "Iteration 2172: Loss = 0.2810, Accuracy = 0.8110 Test Loss = 0.2816, Test Accuracy = 0.8239\n",
      "Iteration 2173: Loss = 0.2749, Accuracy = 0.8100 Test Loss = 0.2816, Test Accuracy = 0.8227\n",
      "Iteration 2174: Loss = 0.2960, Accuracy = 0.8180 Test Loss = 0.2815, Test Accuracy = 0.8237\n",
      "Iteration 2175: Loss = 0.3027, Accuracy = 0.8120 Test Loss = 0.2816, Test Accuracy = 0.8232\n",
      "Iteration 2176: Loss = 0.2699, Accuracy = 0.8220 Test Loss = 0.2815, Test Accuracy = 0.8234\n",
      "Iteration 2177: Loss = 0.2731, Accuracy = 0.8310 Test Loss = 0.2815, Test Accuracy = 0.8234\n",
      "Iteration 2178: Loss = 0.2869, Accuracy = 0.8010 Test Loss = 0.2814, Test Accuracy = 0.8223\n",
      "Iteration 2179: Loss = 0.2737, Accuracy = 0.8190 Test Loss = 0.2813, Test Accuracy = 0.8239\n",
      "Iteration 2180: Loss = 0.2712, Accuracy = 0.8240 Test Loss = 0.2813, Test Accuracy = 0.8239\n",
      "Iteration 2181: Loss = 0.2636, Accuracy = 0.8030 Test Loss = 0.2812, Test Accuracy = 0.8218\n",
      "Iteration 2182: Loss = 0.2798, Accuracy = 0.8130 Test Loss = 0.2812, Test Accuracy = 0.8219\n",
      "Iteration 2183: Loss = 0.2456, Accuracy = 0.8210 Test Loss = 0.2812, Test Accuracy = 0.8243\n",
      "Iteration 2184: Loss = 0.2728, Accuracy = 0.8340 Test Loss = 0.2811, Test Accuracy = 0.8230\n",
      "Iteration 2185: Loss = 0.2696, Accuracy = 0.8150 Test Loss = 0.2810, Test Accuracy = 0.8234\n",
      "Iteration 2186: Loss = 0.2752, Accuracy = 0.8260 Test Loss = 0.2811, Test Accuracy = 0.8222\n",
      "Iteration 2187: Loss = 0.2600, Accuracy = 0.8170 Test Loss = 0.2811, Test Accuracy = 0.8228\n",
      "Iteration 2188: Loss = 0.2735, Accuracy = 0.8340 Test Loss = 0.2809, Test Accuracy = 0.8245\n",
      "Iteration 2189: Loss = 0.2879, Accuracy = 0.8230 Test Loss = 0.2809, Test Accuracy = 0.8220\n",
      "Iteration 2190: Loss = 0.2803, Accuracy = 0.8110 Test Loss = 0.2808, Test Accuracy = 0.8239\n",
      "Iteration 2191: Loss = 0.2938, Accuracy = 0.8140 Test Loss = 0.2807, Test Accuracy = 0.8227\n",
      "Iteration 2192: Loss = 0.2883, Accuracy = 0.8150 Test Loss = 0.2807, Test Accuracy = 0.8232\n",
      "Iteration 2193: Loss = 0.2753, Accuracy = 0.8350 Test Loss = 0.2806, Test Accuracy = 0.8229\n",
      "Iteration 2194: Loss = 0.2972, Accuracy = 0.8170 Test Loss = 0.2808, Test Accuracy = 0.8203\n",
      "Iteration 2195: Loss = 0.2623, Accuracy = 0.8260 Test Loss = 0.2805, Test Accuracy = 0.8243\n",
      "Iteration 2196: Loss = 0.2726, Accuracy = 0.8200 Test Loss = 0.2805, Test Accuracy = 0.8241\n",
      "Iteration 2197: Loss = 0.2882, Accuracy = 0.8060 Test Loss = 0.2804, Test Accuracy = 0.8242\n",
      "Iteration 2198: Loss = 0.2833, Accuracy = 0.8200 Test Loss = 0.2805, Test Accuracy = 0.8229\n",
      "Iteration 2199: Loss = 0.2805, Accuracy = 0.8140 Test Loss = 0.2804, Test Accuracy = 0.8226\n",
      "Iteration 2200: Loss = 0.2679, Accuracy = 0.8060 Test Loss = 0.2803, Test Accuracy = 0.8233\n",
      "Iteration 2201: Loss = 0.2758, Accuracy = 0.8260 Test Loss = 0.2803, Test Accuracy = 0.8231\n",
      "Iteration 2202: Loss = 0.2973, Accuracy = 0.8090 Test Loss = 0.2803, Test Accuracy = 0.8240\n",
      "Iteration 2203: Loss = 0.2650, Accuracy = 0.8240 Test Loss = 0.2803, Test Accuracy = 0.8245\n",
      "Iteration 2204: Loss = 0.2650, Accuracy = 0.8130 Test Loss = 0.2802, Test Accuracy = 0.8234\n",
      "Iteration 2205: Loss = 0.2959, Accuracy = 0.8150 Test Loss = 0.2802, Test Accuracy = 0.8215\n",
      "Iteration 2206: Loss = 0.2777, Accuracy = 0.8150 Test Loss = 0.2801, Test Accuracy = 0.8234\n",
      "Iteration 2207: Loss = 0.2481, Accuracy = 0.8250 Test Loss = 0.2802, Test Accuracy = 0.8221\n",
      "Iteration 2208: Loss = 0.2864, Accuracy = 0.8150 Test Loss = 0.2801, Test Accuracy = 0.8242\n",
      "Iteration 2209: Loss = 0.2635, Accuracy = 0.8150 Test Loss = 0.2799, Test Accuracy = 0.8247\n",
      "Iteration 2210: Loss = 0.2642, Accuracy = 0.8210 Test Loss = 0.2799, Test Accuracy = 0.8243\n",
      "Iteration 2211: Loss = 0.2768, Accuracy = 0.8210 Test Loss = 0.2798, Test Accuracy = 0.8241\n",
      "Iteration 2212: Loss = 0.2660, Accuracy = 0.8250 Test Loss = 0.2798, Test Accuracy = 0.8225\n",
      "Iteration 2213: Loss = 0.2842, Accuracy = 0.8220 Test Loss = 0.2797, Test Accuracy = 0.8244\n",
      "Iteration 2214: Loss = 0.2744, Accuracy = 0.8190 Test Loss = 0.2797, Test Accuracy = 0.8245\n",
      "Iteration 2215: Loss = 0.2633, Accuracy = 0.8200 Test Loss = 0.2798, Test Accuracy = 0.8222\n",
      "Iteration 2216: Loss = 0.2717, Accuracy = 0.8350 Test Loss = 0.2796, Test Accuracy = 0.8249\n",
      "Iteration 2217: Loss = 0.2675, Accuracy = 0.8270 Test Loss = 0.2797, Test Accuracy = 0.8232\n",
      "Iteration 2218: Loss = 0.2744, Accuracy = 0.8240 Test Loss = 0.2795, Test Accuracy = 0.8245\n",
      "Iteration 2219: Loss = 0.2659, Accuracy = 0.8280 Test Loss = 0.2794, Test Accuracy = 0.8233\n",
      "Iteration 2220: Loss = 0.2573, Accuracy = 0.8270 Test Loss = 0.2794, Test Accuracy = 0.8242\n",
      "Iteration 2221: Loss = 0.2873, Accuracy = 0.8110 Test Loss = 0.2794, Test Accuracy = 0.8238\n",
      "Iteration 2222: Loss = 0.2700, Accuracy = 0.8170 Test Loss = 0.2793, Test Accuracy = 0.8227\n",
      "Iteration 2223: Loss = 0.2845, Accuracy = 0.8150 Test Loss = 0.2794, Test Accuracy = 0.8238\n",
      "Iteration 2224: Loss = 0.2743, Accuracy = 0.8170 Test Loss = 0.2793, Test Accuracy = 0.8241\n",
      "Iteration 2225: Loss = 0.3059, Accuracy = 0.8040 Test Loss = 0.2792, Test Accuracy = 0.8246\n",
      "Iteration 2226: Loss = 0.2692, Accuracy = 0.8410 Test Loss = 0.2791, Test Accuracy = 0.8251\n",
      "Iteration 2227: Loss = 0.2900, Accuracy = 0.7960 Test Loss = 0.2791, Test Accuracy = 0.8234\n",
      "Iteration 2228: Loss = 0.2632, Accuracy = 0.8210 Test Loss = 0.2791, Test Accuracy = 0.8242\n",
      "Iteration 2229: Loss = 0.2848, Accuracy = 0.8360 Test Loss = 0.2791, Test Accuracy = 0.8236\n",
      "Iteration 2230: Loss = 0.2982, Accuracy = 0.8150 Test Loss = 0.2790, Test Accuracy = 0.8235\n",
      "Iteration 2231: Loss = 0.2628, Accuracy = 0.8280 Test Loss = 0.2789, Test Accuracy = 0.8242\n",
      "Iteration 2232: Loss = 0.2516, Accuracy = 0.8430 Test Loss = 0.2789, Test Accuracy = 0.8244\n",
      "Iteration 2233: Loss = 0.2933, Accuracy = 0.8110 Test Loss = 0.2788, Test Accuracy = 0.8238\n",
      "Iteration 2234: Loss = 0.2835, Accuracy = 0.8390 Test Loss = 0.2788, Test Accuracy = 0.8234\n",
      "Iteration 2235: Loss = 0.2973, Accuracy = 0.8070 Test Loss = 0.2787, Test Accuracy = 0.8244\n",
      "Iteration 2236: Loss = 0.2757, Accuracy = 0.8040 Test Loss = 0.2787, Test Accuracy = 0.8249\n",
      "Iteration 2237: Loss = 0.2605, Accuracy = 0.8310 Test Loss = 0.2788, Test Accuracy = 0.8227\n",
      "Iteration 2238: Loss = 0.2696, Accuracy = 0.8230 Test Loss = 0.2786, Test Accuracy = 0.8231\n",
      "Iteration 2239: Loss = 0.2699, Accuracy = 0.8290 Test Loss = 0.2786, Test Accuracy = 0.8242\n",
      "Iteration 2240: Loss = 0.2653, Accuracy = 0.8180 Test Loss = 0.2786, Test Accuracy = 0.8231\n",
      "Iteration 2241: Loss = 0.2974, Accuracy = 0.8060 Test Loss = 0.2786, Test Accuracy = 0.8248\n",
      "Iteration 2242: Loss = 0.2732, Accuracy = 0.8050 Test Loss = 0.2785, Test Accuracy = 0.8243\n",
      "Iteration 2243: Loss = 0.2905, Accuracy = 0.8150 Test Loss = 0.2784, Test Accuracy = 0.8258\n",
      "Iteration 2244: Loss = 0.2738, Accuracy = 0.8180 Test Loss = 0.2784, Test Accuracy = 0.8240\n",
      "Iteration 2245: Loss = 0.2734, Accuracy = 0.7910 Test Loss = 0.2783, Test Accuracy = 0.8244\n",
      "Iteration 2246: Loss = 0.2780, Accuracy = 0.8150 Test Loss = 0.2783, Test Accuracy = 0.8248\n",
      "Iteration 2247: Loss = 0.2868, Accuracy = 0.8150 Test Loss = 0.2783, Test Accuracy = 0.8241\n",
      "Iteration 2248: Loss = 0.2754, Accuracy = 0.8240 Test Loss = 0.2782, Test Accuracy = 0.8249\n",
      "Iteration 2249: Loss = 0.2908, Accuracy = 0.8210 Test Loss = 0.2782, Test Accuracy = 0.8261\n",
      "Iteration 2250: Loss = 0.2783, Accuracy = 0.8130 Test Loss = 0.2781, Test Accuracy = 0.8233\n",
      "Iteration 2251: Loss = 0.2670, Accuracy = 0.8240 Test Loss = 0.2780, Test Accuracy = 0.8236\n",
      "Iteration 2252: Loss = 0.2736, Accuracy = 0.8030 Test Loss = 0.2780, Test Accuracy = 0.8252\n",
      "Iteration 2253: Loss = 0.2784, Accuracy = 0.8060 Test Loss = 0.2780, Test Accuracy = 0.8231\n",
      "Iteration 2254: Loss = 0.2901, Accuracy = 0.8100 Test Loss = 0.2779, Test Accuracy = 0.8243\n",
      "Iteration 2255: Loss = 0.2553, Accuracy = 0.8260 Test Loss = 0.2778, Test Accuracy = 0.8246\n",
      "Iteration 2256: Loss = 0.2729, Accuracy = 0.8200 Test Loss = 0.2778, Test Accuracy = 0.8252\n",
      "Iteration 2257: Loss = 0.2843, Accuracy = 0.8290 Test Loss = 0.2778, Test Accuracy = 0.8252\n",
      "Iteration 2258: Loss = 0.3137, Accuracy = 0.8300 Test Loss = 0.2778, Test Accuracy = 0.8240\n",
      "Iteration 2259: Loss = 0.2806, Accuracy = 0.8220 Test Loss = 0.2777, Test Accuracy = 0.8240\n",
      "Iteration 2260: Loss = 0.2815, Accuracy = 0.8100 Test Loss = 0.2776, Test Accuracy = 0.8257\n",
      "Iteration 2261: Loss = 0.2709, Accuracy = 0.8290 Test Loss = 0.2776, Test Accuracy = 0.8250\n",
      "Iteration 2262: Loss = 0.2578, Accuracy = 0.8340 Test Loss = 0.2776, Test Accuracy = 0.8246\n",
      "Iteration 2263: Loss = 0.2647, Accuracy = 0.8220 Test Loss = 0.2775, Test Accuracy = 0.8240\n",
      "Iteration 2264: Loss = 0.2794, Accuracy = 0.8200 Test Loss = 0.2775, Test Accuracy = 0.8250\n",
      "Iteration 2265: Loss = 0.2703, Accuracy = 0.8010 Test Loss = 0.2775, Test Accuracy = 0.8245\n",
      "Iteration 2266: Loss = 0.2603, Accuracy = 0.8240 Test Loss = 0.2774, Test Accuracy = 0.8248\n",
      "Iteration 2267: Loss = 0.2748, Accuracy = 0.8370 Test Loss = 0.2773, Test Accuracy = 0.8249\n",
      "Iteration 2268: Loss = 0.2527, Accuracy = 0.8290 Test Loss = 0.2773, Test Accuracy = 0.8245\n",
      "Iteration 2269: Loss = 0.2854, Accuracy = 0.8180 Test Loss = 0.2773, Test Accuracy = 0.8248\n",
      "Iteration 2270: Loss = 0.2716, Accuracy = 0.8370 Test Loss = 0.2772, Test Accuracy = 0.8247\n",
      "Iteration 2271: Loss = 0.2835, Accuracy = 0.8290 Test Loss = 0.2772, Test Accuracy = 0.8231\n",
      "Iteration 2272: Loss = 0.2731, Accuracy = 0.8210 Test Loss = 0.2771, Test Accuracy = 0.8251\n",
      "Iteration 2273: Loss = 0.2857, Accuracy = 0.8370 Test Loss = 0.2772, Test Accuracy = 0.8254\n",
      "Iteration 2274: Loss = 0.2687, Accuracy = 0.8020 Test Loss = 0.2770, Test Accuracy = 0.8248\n",
      "Iteration 2275: Loss = 0.2814, Accuracy = 0.7890 Test Loss = 0.2770, Test Accuracy = 0.8254\n",
      "Iteration 2276: Loss = 0.3028, Accuracy = 0.8100 Test Loss = 0.2769, Test Accuracy = 0.8254\n",
      "Iteration 2277: Loss = 0.2977, Accuracy = 0.7820 Test Loss = 0.2769, Test Accuracy = 0.8257\n",
      "Iteration 2278: Loss = 0.2770, Accuracy = 0.8100 Test Loss = 0.2769, Test Accuracy = 0.8261\n",
      "Iteration 2279: Loss = 0.2675, Accuracy = 0.8040 Test Loss = 0.2769, Test Accuracy = 0.8247\n",
      "Iteration 2280: Loss = 0.2727, Accuracy = 0.8270 Test Loss = 0.2768, Test Accuracy = 0.8234\n",
      "Iteration 2281: Loss = 0.2650, Accuracy = 0.8130 Test Loss = 0.2768, Test Accuracy = 0.8250\n",
      "Iteration 2282: Loss = 0.2589, Accuracy = 0.8290 Test Loss = 0.2768, Test Accuracy = 0.8269\n",
      "Iteration 2283: Loss = 0.2621, Accuracy = 0.8290 Test Loss = 0.2767, Test Accuracy = 0.8245\n",
      "Iteration 2284: Loss = 0.2677, Accuracy = 0.8390 Test Loss = 0.2767, Test Accuracy = 0.8239\n",
      "Iteration 2285: Loss = 0.3048, Accuracy = 0.8390 Test Loss = 0.2766, Test Accuracy = 0.8249\n",
      "Iteration 2286: Loss = 0.2673, Accuracy = 0.8210 Test Loss = 0.2765, Test Accuracy = 0.8266\n",
      "Iteration 2287: Loss = 0.2759, Accuracy = 0.8230 Test Loss = 0.2765, Test Accuracy = 0.8241\n",
      "Iteration 2288: Loss = 0.2797, Accuracy = 0.8320 Test Loss = 0.2765, Test Accuracy = 0.8245\n",
      "Iteration 2289: Loss = 0.2720, Accuracy = 0.8240 Test Loss = 0.2764, Test Accuracy = 0.8264\n",
      "Iteration 2290: Loss = 0.2762, Accuracy = 0.8040 Test Loss = 0.2764, Test Accuracy = 0.8238\n",
      "Iteration 2291: Loss = 0.2842, Accuracy = 0.7990 Test Loss = 0.2763, Test Accuracy = 0.8254\n",
      "Iteration 2292: Loss = 0.2774, Accuracy = 0.8180 Test Loss = 0.2764, Test Accuracy = 0.8257\n",
      "Iteration 2293: Loss = 0.2526, Accuracy = 0.8350 Test Loss = 0.2763, Test Accuracy = 0.8249\n",
      "Iteration 2294: Loss = 0.2790, Accuracy = 0.8110 Test Loss = 0.2762, Test Accuracy = 0.8258\n",
      "Iteration 2295: Loss = 0.2721, Accuracy = 0.8060 Test Loss = 0.2762, Test Accuracy = 0.8259\n",
      "Iteration 2296: Loss = 0.2566, Accuracy = 0.8240 Test Loss = 0.2761, Test Accuracy = 0.8258\n",
      "Iteration 2297: Loss = 0.2664, Accuracy = 0.8150 Test Loss = 0.2761, Test Accuracy = 0.8249\n",
      "Iteration 2298: Loss = 0.2822, Accuracy = 0.8040 Test Loss = 0.2761, Test Accuracy = 0.8246\n",
      "Iteration 2299: Loss = 0.2894, Accuracy = 0.8150 Test Loss = 0.2760, Test Accuracy = 0.8249\n",
      "Iteration 2300: Loss = 0.2480, Accuracy = 0.8120 Test Loss = 0.2759, Test Accuracy = 0.8258\n",
      "Iteration 2301: Loss = 0.2702, Accuracy = 0.8120 Test Loss = 0.2759, Test Accuracy = 0.8251\n",
      "Iteration 2302: Loss = 0.2819, Accuracy = 0.8320 Test Loss = 0.2759, Test Accuracy = 0.8267\n",
      "Iteration 2303: Loss = 0.2800, Accuracy = 0.8100 Test Loss = 0.2759, Test Accuracy = 0.8258\n",
      "Iteration 2304: Loss = 0.2818, Accuracy = 0.7960 Test Loss = 0.2758, Test Accuracy = 0.8247\n",
      "Iteration 2305: Loss = 0.2710, Accuracy = 0.8020 Test Loss = 0.2757, Test Accuracy = 0.8266\n",
      "Iteration 2306: Loss = 0.2634, Accuracy = 0.8350 Test Loss = 0.2757, Test Accuracy = 0.8256\n",
      "Iteration 2307: Loss = 0.2760, Accuracy = 0.8340 Test Loss = 0.2756, Test Accuracy = 0.8253\n",
      "Iteration 2308: Loss = 0.2583, Accuracy = 0.8150 Test Loss = 0.2756, Test Accuracy = 0.8264\n",
      "Iteration 2309: Loss = 0.2603, Accuracy = 0.8110 Test Loss = 0.2756, Test Accuracy = 0.8253\n",
      "Iteration 2310: Loss = 0.3053, Accuracy = 0.8320 Test Loss = 0.2755, Test Accuracy = 0.8259\n",
      "Iteration 2311: Loss = 0.2840, Accuracy = 0.8040 Test Loss = 0.2756, Test Accuracy = 0.8257\n",
      "Iteration 2312: Loss = 0.2601, Accuracy = 0.8380 Test Loss = 0.2756, Test Accuracy = 0.8262\n",
      "Iteration 2313: Loss = 0.2795, Accuracy = 0.8140 Test Loss = 0.2755, Test Accuracy = 0.8262\n",
      "Iteration 2314: Loss = 0.2705, Accuracy = 0.8190 Test Loss = 0.2754, Test Accuracy = 0.8259\n",
      "Iteration 2315: Loss = 0.2808, Accuracy = 0.8050 Test Loss = 0.2754, Test Accuracy = 0.8258\n",
      "Iteration 2316: Loss = 0.2839, Accuracy = 0.8290 Test Loss = 0.2753, Test Accuracy = 0.8241\n",
      "Iteration 2317: Loss = 0.2865, Accuracy = 0.8270 Test Loss = 0.2753, Test Accuracy = 0.8247\n",
      "Iteration 2318: Loss = 0.2927, Accuracy = 0.7980 Test Loss = 0.2753, Test Accuracy = 0.8272\n",
      "Iteration 2319: Loss = 0.2760, Accuracy = 0.8070 Test Loss = 0.2753, Test Accuracy = 0.8263\n",
      "Iteration 2320: Loss = 0.2808, Accuracy = 0.8360 Test Loss = 0.2752, Test Accuracy = 0.8247\n",
      "Iteration 2321: Loss = 0.2564, Accuracy = 0.8290 Test Loss = 0.2752, Test Accuracy = 0.8260\n",
      "Iteration 2322: Loss = 0.2785, Accuracy = 0.8120 Test Loss = 0.2751, Test Accuracy = 0.8256\n",
      "Iteration 2323: Loss = 0.2715, Accuracy = 0.8100 Test Loss = 0.2751, Test Accuracy = 0.8263\n",
      "Iteration 2324: Loss = 0.2727, Accuracy = 0.8190 Test Loss = 0.2751, Test Accuracy = 0.8278\n",
      "Iteration 2325: Loss = 0.2724, Accuracy = 0.8190 Test Loss = 0.2749, Test Accuracy = 0.8272\n",
      "Iteration 2326: Loss = 0.2707, Accuracy = 0.8140 Test Loss = 0.2749, Test Accuracy = 0.8267\n",
      "Iteration 2327: Loss = 0.2613, Accuracy = 0.8280 Test Loss = 0.2748, Test Accuracy = 0.8253\n",
      "Iteration 2328: Loss = 0.2773, Accuracy = 0.8190 Test Loss = 0.2748, Test Accuracy = 0.8268\n",
      "Iteration 2329: Loss = 0.2744, Accuracy = 0.8340 Test Loss = 0.2747, Test Accuracy = 0.8258\n",
      "Iteration 2330: Loss = 0.3029, Accuracy = 0.7990 Test Loss = 0.2746, Test Accuracy = 0.8279\n",
      "Iteration 2331: Loss = 0.2777, Accuracy = 0.8220 Test Loss = 0.2747, Test Accuracy = 0.8275\n",
      "Iteration 2332: Loss = 0.2796, Accuracy = 0.8080 Test Loss = 0.2746, Test Accuracy = 0.8266\n",
      "Iteration 2333: Loss = 0.2710, Accuracy = 0.8140 Test Loss = 0.2745, Test Accuracy = 0.8269\n",
      "Iteration 2334: Loss = 0.2800, Accuracy = 0.8200 Test Loss = 0.2746, Test Accuracy = 0.8261\n",
      "Iteration 2335: Loss = 0.2652, Accuracy = 0.8070 Test Loss = 0.2745, Test Accuracy = 0.8275\n",
      "Iteration 2336: Loss = 0.2856, Accuracy = 0.7990 Test Loss = 0.2744, Test Accuracy = 0.8281\n",
      "Iteration 2337: Loss = 0.2894, Accuracy = 0.8160 Test Loss = 0.2745, Test Accuracy = 0.8267\n",
      "Iteration 2338: Loss = 0.2761, Accuracy = 0.8230 Test Loss = 0.2745, Test Accuracy = 0.8276\n",
      "Iteration 2339: Loss = 0.2821, Accuracy = 0.8150 Test Loss = 0.2743, Test Accuracy = 0.8281\n",
      "Iteration 2340: Loss = 0.2849, Accuracy = 0.8090 Test Loss = 0.2744, Test Accuracy = 0.8254\n",
      "Iteration 2341: Loss = 0.2787, Accuracy = 0.8140 Test Loss = 0.2744, Test Accuracy = 0.8269\n",
      "Iteration 2342: Loss = 0.2909, Accuracy = 0.8150 Test Loss = 0.2742, Test Accuracy = 0.8265\n",
      "Iteration 2343: Loss = 0.2669, Accuracy = 0.8260 Test Loss = 0.2742, Test Accuracy = 0.8263\n",
      "Iteration 2344: Loss = 0.2876, Accuracy = 0.8120 Test Loss = 0.2742, Test Accuracy = 0.8266\n",
      "Iteration 2345: Loss = 0.2584, Accuracy = 0.8140 Test Loss = 0.2742, Test Accuracy = 0.8269\n",
      "Iteration 2346: Loss = 0.2766, Accuracy = 0.8260 Test Loss = 0.2740, Test Accuracy = 0.8271\n",
      "Iteration 2347: Loss = 0.2559, Accuracy = 0.8290 Test Loss = 0.2741, Test Accuracy = 0.8264\n",
      "Iteration 2348: Loss = 0.2604, Accuracy = 0.8290 Test Loss = 0.2740, Test Accuracy = 0.8267\n",
      "Iteration 2349: Loss = 0.2737, Accuracy = 0.8120 Test Loss = 0.2741, Test Accuracy = 0.8270\n",
      "Iteration 2350: Loss = 0.2611, Accuracy = 0.8090 Test Loss = 0.2739, Test Accuracy = 0.8286\n",
      "Iteration 2351: Loss = 0.2568, Accuracy = 0.8380 Test Loss = 0.2739, Test Accuracy = 0.8258\n",
      "Iteration 2352: Loss = 0.2731, Accuracy = 0.8140 Test Loss = 0.2739, Test Accuracy = 0.8265\n",
      "Iteration 2353: Loss = 0.2789, Accuracy = 0.8130 Test Loss = 0.2737, Test Accuracy = 0.8273\n",
      "Iteration 2354: Loss = 0.2772, Accuracy = 0.8180 Test Loss = 0.2738, Test Accuracy = 0.8277\n",
      "Iteration 2355: Loss = 0.2777, Accuracy = 0.8160 Test Loss = 0.2738, Test Accuracy = 0.8270\n",
      "Iteration 2356: Loss = 0.2700, Accuracy = 0.8430 Test Loss = 0.2736, Test Accuracy = 0.8277\n",
      "Iteration 2357: Loss = 0.2891, Accuracy = 0.8030 Test Loss = 0.2736, Test Accuracy = 0.8274\n",
      "Iteration 2358: Loss = 0.2493, Accuracy = 0.8390 Test Loss = 0.2736, Test Accuracy = 0.8283\n",
      "Iteration 2359: Loss = 0.2712, Accuracy = 0.8180 Test Loss = 0.2737, Test Accuracy = 0.8273\n",
      "Iteration 2360: Loss = 0.2719, Accuracy = 0.8230 Test Loss = 0.2736, Test Accuracy = 0.8274\n",
      "Iteration 2361: Loss = 0.2795, Accuracy = 0.8070 Test Loss = 0.2736, Test Accuracy = 0.8271\n",
      "Iteration 2362: Loss = 0.2686, Accuracy = 0.8290 Test Loss = 0.2734, Test Accuracy = 0.8268\n",
      "Iteration 2363: Loss = 0.2827, Accuracy = 0.8170 Test Loss = 0.2734, Test Accuracy = 0.8278\n",
      "Iteration 2364: Loss = 0.2521, Accuracy = 0.8350 Test Loss = 0.2734, Test Accuracy = 0.8270\n",
      "Iteration 2365: Loss = 0.2881, Accuracy = 0.7960 Test Loss = 0.2733, Test Accuracy = 0.8284\n",
      "Iteration 2366: Loss = 0.2876, Accuracy = 0.8090 Test Loss = 0.2733, Test Accuracy = 0.8279\n",
      "Iteration 2367: Loss = 0.2611, Accuracy = 0.8390 Test Loss = 0.2732, Test Accuracy = 0.8266\n",
      "Iteration 2368: Loss = 0.3003, Accuracy = 0.8060 Test Loss = 0.2732, Test Accuracy = 0.8269\n",
      "Iteration 2369: Loss = 0.2510, Accuracy = 0.8390 Test Loss = 0.2731, Test Accuracy = 0.8274\n",
      "Iteration 2370: Loss = 0.2627, Accuracy = 0.8230 Test Loss = 0.2731, Test Accuracy = 0.8278\n",
      "Iteration 2371: Loss = 0.2671, Accuracy = 0.8160 Test Loss = 0.2732, Test Accuracy = 0.8271\n",
      "Iteration 2372: Loss = 0.2703, Accuracy = 0.8150 Test Loss = 0.2730, Test Accuracy = 0.8274\n",
      "Iteration 2373: Loss = 0.2782, Accuracy = 0.8070 Test Loss = 0.2731, Test Accuracy = 0.8259\n",
      "Iteration 2374: Loss = 0.2837, Accuracy = 0.8390 Test Loss = 0.2729, Test Accuracy = 0.8280\n",
      "Iteration 2375: Loss = 0.2906, Accuracy = 0.8040 Test Loss = 0.2729, Test Accuracy = 0.8295\n",
      "Iteration 2376: Loss = 0.2613, Accuracy = 0.8160 Test Loss = 0.2728, Test Accuracy = 0.8287\n",
      "Iteration 2377: Loss = 0.2787, Accuracy = 0.8140 Test Loss = 0.2729, Test Accuracy = 0.8272\n",
      "Iteration 2378: Loss = 0.2633, Accuracy = 0.8320 Test Loss = 0.2728, Test Accuracy = 0.8276\n",
      "Iteration 2379: Loss = 0.2725, Accuracy = 0.8250 Test Loss = 0.2728, Test Accuracy = 0.8273\n",
      "Iteration 2380: Loss = 0.2655, Accuracy = 0.8390 Test Loss = 0.2727, Test Accuracy = 0.8281\n",
      "Iteration 2381: Loss = 0.2789, Accuracy = 0.8150 Test Loss = 0.2728, Test Accuracy = 0.8255\n",
      "Iteration 2382: Loss = 0.2657, Accuracy = 0.8050 Test Loss = 0.2727, Test Accuracy = 0.8273\n",
      "Iteration 2383: Loss = 0.2785, Accuracy = 0.7990 Test Loss = 0.2726, Test Accuracy = 0.8278\n",
      "Iteration 2384: Loss = 0.2746, Accuracy = 0.8020 Test Loss = 0.2726, Test Accuracy = 0.8275\n",
      "Iteration 2385: Loss = 0.2576, Accuracy = 0.8290 Test Loss = 0.2725, Test Accuracy = 0.8281\n",
      "Iteration 2386: Loss = 0.2835, Accuracy = 0.8160 Test Loss = 0.2725, Test Accuracy = 0.8267\n",
      "Iteration 2387: Loss = 0.2890, Accuracy = 0.8280 Test Loss = 0.2725, Test Accuracy = 0.8279\n",
      "Iteration 2388: Loss = 0.2865, Accuracy = 0.8170 Test Loss = 0.2725, Test Accuracy = 0.8282\n",
      "Iteration 2389: Loss = 0.2904, Accuracy = 0.8150 Test Loss = 0.2723, Test Accuracy = 0.8281\n",
      "Iteration 2390: Loss = 0.2718, Accuracy = 0.8380 Test Loss = 0.2724, Test Accuracy = 0.8279\n",
      "Iteration 2391: Loss = 0.2742, Accuracy = 0.8200 Test Loss = 0.2723, Test Accuracy = 0.8278\n",
      "Iteration 2392: Loss = 0.2541, Accuracy = 0.8290 Test Loss = 0.2723, Test Accuracy = 0.8269\n",
      "Iteration 2393: Loss = 0.2818, Accuracy = 0.8150 Test Loss = 0.2722, Test Accuracy = 0.8271\n",
      "Iteration 2394: Loss = 0.2647, Accuracy = 0.8350 Test Loss = 0.2722, Test Accuracy = 0.8282\n",
      "Iteration 2395: Loss = 0.2653, Accuracy = 0.8120 Test Loss = 0.2722, Test Accuracy = 0.8276\n",
      "Iteration 2396: Loss = 0.2640, Accuracy = 0.8180 Test Loss = 0.2721, Test Accuracy = 0.8290\n",
      "Iteration 2397: Loss = 0.2801, Accuracy = 0.8140 Test Loss = 0.2720, Test Accuracy = 0.8286\n",
      "Iteration 2398: Loss = 0.2621, Accuracy = 0.8390 Test Loss = 0.2721, Test Accuracy = 0.8279\n",
      "Iteration 2399: Loss = 0.2833, Accuracy = 0.8290 Test Loss = 0.2720, Test Accuracy = 0.8289\n",
      "Iteration 2400: Loss = 0.2735, Accuracy = 0.7940 Test Loss = 0.2721, Test Accuracy = 0.8280\n",
      "Iteration 2401: Loss = 0.2753, Accuracy = 0.8290 Test Loss = 0.2719, Test Accuracy = 0.8293\n",
      "Iteration 2402: Loss = 0.2564, Accuracy = 0.8090 Test Loss = 0.2718, Test Accuracy = 0.8279\n",
      "Iteration 2403: Loss = 0.2601, Accuracy = 0.8230 Test Loss = 0.2719, Test Accuracy = 0.8278\n",
      "Iteration 2404: Loss = 0.2771, Accuracy = 0.8250 Test Loss = 0.2718, Test Accuracy = 0.8283\n",
      "Iteration 2405: Loss = 0.2571, Accuracy = 0.8340 Test Loss = 0.2718, Test Accuracy = 0.8288\n",
      "Iteration 2406: Loss = 0.2668, Accuracy = 0.8200 Test Loss = 0.2717, Test Accuracy = 0.8286\n",
      "Iteration 2407: Loss = 0.2630, Accuracy = 0.8310 Test Loss = 0.2717, Test Accuracy = 0.8273\n",
      "Iteration 2408: Loss = 0.2607, Accuracy = 0.8250 Test Loss = 0.2718, Test Accuracy = 0.8275\n",
      "Iteration 2409: Loss = 0.2666, Accuracy = 0.8370 Test Loss = 0.2716, Test Accuracy = 0.8266\n",
      "Iteration 2410: Loss = 0.2691, Accuracy = 0.8320 Test Loss = 0.2716, Test Accuracy = 0.8268\n",
      "Iteration 2411: Loss = 0.2729, Accuracy = 0.8020 Test Loss = 0.2715, Test Accuracy = 0.8277\n",
      "Iteration 2412: Loss = 0.2647, Accuracy = 0.8230 Test Loss = 0.2715, Test Accuracy = 0.8277\n",
      "Iteration 2413: Loss = 0.2788, Accuracy = 0.8150 Test Loss = 0.2714, Test Accuracy = 0.8281\n",
      "Iteration 2414: Loss = 0.2584, Accuracy = 0.8430 Test Loss = 0.2714, Test Accuracy = 0.8284\n",
      "Iteration 2415: Loss = 0.2956, Accuracy = 0.8120 Test Loss = 0.2713, Test Accuracy = 0.8283\n",
      "Iteration 2416: Loss = 0.2417, Accuracy = 0.8590 Test Loss = 0.2714, Test Accuracy = 0.8281\n",
      "Iteration 2417: Loss = 0.2708, Accuracy = 0.8090 Test Loss = 0.2713, Test Accuracy = 0.8275\n",
      "Iteration 2418: Loss = 0.2659, Accuracy = 0.8320 Test Loss = 0.2714, Test Accuracy = 0.8271\n",
      "Iteration 2419: Loss = 0.2688, Accuracy = 0.8100 Test Loss = 0.2712, Test Accuracy = 0.8275\n",
      "Iteration 2420: Loss = 0.2612, Accuracy = 0.8190 Test Loss = 0.2712, Test Accuracy = 0.8277\n",
      "Iteration 2421: Loss = 0.2740, Accuracy = 0.8210 Test Loss = 0.2711, Test Accuracy = 0.8283\n",
      "Iteration 2422: Loss = 0.2676, Accuracy = 0.8250 Test Loss = 0.2711, Test Accuracy = 0.8286\n",
      "Iteration 2423: Loss = 0.2816, Accuracy = 0.8170 Test Loss = 0.2711, Test Accuracy = 0.8281\n",
      "Iteration 2424: Loss = 0.2696, Accuracy = 0.8160 Test Loss = 0.2711, Test Accuracy = 0.8277\n",
      "Iteration 2425: Loss = 0.2602, Accuracy = 0.8400 Test Loss = 0.2710, Test Accuracy = 0.8281\n",
      "Iteration 2426: Loss = 0.2667, Accuracy = 0.8410 Test Loss = 0.2710, Test Accuracy = 0.8272\n",
      "Iteration 2427: Loss = 0.2580, Accuracy = 0.8330 Test Loss = 0.2711, Test Accuracy = 0.8261\n",
      "Iteration 2428: Loss = 0.2504, Accuracy = 0.8100 Test Loss = 0.2709, Test Accuracy = 0.8265\n",
      "Iteration 2429: Loss = 0.2757, Accuracy = 0.8080 Test Loss = 0.2708, Test Accuracy = 0.8288\n",
      "Iteration 2430: Loss = 0.2826, Accuracy = 0.8350 Test Loss = 0.2709, Test Accuracy = 0.8280\n",
      "Iteration 2431: Loss = 0.2722, Accuracy = 0.8330 Test Loss = 0.2708, Test Accuracy = 0.8266\n",
      "Iteration 2432: Loss = 0.2748, Accuracy = 0.8160 Test Loss = 0.2707, Test Accuracy = 0.8281\n",
      "Iteration 2433: Loss = 0.2434, Accuracy = 0.8340 Test Loss = 0.2707, Test Accuracy = 0.8282\n",
      "Iteration 2434: Loss = 0.2628, Accuracy = 0.8370 Test Loss = 0.2707, Test Accuracy = 0.8281\n",
      "Iteration 2435: Loss = 0.2819, Accuracy = 0.8000 Test Loss = 0.2707, Test Accuracy = 0.8284\n",
      "Iteration 2436: Loss = 0.2593, Accuracy = 0.8350 Test Loss = 0.2706, Test Accuracy = 0.8283\n",
      "Iteration 2437: Loss = 0.2554, Accuracy = 0.8200 Test Loss = 0.2705, Test Accuracy = 0.8283\n",
      "Iteration 2438: Loss = 0.2522, Accuracy = 0.8460 Test Loss = 0.2705, Test Accuracy = 0.8284\n",
      "Iteration 2439: Loss = 0.2632, Accuracy = 0.8380 Test Loss = 0.2705, Test Accuracy = 0.8283\n",
      "Iteration 2440: Loss = 0.2695, Accuracy = 0.8400 Test Loss = 0.2705, Test Accuracy = 0.8269\n",
      "Iteration 2441: Loss = 0.2804, Accuracy = 0.8130 Test Loss = 0.2704, Test Accuracy = 0.8292\n",
      "Iteration 2442: Loss = 0.2695, Accuracy = 0.8250 Test Loss = 0.2703, Test Accuracy = 0.8287\n",
      "Iteration 2443: Loss = 0.2522, Accuracy = 0.8360 Test Loss = 0.2703, Test Accuracy = 0.8293\n",
      "Iteration 2444: Loss = 0.2502, Accuracy = 0.8310 Test Loss = 0.2703, Test Accuracy = 0.8270\n",
      "Iteration 2445: Loss = 0.2831, Accuracy = 0.8160 Test Loss = 0.2703, Test Accuracy = 0.8288\n",
      "Iteration 2446: Loss = 0.2756, Accuracy = 0.8150 Test Loss = 0.2702, Test Accuracy = 0.8281\n",
      "Iteration 2447: Loss = 0.2487, Accuracy = 0.8250 Test Loss = 0.2703, Test Accuracy = 0.8269\n",
      "Iteration 2448: Loss = 0.2643, Accuracy = 0.8380 Test Loss = 0.2703, Test Accuracy = 0.8267\n",
      "Iteration 2449: Loss = 0.2511, Accuracy = 0.8180 Test Loss = 0.2701, Test Accuracy = 0.8298\n",
      "Iteration 2450: Loss = 0.2694, Accuracy = 0.8060 Test Loss = 0.2701, Test Accuracy = 0.8289\n",
      "Iteration 2451: Loss = 0.2737, Accuracy = 0.8240 Test Loss = 0.2700, Test Accuracy = 0.8286\n",
      "Iteration 2452: Loss = 0.2728, Accuracy = 0.8400 Test Loss = 0.2700, Test Accuracy = 0.8267\n",
      "Iteration 2453: Loss = 0.2699, Accuracy = 0.8270 Test Loss = 0.2700, Test Accuracy = 0.8285\n",
      "Iteration 2454: Loss = 0.2532, Accuracy = 0.8440 Test Loss = 0.2700, Test Accuracy = 0.8271\n",
      "Iteration 2455: Loss = 0.2714, Accuracy = 0.8080 Test Loss = 0.2700, Test Accuracy = 0.8284\n",
      "Iteration 2456: Loss = 0.2587, Accuracy = 0.8360 Test Loss = 0.2699, Test Accuracy = 0.8287\n",
      "Iteration 2457: Loss = 0.2683, Accuracy = 0.8350 Test Loss = 0.2698, Test Accuracy = 0.8280\n",
      "Iteration 2458: Loss = 0.2706, Accuracy = 0.8040 Test Loss = 0.2698, Test Accuracy = 0.8277\n",
      "Iteration 2459: Loss = 0.2624, Accuracy = 0.8140 Test Loss = 0.2698, Test Accuracy = 0.8276\n",
      "Iteration 2460: Loss = 0.2509, Accuracy = 0.8300 Test Loss = 0.2697, Test Accuracy = 0.8283\n",
      "Iteration 2461: Loss = 0.2768, Accuracy = 0.8210 Test Loss = 0.2697, Test Accuracy = 0.8285\n",
      "Iteration 2462: Loss = 0.2674, Accuracy = 0.8280 Test Loss = 0.2697, Test Accuracy = 0.8290\n",
      "Iteration 2463: Loss = 0.2913, Accuracy = 0.8090 Test Loss = 0.2697, Test Accuracy = 0.8275\n",
      "Iteration 2464: Loss = 0.2691, Accuracy = 0.8080 Test Loss = 0.2696, Test Accuracy = 0.8292\n",
      "Iteration 2465: Loss = 0.2651, Accuracy = 0.8370 Test Loss = 0.2696, Test Accuracy = 0.8287\n",
      "Iteration 2466: Loss = 0.2681, Accuracy = 0.8230 Test Loss = 0.2696, Test Accuracy = 0.8282\n",
      "Iteration 2467: Loss = 0.2877, Accuracy = 0.8070 Test Loss = 0.2695, Test Accuracy = 0.8278\n",
      "Iteration 2468: Loss = 0.2793, Accuracy = 0.8120 Test Loss = 0.2694, Test Accuracy = 0.8297\n",
      "Iteration 2469: Loss = 0.2507, Accuracy = 0.8410 Test Loss = 0.2695, Test Accuracy = 0.8272\n",
      "Iteration 2470: Loss = 0.2752, Accuracy = 0.8140 Test Loss = 0.2694, Test Accuracy = 0.8282\n",
      "Iteration 2471: Loss = 0.2816, Accuracy = 0.8310 Test Loss = 0.2694, Test Accuracy = 0.8291\n",
      "Iteration 2472: Loss = 0.2542, Accuracy = 0.8170 Test Loss = 0.2693, Test Accuracy = 0.8294\n",
      "Iteration 2473: Loss = 0.2584, Accuracy = 0.8210 Test Loss = 0.2693, Test Accuracy = 0.8282\n",
      "Iteration 2474: Loss = 0.2518, Accuracy = 0.8380 Test Loss = 0.2693, Test Accuracy = 0.8286\n",
      "Iteration 2475: Loss = 0.2878, Accuracy = 0.8040 Test Loss = 0.2694, Test Accuracy = 0.8285\n",
      "Iteration 2476: Loss = 0.2732, Accuracy = 0.8160 Test Loss = 0.2692, Test Accuracy = 0.8294\n",
      "Iteration 2477: Loss = 0.2691, Accuracy = 0.8100 Test Loss = 0.2691, Test Accuracy = 0.8279\n",
      "Iteration 2478: Loss = 0.2774, Accuracy = 0.8280 Test Loss = 0.2692, Test Accuracy = 0.8295\n",
      "Iteration 2479: Loss = 0.2760, Accuracy = 0.8320 Test Loss = 0.2690, Test Accuracy = 0.8289\n",
      "Iteration 2480: Loss = 0.2822, Accuracy = 0.8080 Test Loss = 0.2690, Test Accuracy = 0.8282\n",
      "Iteration 2481: Loss = 0.2649, Accuracy = 0.8060 Test Loss = 0.2690, Test Accuracy = 0.8290\n",
      "Iteration 2482: Loss = 0.2618, Accuracy = 0.8070 Test Loss = 0.2689, Test Accuracy = 0.8293\n",
      "Iteration 2483: Loss = 0.2753, Accuracy = 0.8170 Test Loss = 0.2689, Test Accuracy = 0.8294\n",
      "Iteration 2484: Loss = 0.2618, Accuracy = 0.8370 Test Loss = 0.2690, Test Accuracy = 0.8288\n",
      "Iteration 2485: Loss = 0.2549, Accuracy = 0.8300 Test Loss = 0.2688, Test Accuracy = 0.8282\n",
      "Iteration 2486: Loss = 0.2610, Accuracy = 0.8250 Test Loss = 0.2689, Test Accuracy = 0.8278\n",
      "Iteration 2487: Loss = 0.2656, Accuracy = 0.8120 Test Loss = 0.2688, Test Accuracy = 0.8287\n",
      "Iteration 2488: Loss = 0.2610, Accuracy = 0.8350 Test Loss = 0.2688, Test Accuracy = 0.8287\n",
      "Iteration 2489: Loss = 0.2643, Accuracy = 0.8260 Test Loss = 0.2687, Test Accuracy = 0.8293\n",
      "Iteration 2490: Loss = 0.2645, Accuracy = 0.8140 Test Loss = 0.2688, Test Accuracy = 0.8272\n",
      "Iteration 2491: Loss = 0.2551, Accuracy = 0.8230 Test Loss = 0.2686, Test Accuracy = 0.8280\n",
      "Iteration 2492: Loss = 0.2741, Accuracy = 0.8110 Test Loss = 0.2686, Test Accuracy = 0.8296\n",
      "Iteration 2493: Loss = 0.2760, Accuracy = 0.8110 Test Loss = 0.2686, Test Accuracy = 0.8282\n",
      "Iteration 2494: Loss = 0.2911, Accuracy = 0.8110 Test Loss = 0.2685, Test Accuracy = 0.8283\n",
      "Iteration 2495: Loss = 0.2770, Accuracy = 0.8270 Test Loss = 0.2684, Test Accuracy = 0.8283\n",
      "Iteration 2496: Loss = 0.2673, Accuracy = 0.8150 Test Loss = 0.2684, Test Accuracy = 0.8289\n",
      "Iteration 2497: Loss = 0.2678, Accuracy = 0.8090 Test Loss = 0.2684, Test Accuracy = 0.8291\n",
      "Iteration 2498: Loss = 0.2832, Accuracy = 0.8220 Test Loss = 0.2684, Test Accuracy = 0.8278\n",
      "Iteration 2499: Loss = 0.2565, Accuracy = 0.8250 Test Loss = 0.2684, Test Accuracy = 0.8292\n",
      "Iteration 2500: Loss = 0.2738, Accuracy = 0.8360 Test Loss = 0.2683, Test Accuracy = 0.8281\n",
      "Iteration 2501: Loss = 0.2821, Accuracy = 0.8030 Test Loss = 0.2683, Test Accuracy = 0.8296\n",
      "Iteration 2502: Loss = 0.2650, Accuracy = 0.8370 Test Loss = 0.2682, Test Accuracy = 0.8291\n",
      "Iteration 2503: Loss = 0.2717, Accuracy = 0.8220 Test Loss = 0.2681, Test Accuracy = 0.8287\n",
      "Iteration 2504: Loss = 0.2663, Accuracy = 0.8140 Test Loss = 0.2682, Test Accuracy = 0.8298\n",
      "Iteration 2505: Loss = 0.2642, Accuracy = 0.8380 Test Loss = 0.2681, Test Accuracy = 0.8297\n",
      "Iteration 2506: Loss = 0.2638, Accuracy = 0.8330 Test Loss = 0.2682, Test Accuracy = 0.8280\n",
      "Iteration 2507: Loss = 0.2785, Accuracy = 0.8020 Test Loss = 0.2681, Test Accuracy = 0.8300\n",
      "Iteration 2508: Loss = 0.2592, Accuracy = 0.8480 Test Loss = 0.2680, Test Accuracy = 0.8290\n",
      "Iteration 2509: Loss = 0.2435, Accuracy = 0.8490 Test Loss = 0.2680, Test Accuracy = 0.8284\n",
      "Iteration 2510: Loss = 0.2760, Accuracy = 0.8050 Test Loss = 0.2680, Test Accuracy = 0.8303\n",
      "Iteration 2511: Loss = 0.2587, Accuracy = 0.8260 Test Loss = 0.2679, Test Accuracy = 0.8301\n",
      "Iteration 2512: Loss = 0.2515, Accuracy = 0.8470 Test Loss = 0.2679, Test Accuracy = 0.8291\n",
      "Iteration 2513: Loss = 0.2862, Accuracy = 0.8260 Test Loss = 0.2679, Test Accuracy = 0.8288\n",
      "Iteration 2514: Loss = 0.2600, Accuracy = 0.8240 Test Loss = 0.2679, Test Accuracy = 0.8280\n",
      "Iteration 2515: Loss = 0.2591, Accuracy = 0.8250 Test Loss = 0.2677, Test Accuracy = 0.8295\n",
      "Iteration 2516: Loss = 0.2649, Accuracy = 0.8270 Test Loss = 0.2678, Test Accuracy = 0.8289\n",
      "Iteration 2517: Loss = 0.2657, Accuracy = 0.8230 Test Loss = 0.2678, Test Accuracy = 0.8278\n",
      "Iteration 2518: Loss = 0.2517, Accuracy = 0.8280 Test Loss = 0.2677, Test Accuracy = 0.8294\n",
      "Iteration 2519: Loss = 0.2769, Accuracy = 0.8250 Test Loss = 0.2677, Test Accuracy = 0.8297\n",
      "Iteration 2520: Loss = 0.2676, Accuracy = 0.8350 Test Loss = 0.2676, Test Accuracy = 0.8278\n",
      "Iteration 2521: Loss = 0.2611, Accuracy = 0.8170 Test Loss = 0.2675, Test Accuracy = 0.8282\n",
      "Iteration 2522: Loss = 0.2610, Accuracy = 0.8160 Test Loss = 0.2675, Test Accuracy = 0.8287\n",
      "Iteration 2523: Loss = 0.2548, Accuracy = 0.8210 Test Loss = 0.2674, Test Accuracy = 0.8291\n",
      "Iteration 2524: Loss = 0.2805, Accuracy = 0.8090 Test Loss = 0.2676, Test Accuracy = 0.8287\n",
      "Iteration 2525: Loss = 0.2771, Accuracy = 0.8040 Test Loss = 0.2675, Test Accuracy = 0.8292\n",
      "Iteration 2526: Loss = 0.2800, Accuracy = 0.8080 Test Loss = 0.2674, Test Accuracy = 0.8279\n",
      "Iteration 2527: Loss = 0.2675, Accuracy = 0.8310 Test Loss = 0.2675, Test Accuracy = 0.8276\n",
      "Iteration 2528: Loss = 0.2700, Accuracy = 0.8370 Test Loss = 0.2673, Test Accuracy = 0.8280\n",
      "Iteration 2529: Loss = 0.2812, Accuracy = 0.8160 Test Loss = 0.2674, Test Accuracy = 0.8291\n",
      "Iteration 2530: Loss = 0.2906, Accuracy = 0.8320 Test Loss = 0.2673, Test Accuracy = 0.8292\n",
      "Iteration 2531: Loss = 0.2568, Accuracy = 0.8220 Test Loss = 0.2672, Test Accuracy = 0.8298\n",
      "Iteration 2532: Loss = 0.2548, Accuracy = 0.8100 Test Loss = 0.2673, Test Accuracy = 0.8287\n",
      "Iteration 2533: Loss = 0.2702, Accuracy = 0.8250 Test Loss = 0.2672, Test Accuracy = 0.8292\n",
      "Iteration 2534: Loss = 0.2592, Accuracy = 0.8250 Test Loss = 0.2671, Test Accuracy = 0.8296\n",
      "Iteration 2535: Loss = 0.2571, Accuracy = 0.8200 Test Loss = 0.2671, Test Accuracy = 0.8281\n",
      "Iteration 2536: Loss = 0.2496, Accuracy = 0.8340 Test Loss = 0.2670, Test Accuracy = 0.8282\n",
      "Iteration 2537: Loss = 0.2545, Accuracy = 0.8330 Test Loss = 0.2670, Test Accuracy = 0.8297\n",
      "Iteration 2538: Loss = 0.2532, Accuracy = 0.8330 Test Loss = 0.2671, Test Accuracy = 0.8282\n",
      "Iteration 2539: Loss = 0.2596, Accuracy = 0.8100 Test Loss = 0.2669, Test Accuracy = 0.8294\n",
      "Iteration 2540: Loss = 0.2687, Accuracy = 0.8250 Test Loss = 0.2669, Test Accuracy = 0.8292\n",
      "Iteration 2541: Loss = 0.2623, Accuracy = 0.8250 Test Loss = 0.2669, Test Accuracy = 0.8288\n",
      "Iteration 2542: Loss = 0.2681, Accuracy = 0.8100 Test Loss = 0.2668, Test Accuracy = 0.8293\n",
      "Iteration 2543: Loss = 0.3064, Accuracy = 0.8150 Test Loss = 0.2668, Test Accuracy = 0.8281\n",
      "Iteration 2544: Loss = 0.2586, Accuracy = 0.8230 Test Loss = 0.2668, Test Accuracy = 0.8285\n",
      "Iteration 2545: Loss = 0.2577, Accuracy = 0.8400 Test Loss = 0.2668, Test Accuracy = 0.8302\n",
      "Iteration 2546: Loss = 0.2733, Accuracy = 0.8400 Test Loss = 0.2667, Test Accuracy = 0.8275\n",
      "Iteration 2547: Loss = 0.2576, Accuracy = 0.8550 Test Loss = 0.2668, Test Accuracy = 0.8289\n",
      "Iteration 2548: Loss = 0.2656, Accuracy = 0.8250 Test Loss = 0.2667, Test Accuracy = 0.8293\n",
      "Iteration 2549: Loss = 0.2751, Accuracy = 0.7840 Test Loss = 0.2666, Test Accuracy = 0.8290\n",
      "Iteration 2550: Loss = 0.2587, Accuracy = 0.8360 Test Loss = 0.2666, Test Accuracy = 0.8299\n",
      "Iteration 2551: Loss = 0.2889, Accuracy = 0.8030 Test Loss = 0.2667, Test Accuracy = 0.8280\n",
      "Iteration 2552: Loss = 0.2759, Accuracy = 0.8070 Test Loss = 0.2666, Test Accuracy = 0.8298\n",
      "Iteration 2553: Loss = 0.2443, Accuracy = 0.8340 Test Loss = 0.2665, Test Accuracy = 0.8289\n",
      "Iteration 2554: Loss = 0.2741, Accuracy = 0.8150 Test Loss = 0.2664, Test Accuracy = 0.8299\n",
      "Iteration 2555: Loss = 0.2742, Accuracy = 0.8040 Test Loss = 0.2664, Test Accuracy = 0.8289\n",
      "Iteration 2556: Loss = 0.2673, Accuracy = 0.8350 Test Loss = 0.2663, Test Accuracy = 0.8293\n",
      "Iteration 2557: Loss = 0.2693, Accuracy = 0.8070 Test Loss = 0.2664, Test Accuracy = 0.8279\n",
      "Iteration 2558: Loss = 0.2754, Accuracy = 0.8060 Test Loss = 0.2663, Test Accuracy = 0.8298\n",
      "Iteration 2559: Loss = 0.2828, Accuracy = 0.8430 Test Loss = 0.2664, Test Accuracy = 0.8280\n",
      "Iteration 2560: Loss = 0.2513, Accuracy = 0.8290 Test Loss = 0.2662, Test Accuracy = 0.8284\n",
      "Iteration 2561: Loss = 0.2642, Accuracy = 0.8060 Test Loss = 0.2662, Test Accuracy = 0.8300\n",
      "Iteration 2562: Loss = 0.2661, Accuracy = 0.8350 Test Loss = 0.2661, Test Accuracy = 0.8293\n",
      "Iteration 2563: Loss = 0.2670, Accuracy = 0.8210 Test Loss = 0.2662, Test Accuracy = 0.8297\n",
      "Iteration 2564: Loss = 0.2906, Accuracy = 0.8100 Test Loss = 0.2662, Test Accuracy = 0.8291\n",
      "Iteration 2565: Loss = 0.2607, Accuracy = 0.8400 Test Loss = 0.2661, Test Accuracy = 0.8289\n",
      "Iteration 2566: Loss = 0.2766, Accuracy = 0.8120 Test Loss = 0.2661, Test Accuracy = 0.8297\n",
      "Iteration 2567: Loss = 0.2588, Accuracy = 0.8240 Test Loss = 0.2661, Test Accuracy = 0.8287\n",
      "Iteration 2568: Loss = 0.2596, Accuracy = 0.8190 Test Loss = 0.2660, Test Accuracy = 0.8299\n",
      "Iteration 2569: Loss = 0.2527, Accuracy = 0.8360 Test Loss = 0.2660, Test Accuracy = 0.8303\n",
      "Iteration 2570: Loss = 0.2699, Accuracy = 0.8130 Test Loss = 0.2660, Test Accuracy = 0.8300\n",
      "Iteration 2571: Loss = 0.2802, Accuracy = 0.8310 Test Loss = 0.2660, Test Accuracy = 0.8294\n",
      "Iteration 2572: Loss = 0.2537, Accuracy = 0.8120 Test Loss = 0.2659, Test Accuracy = 0.8302\n",
      "Iteration 2573: Loss = 0.2612, Accuracy = 0.8130 Test Loss = 0.2658, Test Accuracy = 0.8296\n",
      "Iteration 2574: Loss = 0.2647, Accuracy = 0.8160 Test Loss = 0.2658, Test Accuracy = 0.8298\n",
      "Iteration 2575: Loss = 0.2640, Accuracy = 0.8350 Test Loss = 0.2659, Test Accuracy = 0.8288\n",
      "Iteration 2576: Loss = 0.2574, Accuracy = 0.8160 Test Loss = 0.2658, Test Accuracy = 0.8291\n",
      "Iteration 2577: Loss = 0.2628, Accuracy = 0.8350 Test Loss = 0.2657, Test Accuracy = 0.8295\n",
      "Iteration 2578: Loss = 0.2736, Accuracy = 0.8300 Test Loss = 0.2657, Test Accuracy = 0.8282\n",
      "Iteration 2579: Loss = 0.2490, Accuracy = 0.8150 Test Loss = 0.2656, Test Accuracy = 0.8290\n",
      "Iteration 2580: Loss = 0.2726, Accuracy = 0.8070 Test Loss = 0.2656, Test Accuracy = 0.8295\n",
      "Iteration 2581: Loss = 0.2688, Accuracy = 0.8200 Test Loss = 0.2655, Test Accuracy = 0.8302\n",
      "Iteration 2582: Loss = 0.2830, Accuracy = 0.8140 Test Loss = 0.2656, Test Accuracy = 0.8288\n",
      "Iteration 2583: Loss = 0.2602, Accuracy = 0.8120 Test Loss = 0.2655, Test Accuracy = 0.8292\n",
      "Iteration 2584: Loss = 0.2620, Accuracy = 0.8190 Test Loss = 0.2655, Test Accuracy = 0.8285\n",
      "Iteration 2585: Loss = 0.2639, Accuracy = 0.8250 Test Loss = 0.2655, Test Accuracy = 0.8290\n",
      "Iteration 2586: Loss = 0.2653, Accuracy = 0.8380 Test Loss = 0.2655, Test Accuracy = 0.8299\n",
      "Iteration 2587: Loss = 0.2594, Accuracy = 0.8250 Test Loss = 0.2655, Test Accuracy = 0.8277\n",
      "Iteration 2588: Loss = 0.2608, Accuracy = 0.8270 Test Loss = 0.2654, Test Accuracy = 0.8290\n",
      "Iteration 2589: Loss = 0.2701, Accuracy = 0.8060 Test Loss = 0.2653, Test Accuracy = 0.8298\n",
      "Iteration 2590: Loss = 0.2564, Accuracy = 0.8300 Test Loss = 0.2653, Test Accuracy = 0.8294\n",
      "Iteration 2591: Loss = 0.2536, Accuracy = 0.8220 Test Loss = 0.2654, Test Accuracy = 0.8287\n",
      "Iteration 2592: Loss = 0.2792, Accuracy = 0.8200 Test Loss = 0.2653, Test Accuracy = 0.8295\n",
      "Iteration 2593: Loss = 0.2568, Accuracy = 0.8230 Test Loss = 0.2653, Test Accuracy = 0.8272\n",
      "Iteration 2594: Loss = 0.2641, Accuracy = 0.8210 Test Loss = 0.2653, Test Accuracy = 0.8286\n",
      "Iteration 2595: Loss = 0.2520, Accuracy = 0.8090 Test Loss = 0.2652, Test Accuracy = 0.8282\n",
      "Iteration 2596: Loss = 0.2783, Accuracy = 0.8210 Test Loss = 0.2651, Test Accuracy = 0.8298\n",
      "Iteration 2597: Loss = 0.2636, Accuracy = 0.8000 Test Loss = 0.2652, Test Accuracy = 0.8287\n",
      "Iteration 2598: Loss = 0.2595, Accuracy = 0.8420 Test Loss = 0.2651, Test Accuracy = 0.8299\n",
      "Iteration 2599: Loss = 0.2454, Accuracy = 0.8320 Test Loss = 0.2651, Test Accuracy = 0.8301\n",
      "Iteration 2600: Loss = 0.2708, Accuracy = 0.7980 Test Loss = 0.2650, Test Accuracy = 0.8292\n",
      "Iteration 2601: Loss = 0.2627, Accuracy = 0.8300 Test Loss = 0.2649, Test Accuracy = 0.8314\n",
      "Iteration 2602: Loss = 0.2777, Accuracy = 0.8290 Test Loss = 0.2649, Test Accuracy = 0.8305\n",
      "Iteration 2603: Loss = 0.2462, Accuracy = 0.8380 Test Loss = 0.2649, Test Accuracy = 0.8301\n",
      "Iteration 2604: Loss = 0.2549, Accuracy = 0.8370 Test Loss = 0.2648, Test Accuracy = 0.8291\n",
      "Iteration 2605: Loss = 0.2522, Accuracy = 0.8190 Test Loss = 0.2648, Test Accuracy = 0.8286\n",
      "Iteration 2606: Loss = 0.2887, Accuracy = 0.8020 Test Loss = 0.2648, Test Accuracy = 0.8285\n",
      "Iteration 2607: Loss = 0.2780, Accuracy = 0.8110 Test Loss = 0.2647, Test Accuracy = 0.8308\n",
      "Iteration 2608: Loss = 0.2576, Accuracy = 0.8250 Test Loss = 0.2647, Test Accuracy = 0.8296\n",
      "Iteration 2609: Loss = 0.2867, Accuracy = 0.8360 Test Loss = 0.2647, Test Accuracy = 0.8300\n",
      "Iteration 2610: Loss = 0.2607, Accuracy = 0.8240 Test Loss = 0.2647, Test Accuracy = 0.8294\n",
      "Iteration 2611: Loss = 0.2621, Accuracy = 0.8290 Test Loss = 0.2646, Test Accuracy = 0.8299\n",
      "Iteration 2612: Loss = 0.2763, Accuracy = 0.8190 Test Loss = 0.2646, Test Accuracy = 0.8276\n",
      "Iteration 2613: Loss = 0.2637, Accuracy = 0.8270 Test Loss = 0.2646, Test Accuracy = 0.8295\n",
      "Iteration 2614: Loss = 0.2498, Accuracy = 0.8380 Test Loss = 0.2645, Test Accuracy = 0.8301\n",
      "Iteration 2615: Loss = 0.2629, Accuracy = 0.8300 Test Loss = 0.2645, Test Accuracy = 0.8288\n",
      "Iteration 2616: Loss = 0.2606, Accuracy = 0.8330 Test Loss = 0.2644, Test Accuracy = 0.8292\n",
      "Iteration 2617: Loss = 0.2667, Accuracy = 0.8300 Test Loss = 0.2644, Test Accuracy = 0.8287\n",
      "Iteration 2618: Loss = 0.2755, Accuracy = 0.8160 Test Loss = 0.2644, Test Accuracy = 0.8312\n",
      "Iteration 2619: Loss = 0.2754, Accuracy = 0.8200 Test Loss = 0.2644, Test Accuracy = 0.8301\n",
      "Iteration 2620: Loss = 0.2675, Accuracy = 0.8120 Test Loss = 0.2642, Test Accuracy = 0.8300\n",
      "Iteration 2621: Loss = 0.2782, Accuracy = 0.8230 Test Loss = 0.2643, Test Accuracy = 0.8300\n",
      "Iteration 2622: Loss = 0.2739, Accuracy = 0.8260 Test Loss = 0.2643, Test Accuracy = 0.8303\n",
      "Iteration 2623: Loss = 0.2706, Accuracy = 0.8060 Test Loss = 0.2642, Test Accuracy = 0.8303\n",
      "Iteration 2624: Loss = 0.2507, Accuracy = 0.8260 Test Loss = 0.2643, Test Accuracy = 0.8289\n",
      "Iteration 2625: Loss = 0.2696, Accuracy = 0.8210 Test Loss = 0.2642, Test Accuracy = 0.8310\n",
      "Iteration 2626: Loss = 0.2479, Accuracy = 0.8140 Test Loss = 0.2642, Test Accuracy = 0.8303\n",
      "Iteration 2627: Loss = 0.2462, Accuracy = 0.8280 Test Loss = 0.2641, Test Accuracy = 0.8301\n",
      "Iteration 2628: Loss = 0.2746, Accuracy = 0.8320 Test Loss = 0.2642, Test Accuracy = 0.8298\n",
      "Iteration 2629: Loss = 0.2619, Accuracy = 0.8340 Test Loss = 0.2641, Test Accuracy = 0.8284\n",
      "Iteration 2630: Loss = 0.2602, Accuracy = 0.8130 Test Loss = 0.2641, Test Accuracy = 0.8310\n",
      "Iteration 2631: Loss = 0.2527, Accuracy = 0.8300 Test Loss = 0.2639, Test Accuracy = 0.8306\n",
      "Iteration 2632: Loss = 0.2817, Accuracy = 0.8080 Test Loss = 0.2640, Test Accuracy = 0.8301\n",
      "Iteration 2633: Loss = 0.2631, Accuracy = 0.8140 Test Loss = 0.2639, Test Accuracy = 0.8286\n",
      "Iteration 2634: Loss = 0.2725, Accuracy = 0.8040 Test Loss = 0.2638, Test Accuracy = 0.8296\n",
      "Iteration 2635: Loss = 0.2643, Accuracy = 0.8580 Test Loss = 0.2638, Test Accuracy = 0.8293\n",
      "Iteration 2636: Loss = 0.2873, Accuracy = 0.8290 Test Loss = 0.2640, Test Accuracy = 0.8287\n",
      "Iteration 2637: Loss = 0.2691, Accuracy = 0.8320 Test Loss = 0.2638, Test Accuracy = 0.8310\n",
      "Iteration 2638: Loss = 0.2640, Accuracy = 0.8420 Test Loss = 0.2638, Test Accuracy = 0.8286\n",
      "Iteration 2639: Loss = 0.2606, Accuracy = 0.8370 Test Loss = 0.2638, Test Accuracy = 0.8293\n",
      "Iteration 2640: Loss = 0.2524, Accuracy = 0.8340 Test Loss = 0.2637, Test Accuracy = 0.8302\n",
      "Iteration 2641: Loss = 0.2491, Accuracy = 0.8300 Test Loss = 0.2636, Test Accuracy = 0.8309\n",
      "Iteration 2642: Loss = 0.2723, Accuracy = 0.8090 Test Loss = 0.2637, Test Accuracy = 0.8303\n",
      "Iteration 2643: Loss = 0.2586, Accuracy = 0.8420 Test Loss = 0.2636, Test Accuracy = 0.8296\n",
      "Iteration 2644: Loss = 0.2646, Accuracy = 0.8190 Test Loss = 0.2637, Test Accuracy = 0.8297\n",
      "Iteration 2645: Loss = 0.2535, Accuracy = 0.8270 Test Loss = 0.2636, Test Accuracy = 0.8301\n",
      "Iteration 2646: Loss = 0.2625, Accuracy = 0.8020 Test Loss = 0.2636, Test Accuracy = 0.8305\n",
      "Iteration 2647: Loss = 0.2527, Accuracy = 0.8180 Test Loss = 0.2635, Test Accuracy = 0.8296\n",
      "Iteration 2648: Loss = 0.2567, Accuracy = 0.8150 Test Loss = 0.2635, Test Accuracy = 0.8299\n",
      "Iteration 2649: Loss = 0.2498, Accuracy = 0.8370 Test Loss = 0.2634, Test Accuracy = 0.8303\n",
      "Iteration 2650: Loss = 0.2569, Accuracy = 0.8420 Test Loss = 0.2635, Test Accuracy = 0.8285\n",
      "Iteration 2651: Loss = 0.2484, Accuracy = 0.8420 Test Loss = 0.2634, Test Accuracy = 0.8300\n",
      "Iteration 2652: Loss = 0.2918, Accuracy = 0.8090 Test Loss = 0.2632, Test Accuracy = 0.8290\n",
      "Iteration 2653: Loss = 0.2538, Accuracy = 0.8230 Test Loss = 0.2633, Test Accuracy = 0.8286\n",
      "Iteration 2654: Loss = 0.2530, Accuracy = 0.8440 Test Loss = 0.2634, Test Accuracy = 0.8280\n",
      "Iteration 2655: Loss = 0.2696, Accuracy = 0.8360 Test Loss = 0.2633, Test Accuracy = 0.8292\n",
      "Iteration 2656: Loss = 0.2479, Accuracy = 0.8310 Test Loss = 0.2632, Test Accuracy = 0.8297\n",
      "Iteration 2657: Loss = 0.2484, Accuracy = 0.8340 Test Loss = 0.2633, Test Accuracy = 0.8294\n",
      "Iteration 2658: Loss = 0.2562, Accuracy = 0.8340 Test Loss = 0.2632, Test Accuracy = 0.8291\n",
      "Iteration 2659: Loss = 0.2537, Accuracy = 0.8570 Test Loss = 0.2631, Test Accuracy = 0.8297\n",
      "Iteration 2660: Loss = 0.2699, Accuracy = 0.8280 Test Loss = 0.2631, Test Accuracy = 0.8298\n",
      "Iteration 2661: Loss = 0.2619, Accuracy = 0.8310 Test Loss = 0.2632, Test Accuracy = 0.8292\n",
      "Iteration 2662: Loss = 0.2571, Accuracy = 0.8190 Test Loss = 0.2630, Test Accuracy = 0.8306\n",
      "Iteration 2663: Loss = 0.2643, Accuracy = 0.8080 Test Loss = 0.2630, Test Accuracy = 0.8314\n",
      "Iteration 2664: Loss = 0.2770, Accuracy = 0.8170 Test Loss = 0.2630, Test Accuracy = 0.8288\n",
      "Iteration 2665: Loss = 0.2720, Accuracy = 0.8090 Test Loss = 0.2630, Test Accuracy = 0.8291\n",
      "Iteration 2666: Loss = 0.2438, Accuracy = 0.8400 Test Loss = 0.2629, Test Accuracy = 0.8309\n",
      "Iteration 2667: Loss = 0.2931, Accuracy = 0.8110 Test Loss = 0.2631, Test Accuracy = 0.8297\n",
      "Iteration 2668: Loss = 0.2497, Accuracy = 0.8320 Test Loss = 0.2628, Test Accuracy = 0.8298\n",
      "Iteration 2669: Loss = 0.2580, Accuracy = 0.8250 Test Loss = 0.2629, Test Accuracy = 0.8299\n",
      "Iteration 2670: Loss = 0.2698, Accuracy = 0.8190 Test Loss = 0.2627, Test Accuracy = 0.8300\n",
      "Iteration 2671: Loss = 0.2599, Accuracy = 0.8320 Test Loss = 0.2628, Test Accuracy = 0.8292\n",
      "Iteration 2672: Loss = 0.2725, Accuracy = 0.8200 Test Loss = 0.2627, Test Accuracy = 0.8299\n",
      "Iteration 2673: Loss = 0.2515, Accuracy = 0.8430 Test Loss = 0.2628, Test Accuracy = 0.8296\n",
      "Iteration 2674: Loss = 0.2556, Accuracy = 0.8210 Test Loss = 0.2628, Test Accuracy = 0.8306\n",
      "Iteration 2675: Loss = 0.2510, Accuracy = 0.8260 Test Loss = 0.2627, Test Accuracy = 0.8294\n",
      "Iteration 2676: Loss = 0.2684, Accuracy = 0.8090 Test Loss = 0.2626, Test Accuracy = 0.8302\n",
      "Iteration 2677: Loss = 0.2595, Accuracy = 0.8350 Test Loss = 0.2626, Test Accuracy = 0.8302\n",
      "Iteration 2678: Loss = 0.2599, Accuracy = 0.8280 Test Loss = 0.2626, Test Accuracy = 0.8298\n",
      "Iteration 2679: Loss = 0.2653, Accuracy = 0.8280 Test Loss = 0.2625, Test Accuracy = 0.8297\n",
      "Iteration 2680: Loss = 0.2609, Accuracy = 0.7990 Test Loss = 0.2625, Test Accuracy = 0.8317\n",
      "Iteration 2681: Loss = 0.2555, Accuracy = 0.8320 Test Loss = 0.2625, Test Accuracy = 0.8290\n",
      "Iteration 2682: Loss = 0.2548, Accuracy = 0.8310 Test Loss = 0.2625, Test Accuracy = 0.8305\n",
      "Iteration 2683: Loss = 0.2885, Accuracy = 0.8050 Test Loss = 0.2625, Test Accuracy = 0.8309\n",
      "Iteration 2684: Loss = 0.2501, Accuracy = 0.8330 Test Loss = 0.2624, Test Accuracy = 0.8307\n",
      "Iteration 2685: Loss = 0.2674, Accuracy = 0.8160 Test Loss = 0.2623, Test Accuracy = 0.8300\n",
      "Iteration 2686: Loss = 0.2509, Accuracy = 0.8460 Test Loss = 0.2623, Test Accuracy = 0.8300\n",
      "Iteration 2687: Loss = 0.2593, Accuracy = 0.8360 Test Loss = 0.2622, Test Accuracy = 0.8294\n",
      "Iteration 2688: Loss = 0.2440, Accuracy = 0.8430 Test Loss = 0.2622, Test Accuracy = 0.8304\n",
      "Iteration 2689: Loss = 0.2520, Accuracy = 0.8320 Test Loss = 0.2622, Test Accuracy = 0.8308\n",
      "Iteration 2690: Loss = 0.2643, Accuracy = 0.8280 Test Loss = 0.2621, Test Accuracy = 0.8296\n",
      "Iteration 2691: Loss = 0.2869, Accuracy = 0.8260 Test Loss = 0.2621, Test Accuracy = 0.8303\n",
      "Iteration 2692: Loss = 0.2682, Accuracy = 0.8190 Test Loss = 0.2621, Test Accuracy = 0.8302\n",
      "Iteration 2693: Loss = 0.2545, Accuracy = 0.8330 Test Loss = 0.2621, Test Accuracy = 0.8299\n",
      "Iteration 2694: Loss = 0.2771, Accuracy = 0.8260 Test Loss = 0.2621, Test Accuracy = 0.8314\n",
      "Iteration 2695: Loss = 0.2523, Accuracy = 0.8260 Test Loss = 0.2621, Test Accuracy = 0.8300\n",
      "Iteration 2696: Loss = 0.2635, Accuracy = 0.8400 Test Loss = 0.2620, Test Accuracy = 0.8304\n",
      "Iteration 2697: Loss = 0.2405, Accuracy = 0.8330 Test Loss = 0.2621, Test Accuracy = 0.8294\n",
      "Iteration 2698: Loss = 0.2542, Accuracy = 0.8430 Test Loss = 0.2621, Test Accuracy = 0.8308\n",
      "Iteration 2699: Loss = 0.2644, Accuracy = 0.8220 Test Loss = 0.2619, Test Accuracy = 0.8300\n",
      "Iteration 2700: Loss = 0.2558, Accuracy = 0.8400 Test Loss = 0.2620, Test Accuracy = 0.8287\n",
      "Iteration 2701: Loss = 0.2580, Accuracy = 0.8370 Test Loss = 0.2619, Test Accuracy = 0.8302\n",
      "Iteration 2702: Loss = 0.2561, Accuracy = 0.8260 Test Loss = 0.2619, Test Accuracy = 0.8294\n",
      "Iteration 2703: Loss = 0.2699, Accuracy = 0.8250 Test Loss = 0.2618, Test Accuracy = 0.8308\n",
      "Iteration 2704: Loss = 0.2566, Accuracy = 0.8240 Test Loss = 0.2618, Test Accuracy = 0.8316\n",
      "Iteration 2705: Loss = 0.2706, Accuracy = 0.8200 Test Loss = 0.2617, Test Accuracy = 0.8296\n",
      "Iteration 2706: Loss = 0.2637, Accuracy = 0.8290 Test Loss = 0.2619, Test Accuracy = 0.8293\n",
      "Iteration 2707: Loss = 0.2516, Accuracy = 0.8300 Test Loss = 0.2617, Test Accuracy = 0.8302\n",
      "Iteration 2708: Loss = 0.2383, Accuracy = 0.8470 Test Loss = 0.2617, Test Accuracy = 0.8301\n",
      "Iteration 2709: Loss = 0.2653, Accuracy = 0.8220 Test Loss = 0.2617, Test Accuracy = 0.8297\n",
      "Iteration 2710: Loss = 0.2522, Accuracy = 0.8230 Test Loss = 0.2616, Test Accuracy = 0.8322\n",
      "Iteration 2711: Loss = 0.2593, Accuracy = 0.8170 Test Loss = 0.2617, Test Accuracy = 0.8290\n",
      "Iteration 2712: Loss = 0.2834, Accuracy = 0.8170 Test Loss = 0.2616, Test Accuracy = 0.8303\n",
      "Iteration 2713: Loss = 0.2483, Accuracy = 0.8540 Test Loss = 0.2615, Test Accuracy = 0.8288\n",
      "Iteration 2714: Loss = 0.2484, Accuracy = 0.8330 Test Loss = 0.2615, Test Accuracy = 0.8307\n",
      "Iteration 2715: Loss = 0.2609, Accuracy = 0.8200 Test Loss = 0.2614, Test Accuracy = 0.8301\n",
      "Iteration 2716: Loss = 0.2540, Accuracy = 0.8400 Test Loss = 0.2615, Test Accuracy = 0.8315\n",
      "Iteration 2717: Loss = 0.2541, Accuracy = 0.8270 Test Loss = 0.2616, Test Accuracy = 0.8296\n",
      "Iteration 2718: Loss = 0.2486, Accuracy = 0.8370 Test Loss = 0.2614, Test Accuracy = 0.8292\n",
      "Iteration 2719: Loss = 0.2687, Accuracy = 0.8250 Test Loss = 0.2613, Test Accuracy = 0.8301\n",
      "Iteration 2720: Loss = 0.2603, Accuracy = 0.7950 Test Loss = 0.2613, Test Accuracy = 0.8303\n",
      "Iteration 2721: Loss = 0.2687, Accuracy = 0.8060 Test Loss = 0.2614, Test Accuracy = 0.8299\n",
      "Iteration 2722: Loss = 0.2587, Accuracy = 0.8210 Test Loss = 0.2612, Test Accuracy = 0.8302\n",
      "Iteration 2723: Loss = 0.2357, Accuracy = 0.8540 Test Loss = 0.2612, Test Accuracy = 0.8297\n",
      "Iteration 2724: Loss = 0.2555, Accuracy = 0.8290 Test Loss = 0.2612, Test Accuracy = 0.8302\n",
      "Iteration 2725: Loss = 0.2811, Accuracy = 0.8370 Test Loss = 0.2612, Test Accuracy = 0.8310\n",
      "Iteration 2726: Loss = 0.2645, Accuracy = 0.8210 Test Loss = 0.2611, Test Accuracy = 0.8307\n",
      "Iteration 2727: Loss = 0.2619, Accuracy = 0.8270 Test Loss = 0.2611, Test Accuracy = 0.8298\n",
      "Iteration 2728: Loss = 0.2778, Accuracy = 0.8280 Test Loss = 0.2611, Test Accuracy = 0.8306\n",
      "Iteration 2729: Loss = 0.2605, Accuracy = 0.8180 Test Loss = 0.2611, Test Accuracy = 0.8293\n",
      "Iteration 2730: Loss = 0.2722, Accuracy = 0.8210 Test Loss = 0.2612, Test Accuracy = 0.8298\n",
      "Iteration 2731: Loss = 0.2614, Accuracy = 0.8130 Test Loss = 0.2610, Test Accuracy = 0.8310\n",
      "Iteration 2732: Loss = 0.2389, Accuracy = 0.8540 Test Loss = 0.2609, Test Accuracy = 0.8294\n",
      "Iteration 2733: Loss = 0.2581, Accuracy = 0.8420 Test Loss = 0.2609, Test Accuracy = 0.8310\n",
      "Iteration 2734: Loss = 0.2601, Accuracy = 0.8240 Test Loss = 0.2610, Test Accuracy = 0.8315\n",
      "Iteration 2735: Loss = 0.2465, Accuracy = 0.8270 Test Loss = 0.2609, Test Accuracy = 0.8302\n",
      "Iteration 2736: Loss = 0.2617, Accuracy = 0.8170 Test Loss = 0.2609, Test Accuracy = 0.8304\n",
      "Iteration 2737: Loss = 0.2683, Accuracy = 0.8420 Test Loss = 0.2608, Test Accuracy = 0.8306\n",
      "Iteration 2738: Loss = 0.2558, Accuracy = 0.8250 Test Loss = 0.2609, Test Accuracy = 0.8317\n",
      "Iteration 2739: Loss = 0.2731, Accuracy = 0.7900 Test Loss = 0.2608, Test Accuracy = 0.8293\n",
      "Iteration 2740: Loss = 0.2571, Accuracy = 0.8370 Test Loss = 0.2608, Test Accuracy = 0.8294\n",
      "Iteration 2741: Loss = 0.2633, Accuracy = 0.8190 Test Loss = 0.2607, Test Accuracy = 0.8304\n",
      "Iteration 2742: Loss = 0.2816, Accuracy = 0.8220 Test Loss = 0.2607, Test Accuracy = 0.8304\n",
      "Iteration 2743: Loss = 0.2608, Accuracy = 0.7960 Test Loss = 0.2606, Test Accuracy = 0.8311\n",
      "Iteration 2744: Loss = 0.2594, Accuracy = 0.8310 Test Loss = 0.2606, Test Accuracy = 0.8323\n",
      "Iteration 2745: Loss = 0.2470, Accuracy = 0.8330 Test Loss = 0.2605, Test Accuracy = 0.8309\n",
      "Iteration 2746: Loss = 0.2528, Accuracy = 0.8250 Test Loss = 0.2606, Test Accuracy = 0.8293\n",
      "Iteration 2747: Loss = 0.2499, Accuracy = 0.8240 Test Loss = 0.2605, Test Accuracy = 0.8305\n",
      "Iteration 2748: Loss = 0.2562, Accuracy = 0.8120 Test Loss = 0.2605, Test Accuracy = 0.8300\n",
      "Iteration 2749: Loss = 0.2446, Accuracy = 0.8430 Test Loss = 0.2605, Test Accuracy = 0.8307\n",
      "Iteration 2750: Loss = 0.2695, Accuracy = 0.8070 Test Loss = 0.2605, Test Accuracy = 0.8295\n",
      "Iteration 2751: Loss = 0.2551, Accuracy = 0.8280 Test Loss = 0.2604, Test Accuracy = 0.8303\n",
      "Iteration 2752: Loss = 0.2612, Accuracy = 0.8200 Test Loss = 0.2605, Test Accuracy = 0.8315\n",
      "Iteration 2753: Loss = 0.2619, Accuracy = 0.8210 Test Loss = 0.2604, Test Accuracy = 0.8285\n",
      "Iteration 2754: Loss = 0.2486, Accuracy = 0.8210 Test Loss = 0.2604, Test Accuracy = 0.8308\n",
      "Iteration 2755: Loss = 0.2785, Accuracy = 0.8000 Test Loss = 0.2603, Test Accuracy = 0.8301\n",
      "Iteration 2756: Loss = 0.2584, Accuracy = 0.8210 Test Loss = 0.2603, Test Accuracy = 0.8314\n",
      "Iteration 2757: Loss = 0.2550, Accuracy = 0.8290 Test Loss = 0.2603, Test Accuracy = 0.8306\n",
      "Iteration 2758: Loss = 0.2654, Accuracy = 0.8050 Test Loss = 0.2602, Test Accuracy = 0.8301\n",
      "Iteration 2759: Loss = 0.2664, Accuracy = 0.8290 Test Loss = 0.2601, Test Accuracy = 0.8294\n",
      "Iteration 2760: Loss = 0.2684, Accuracy = 0.7940 Test Loss = 0.2602, Test Accuracy = 0.8291\n",
      "Iteration 2761: Loss = 0.2631, Accuracy = 0.8160 Test Loss = 0.2601, Test Accuracy = 0.8307\n",
      "Iteration 2762: Loss = 0.2739, Accuracy = 0.8210 Test Loss = 0.2602, Test Accuracy = 0.8313\n",
      "Iteration 2763: Loss = 0.2481, Accuracy = 0.8410 Test Loss = 0.2601, Test Accuracy = 0.8320\n",
      "Iteration 2764: Loss = 0.2580, Accuracy = 0.8290 Test Loss = 0.2601, Test Accuracy = 0.8310\n",
      "Iteration 2765: Loss = 0.2563, Accuracy = 0.8360 Test Loss = 0.2601, Test Accuracy = 0.8301\n",
      "Iteration 2766: Loss = 0.2515, Accuracy = 0.8280 Test Loss = 0.2600, Test Accuracy = 0.8323\n",
      "Iteration 2767: Loss = 0.2614, Accuracy = 0.8230 Test Loss = 0.2600, Test Accuracy = 0.8311\n",
      "Iteration 2768: Loss = 0.2588, Accuracy = 0.8410 Test Loss = 0.2600, Test Accuracy = 0.8294\n",
      "Iteration 2769: Loss = 0.2590, Accuracy = 0.8250 Test Loss = 0.2599, Test Accuracy = 0.8298\n",
      "Iteration 2770: Loss = 0.2987, Accuracy = 0.8140 Test Loss = 0.2599, Test Accuracy = 0.8312\n",
      "Iteration 2771: Loss = 0.2581, Accuracy = 0.8190 Test Loss = 0.2598, Test Accuracy = 0.8311\n",
      "Iteration 2772: Loss = 0.2774, Accuracy = 0.8200 Test Loss = 0.2598, Test Accuracy = 0.8302\n",
      "Iteration 2773: Loss = 0.2424, Accuracy = 0.8320 Test Loss = 0.2599, Test Accuracy = 0.8305\n",
      "Iteration 2774: Loss = 0.2492, Accuracy = 0.8380 Test Loss = 0.2597, Test Accuracy = 0.8317\n",
      "Iteration 2775: Loss = 0.2438, Accuracy = 0.8380 Test Loss = 0.2598, Test Accuracy = 0.8310\n",
      "Iteration 2776: Loss = 0.2655, Accuracy = 0.8360 Test Loss = 0.2597, Test Accuracy = 0.8302\n",
      "Iteration 2777: Loss = 0.2625, Accuracy = 0.8300 Test Loss = 0.2597, Test Accuracy = 0.8303\n",
      "Iteration 2778: Loss = 0.2642, Accuracy = 0.8400 Test Loss = 0.2597, Test Accuracy = 0.8302\n",
      "Iteration 2779: Loss = 0.2714, Accuracy = 0.8290 Test Loss = 0.2597, Test Accuracy = 0.8317\n",
      "Iteration 2780: Loss = 0.2582, Accuracy = 0.8250 Test Loss = 0.2596, Test Accuracy = 0.8312\n",
      "Iteration 2781: Loss = 0.2696, Accuracy = 0.8080 Test Loss = 0.2596, Test Accuracy = 0.8298\n",
      "Iteration 2782: Loss = 0.2783, Accuracy = 0.8240 Test Loss = 0.2596, Test Accuracy = 0.8310\n",
      "Iteration 2783: Loss = 0.2514, Accuracy = 0.8280 Test Loss = 0.2595, Test Accuracy = 0.8308\n",
      "Iteration 2784: Loss = 0.2680, Accuracy = 0.8010 Test Loss = 0.2595, Test Accuracy = 0.8304\n",
      "Iteration 2785: Loss = 0.2592, Accuracy = 0.8260 Test Loss = 0.2595, Test Accuracy = 0.8312\n",
      "Iteration 2786: Loss = 0.2506, Accuracy = 0.8350 Test Loss = 0.2595, Test Accuracy = 0.8318\n",
      "Iteration 2787: Loss = 0.2487, Accuracy = 0.8430 Test Loss = 0.2594, Test Accuracy = 0.8324\n",
      "Iteration 2788: Loss = 0.2440, Accuracy = 0.8520 Test Loss = 0.2594, Test Accuracy = 0.8305\n",
      "Iteration 2789: Loss = 0.2498, Accuracy = 0.8280 Test Loss = 0.2594, Test Accuracy = 0.8305\n",
      "Iteration 2790: Loss = 0.2494, Accuracy = 0.8230 Test Loss = 0.2594, Test Accuracy = 0.8302\n",
      "Iteration 2791: Loss = 0.2533, Accuracy = 0.8430 Test Loss = 0.2592, Test Accuracy = 0.8306\n",
      "Iteration 2792: Loss = 0.2708, Accuracy = 0.8330 Test Loss = 0.2593, Test Accuracy = 0.8305\n",
      "Iteration 2793: Loss = 0.2548, Accuracy = 0.8180 Test Loss = 0.2593, Test Accuracy = 0.8311\n",
      "Iteration 2794: Loss = 0.2531, Accuracy = 0.8150 Test Loss = 0.2592, Test Accuracy = 0.8316\n",
      "Iteration 2795: Loss = 0.2554, Accuracy = 0.8150 Test Loss = 0.2593, Test Accuracy = 0.8311\n",
      "Iteration 2796: Loss = 0.2656, Accuracy = 0.8090 Test Loss = 0.2592, Test Accuracy = 0.8316\n",
      "Iteration 2797: Loss = 0.2485, Accuracy = 0.8340 Test Loss = 0.2592, Test Accuracy = 0.8316\n",
      "Iteration 2798: Loss = 0.2412, Accuracy = 0.8550 Test Loss = 0.2591, Test Accuracy = 0.8301\n",
      "Iteration 2799: Loss = 0.2687, Accuracy = 0.8170 Test Loss = 0.2592, Test Accuracy = 0.8288\n",
      "Iteration 2800: Loss = 0.2596, Accuracy = 0.8250 Test Loss = 0.2592, Test Accuracy = 0.8297\n",
      "Iteration 2801: Loss = 0.2500, Accuracy = 0.8360 Test Loss = 0.2592, Test Accuracy = 0.8318\n",
      "Iteration 2802: Loss = 0.2483, Accuracy = 0.8300 Test Loss = 0.2590, Test Accuracy = 0.8305\n",
      "Iteration 2803: Loss = 0.2759, Accuracy = 0.7970 Test Loss = 0.2591, Test Accuracy = 0.8311\n",
      "Iteration 2804: Loss = 0.2646, Accuracy = 0.8230 Test Loss = 0.2590, Test Accuracy = 0.8306\n",
      "Iteration 2805: Loss = 0.2547, Accuracy = 0.8280 Test Loss = 0.2589, Test Accuracy = 0.8307\n",
      "Iteration 2806: Loss = 0.2460, Accuracy = 0.8250 Test Loss = 0.2589, Test Accuracy = 0.8307\n",
      "Iteration 2807: Loss = 0.2644, Accuracy = 0.8310 Test Loss = 0.2589, Test Accuracy = 0.8311\n",
      "Iteration 2808: Loss = 0.2592, Accuracy = 0.8130 Test Loss = 0.2589, Test Accuracy = 0.8324\n",
      "Iteration 2809: Loss = 0.2552, Accuracy = 0.8220 Test Loss = 0.2588, Test Accuracy = 0.8306\n",
      "Iteration 2810: Loss = 0.2631, Accuracy = 0.8340 Test Loss = 0.2588, Test Accuracy = 0.8300\n",
      "Iteration 2811: Loss = 0.2594, Accuracy = 0.8160 Test Loss = 0.2587, Test Accuracy = 0.8315\n",
      "Iteration 2812: Loss = 0.2574, Accuracy = 0.8310 Test Loss = 0.2589, Test Accuracy = 0.8296\n",
      "Iteration 2813: Loss = 0.2617, Accuracy = 0.8350 Test Loss = 0.2588, Test Accuracy = 0.8302\n",
      "Iteration 2814: Loss = 0.2492, Accuracy = 0.8310 Test Loss = 0.2588, Test Accuracy = 0.8312\n",
      "Iteration 2815: Loss = 0.2412, Accuracy = 0.8380 Test Loss = 0.2587, Test Accuracy = 0.8301\n",
      "Iteration 2816: Loss = 0.2584, Accuracy = 0.8270 Test Loss = 0.2587, Test Accuracy = 0.8306\n",
      "Iteration 2817: Loss = 0.2688, Accuracy = 0.8340 Test Loss = 0.2586, Test Accuracy = 0.8314\n",
      "Iteration 2818: Loss = 0.2614, Accuracy = 0.8240 Test Loss = 0.2586, Test Accuracy = 0.8299\n",
      "Iteration 2819: Loss = 0.2498, Accuracy = 0.8340 Test Loss = 0.2586, Test Accuracy = 0.8313\n",
      "Iteration 2820: Loss = 0.2780, Accuracy = 0.7930 Test Loss = 0.2586, Test Accuracy = 0.8318\n",
      "Iteration 2821: Loss = 0.2650, Accuracy = 0.8260 Test Loss = 0.2586, Test Accuracy = 0.8314\n",
      "Iteration 2822: Loss = 0.2559, Accuracy = 0.8100 Test Loss = 0.2585, Test Accuracy = 0.8305\n",
      "Iteration 2823: Loss = 0.2576, Accuracy = 0.8150 Test Loss = 0.2585, Test Accuracy = 0.8324\n",
      "Iteration 2824: Loss = 0.2409, Accuracy = 0.8300 Test Loss = 0.2584, Test Accuracy = 0.8308\n",
      "Iteration 2825: Loss = 0.2531, Accuracy = 0.8070 Test Loss = 0.2584, Test Accuracy = 0.8317\n",
      "Iteration 2826: Loss = 0.2530, Accuracy = 0.8460 Test Loss = 0.2584, Test Accuracy = 0.8303\n",
      "Iteration 2827: Loss = 0.2474, Accuracy = 0.8350 Test Loss = 0.2583, Test Accuracy = 0.8314\n",
      "Iteration 2828: Loss = 0.2396, Accuracy = 0.8170 Test Loss = 0.2584, Test Accuracy = 0.8311\n",
      "Iteration 2829: Loss = 0.2616, Accuracy = 0.8110 Test Loss = 0.2583, Test Accuracy = 0.8314\n",
      "Iteration 2830: Loss = 0.2589, Accuracy = 0.8320 Test Loss = 0.2584, Test Accuracy = 0.8306\n",
      "Iteration 2831: Loss = 0.2552, Accuracy = 0.8050 Test Loss = 0.2583, Test Accuracy = 0.8304\n",
      "Iteration 2832: Loss = 0.2579, Accuracy = 0.8220 Test Loss = 0.2582, Test Accuracy = 0.8303\n",
      "Iteration 2833: Loss = 0.2444, Accuracy = 0.8410 Test Loss = 0.2582, Test Accuracy = 0.8314\n",
      "Iteration 2834: Loss = 0.2640, Accuracy = 0.8220 Test Loss = 0.2582, Test Accuracy = 0.8318\n",
      "Iteration 2835: Loss = 0.2549, Accuracy = 0.8240 Test Loss = 0.2582, Test Accuracy = 0.8314\n",
      "Iteration 2836: Loss = 0.2338, Accuracy = 0.8520 Test Loss = 0.2582, Test Accuracy = 0.8314\n",
      "Iteration 2837: Loss = 0.2675, Accuracy = 0.8420 Test Loss = 0.2582, Test Accuracy = 0.8310\n",
      "Iteration 2838: Loss = 0.2806, Accuracy = 0.8040 Test Loss = 0.2580, Test Accuracy = 0.8322\n",
      "Iteration 2839: Loss = 0.2509, Accuracy = 0.8410 Test Loss = 0.2580, Test Accuracy = 0.8313\n",
      "Iteration 2840: Loss = 0.2487, Accuracy = 0.8070 Test Loss = 0.2580, Test Accuracy = 0.8318\n",
      "Iteration 2841: Loss = 0.2494, Accuracy = 0.8260 Test Loss = 0.2580, Test Accuracy = 0.8311\n",
      "Iteration 2842: Loss = 0.2708, Accuracy = 0.8180 Test Loss = 0.2580, Test Accuracy = 0.8310\n",
      "Iteration 2843: Loss = 0.2640, Accuracy = 0.8190 Test Loss = 0.2578, Test Accuracy = 0.8320\n",
      "Iteration 2844: Loss = 0.2608, Accuracy = 0.8280 Test Loss = 0.2579, Test Accuracy = 0.8309\n",
      "Iteration 2845: Loss = 0.2618, Accuracy = 0.8120 Test Loss = 0.2578, Test Accuracy = 0.8321\n",
      "Iteration 2846: Loss = 0.2487, Accuracy = 0.8400 Test Loss = 0.2579, Test Accuracy = 0.8323\n",
      "Iteration 2847: Loss = 0.2537, Accuracy = 0.8280 Test Loss = 0.2579, Test Accuracy = 0.8323\n",
      "Iteration 2848: Loss = 0.2823, Accuracy = 0.8100 Test Loss = 0.2578, Test Accuracy = 0.8303\n",
      "Iteration 2849: Loss = 0.2575, Accuracy = 0.8260 Test Loss = 0.2577, Test Accuracy = 0.8315\n",
      "Iteration 2850: Loss = 0.2761, Accuracy = 0.8020 Test Loss = 0.2577, Test Accuracy = 0.8311\n",
      "Iteration 2851: Loss = 0.2563, Accuracy = 0.8290 Test Loss = 0.2577, Test Accuracy = 0.8320\n",
      "Iteration 2852: Loss = 0.2674, Accuracy = 0.8110 Test Loss = 0.2577, Test Accuracy = 0.8332\n",
      "Iteration 2853: Loss = 0.2459, Accuracy = 0.8470 Test Loss = 0.2578, Test Accuracy = 0.8330\n",
      "Iteration 2854: Loss = 0.2526, Accuracy = 0.8380 Test Loss = 0.2577, Test Accuracy = 0.8322\n",
      "Iteration 2855: Loss = 0.2549, Accuracy = 0.8290 Test Loss = 0.2576, Test Accuracy = 0.8323\n",
      "Iteration 2856: Loss = 0.2568, Accuracy = 0.8140 Test Loss = 0.2577, Test Accuracy = 0.8336\n",
      "Iteration 2857: Loss = 0.2588, Accuracy = 0.8340 Test Loss = 0.2576, Test Accuracy = 0.8327\n",
      "Iteration 2858: Loss = 0.2627, Accuracy = 0.8520 Test Loss = 0.2575, Test Accuracy = 0.8319\n",
      "Iteration 2859: Loss = 0.2488, Accuracy = 0.8390 Test Loss = 0.2575, Test Accuracy = 0.8327\n",
      "Iteration 2860: Loss = 0.2419, Accuracy = 0.8390 Test Loss = 0.2575, Test Accuracy = 0.8314\n",
      "Iteration 2861: Loss = 0.2513, Accuracy = 0.8410 Test Loss = 0.2574, Test Accuracy = 0.8319\n",
      "Iteration 2862: Loss = 0.2453, Accuracy = 0.8430 Test Loss = 0.2575, Test Accuracy = 0.8311\n",
      "Iteration 2863: Loss = 0.2448, Accuracy = 0.8360 Test Loss = 0.2575, Test Accuracy = 0.8307\n",
      "Iteration 2864: Loss = 0.2432, Accuracy = 0.8330 Test Loss = 0.2574, Test Accuracy = 0.8331\n",
      "Iteration 2865: Loss = 0.2598, Accuracy = 0.8290 Test Loss = 0.2574, Test Accuracy = 0.8329\n",
      "Iteration 2866: Loss = 0.2697, Accuracy = 0.8190 Test Loss = 0.2574, Test Accuracy = 0.8323\n",
      "Iteration 2867: Loss = 0.2773, Accuracy = 0.8240 Test Loss = 0.2574, Test Accuracy = 0.8303\n",
      "Iteration 2868: Loss = 0.2442, Accuracy = 0.8170 Test Loss = 0.2573, Test Accuracy = 0.8308\n",
      "Iteration 2869: Loss = 0.2582, Accuracy = 0.8240 Test Loss = 0.2573, Test Accuracy = 0.8320\n",
      "Iteration 2870: Loss = 0.2482, Accuracy = 0.8420 Test Loss = 0.2573, Test Accuracy = 0.8327\n",
      "Iteration 2871: Loss = 0.2546, Accuracy = 0.8160 Test Loss = 0.2572, Test Accuracy = 0.8314\n",
      "Iteration 2872: Loss = 0.2523, Accuracy = 0.8180 Test Loss = 0.2573, Test Accuracy = 0.8333\n",
      "Iteration 2873: Loss = 0.2752, Accuracy = 0.8400 Test Loss = 0.2571, Test Accuracy = 0.8333\n",
      "Iteration 2874: Loss = 0.2726, Accuracy = 0.8370 Test Loss = 0.2571, Test Accuracy = 0.8327\n",
      "Iteration 2875: Loss = 0.2465, Accuracy = 0.8470 Test Loss = 0.2571, Test Accuracy = 0.8323\n",
      "Iteration 2876: Loss = 0.2600, Accuracy = 0.8450 Test Loss = 0.2571, Test Accuracy = 0.8329\n",
      "Iteration 2877: Loss = 0.2412, Accuracy = 0.8400 Test Loss = 0.2571, Test Accuracy = 0.8323\n",
      "Iteration 2878: Loss = 0.2577, Accuracy = 0.8170 Test Loss = 0.2570, Test Accuracy = 0.8325\n",
      "Iteration 2879: Loss = 0.2587, Accuracy = 0.8310 Test Loss = 0.2570, Test Accuracy = 0.8315\n",
      "Iteration 2880: Loss = 0.2943, Accuracy = 0.8110 Test Loss = 0.2569, Test Accuracy = 0.8325\n",
      "Iteration 2881: Loss = 0.2448, Accuracy = 0.8530 Test Loss = 0.2569, Test Accuracy = 0.8337\n",
      "Iteration 2882: Loss = 0.2466, Accuracy = 0.8330 Test Loss = 0.2569, Test Accuracy = 0.8324\n",
      "Iteration 2883: Loss = 0.2580, Accuracy = 0.8360 Test Loss = 0.2569, Test Accuracy = 0.8314\n",
      "Iteration 2884: Loss = 0.2527, Accuracy = 0.8330 Test Loss = 0.2569, Test Accuracy = 0.8324\n",
      "Iteration 2885: Loss = 0.2546, Accuracy = 0.8220 Test Loss = 0.2568, Test Accuracy = 0.8332\n",
      "Iteration 2886: Loss = 0.2456, Accuracy = 0.8390 Test Loss = 0.2568, Test Accuracy = 0.8329\n",
      "Iteration 2887: Loss = 0.2527, Accuracy = 0.8250 Test Loss = 0.2568, Test Accuracy = 0.8318\n",
      "Iteration 2888: Loss = 0.2562, Accuracy = 0.8440 Test Loss = 0.2567, Test Accuracy = 0.8327\n",
      "Iteration 2889: Loss = 0.2524, Accuracy = 0.8400 Test Loss = 0.2568, Test Accuracy = 0.8325\n",
      "Iteration 2890: Loss = 0.2419, Accuracy = 0.8270 Test Loss = 0.2568, Test Accuracy = 0.8329\n",
      "Iteration 2891: Loss = 0.2627, Accuracy = 0.8420 Test Loss = 0.2567, Test Accuracy = 0.8331\n",
      "Iteration 2892: Loss = 0.2739, Accuracy = 0.8190 Test Loss = 0.2567, Test Accuracy = 0.8323\n",
      "Iteration 2893: Loss = 0.2427, Accuracy = 0.8360 Test Loss = 0.2567, Test Accuracy = 0.8336\n",
      "Iteration 2894: Loss = 0.2730, Accuracy = 0.8020 Test Loss = 0.2567, Test Accuracy = 0.8321\n",
      "Iteration 2895: Loss = 0.2505, Accuracy = 0.8310 Test Loss = 0.2566, Test Accuracy = 0.8324\n",
      "Iteration 2896: Loss = 0.2597, Accuracy = 0.8280 Test Loss = 0.2566, Test Accuracy = 0.8331\n",
      "Iteration 2897: Loss = 0.2663, Accuracy = 0.8120 Test Loss = 0.2566, Test Accuracy = 0.8343\n",
      "Iteration 2898: Loss = 0.2609, Accuracy = 0.8260 Test Loss = 0.2565, Test Accuracy = 0.8319\n",
      "Iteration 2899: Loss = 0.2741, Accuracy = 0.8230 Test Loss = 0.2565, Test Accuracy = 0.8332\n",
      "Iteration 2900: Loss = 0.2524, Accuracy = 0.8260 Test Loss = 0.2565, Test Accuracy = 0.8317\n",
      "Iteration 2901: Loss = 0.2502, Accuracy = 0.8410 Test Loss = 0.2564, Test Accuracy = 0.8328\n",
      "Iteration 2902: Loss = 0.2472, Accuracy = 0.8280 Test Loss = 0.2564, Test Accuracy = 0.8315\n",
      "Iteration 2903: Loss = 0.2604, Accuracy = 0.8070 Test Loss = 0.2564, Test Accuracy = 0.8313\n",
      "Iteration 2904: Loss = 0.2472, Accuracy = 0.8270 Test Loss = 0.2563, Test Accuracy = 0.8317\n",
      "Iteration 2905: Loss = 0.2495, Accuracy = 0.8240 Test Loss = 0.2563, Test Accuracy = 0.8330\n",
      "Iteration 2906: Loss = 0.2449, Accuracy = 0.8420 Test Loss = 0.2563, Test Accuracy = 0.8321\n",
      "Iteration 2907: Loss = 0.2585, Accuracy = 0.8500 Test Loss = 0.2564, Test Accuracy = 0.8314\n",
      "Iteration 2908: Loss = 0.2770, Accuracy = 0.8090 Test Loss = 0.2563, Test Accuracy = 0.8329\n",
      "Iteration 2909: Loss = 0.2607, Accuracy = 0.8330 Test Loss = 0.2562, Test Accuracy = 0.8327\n",
      "Iteration 2910: Loss = 0.2413, Accuracy = 0.8490 Test Loss = 0.2563, Test Accuracy = 0.8337\n",
      "Iteration 2911: Loss = 0.2407, Accuracy = 0.8320 Test Loss = 0.2562, Test Accuracy = 0.8327\n",
      "Iteration 2912: Loss = 0.2470, Accuracy = 0.8170 Test Loss = 0.2561, Test Accuracy = 0.8336\n",
      "Iteration 2913: Loss = 0.2446, Accuracy = 0.8420 Test Loss = 0.2561, Test Accuracy = 0.8333\n",
      "Iteration 2914: Loss = 0.2480, Accuracy = 0.8510 Test Loss = 0.2561, Test Accuracy = 0.8334\n",
      "Iteration 2915: Loss = 0.2498, Accuracy = 0.8270 Test Loss = 0.2562, Test Accuracy = 0.8329\n",
      "Iteration 2916: Loss = 0.2540, Accuracy = 0.8370 Test Loss = 0.2561, Test Accuracy = 0.8316\n",
      "Iteration 2917: Loss = 0.2624, Accuracy = 0.8290 Test Loss = 0.2561, Test Accuracy = 0.8331\n",
      "Iteration 2918: Loss = 0.2396, Accuracy = 0.8320 Test Loss = 0.2560, Test Accuracy = 0.8327\n",
      "Iteration 2919: Loss = 0.2636, Accuracy = 0.8290 Test Loss = 0.2560, Test Accuracy = 0.8339\n",
      "Iteration 2920: Loss = 0.2443, Accuracy = 0.8250 Test Loss = 0.2559, Test Accuracy = 0.8338\n",
      "Iteration 2921: Loss = 0.2744, Accuracy = 0.8220 Test Loss = 0.2559, Test Accuracy = 0.8334\n",
      "Iteration 2922: Loss = 0.2307, Accuracy = 0.8390 Test Loss = 0.2559, Test Accuracy = 0.8326\n",
      "Iteration 2923: Loss = 0.2671, Accuracy = 0.8160 Test Loss = 0.2559, Test Accuracy = 0.8328\n",
      "Iteration 2924: Loss = 0.2490, Accuracy = 0.8220 Test Loss = 0.2558, Test Accuracy = 0.8326\n",
      "Iteration 2925: Loss = 0.2447, Accuracy = 0.8410 Test Loss = 0.2558, Test Accuracy = 0.8334\n",
      "Iteration 2926: Loss = 0.2444, Accuracy = 0.8460 Test Loss = 0.2558, Test Accuracy = 0.8341\n",
      "Iteration 2927: Loss = 0.2375, Accuracy = 0.8560 Test Loss = 0.2559, Test Accuracy = 0.8321\n",
      "Iteration 2928: Loss = 0.2631, Accuracy = 0.8140 Test Loss = 0.2558, Test Accuracy = 0.8321\n",
      "Iteration 2929: Loss = 0.2473, Accuracy = 0.8260 Test Loss = 0.2557, Test Accuracy = 0.8323\n",
      "Iteration 2930: Loss = 0.2407, Accuracy = 0.8490 Test Loss = 0.2557, Test Accuracy = 0.8318\n",
      "Iteration 2931: Loss = 0.2703, Accuracy = 0.8240 Test Loss = 0.2557, Test Accuracy = 0.8321\n",
      "Iteration 2932: Loss = 0.2457, Accuracy = 0.8310 Test Loss = 0.2557, Test Accuracy = 0.8332\n",
      "Iteration 2933: Loss = 0.2764, Accuracy = 0.8150 Test Loss = 0.2557, Test Accuracy = 0.8331\n",
      "Iteration 2934: Loss = 0.2561, Accuracy = 0.8270 Test Loss = 0.2557, Test Accuracy = 0.8333\n",
      "Iteration 2935: Loss = 0.2639, Accuracy = 0.8330 Test Loss = 0.2557, Test Accuracy = 0.8323\n",
      "Iteration 2936: Loss = 0.2605, Accuracy = 0.8350 Test Loss = 0.2556, Test Accuracy = 0.8323\n",
      "Iteration 2937: Loss = 0.2403, Accuracy = 0.8270 Test Loss = 0.2556, Test Accuracy = 0.8319\n",
      "Iteration 2938: Loss = 0.2548, Accuracy = 0.8410 Test Loss = 0.2556, Test Accuracy = 0.8329\n",
      "Iteration 2939: Loss = 0.2448, Accuracy = 0.8320 Test Loss = 0.2555, Test Accuracy = 0.8314\n",
      "Iteration 2940: Loss = 0.2432, Accuracy = 0.8380 Test Loss = 0.2555, Test Accuracy = 0.8342\n",
      "Iteration 2941: Loss = 0.2612, Accuracy = 0.8380 Test Loss = 0.2555, Test Accuracy = 0.8332\n",
      "Iteration 2942: Loss = 0.2461, Accuracy = 0.8400 Test Loss = 0.2555, Test Accuracy = 0.8315\n",
      "Iteration 2943: Loss = 0.2459, Accuracy = 0.8400 Test Loss = 0.2553, Test Accuracy = 0.8329\n",
      "Iteration 2944: Loss = 0.2540, Accuracy = 0.8180 Test Loss = 0.2554, Test Accuracy = 0.8330\n",
      "Iteration 2945: Loss = 0.2535, Accuracy = 0.8330 Test Loss = 0.2554, Test Accuracy = 0.8313\n",
      "Iteration 2946: Loss = 0.2409, Accuracy = 0.8500 Test Loss = 0.2552, Test Accuracy = 0.8328\n",
      "Iteration 2947: Loss = 0.2538, Accuracy = 0.8140 Test Loss = 0.2553, Test Accuracy = 0.8339\n",
      "Iteration 2948: Loss = 0.2456, Accuracy = 0.8430 Test Loss = 0.2553, Test Accuracy = 0.8330\n",
      "Iteration 2949: Loss = 0.2540, Accuracy = 0.8270 Test Loss = 0.2552, Test Accuracy = 0.8330\n",
      "Iteration 2950: Loss = 0.2416, Accuracy = 0.8430 Test Loss = 0.2552, Test Accuracy = 0.8329\n",
      "Iteration 2951: Loss = 0.2581, Accuracy = 0.8220 Test Loss = 0.2552, Test Accuracy = 0.8329\n",
      "Iteration 2952: Loss = 0.2511, Accuracy = 0.8200 Test Loss = 0.2552, Test Accuracy = 0.8340\n",
      "Iteration 2953: Loss = 0.2469, Accuracy = 0.8360 Test Loss = 0.2552, Test Accuracy = 0.8328\n",
      "Iteration 2954: Loss = 0.2506, Accuracy = 0.8330 Test Loss = 0.2552, Test Accuracy = 0.8323\n",
      "Iteration 2955: Loss = 0.2613, Accuracy = 0.8220 Test Loss = 0.2552, Test Accuracy = 0.8329\n",
      "Iteration 2956: Loss = 0.2563, Accuracy = 0.8330 Test Loss = 0.2551, Test Accuracy = 0.8322\n",
      "Iteration 2957: Loss = 0.2456, Accuracy = 0.8310 Test Loss = 0.2550, Test Accuracy = 0.8333\n",
      "Iteration 2958: Loss = 0.2480, Accuracy = 0.8410 Test Loss = 0.2550, Test Accuracy = 0.8324\n",
      "Iteration 2959: Loss = 0.2539, Accuracy = 0.8180 Test Loss = 0.2550, Test Accuracy = 0.8321\n",
      "Iteration 2960: Loss = 0.2478, Accuracy = 0.8330 Test Loss = 0.2550, Test Accuracy = 0.8341\n",
      "Iteration 2961: Loss = 0.2469, Accuracy = 0.8310 Test Loss = 0.2549, Test Accuracy = 0.8328\n",
      "Iteration 2962: Loss = 0.2611, Accuracy = 0.8220 Test Loss = 0.2551, Test Accuracy = 0.8342\n",
      "Iteration 2963: Loss = 0.2608, Accuracy = 0.8130 Test Loss = 0.2551, Test Accuracy = 0.8327\n",
      "Iteration 2964: Loss = 0.2451, Accuracy = 0.8290 Test Loss = 0.2549, Test Accuracy = 0.8329\n",
      "Iteration 2965: Loss = 0.2652, Accuracy = 0.8120 Test Loss = 0.2549, Test Accuracy = 0.8327\n",
      "Iteration 2966: Loss = 0.2518, Accuracy = 0.8250 Test Loss = 0.2549, Test Accuracy = 0.8336\n",
      "Iteration 2967: Loss = 0.2498, Accuracy = 0.8190 Test Loss = 0.2548, Test Accuracy = 0.8343\n",
      "Iteration 2968: Loss = 0.2404, Accuracy = 0.8300 Test Loss = 0.2548, Test Accuracy = 0.8339\n",
      "Iteration 2969: Loss = 0.2552, Accuracy = 0.8130 Test Loss = 0.2548, Test Accuracy = 0.8337\n",
      "Iteration 2970: Loss = 0.2551, Accuracy = 0.8230 Test Loss = 0.2547, Test Accuracy = 0.8329\n",
      "Iteration 2971: Loss = 0.2574, Accuracy = 0.8270 Test Loss = 0.2547, Test Accuracy = 0.8334\n",
      "Iteration 2972: Loss = 0.2461, Accuracy = 0.8230 Test Loss = 0.2548, Test Accuracy = 0.8339\n",
      "Iteration 2973: Loss = 0.2489, Accuracy = 0.8250 Test Loss = 0.2547, Test Accuracy = 0.8332\n",
      "Iteration 2974: Loss = 0.2551, Accuracy = 0.8130 Test Loss = 0.2547, Test Accuracy = 0.8340\n",
      "Iteration 2975: Loss = 0.2583, Accuracy = 0.8290 Test Loss = 0.2546, Test Accuracy = 0.8346\n",
      "Iteration 2976: Loss = 0.2545, Accuracy = 0.8080 Test Loss = 0.2546, Test Accuracy = 0.8332\n",
      "Iteration 2977: Loss = 0.2830, Accuracy = 0.8100 Test Loss = 0.2546, Test Accuracy = 0.8330\n",
      "Iteration 2978: Loss = 0.2524, Accuracy = 0.8060 Test Loss = 0.2546, Test Accuracy = 0.8336\n",
      "Iteration 2979: Loss = 0.2645, Accuracy = 0.8220 Test Loss = 0.2546, Test Accuracy = 0.8351\n",
      "Iteration 2980: Loss = 0.2511, Accuracy = 0.8350 Test Loss = 0.2545, Test Accuracy = 0.8342\n",
      "Iteration 2981: Loss = 0.2445, Accuracy = 0.8370 Test Loss = 0.2545, Test Accuracy = 0.8338\n",
      "Iteration 2982: Loss = 0.2593, Accuracy = 0.8190 Test Loss = 0.2545, Test Accuracy = 0.8323\n",
      "Iteration 2983: Loss = 0.2386, Accuracy = 0.8410 Test Loss = 0.2544, Test Accuracy = 0.8331\n",
      "Iteration 2984: Loss = 0.2504, Accuracy = 0.8310 Test Loss = 0.2544, Test Accuracy = 0.8346\n",
      "Iteration 2985: Loss = 0.2543, Accuracy = 0.8300 Test Loss = 0.2545, Test Accuracy = 0.8332\n",
      "Iteration 2986: Loss = 0.2487, Accuracy = 0.8370 Test Loss = 0.2544, Test Accuracy = 0.8331\n",
      "Iteration 2987: Loss = 0.2493, Accuracy = 0.8130 Test Loss = 0.2543, Test Accuracy = 0.8330\n",
      "Iteration 2988: Loss = 0.2310, Accuracy = 0.8300 Test Loss = 0.2543, Test Accuracy = 0.8343\n",
      "Iteration 2989: Loss = 0.2616, Accuracy = 0.8270 Test Loss = 0.2543, Test Accuracy = 0.8339\n",
      "Iteration 2990: Loss = 0.2570, Accuracy = 0.8280 Test Loss = 0.2543, Test Accuracy = 0.8326\n",
      "Iteration 2991: Loss = 0.2737, Accuracy = 0.8040 Test Loss = 0.2543, Test Accuracy = 0.8344\n",
      "Iteration 2992: Loss = 0.2441, Accuracy = 0.8510 Test Loss = 0.2543, Test Accuracy = 0.8352\n",
      "Iteration 2993: Loss = 0.2580, Accuracy = 0.8120 Test Loss = 0.2541, Test Accuracy = 0.8326\n",
      "Iteration 2994: Loss = 0.2520, Accuracy = 0.8430 Test Loss = 0.2542, Test Accuracy = 0.8344\n",
      "Iteration 2995: Loss = 0.2545, Accuracy = 0.8300 Test Loss = 0.2541, Test Accuracy = 0.8341\n",
      "Iteration 2996: Loss = 0.2397, Accuracy = 0.8410 Test Loss = 0.2541, Test Accuracy = 0.8346\n",
      "Iteration 2997: Loss = 0.2543, Accuracy = 0.8330 Test Loss = 0.2541, Test Accuracy = 0.8337\n",
      "Iteration 2998: Loss = 0.2589, Accuracy = 0.8040 Test Loss = 0.2541, Test Accuracy = 0.8343\n",
      "Iteration 2999: Loss = 0.2514, Accuracy = 0.8230 Test Loss = 0.2541, Test Accuracy = 0.8342\n",
      "Iteration 3000: Loss = 0.2624, Accuracy = 0.8270 Test Loss = 0.2541, Test Accuracy = 0.8345\n",
      "Iteration 3001: Loss = 0.2362, Accuracy = 0.8420 Test Loss = 0.2540, Test Accuracy = 0.8341\n",
      "Iteration 3002: Loss = 0.2715, Accuracy = 0.8090 Test Loss = 0.2540, Test Accuracy = 0.8345\n",
      "Iteration 3003: Loss = 0.2382, Accuracy = 0.8340 Test Loss = 0.2540, Test Accuracy = 0.8338\n",
      "Iteration 3004: Loss = 0.2677, Accuracy = 0.8400 Test Loss = 0.2540, Test Accuracy = 0.8347\n",
      "Iteration 3005: Loss = 0.2360, Accuracy = 0.8480 Test Loss = 0.2541, Test Accuracy = 0.8340\n",
      "Iteration 3006: Loss = 0.2335, Accuracy = 0.8390 Test Loss = 0.2539, Test Accuracy = 0.8331\n",
      "Iteration 3007: Loss = 0.2828, Accuracy = 0.7900 Test Loss = 0.2539, Test Accuracy = 0.8351\n",
      "Iteration 3008: Loss = 0.2480, Accuracy = 0.8090 Test Loss = 0.2539, Test Accuracy = 0.8336\n",
      "Iteration 3009: Loss = 0.2483, Accuracy = 0.8410 Test Loss = 0.2538, Test Accuracy = 0.8330\n",
      "Iteration 3010: Loss = 0.2458, Accuracy = 0.8330 Test Loss = 0.2539, Test Accuracy = 0.8347\n",
      "Iteration 3011: Loss = 0.2462, Accuracy = 0.8310 Test Loss = 0.2538, Test Accuracy = 0.8338\n",
      "Iteration 3012: Loss = 0.2521, Accuracy = 0.8150 Test Loss = 0.2538, Test Accuracy = 0.8328\n",
      "Iteration 3013: Loss = 0.2413, Accuracy = 0.8330 Test Loss = 0.2538, Test Accuracy = 0.8343\n",
      "Iteration 3014: Loss = 0.2437, Accuracy = 0.8150 Test Loss = 0.2537, Test Accuracy = 0.8349\n",
      "Iteration 3015: Loss = 0.2360, Accuracy = 0.8400 Test Loss = 0.2537, Test Accuracy = 0.8330\n",
      "Iteration 3016: Loss = 0.2535, Accuracy = 0.8270 Test Loss = 0.2537, Test Accuracy = 0.8346\n",
      "Iteration 3017: Loss = 0.2564, Accuracy = 0.8280 Test Loss = 0.2536, Test Accuracy = 0.8338\n",
      "Iteration 3018: Loss = 0.2596, Accuracy = 0.8130 Test Loss = 0.2536, Test Accuracy = 0.8324\n",
      "Iteration 3019: Loss = 0.2596, Accuracy = 0.8410 Test Loss = 0.2536, Test Accuracy = 0.8336\n",
      "Iteration 3020: Loss = 0.2706, Accuracy = 0.8390 Test Loss = 0.2536, Test Accuracy = 0.8323\n",
      "Iteration 3021: Loss = 0.2600, Accuracy = 0.8230 Test Loss = 0.2536, Test Accuracy = 0.8327\n",
      "Iteration 3022: Loss = 0.2401, Accuracy = 0.8370 Test Loss = 0.2536, Test Accuracy = 0.8350\n",
      "Iteration 3023: Loss = 0.2526, Accuracy = 0.8290 Test Loss = 0.2536, Test Accuracy = 0.8339\n",
      "Iteration 3024: Loss = 0.2455, Accuracy = 0.8420 Test Loss = 0.2535, Test Accuracy = 0.8345\n",
      "Iteration 3025: Loss = 0.2427, Accuracy = 0.8240 Test Loss = 0.2535, Test Accuracy = 0.8339\n",
      "Iteration 3026: Loss = 0.2681, Accuracy = 0.8330 Test Loss = 0.2535, Test Accuracy = 0.8335\n",
      "Iteration 3027: Loss = 0.2342, Accuracy = 0.8500 Test Loss = 0.2535, Test Accuracy = 0.8348\n",
      "Iteration 3028: Loss = 0.2410, Accuracy = 0.8520 Test Loss = 0.2535, Test Accuracy = 0.8334\n",
      "Iteration 3029: Loss = 0.2571, Accuracy = 0.8270 Test Loss = 0.2534, Test Accuracy = 0.8347\n",
      "Iteration 3030: Loss = 0.2591, Accuracy = 0.8050 Test Loss = 0.2535, Test Accuracy = 0.8347\n",
      "Iteration 3031: Loss = 0.2465, Accuracy = 0.8450 Test Loss = 0.2534, Test Accuracy = 0.8338\n",
      "Iteration 3032: Loss = 0.2591, Accuracy = 0.8270 Test Loss = 0.2535, Test Accuracy = 0.8333\n",
      "Iteration 3033: Loss = 0.2532, Accuracy = 0.8320 Test Loss = 0.2534, Test Accuracy = 0.8341\n",
      "Iteration 3034: Loss = 0.2515, Accuracy = 0.8310 Test Loss = 0.2532, Test Accuracy = 0.8346\n",
      "Iteration 3035: Loss = 0.2614, Accuracy = 0.8300 Test Loss = 0.2532, Test Accuracy = 0.8345\n",
      "Iteration 3036: Loss = 0.2398, Accuracy = 0.8530 Test Loss = 0.2532, Test Accuracy = 0.8341\n",
      "Iteration 3037: Loss = 0.2676, Accuracy = 0.8330 Test Loss = 0.2532, Test Accuracy = 0.8334\n",
      "Iteration 3038: Loss = 0.2427, Accuracy = 0.8190 Test Loss = 0.2532, Test Accuracy = 0.8359\n",
      "Iteration 3039: Loss = 0.2464, Accuracy = 0.8330 Test Loss = 0.2532, Test Accuracy = 0.8338\n",
      "Iteration 3040: Loss = 0.2454, Accuracy = 0.8340 Test Loss = 0.2531, Test Accuracy = 0.8360\n",
      "Iteration 3041: Loss = 0.2516, Accuracy = 0.8180 Test Loss = 0.2533, Test Accuracy = 0.8336\n",
      "Iteration 3042: Loss = 0.2587, Accuracy = 0.8120 Test Loss = 0.2531, Test Accuracy = 0.8354\n",
      "Iteration 3043: Loss = 0.2550, Accuracy = 0.8290 Test Loss = 0.2532, Test Accuracy = 0.8342\n",
      "Iteration 3044: Loss = 0.2608, Accuracy = 0.8070 Test Loss = 0.2530, Test Accuracy = 0.8344\n",
      "Iteration 3045: Loss = 0.2333, Accuracy = 0.8410 Test Loss = 0.2530, Test Accuracy = 0.8343\n",
      "Iteration 3046: Loss = 0.2467, Accuracy = 0.8300 Test Loss = 0.2530, Test Accuracy = 0.8348\n",
      "Iteration 3047: Loss = 0.2339, Accuracy = 0.8560 Test Loss = 0.2530, Test Accuracy = 0.8356\n",
      "Iteration 3048: Loss = 0.2561, Accuracy = 0.8300 Test Loss = 0.2530, Test Accuracy = 0.8343\n",
      "Iteration 3049: Loss = 0.2578, Accuracy = 0.8310 Test Loss = 0.2530, Test Accuracy = 0.8353\n",
      "Iteration 3050: Loss = 0.2458, Accuracy = 0.8680 Test Loss = 0.2529, Test Accuracy = 0.8338\n",
      "Iteration 3051: Loss = 0.2544, Accuracy = 0.8460 Test Loss = 0.2529, Test Accuracy = 0.8337\n",
      "Iteration 3052: Loss = 0.2588, Accuracy = 0.8070 Test Loss = 0.2530, Test Accuracy = 0.8347\n",
      "Iteration 3053: Loss = 0.2437, Accuracy = 0.8390 Test Loss = 0.2528, Test Accuracy = 0.8335\n",
      "Iteration 3054: Loss = 0.2463, Accuracy = 0.8200 Test Loss = 0.2528, Test Accuracy = 0.8351\n",
      "Iteration 3055: Loss = 0.2615, Accuracy = 0.8240 Test Loss = 0.2527, Test Accuracy = 0.8346\n",
      "Iteration 3056: Loss = 0.2419, Accuracy = 0.8370 Test Loss = 0.2528, Test Accuracy = 0.8346\n",
      "Iteration 3057: Loss = 0.2417, Accuracy = 0.8220 Test Loss = 0.2528, Test Accuracy = 0.8353\n",
      "Iteration 3058: Loss = 0.2564, Accuracy = 0.8160 Test Loss = 0.2528, Test Accuracy = 0.8342\n",
      "Iteration 3059: Loss = 0.2576, Accuracy = 0.8240 Test Loss = 0.2527, Test Accuracy = 0.8348\n",
      "Iteration 3060: Loss = 0.2538, Accuracy = 0.8410 Test Loss = 0.2527, Test Accuracy = 0.8343\n",
      "Iteration 3061: Loss = 0.2588, Accuracy = 0.8290 Test Loss = 0.2528, Test Accuracy = 0.8351\n",
      "Iteration 3062: Loss = 0.2451, Accuracy = 0.8290 Test Loss = 0.2527, Test Accuracy = 0.8339\n",
      "Iteration 3063: Loss = 0.2539, Accuracy = 0.8440 Test Loss = 0.2527, Test Accuracy = 0.8359\n",
      "Iteration 3064: Loss = 0.2432, Accuracy = 0.8340 Test Loss = 0.2526, Test Accuracy = 0.8332\n",
      "Iteration 3065: Loss = 0.2694, Accuracy = 0.8260 Test Loss = 0.2526, Test Accuracy = 0.8347\n",
      "Iteration 3066: Loss = 0.2622, Accuracy = 0.8150 Test Loss = 0.2525, Test Accuracy = 0.8353\n",
      "Iteration 3067: Loss = 0.2427, Accuracy = 0.8350 Test Loss = 0.2526, Test Accuracy = 0.8350\n",
      "Iteration 3068: Loss = 0.2456, Accuracy = 0.8350 Test Loss = 0.2526, Test Accuracy = 0.8351\n",
      "Iteration 3069: Loss = 0.2467, Accuracy = 0.8390 Test Loss = 0.2525, Test Accuracy = 0.8340\n",
      "Iteration 3070: Loss = 0.2483, Accuracy = 0.8280 Test Loss = 0.2525, Test Accuracy = 0.8343\n",
      "Iteration 3071: Loss = 0.2658, Accuracy = 0.8140 Test Loss = 0.2524, Test Accuracy = 0.8339\n",
      "Iteration 3072: Loss = 0.2640, Accuracy = 0.8390 Test Loss = 0.2523, Test Accuracy = 0.8357\n",
      "Iteration 3073: Loss = 0.2420, Accuracy = 0.8390 Test Loss = 0.2525, Test Accuracy = 0.8348\n",
      "Iteration 3074: Loss = 0.2512, Accuracy = 0.8400 Test Loss = 0.2524, Test Accuracy = 0.8349\n",
      "Iteration 3075: Loss = 0.2444, Accuracy = 0.8420 Test Loss = 0.2523, Test Accuracy = 0.8342\n",
      "Iteration 3076: Loss = 0.2652, Accuracy = 0.8490 Test Loss = 0.2524, Test Accuracy = 0.8364\n",
      "Iteration 3077: Loss = 0.2722, Accuracy = 0.8240 Test Loss = 0.2524, Test Accuracy = 0.8344\n",
      "Iteration 3078: Loss = 0.2571, Accuracy = 0.8000 Test Loss = 0.2523, Test Accuracy = 0.8352\n",
      "Iteration 3079: Loss = 0.2531, Accuracy = 0.8150 Test Loss = 0.2524, Test Accuracy = 0.8353\n",
      "Iteration 3080: Loss = 0.2640, Accuracy = 0.8060 Test Loss = 0.2523, Test Accuracy = 0.8361\n",
      "Iteration 3081: Loss = 0.2571, Accuracy = 0.8230 Test Loss = 0.2522, Test Accuracy = 0.8350\n",
      "Iteration 3082: Loss = 0.2311, Accuracy = 0.8420 Test Loss = 0.2522, Test Accuracy = 0.8346\n",
      "Iteration 3083: Loss = 0.2516, Accuracy = 0.8470 Test Loss = 0.2523, Test Accuracy = 0.8341\n",
      "Iteration 3084: Loss = 0.2477, Accuracy = 0.8390 Test Loss = 0.2522, Test Accuracy = 0.8350\n",
      "Iteration 3085: Loss = 0.2468, Accuracy = 0.8340 Test Loss = 0.2521, Test Accuracy = 0.8359\n",
      "Iteration 3086: Loss = 0.2518, Accuracy = 0.8220 Test Loss = 0.2522, Test Accuracy = 0.8348\n",
      "Iteration 3087: Loss = 0.2535, Accuracy = 0.8120 Test Loss = 0.2521, Test Accuracy = 0.8344\n",
      "Iteration 3088: Loss = 0.2678, Accuracy = 0.8100 Test Loss = 0.2521, Test Accuracy = 0.8348\n",
      "Iteration 3089: Loss = 0.2514, Accuracy = 0.8340 Test Loss = 0.2521, Test Accuracy = 0.8327\n",
      "Iteration 3090: Loss = 0.2489, Accuracy = 0.8320 Test Loss = 0.2521, Test Accuracy = 0.8345\n",
      "Iteration 3091: Loss = 0.2466, Accuracy = 0.8370 Test Loss = 0.2520, Test Accuracy = 0.8361\n",
      "Iteration 3092: Loss = 0.2467, Accuracy = 0.8230 Test Loss = 0.2519, Test Accuracy = 0.8335\n",
      "Iteration 3093: Loss = 0.2479, Accuracy = 0.8160 Test Loss = 0.2520, Test Accuracy = 0.8331\n",
      "Iteration 3094: Loss = 0.2446, Accuracy = 0.8280 Test Loss = 0.2520, Test Accuracy = 0.8341\n",
      "Iteration 3095: Loss = 0.2446, Accuracy = 0.8450 Test Loss = 0.2519, Test Accuracy = 0.8346\n",
      "Iteration 3096: Loss = 0.2398, Accuracy = 0.8330 Test Loss = 0.2519, Test Accuracy = 0.8355\n",
      "Iteration 3097: Loss = 0.2625, Accuracy = 0.8150 Test Loss = 0.2519, Test Accuracy = 0.8341\n",
      "Iteration 3098: Loss = 0.2466, Accuracy = 0.8140 Test Loss = 0.2518, Test Accuracy = 0.8349\n",
      "Iteration 3099: Loss = 0.2424, Accuracy = 0.8500 Test Loss = 0.2519, Test Accuracy = 0.8353\n",
      "Iteration 3100: Loss = 0.2503, Accuracy = 0.8300 Test Loss = 0.2518, Test Accuracy = 0.8365\n",
      "Iteration 3101: Loss = 0.2610, Accuracy = 0.8160 Test Loss = 0.2518, Test Accuracy = 0.8349\n",
      "Iteration 3102: Loss = 0.2421, Accuracy = 0.8430 Test Loss = 0.2518, Test Accuracy = 0.8346\n",
      "Iteration 3103: Loss = 0.2447, Accuracy = 0.8320 Test Loss = 0.2518, Test Accuracy = 0.8347\n",
      "Iteration 3104: Loss = 0.2673, Accuracy = 0.8260 Test Loss = 0.2517, Test Accuracy = 0.8361\n",
      "Iteration 3105: Loss = 0.2501, Accuracy = 0.8300 Test Loss = 0.2518, Test Accuracy = 0.8349\n",
      "Iteration 3106: Loss = 0.2585, Accuracy = 0.8180 Test Loss = 0.2517, Test Accuracy = 0.8351\n",
      "Iteration 3107: Loss = 0.2530, Accuracy = 0.8250 Test Loss = 0.2517, Test Accuracy = 0.8359\n",
      "Iteration 3108: Loss = 0.2369, Accuracy = 0.8500 Test Loss = 0.2516, Test Accuracy = 0.8350\n",
      "Iteration 3109: Loss = 0.2463, Accuracy = 0.8360 Test Loss = 0.2518, Test Accuracy = 0.8352\n",
      "Iteration 3110: Loss = 0.2477, Accuracy = 0.8440 Test Loss = 0.2516, Test Accuracy = 0.8350\n",
      "Iteration 3111: Loss = 0.2332, Accuracy = 0.8240 Test Loss = 0.2516, Test Accuracy = 0.8350\n",
      "Iteration 3112: Loss = 0.2431, Accuracy = 0.8170 Test Loss = 0.2517, Test Accuracy = 0.8366\n",
      "Iteration 3113: Loss = 0.2419, Accuracy = 0.8290 Test Loss = 0.2515, Test Accuracy = 0.8360\n",
      "Iteration 3114: Loss = 0.2578, Accuracy = 0.8360 Test Loss = 0.2515, Test Accuracy = 0.8357\n",
      "Iteration 3115: Loss = 0.2548, Accuracy = 0.8440 Test Loss = 0.2515, Test Accuracy = 0.8340\n",
      "Iteration 3116: Loss = 0.2472, Accuracy = 0.8140 Test Loss = 0.2514, Test Accuracy = 0.8353\n",
      "Iteration 3117: Loss = 0.2500, Accuracy = 0.8380 Test Loss = 0.2514, Test Accuracy = 0.8353\n",
      "Iteration 3118: Loss = 0.2559, Accuracy = 0.8270 Test Loss = 0.2514, Test Accuracy = 0.8345\n",
      "Iteration 3119: Loss = 0.2559, Accuracy = 0.8080 Test Loss = 0.2514, Test Accuracy = 0.8362\n",
      "Iteration 3120: Loss = 0.2558, Accuracy = 0.8240 Test Loss = 0.2514, Test Accuracy = 0.8344\n",
      "Iteration 3121: Loss = 0.2617, Accuracy = 0.8060 Test Loss = 0.2514, Test Accuracy = 0.8347\n",
      "Iteration 3122: Loss = 0.2499, Accuracy = 0.8360 Test Loss = 0.2513, Test Accuracy = 0.8365\n",
      "Iteration 3123: Loss = 0.2463, Accuracy = 0.8350 Test Loss = 0.2515, Test Accuracy = 0.8350\n",
      "Iteration 3124: Loss = 0.2427, Accuracy = 0.8340 Test Loss = 0.2513, Test Accuracy = 0.8357\n",
      "Iteration 3125: Loss = 0.2702, Accuracy = 0.8210 Test Loss = 0.2513, Test Accuracy = 0.8348\n",
      "Iteration 3126: Loss = 0.2526, Accuracy = 0.8280 Test Loss = 0.2512, Test Accuracy = 0.8346\n",
      "Iteration 3127: Loss = 0.2405, Accuracy = 0.8320 Test Loss = 0.2513, Test Accuracy = 0.8347\n",
      "Iteration 3128: Loss = 0.2639, Accuracy = 0.8290 Test Loss = 0.2512, Test Accuracy = 0.8358\n",
      "Iteration 3129: Loss = 0.2498, Accuracy = 0.8170 Test Loss = 0.2511, Test Accuracy = 0.8362\n",
      "Iteration 3130: Loss = 0.2407, Accuracy = 0.8280 Test Loss = 0.2511, Test Accuracy = 0.8346\n",
      "Iteration 3131: Loss = 0.2549, Accuracy = 0.8330 Test Loss = 0.2511, Test Accuracy = 0.8363\n",
      "Iteration 3132: Loss = 0.2435, Accuracy = 0.8280 Test Loss = 0.2511, Test Accuracy = 0.8354\n",
      "Iteration 3133: Loss = 0.2572, Accuracy = 0.8370 Test Loss = 0.2511, Test Accuracy = 0.8366\n",
      "Iteration 3134: Loss = 0.2615, Accuracy = 0.8070 Test Loss = 0.2512, Test Accuracy = 0.8357\n",
      "Iteration 3135: Loss = 0.2695, Accuracy = 0.8250 Test Loss = 0.2511, Test Accuracy = 0.8351\n",
      "Iteration 3136: Loss = 0.2494, Accuracy = 0.8340 Test Loss = 0.2510, Test Accuracy = 0.8370\n",
      "Iteration 3137: Loss = 0.2493, Accuracy = 0.8290 Test Loss = 0.2511, Test Accuracy = 0.8333\n",
      "Iteration 3138: Loss = 0.2439, Accuracy = 0.8410 Test Loss = 0.2510, Test Accuracy = 0.8355\n",
      "Iteration 3139: Loss = 0.2558, Accuracy = 0.8330 Test Loss = 0.2510, Test Accuracy = 0.8349\n",
      "Iteration 3140: Loss = 0.2462, Accuracy = 0.8310 Test Loss = 0.2509, Test Accuracy = 0.8346\n",
      "Iteration 3141: Loss = 0.2415, Accuracy = 0.8390 Test Loss = 0.2509, Test Accuracy = 0.8358\n",
      "Iteration 3142: Loss = 0.2419, Accuracy = 0.8150 Test Loss = 0.2509, Test Accuracy = 0.8373\n",
      "Iteration 3143: Loss = 0.2465, Accuracy = 0.8400 Test Loss = 0.2508, Test Accuracy = 0.8358\n",
      "Iteration 3144: Loss = 0.2474, Accuracy = 0.8350 Test Loss = 0.2509, Test Accuracy = 0.8358\n",
      "Iteration 3145: Loss = 0.2347, Accuracy = 0.8310 Test Loss = 0.2508, Test Accuracy = 0.8353\n",
      "Iteration 3146: Loss = 0.2459, Accuracy = 0.8490 Test Loss = 0.2508, Test Accuracy = 0.8344\n",
      "Iteration 3147: Loss = 0.2678, Accuracy = 0.8280 Test Loss = 0.2509, Test Accuracy = 0.8344\n",
      "Iteration 3148: Loss = 0.2555, Accuracy = 0.8470 Test Loss = 0.2509, Test Accuracy = 0.8357\n",
      "Iteration 3149: Loss = 0.2496, Accuracy = 0.8360 Test Loss = 0.2508, Test Accuracy = 0.8356\n",
      "Iteration 3150: Loss = 0.2492, Accuracy = 0.8310 Test Loss = 0.2507, Test Accuracy = 0.8345\n",
      "Iteration 3151: Loss = 0.2380, Accuracy = 0.8370 Test Loss = 0.2507, Test Accuracy = 0.8351\n",
      "Iteration 3152: Loss = 0.2449, Accuracy = 0.8360 Test Loss = 0.2507, Test Accuracy = 0.8352\n",
      "Iteration 3153: Loss = 0.2345, Accuracy = 0.8380 Test Loss = 0.2507, Test Accuracy = 0.8359\n",
      "Iteration 3154: Loss = 0.2442, Accuracy = 0.7950 Test Loss = 0.2506, Test Accuracy = 0.8363\n",
      "Iteration 3155: Loss = 0.2371, Accuracy = 0.8260 Test Loss = 0.2506, Test Accuracy = 0.8354\n",
      "Iteration 3156: Loss = 0.2368, Accuracy = 0.8400 Test Loss = 0.2507, Test Accuracy = 0.8355\n",
      "Iteration 3157: Loss = 0.2491, Accuracy = 0.8350 Test Loss = 0.2506, Test Accuracy = 0.8347\n",
      "Iteration 3158: Loss = 0.2579, Accuracy = 0.8160 Test Loss = 0.2506, Test Accuracy = 0.8350\n",
      "Iteration 3159: Loss = 0.2433, Accuracy = 0.8610 Test Loss = 0.2506, Test Accuracy = 0.8341\n",
      "Iteration 3160: Loss = 0.2490, Accuracy = 0.8300 Test Loss = 0.2507, Test Accuracy = 0.8354\n",
      "Iteration 3161: Loss = 0.2448, Accuracy = 0.8320 Test Loss = 0.2506, Test Accuracy = 0.8347\n",
      "Iteration 3162: Loss = 0.2548, Accuracy = 0.8370 Test Loss = 0.2505, Test Accuracy = 0.8354\n",
      "Iteration 3163: Loss = 0.2545, Accuracy = 0.8210 Test Loss = 0.2504, Test Accuracy = 0.8355\n",
      "Iteration 3164: Loss = 0.2484, Accuracy = 0.8250 Test Loss = 0.2505, Test Accuracy = 0.8353\n",
      "Iteration 3165: Loss = 0.2483, Accuracy = 0.8190 Test Loss = 0.2505, Test Accuracy = 0.8362\n",
      "Iteration 3166: Loss = 0.2482, Accuracy = 0.8250 Test Loss = 0.2505, Test Accuracy = 0.8351\n",
      "Iteration 3167: Loss = 0.2561, Accuracy = 0.8330 Test Loss = 0.2504, Test Accuracy = 0.8347\n",
      "Iteration 3168: Loss = 0.2495, Accuracy = 0.8300 Test Loss = 0.2504, Test Accuracy = 0.8349\n",
      "Iteration 3169: Loss = 0.2587, Accuracy = 0.8110 Test Loss = 0.2504, Test Accuracy = 0.8355\n",
      "Iteration 3170: Loss = 0.2386, Accuracy = 0.8480 Test Loss = 0.2504, Test Accuracy = 0.8360\n",
      "Iteration 3171: Loss = 0.2383, Accuracy = 0.8260 Test Loss = 0.2504, Test Accuracy = 0.8367\n",
      "Iteration 3172: Loss = 0.2615, Accuracy = 0.8110 Test Loss = 0.2504, Test Accuracy = 0.8355\n",
      "Iteration 3173: Loss = 0.2367, Accuracy = 0.8160 Test Loss = 0.2502, Test Accuracy = 0.8353\n",
      "Iteration 3174: Loss = 0.2650, Accuracy = 0.8300 Test Loss = 0.2503, Test Accuracy = 0.8357\n",
      "Iteration 3175: Loss = 0.2569, Accuracy = 0.8500 Test Loss = 0.2502, Test Accuracy = 0.8355\n",
      "Iteration 3176: Loss = 0.2533, Accuracy = 0.8390 Test Loss = 0.2502, Test Accuracy = 0.8358\n",
      "Iteration 3177: Loss = 0.2446, Accuracy = 0.8300 Test Loss = 0.2501, Test Accuracy = 0.8362\n",
      "Iteration 3178: Loss = 0.2564, Accuracy = 0.8110 Test Loss = 0.2501, Test Accuracy = 0.8361\n",
      "Iteration 3179: Loss = 0.2398, Accuracy = 0.8440 Test Loss = 0.2501, Test Accuracy = 0.8367\n",
      "Iteration 3180: Loss = 0.2396, Accuracy = 0.8190 Test Loss = 0.2501, Test Accuracy = 0.8367\n",
      "Iteration 3181: Loss = 0.2518, Accuracy = 0.8140 Test Loss = 0.2501, Test Accuracy = 0.8361\n",
      "Iteration 3182: Loss = 0.2363, Accuracy = 0.8390 Test Loss = 0.2500, Test Accuracy = 0.8363\n",
      "Iteration 3183: Loss = 0.2375, Accuracy = 0.8610 Test Loss = 0.2501, Test Accuracy = 0.8342\n",
      "Iteration 3184: Loss = 0.2463, Accuracy = 0.8330 Test Loss = 0.2501, Test Accuracy = 0.8359\n",
      "Iteration 3185: Loss = 0.2605, Accuracy = 0.8520 Test Loss = 0.2501, Test Accuracy = 0.8343\n",
      "Iteration 3186: Loss = 0.2486, Accuracy = 0.8390 Test Loss = 0.2501, Test Accuracy = 0.8365\n",
      "Iteration 3187: Loss = 0.2366, Accuracy = 0.8320 Test Loss = 0.2500, Test Accuracy = 0.8359\n",
      "Iteration 3188: Loss = 0.2532, Accuracy = 0.8270 Test Loss = 0.2500, Test Accuracy = 0.8354\n",
      "Iteration 3189: Loss = 0.2423, Accuracy = 0.8400 Test Loss = 0.2500, Test Accuracy = 0.8347\n",
      "Iteration 3190: Loss = 0.2758, Accuracy = 0.8120 Test Loss = 0.2499, Test Accuracy = 0.8364\n",
      "Iteration 3191: Loss = 0.2516, Accuracy = 0.8300 Test Loss = 0.2499, Test Accuracy = 0.8361\n",
      "Iteration 3192: Loss = 0.2444, Accuracy = 0.8440 Test Loss = 0.2499, Test Accuracy = 0.8357\n",
      "Iteration 3193: Loss = 0.2468, Accuracy = 0.8280 Test Loss = 0.2499, Test Accuracy = 0.8355\n",
      "Iteration 3194: Loss = 0.2328, Accuracy = 0.8560 Test Loss = 0.2500, Test Accuracy = 0.8348\n",
      "Iteration 3195: Loss = 0.2521, Accuracy = 0.8340 Test Loss = 0.2498, Test Accuracy = 0.8353\n",
      "Iteration 3196: Loss = 0.2499, Accuracy = 0.8450 Test Loss = 0.2498, Test Accuracy = 0.8361\n",
      "Iteration 3197: Loss = 0.2607, Accuracy = 0.8330 Test Loss = 0.2498, Test Accuracy = 0.8359\n",
      "Iteration 3198: Loss = 0.2509, Accuracy = 0.8310 Test Loss = 0.2498, Test Accuracy = 0.8339\n",
      "Iteration 3199: Loss = 0.2376, Accuracy = 0.8180 Test Loss = 0.2498, Test Accuracy = 0.8356\n",
      "Iteration 3200: Loss = 0.2386, Accuracy = 0.8380 Test Loss = 0.2497, Test Accuracy = 0.8361\n",
      "Iteration 3201: Loss = 0.2240, Accuracy = 0.8440 Test Loss = 0.2498, Test Accuracy = 0.8357\n",
      "Iteration 3202: Loss = 0.2448, Accuracy = 0.8370 Test Loss = 0.2497, Test Accuracy = 0.8366\n",
      "Iteration 3203: Loss = 0.2420, Accuracy = 0.8240 Test Loss = 0.2497, Test Accuracy = 0.8346\n",
      "Iteration 3204: Loss = 0.2449, Accuracy = 0.8350 Test Loss = 0.2497, Test Accuracy = 0.8356\n",
      "Iteration 3205: Loss = 0.2474, Accuracy = 0.8310 Test Loss = 0.2496, Test Accuracy = 0.8362\n",
      "Iteration 3206: Loss = 0.2486, Accuracy = 0.8320 Test Loss = 0.2496, Test Accuracy = 0.8356\n",
      "Iteration 3207: Loss = 0.2453, Accuracy = 0.8450 Test Loss = 0.2496, Test Accuracy = 0.8350\n",
      "Iteration 3208: Loss = 0.2536, Accuracy = 0.8110 Test Loss = 0.2495, Test Accuracy = 0.8359\n",
      "Iteration 3209: Loss = 0.2423, Accuracy = 0.8250 Test Loss = 0.2495, Test Accuracy = 0.8360\n",
      "Iteration 3210: Loss = 0.2515, Accuracy = 0.8360 Test Loss = 0.2496, Test Accuracy = 0.8352\n",
      "Iteration 3211: Loss = 0.2581, Accuracy = 0.8220 Test Loss = 0.2495, Test Accuracy = 0.8360\n",
      "Iteration 3212: Loss = 0.2459, Accuracy = 0.8190 Test Loss = 0.2495, Test Accuracy = 0.8363\n",
      "Iteration 3213: Loss = 0.2391, Accuracy = 0.8290 Test Loss = 0.2495, Test Accuracy = 0.8364\n",
      "Iteration 3214: Loss = 0.2430, Accuracy = 0.8480 Test Loss = 0.2495, Test Accuracy = 0.8364\n",
      "Iteration 3215: Loss = 0.2475, Accuracy = 0.8470 Test Loss = 0.2494, Test Accuracy = 0.8366\n",
      "Iteration 3216: Loss = 0.2413, Accuracy = 0.8460 Test Loss = 0.2494, Test Accuracy = 0.8354\n",
      "Iteration 3217: Loss = 0.2494, Accuracy = 0.8230 Test Loss = 0.2494, Test Accuracy = 0.8354\n",
      "Iteration 3218: Loss = 0.2599, Accuracy = 0.8360 Test Loss = 0.2494, Test Accuracy = 0.8363\n",
      "Iteration 3219: Loss = 0.2399, Accuracy = 0.8350 Test Loss = 0.2494, Test Accuracy = 0.8350\n",
      "Iteration 3220: Loss = 0.2516, Accuracy = 0.8320 Test Loss = 0.2494, Test Accuracy = 0.8353\n",
      "Iteration 3221: Loss = 0.2580, Accuracy = 0.8020 Test Loss = 0.2493, Test Accuracy = 0.8363\n",
      "Iteration 3222: Loss = 0.2639, Accuracy = 0.8180 Test Loss = 0.2493, Test Accuracy = 0.8358\n",
      "Iteration 3223: Loss = 0.2478, Accuracy = 0.8280 Test Loss = 0.2492, Test Accuracy = 0.8361\n",
      "Iteration 3224: Loss = 0.2685, Accuracy = 0.8170 Test Loss = 0.2493, Test Accuracy = 0.8355\n",
      "Iteration 3225: Loss = 0.2414, Accuracy = 0.8370 Test Loss = 0.2492, Test Accuracy = 0.8361\n",
      "Iteration 3226: Loss = 0.2306, Accuracy = 0.8430 Test Loss = 0.2492, Test Accuracy = 0.8359\n",
      "Iteration 3227: Loss = 0.2478, Accuracy = 0.8170 Test Loss = 0.2491, Test Accuracy = 0.8355\n",
      "Iteration 3228: Loss = 0.2315, Accuracy = 0.8560 Test Loss = 0.2492, Test Accuracy = 0.8367\n",
      "Iteration 3229: Loss = 0.2676, Accuracy = 0.8230 Test Loss = 0.2491, Test Accuracy = 0.8362\n",
      "Iteration 3230: Loss = 0.2482, Accuracy = 0.8360 Test Loss = 0.2491, Test Accuracy = 0.8354\n",
      "Iteration 3231: Loss = 0.2323, Accuracy = 0.8370 Test Loss = 0.2491, Test Accuracy = 0.8362\n",
      "Iteration 3232: Loss = 0.2370, Accuracy = 0.8390 Test Loss = 0.2491, Test Accuracy = 0.8357\n",
      "Iteration 3233: Loss = 0.2464, Accuracy = 0.8430 Test Loss = 0.2491, Test Accuracy = 0.8361\n",
      "Iteration 3234: Loss = 0.2632, Accuracy = 0.8280 Test Loss = 0.2491, Test Accuracy = 0.8358\n",
      "Iteration 3235: Loss = 0.2512, Accuracy = 0.8280 Test Loss = 0.2491, Test Accuracy = 0.8367\n",
      "Iteration 3236: Loss = 0.2409, Accuracy = 0.8480 Test Loss = 0.2490, Test Accuracy = 0.8361\n",
      "Iteration 3237: Loss = 0.2479, Accuracy = 0.8250 Test Loss = 0.2490, Test Accuracy = 0.8358\n",
      "Iteration 3238: Loss = 0.2266, Accuracy = 0.8520 Test Loss = 0.2490, Test Accuracy = 0.8362\n",
      "Iteration 3239: Loss = 0.2363, Accuracy = 0.8520 Test Loss = 0.2489, Test Accuracy = 0.8371\n",
      "Iteration 3240: Loss = 0.2393, Accuracy = 0.8300 Test Loss = 0.2488, Test Accuracy = 0.8366\n",
      "Iteration 3241: Loss = 0.2416, Accuracy = 0.8380 Test Loss = 0.2489, Test Accuracy = 0.8358\n",
      "Iteration 3242: Loss = 0.2292, Accuracy = 0.8580 Test Loss = 0.2489, Test Accuracy = 0.8364\n",
      "Iteration 3243: Loss = 0.2527, Accuracy = 0.8340 Test Loss = 0.2489, Test Accuracy = 0.8364\n",
      "Iteration 3244: Loss = 0.2472, Accuracy = 0.8270 Test Loss = 0.2489, Test Accuracy = 0.8349\n",
      "Iteration 3245: Loss = 0.2298, Accuracy = 0.8400 Test Loss = 0.2489, Test Accuracy = 0.8351\n",
      "Iteration 3246: Loss = 0.2404, Accuracy = 0.8230 Test Loss = 0.2488, Test Accuracy = 0.8353\n",
      "Iteration 3247: Loss = 0.2370, Accuracy = 0.8550 Test Loss = 0.2488, Test Accuracy = 0.8365\n",
      "Iteration 3248: Loss = 0.2463, Accuracy = 0.8460 Test Loss = 0.2487, Test Accuracy = 0.8373\n",
      "Iteration 3249: Loss = 0.2337, Accuracy = 0.8560 Test Loss = 0.2488, Test Accuracy = 0.8369\n",
      "Iteration 3250: Loss = 0.2286, Accuracy = 0.8410 Test Loss = 0.2487, Test Accuracy = 0.8356\n",
      "Iteration 3251: Loss = 0.2590, Accuracy = 0.8140 Test Loss = 0.2487, Test Accuracy = 0.8347\n",
      "Iteration 3252: Loss = 0.2551, Accuracy = 0.8230 Test Loss = 0.2487, Test Accuracy = 0.8369\n",
      "Iteration 3253: Loss = 0.2424, Accuracy = 0.8470 Test Loss = 0.2487, Test Accuracy = 0.8361\n",
      "Iteration 3254: Loss = 0.2434, Accuracy = 0.8230 Test Loss = 0.2487, Test Accuracy = 0.8363\n",
      "Iteration 3255: Loss = 0.2534, Accuracy = 0.8160 Test Loss = 0.2486, Test Accuracy = 0.8364\n",
      "Iteration 3256: Loss = 0.2440, Accuracy = 0.8290 Test Loss = 0.2486, Test Accuracy = 0.8373\n",
      "Iteration 3257: Loss = 0.2500, Accuracy = 0.8340 Test Loss = 0.2486, Test Accuracy = 0.8351\n",
      "Iteration 3258: Loss = 0.2670, Accuracy = 0.8120 Test Loss = 0.2486, Test Accuracy = 0.8362\n",
      "Iteration 3259: Loss = 0.2565, Accuracy = 0.8120 Test Loss = 0.2487, Test Accuracy = 0.8361\n",
      "Iteration 3260: Loss = 0.2500, Accuracy = 0.8300 Test Loss = 0.2485, Test Accuracy = 0.8361\n",
      "Iteration 3261: Loss = 0.2523, Accuracy = 0.8120 Test Loss = 0.2485, Test Accuracy = 0.8371\n",
      "Iteration 3262: Loss = 0.2588, Accuracy = 0.8270 Test Loss = 0.2485, Test Accuracy = 0.8355\n",
      "Iteration 3263: Loss = 0.2487, Accuracy = 0.8320 Test Loss = 0.2485, Test Accuracy = 0.8363\n",
      "Iteration 3264: Loss = 0.2712, Accuracy = 0.8260 Test Loss = 0.2485, Test Accuracy = 0.8365\n",
      "Iteration 3265: Loss = 0.2598, Accuracy = 0.8120 Test Loss = 0.2484, Test Accuracy = 0.8370\n",
      "Iteration 3266: Loss = 0.2393, Accuracy = 0.8580 Test Loss = 0.2484, Test Accuracy = 0.8355\n",
      "Iteration 3267: Loss = 0.2350, Accuracy = 0.8420 Test Loss = 0.2486, Test Accuracy = 0.8366\n",
      "Iteration 3268: Loss = 0.2475, Accuracy = 0.8100 Test Loss = 0.2484, Test Accuracy = 0.8361\n",
      "Iteration 3269: Loss = 0.2508, Accuracy = 0.8100 Test Loss = 0.2484, Test Accuracy = 0.8372\n",
      "Iteration 3270: Loss = 0.2391, Accuracy = 0.8470 Test Loss = 0.2483, Test Accuracy = 0.8358\n",
      "Iteration 3271: Loss = 0.2484, Accuracy = 0.8340 Test Loss = 0.2483, Test Accuracy = 0.8364\n",
      "Iteration 3272: Loss = 0.2386, Accuracy = 0.8420 Test Loss = 0.2483, Test Accuracy = 0.8366\n",
      "Iteration 3273: Loss = 0.2377, Accuracy = 0.8300 Test Loss = 0.2483, Test Accuracy = 0.8359\n",
      "Iteration 3274: Loss = 0.2415, Accuracy = 0.8300 Test Loss = 0.2482, Test Accuracy = 0.8363\n",
      "Iteration 3275: Loss = 0.2624, Accuracy = 0.8270 Test Loss = 0.2482, Test Accuracy = 0.8355\n",
      "Iteration 3276: Loss = 0.2553, Accuracy = 0.8370 Test Loss = 0.2483, Test Accuracy = 0.8338\n",
      "Iteration 3277: Loss = 0.2477, Accuracy = 0.8380 Test Loss = 0.2482, Test Accuracy = 0.8358\n",
      "Iteration 3278: Loss = 0.2643, Accuracy = 0.8130 Test Loss = 0.2483, Test Accuracy = 0.8361\n",
      "Iteration 3279: Loss = 0.2574, Accuracy = 0.8330 Test Loss = 0.2482, Test Accuracy = 0.8359\n",
      "Iteration 3280: Loss = 0.2515, Accuracy = 0.8280 Test Loss = 0.2482, Test Accuracy = 0.8364\n",
      "Iteration 3281: Loss = 0.2544, Accuracy = 0.8370 Test Loss = 0.2483, Test Accuracy = 0.8375\n",
      "Iteration 3282: Loss = 0.2542, Accuracy = 0.8170 Test Loss = 0.2481, Test Accuracy = 0.8368\n",
      "Iteration 3283: Loss = 0.2368, Accuracy = 0.8290 Test Loss = 0.2482, Test Accuracy = 0.8366\n",
      "Iteration 3284: Loss = 0.2553, Accuracy = 0.8350 Test Loss = 0.2481, Test Accuracy = 0.8366\n",
      "Iteration 3285: Loss = 0.2526, Accuracy = 0.8090 Test Loss = 0.2480, Test Accuracy = 0.8357\n",
      "Iteration 3286: Loss = 0.2492, Accuracy = 0.8300 Test Loss = 0.2481, Test Accuracy = 0.8369\n",
      "Iteration 3287: Loss = 0.2315, Accuracy = 0.8520 Test Loss = 0.2481, Test Accuracy = 0.8367\n",
      "Iteration 3288: Loss = 0.2465, Accuracy = 0.8240 Test Loss = 0.2479, Test Accuracy = 0.8366\n",
      "Iteration 3289: Loss = 0.2426, Accuracy = 0.8300 Test Loss = 0.2482, Test Accuracy = 0.8364\n",
      "Iteration 3290: Loss = 0.2506, Accuracy = 0.8100 Test Loss = 0.2480, Test Accuracy = 0.8354\n",
      "Iteration 3291: Loss = 0.2397, Accuracy = 0.8240 Test Loss = 0.2479, Test Accuracy = 0.8367\n",
      "Iteration 3292: Loss = 0.2538, Accuracy = 0.8160 Test Loss = 0.2480, Test Accuracy = 0.8368\n",
      "Iteration 3293: Loss = 0.2453, Accuracy = 0.8250 Test Loss = 0.2479, Test Accuracy = 0.8361\n",
      "Iteration 3294: Loss = 0.2493, Accuracy = 0.8240 Test Loss = 0.2479, Test Accuracy = 0.8353\n",
      "Iteration 3295: Loss = 0.2481, Accuracy = 0.8370 Test Loss = 0.2480, Test Accuracy = 0.8357\n",
      "Iteration 3296: Loss = 0.2576, Accuracy = 0.8280 Test Loss = 0.2479, Test Accuracy = 0.8365\n",
      "Iteration 3297: Loss = 0.2398, Accuracy = 0.8370 Test Loss = 0.2479, Test Accuracy = 0.8363\n",
      "Iteration 3298: Loss = 0.2537, Accuracy = 0.8270 Test Loss = 0.2478, Test Accuracy = 0.8368\n",
      "Iteration 3299: Loss = 0.2445, Accuracy = 0.8450 Test Loss = 0.2479, Test Accuracy = 0.8372\n",
      "Iteration 3300: Loss = 0.2586, Accuracy = 0.8260 Test Loss = 0.2479, Test Accuracy = 0.8365\n",
      "Iteration 3301: Loss = 0.2410, Accuracy = 0.8440 Test Loss = 0.2478, Test Accuracy = 0.8369\n",
      "Iteration 3302: Loss = 0.2552, Accuracy = 0.8230 Test Loss = 0.2479, Test Accuracy = 0.8367\n",
      "Iteration 3303: Loss = 0.2544, Accuracy = 0.8450 Test Loss = 0.2478, Test Accuracy = 0.8357\n",
      "Iteration 3304: Loss = 0.2496, Accuracy = 0.8130 Test Loss = 0.2477, Test Accuracy = 0.8363\n",
      "Iteration 3305: Loss = 0.2494, Accuracy = 0.8330 Test Loss = 0.2476, Test Accuracy = 0.8352\n",
      "Iteration 3306: Loss = 0.2459, Accuracy = 0.8260 Test Loss = 0.2476, Test Accuracy = 0.8366\n",
      "Iteration 3307: Loss = 0.2521, Accuracy = 0.8330 Test Loss = 0.2477, Test Accuracy = 0.8345\n",
      "Iteration 3308: Loss = 0.2321, Accuracy = 0.8570 Test Loss = 0.2477, Test Accuracy = 0.8368\n",
      "Iteration 3309: Loss = 0.2516, Accuracy = 0.8190 Test Loss = 0.2476, Test Accuracy = 0.8378\n",
      "Iteration 3310: Loss = 0.2511, Accuracy = 0.8330 Test Loss = 0.2476, Test Accuracy = 0.8363\n",
      "Iteration 3311: Loss = 0.2445, Accuracy = 0.8240 Test Loss = 0.2476, Test Accuracy = 0.8362\n",
      "Iteration 3312: Loss = 0.2332, Accuracy = 0.8300 Test Loss = 0.2476, Test Accuracy = 0.8362\n",
      "Iteration 3313: Loss = 0.2385, Accuracy = 0.8360 Test Loss = 0.2476, Test Accuracy = 0.8376\n",
      "Iteration 3314: Loss = 0.2521, Accuracy = 0.8270 Test Loss = 0.2476, Test Accuracy = 0.8357\n",
      "Iteration 3315: Loss = 0.2574, Accuracy = 0.8180 Test Loss = 0.2477, Test Accuracy = 0.8364\n",
      "Iteration 3316: Loss = 0.2522, Accuracy = 0.8190 Test Loss = 0.2475, Test Accuracy = 0.8368\n",
      "Iteration 3317: Loss = 0.2379, Accuracy = 0.8490 Test Loss = 0.2475, Test Accuracy = 0.8373\n",
      "Iteration 3318: Loss = 0.2486, Accuracy = 0.8480 Test Loss = 0.2475, Test Accuracy = 0.8366\n",
      "Iteration 3319: Loss = 0.2369, Accuracy = 0.8300 Test Loss = 0.2475, Test Accuracy = 0.8368\n",
      "Iteration 3320: Loss = 0.2441, Accuracy = 0.8280 Test Loss = 0.2474, Test Accuracy = 0.8362\n",
      "Iteration 3321: Loss = 0.2454, Accuracy = 0.8370 Test Loss = 0.2474, Test Accuracy = 0.8365\n",
      "Iteration 3322: Loss = 0.2566, Accuracy = 0.8200 Test Loss = 0.2474, Test Accuracy = 0.8380\n",
      "Iteration 3323: Loss = 0.2596, Accuracy = 0.8390 Test Loss = 0.2473, Test Accuracy = 0.8380\n",
      "Iteration 3324: Loss = 0.2487, Accuracy = 0.8290 Test Loss = 0.2473, Test Accuracy = 0.8368\n",
      "Iteration 3325: Loss = 0.2435, Accuracy = 0.8450 Test Loss = 0.2473, Test Accuracy = 0.8359\n",
      "Iteration 3326: Loss = 0.2551, Accuracy = 0.8380 Test Loss = 0.2473, Test Accuracy = 0.8359\n",
      "Iteration 3327: Loss = 0.2336, Accuracy = 0.8410 Test Loss = 0.2472, Test Accuracy = 0.8375\n",
      "Iteration 3328: Loss = 0.2427, Accuracy = 0.8310 Test Loss = 0.2472, Test Accuracy = 0.8379\n",
      "Iteration 3329: Loss = 0.2276, Accuracy = 0.8340 Test Loss = 0.2472, Test Accuracy = 0.8375\n",
      "Iteration 3330: Loss = 0.2435, Accuracy = 0.8330 Test Loss = 0.2473, Test Accuracy = 0.8371\n",
      "Iteration 3331: Loss = 0.2421, Accuracy = 0.8300 Test Loss = 0.2473, Test Accuracy = 0.8376\n",
      "Iteration 3332: Loss = 0.2450, Accuracy = 0.8380 Test Loss = 0.2473, Test Accuracy = 0.8371\n",
      "Iteration 3333: Loss = 0.2516, Accuracy = 0.8270 Test Loss = 0.2473, Test Accuracy = 0.8362\n",
      "Iteration 3334: Loss = 0.2633, Accuracy = 0.8180 Test Loss = 0.2472, Test Accuracy = 0.8368\n",
      "Iteration 3335: Loss = 0.2387, Accuracy = 0.8300 Test Loss = 0.2471, Test Accuracy = 0.8374\n",
      "Iteration 3336: Loss = 0.2453, Accuracy = 0.8320 Test Loss = 0.2471, Test Accuracy = 0.8369\n",
      "Iteration 3337: Loss = 0.2589, Accuracy = 0.8200 Test Loss = 0.2470, Test Accuracy = 0.8362\n",
      "Iteration 3338: Loss = 0.2589, Accuracy = 0.8190 Test Loss = 0.2471, Test Accuracy = 0.8374\n",
      "Iteration 3339: Loss = 0.2565, Accuracy = 0.8130 Test Loss = 0.2471, Test Accuracy = 0.8377\n",
      "Iteration 3340: Loss = 0.2536, Accuracy = 0.8130 Test Loss = 0.2471, Test Accuracy = 0.8372\n",
      "Iteration 3341: Loss = 0.2344, Accuracy = 0.8260 Test Loss = 0.2470, Test Accuracy = 0.8363\n",
      "Iteration 3342: Loss = 0.2379, Accuracy = 0.8320 Test Loss = 0.2471, Test Accuracy = 0.8365\n",
      "Iteration 3343: Loss = 0.2471, Accuracy = 0.8200 Test Loss = 0.2469, Test Accuracy = 0.8366\n",
      "Iteration 3344: Loss = 0.2251, Accuracy = 0.8640 Test Loss = 0.2470, Test Accuracy = 0.8360\n",
      "Iteration 3345: Loss = 0.2393, Accuracy = 0.8210 Test Loss = 0.2469, Test Accuracy = 0.8377\n",
      "Iteration 3346: Loss = 0.2367, Accuracy = 0.8340 Test Loss = 0.2470, Test Accuracy = 0.8360\n",
      "Iteration 3347: Loss = 0.2364, Accuracy = 0.8410 Test Loss = 0.2469, Test Accuracy = 0.8372\n",
      "Iteration 3348: Loss = 0.2558, Accuracy = 0.8190 Test Loss = 0.2470, Test Accuracy = 0.8379\n",
      "Iteration 3349: Loss = 0.2437, Accuracy = 0.8240 Test Loss = 0.2468, Test Accuracy = 0.8368\n",
      "Iteration 3350: Loss = 0.2343, Accuracy = 0.8370 Test Loss = 0.2469, Test Accuracy = 0.8368\n",
      "Iteration 3351: Loss = 0.2442, Accuracy = 0.8380 Test Loss = 0.2468, Test Accuracy = 0.8370\n",
      "Iteration 3352: Loss = 0.2341, Accuracy = 0.8520 Test Loss = 0.2469, Test Accuracy = 0.8360\n",
      "Iteration 3353: Loss = 0.2426, Accuracy = 0.8140 Test Loss = 0.2468, Test Accuracy = 0.8370\n",
      "Iteration 3354: Loss = 0.2493, Accuracy = 0.8240 Test Loss = 0.2467, Test Accuracy = 0.8362\n",
      "Iteration 3355: Loss = 0.2472, Accuracy = 0.8400 Test Loss = 0.2468, Test Accuracy = 0.8370\n",
      "Iteration 3356: Loss = 0.2352, Accuracy = 0.8390 Test Loss = 0.2467, Test Accuracy = 0.8375\n",
      "Iteration 3357: Loss = 0.2454, Accuracy = 0.8210 Test Loss = 0.2467, Test Accuracy = 0.8375\n",
      "Iteration 3358: Loss = 0.2453, Accuracy = 0.8300 Test Loss = 0.2467, Test Accuracy = 0.8377\n",
      "Iteration 3359: Loss = 0.2362, Accuracy = 0.8410 Test Loss = 0.2467, Test Accuracy = 0.8377\n",
      "Iteration 3360: Loss = 0.2402, Accuracy = 0.8140 Test Loss = 0.2467, Test Accuracy = 0.8372\n",
      "Iteration 3361: Loss = 0.2380, Accuracy = 0.8520 Test Loss = 0.2467, Test Accuracy = 0.8376\n",
      "Iteration 3362: Loss = 0.2462, Accuracy = 0.8370 Test Loss = 0.2466, Test Accuracy = 0.8376\n",
      "Iteration 3363: Loss = 0.2600, Accuracy = 0.8180 Test Loss = 0.2466, Test Accuracy = 0.8367\n",
      "Iteration 3364: Loss = 0.2392, Accuracy = 0.8240 Test Loss = 0.2467, Test Accuracy = 0.8372\n",
      "Iteration 3365: Loss = 0.2595, Accuracy = 0.8150 Test Loss = 0.2466, Test Accuracy = 0.8378\n",
      "Iteration 3366: Loss = 0.2551, Accuracy = 0.8320 Test Loss = 0.2465, Test Accuracy = 0.8367\n",
      "Iteration 3367: Loss = 0.2505, Accuracy = 0.8420 Test Loss = 0.2465, Test Accuracy = 0.8379\n",
      "Iteration 3368: Loss = 0.2360, Accuracy = 0.8460 Test Loss = 0.2466, Test Accuracy = 0.8372\n",
      "Iteration 3369: Loss = 0.2285, Accuracy = 0.8470 Test Loss = 0.2465, Test Accuracy = 0.8384\n",
      "Iteration 3370: Loss = 0.2425, Accuracy = 0.8360 Test Loss = 0.2464, Test Accuracy = 0.8370\n",
      "Iteration 3371: Loss = 0.2367, Accuracy = 0.8550 Test Loss = 0.2465, Test Accuracy = 0.8372\n",
      "Iteration 3372: Loss = 0.2415, Accuracy = 0.8430 Test Loss = 0.2465, Test Accuracy = 0.8376\n",
      "Iteration 3373: Loss = 0.2468, Accuracy = 0.8180 Test Loss = 0.2464, Test Accuracy = 0.8367\n",
      "Iteration 3374: Loss = 0.2684, Accuracy = 0.8250 Test Loss = 0.2464, Test Accuracy = 0.8365\n",
      "Iteration 3375: Loss = 0.2426, Accuracy = 0.8290 Test Loss = 0.2464, Test Accuracy = 0.8359\n",
      "Iteration 3376: Loss = 0.2406, Accuracy = 0.8360 Test Loss = 0.2464, Test Accuracy = 0.8375\n",
      "Iteration 3377: Loss = 0.2446, Accuracy = 0.8440 Test Loss = 0.2464, Test Accuracy = 0.8380\n",
      "Iteration 3378: Loss = 0.2431, Accuracy = 0.8390 Test Loss = 0.2464, Test Accuracy = 0.8386\n",
      "Iteration 3379: Loss = 0.2510, Accuracy = 0.8110 Test Loss = 0.2465, Test Accuracy = 0.8362\n",
      "Iteration 3380: Loss = 0.2607, Accuracy = 0.8340 Test Loss = 0.2463, Test Accuracy = 0.8375\n",
      "Iteration 3381: Loss = 0.2509, Accuracy = 0.8230 Test Loss = 0.2464, Test Accuracy = 0.8378\n",
      "Iteration 3382: Loss = 0.2478, Accuracy = 0.8220 Test Loss = 0.2463, Test Accuracy = 0.8387\n",
      "Iteration 3383: Loss = 0.2341, Accuracy = 0.8540 Test Loss = 0.2463, Test Accuracy = 0.8371\n",
      "Iteration 3384: Loss = 0.2490, Accuracy = 0.8280 Test Loss = 0.2462, Test Accuracy = 0.8364\n",
      "Iteration 3385: Loss = 0.2484, Accuracy = 0.8160 Test Loss = 0.2462, Test Accuracy = 0.8391\n",
      "Iteration 3386: Loss = 0.2386, Accuracy = 0.8390 Test Loss = 0.2462, Test Accuracy = 0.8366\n",
      "Iteration 3387: Loss = 0.2587, Accuracy = 0.8150 Test Loss = 0.2462, Test Accuracy = 0.8375\n",
      "Iteration 3388: Loss = 0.2266, Accuracy = 0.8360 Test Loss = 0.2462, Test Accuracy = 0.8375\n",
      "Iteration 3389: Loss = 0.2283, Accuracy = 0.8380 Test Loss = 0.2461, Test Accuracy = 0.8371\n",
      "Iteration 3390: Loss = 0.2380, Accuracy = 0.8390 Test Loss = 0.2462, Test Accuracy = 0.8368\n",
      "Iteration 3391: Loss = 0.2239, Accuracy = 0.8630 Test Loss = 0.2461, Test Accuracy = 0.8370\n",
      "Iteration 3392: Loss = 0.2442, Accuracy = 0.8400 Test Loss = 0.2461, Test Accuracy = 0.8369\n",
      "Iteration 3393: Loss = 0.2440, Accuracy = 0.8330 Test Loss = 0.2460, Test Accuracy = 0.8383\n",
      "Iteration 3394: Loss = 0.2481, Accuracy = 0.8420 Test Loss = 0.2461, Test Accuracy = 0.8374\n",
      "Iteration 3395: Loss = 0.2336, Accuracy = 0.8330 Test Loss = 0.2460, Test Accuracy = 0.8377\n",
      "Iteration 3396: Loss = 0.2322, Accuracy = 0.8400 Test Loss = 0.2460, Test Accuracy = 0.8377\n",
      "Iteration 3397: Loss = 0.2536, Accuracy = 0.8310 Test Loss = 0.2461, Test Accuracy = 0.8372\n",
      "Iteration 3398: Loss = 0.2295, Accuracy = 0.8470 Test Loss = 0.2460, Test Accuracy = 0.8371\n",
      "Iteration 3399: Loss = 0.2416, Accuracy = 0.8630 Test Loss = 0.2459, Test Accuracy = 0.8368\n",
      "Iteration 3400: Loss = 0.2365, Accuracy = 0.8230 Test Loss = 0.2460, Test Accuracy = 0.8376\n",
      "Iteration 3401: Loss = 0.2508, Accuracy = 0.8200 Test Loss = 0.2460, Test Accuracy = 0.8375\n",
      "Iteration 3402: Loss = 0.2427, Accuracy = 0.8470 Test Loss = 0.2459, Test Accuracy = 0.8369\n",
      "Iteration 3403: Loss = 0.2294, Accuracy = 0.8410 Test Loss = 0.2460, Test Accuracy = 0.8371\n",
      "Iteration 3404: Loss = 0.2391, Accuracy = 0.8380 Test Loss = 0.2458, Test Accuracy = 0.8377\n",
      "Iteration 3405: Loss = 0.2441, Accuracy = 0.8420 Test Loss = 0.2459, Test Accuracy = 0.8369\n",
      "Iteration 3406: Loss = 0.2411, Accuracy = 0.8440 Test Loss = 0.2458, Test Accuracy = 0.8371\n",
      "Iteration 3407: Loss = 0.2465, Accuracy = 0.8340 Test Loss = 0.2458, Test Accuracy = 0.8376\n",
      "Iteration 3408: Loss = 0.2331, Accuracy = 0.8340 Test Loss = 0.2458, Test Accuracy = 0.8376\n",
      "Iteration 3409: Loss = 0.2489, Accuracy = 0.8390 Test Loss = 0.2459, Test Accuracy = 0.8386\n",
      "Iteration 3410: Loss = 0.2510, Accuracy = 0.8300 Test Loss = 0.2458, Test Accuracy = 0.8377\n",
      "Iteration 3411: Loss = 0.2309, Accuracy = 0.8450 Test Loss = 0.2459, Test Accuracy = 0.8383\n",
      "Iteration 3412: Loss = 0.2461, Accuracy = 0.8380 Test Loss = 0.2457, Test Accuracy = 0.8365\n",
      "Iteration 3413: Loss = 0.2422, Accuracy = 0.8320 Test Loss = 0.2457, Test Accuracy = 0.8387\n",
      "Iteration 3414: Loss = 0.2409, Accuracy = 0.8190 Test Loss = 0.2457, Test Accuracy = 0.8363\n",
      "Iteration 3415: Loss = 0.2456, Accuracy = 0.8360 Test Loss = 0.2458, Test Accuracy = 0.8378\n",
      "Iteration 3416: Loss = 0.2506, Accuracy = 0.8250 Test Loss = 0.2457, Test Accuracy = 0.8376\n",
      "Iteration 3417: Loss = 0.2435, Accuracy = 0.8320 Test Loss = 0.2457, Test Accuracy = 0.8388\n",
      "Iteration 3418: Loss = 0.2475, Accuracy = 0.8320 Test Loss = 0.2457, Test Accuracy = 0.8377\n",
      "Iteration 3419: Loss = 0.2325, Accuracy = 0.8450 Test Loss = 0.2457, Test Accuracy = 0.8379\n",
      "Iteration 3420: Loss = 0.2548, Accuracy = 0.8240 Test Loss = 0.2456, Test Accuracy = 0.8383\n",
      "Iteration 3421: Loss = 0.2347, Accuracy = 0.8450 Test Loss = 0.2456, Test Accuracy = 0.8369\n",
      "Iteration 3422: Loss = 0.2420, Accuracy = 0.8460 Test Loss = 0.2457, Test Accuracy = 0.8368\n",
      "Iteration 3423: Loss = 0.2255, Accuracy = 0.8500 Test Loss = 0.2455, Test Accuracy = 0.8371\n",
      "Iteration 3424: Loss = 0.2350, Accuracy = 0.8550 Test Loss = 0.2455, Test Accuracy = 0.8369\n",
      "Iteration 3425: Loss = 0.2379, Accuracy = 0.8210 Test Loss = 0.2455, Test Accuracy = 0.8378\n",
      "Iteration 3426: Loss = 0.2428, Accuracy = 0.8440 Test Loss = 0.2455, Test Accuracy = 0.8379\n",
      "Iteration 3427: Loss = 0.2482, Accuracy = 0.8180 Test Loss = 0.2455, Test Accuracy = 0.8380\n",
      "Iteration 3428: Loss = 0.2403, Accuracy = 0.8260 Test Loss = 0.2455, Test Accuracy = 0.8377\n",
      "Iteration 3429: Loss = 0.2481, Accuracy = 0.8380 Test Loss = 0.2454, Test Accuracy = 0.8374\n",
      "Iteration 3430: Loss = 0.2466, Accuracy = 0.8410 Test Loss = 0.2454, Test Accuracy = 0.8381\n",
      "Iteration 3431: Loss = 0.2387, Accuracy = 0.8450 Test Loss = 0.2454, Test Accuracy = 0.8373\n",
      "Iteration 3432: Loss = 0.2560, Accuracy = 0.8180 Test Loss = 0.2453, Test Accuracy = 0.8383\n",
      "Iteration 3433: Loss = 0.2394, Accuracy = 0.8450 Test Loss = 0.2455, Test Accuracy = 0.8374\n",
      "Iteration 3434: Loss = 0.2341, Accuracy = 0.8490 Test Loss = 0.2455, Test Accuracy = 0.8374\n",
      "Iteration 3435: Loss = 0.2468, Accuracy = 0.8240 Test Loss = 0.2455, Test Accuracy = 0.8385\n",
      "Iteration 3436: Loss = 0.2344, Accuracy = 0.8410 Test Loss = 0.2453, Test Accuracy = 0.8380\n",
      "Iteration 3437: Loss = 0.2387, Accuracy = 0.8240 Test Loss = 0.2453, Test Accuracy = 0.8383\n",
      "Iteration 3438: Loss = 0.2409, Accuracy = 0.8390 Test Loss = 0.2454, Test Accuracy = 0.8382\n",
      "Iteration 3439: Loss = 0.2385, Accuracy = 0.8070 Test Loss = 0.2453, Test Accuracy = 0.8378\n",
      "Iteration 3440: Loss = 0.2373, Accuracy = 0.8390 Test Loss = 0.2453, Test Accuracy = 0.8370\n",
      "Iteration 3441: Loss = 0.2490, Accuracy = 0.8280 Test Loss = 0.2452, Test Accuracy = 0.8385\n",
      "Iteration 3442: Loss = 0.2485, Accuracy = 0.8390 Test Loss = 0.2453, Test Accuracy = 0.8369\n",
      "Iteration 3443: Loss = 0.2501, Accuracy = 0.8320 Test Loss = 0.2452, Test Accuracy = 0.8373\n",
      "Iteration 3444: Loss = 0.2389, Accuracy = 0.8420 Test Loss = 0.2452, Test Accuracy = 0.8377\n",
      "Iteration 3445: Loss = 0.2436, Accuracy = 0.8450 Test Loss = 0.2452, Test Accuracy = 0.8381\n",
      "Iteration 3446: Loss = 0.2445, Accuracy = 0.8440 Test Loss = 0.2452, Test Accuracy = 0.8386\n",
      "Iteration 3447: Loss = 0.2543, Accuracy = 0.8250 Test Loss = 0.2452, Test Accuracy = 0.8389\n",
      "Iteration 3448: Loss = 0.2369, Accuracy = 0.8430 Test Loss = 0.2452, Test Accuracy = 0.8379\n",
      "Iteration 3449: Loss = 0.2475, Accuracy = 0.8360 Test Loss = 0.2451, Test Accuracy = 0.8376\n",
      "Iteration 3450: Loss = 0.2583, Accuracy = 0.8490 Test Loss = 0.2451, Test Accuracy = 0.8385\n",
      "Iteration 3451: Loss = 0.2463, Accuracy = 0.8180 Test Loss = 0.2451, Test Accuracy = 0.8383\n",
      "Iteration 3452: Loss = 0.2334, Accuracy = 0.8420 Test Loss = 0.2450, Test Accuracy = 0.8373\n",
      "Iteration 3453: Loss = 0.2502, Accuracy = 0.8320 Test Loss = 0.2451, Test Accuracy = 0.8382\n",
      "Iteration 3454: Loss = 0.2414, Accuracy = 0.8520 Test Loss = 0.2450, Test Accuracy = 0.8384\n",
      "Iteration 3455: Loss = 0.2440, Accuracy = 0.8480 Test Loss = 0.2449, Test Accuracy = 0.8372\n",
      "Iteration 3456: Loss = 0.2497, Accuracy = 0.8300 Test Loss = 0.2450, Test Accuracy = 0.8388\n",
      "Iteration 3457: Loss = 0.2275, Accuracy = 0.8450 Test Loss = 0.2450, Test Accuracy = 0.8373\n",
      "Iteration 3458: Loss = 0.2439, Accuracy = 0.8360 Test Loss = 0.2450, Test Accuracy = 0.8381\n",
      "Iteration 3459: Loss = 0.2457, Accuracy = 0.8160 Test Loss = 0.2450, Test Accuracy = 0.8380\n",
      "Iteration 3460: Loss = 0.2667, Accuracy = 0.8170 Test Loss = 0.2449, Test Accuracy = 0.8379\n",
      "Iteration 3461: Loss = 0.2497, Accuracy = 0.8520 Test Loss = 0.2450, Test Accuracy = 0.8381\n",
      "Iteration 3462: Loss = 0.2357, Accuracy = 0.8360 Test Loss = 0.2450, Test Accuracy = 0.8375\n",
      "Iteration 3463: Loss = 0.2491, Accuracy = 0.8290 Test Loss = 0.2449, Test Accuracy = 0.8380\n",
      "Iteration 3464: Loss = 0.2347, Accuracy = 0.8300 Test Loss = 0.2448, Test Accuracy = 0.8382\n",
      "Iteration 3465: Loss = 0.2501, Accuracy = 0.8470 Test Loss = 0.2448, Test Accuracy = 0.8389\n",
      "Iteration 3466: Loss = 0.2488, Accuracy = 0.8080 Test Loss = 0.2448, Test Accuracy = 0.8369\n",
      "Iteration 3467: Loss = 0.2588, Accuracy = 0.8210 Test Loss = 0.2448, Test Accuracy = 0.8392\n",
      "Iteration 3468: Loss = 0.2414, Accuracy = 0.8470 Test Loss = 0.2449, Test Accuracy = 0.8377\n",
      "Iteration 3469: Loss = 0.2467, Accuracy = 0.8270 Test Loss = 0.2447, Test Accuracy = 0.8378\n",
      "Iteration 3470: Loss = 0.2428, Accuracy = 0.8190 Test Loss = 0.2448, Test Accuracy = 0.8394\n",
      "Iteration 3471: Loss = 0.2530, Accuracy = 0.8390 Test Loss = 0.2448, Test Accuracy = 0.8374\n",
      "Iteration 3472: Loss = 0.2540, Accuracy = 0.8150 Test Loss = 0.2447, Test Accuracy = 0.8373\n",
      "Iteration 3473: Loss = 0.2529, Accuracy = 0.8220 Test Loss = 0.2448, Test Accuracy = 0.8379\n",
      "Iteration 3474: Loss = 0.2326, Accuracy = 0.8360 Test Loss = 0.2447, Test Accuracy = 0.8386\n",
      "Iteration 3475: Loss = 0.2291, Accuracy = 0.8170 Test Loss = 0.2447, Test Accuracy = 0.8377\n",
      "Iteration 3476: Loss = 0.2382, Accuracy = 0.8340 Test Loss = 0.2447, Test Accuracy = 0.8386\n",
      "Iteration 3477: Loss = 0.2368, Accuracy = 0.8430 Test Loss = 0.2447, Test Accuracy = 0.8383\n",
      "Iteration 3478: Loss = 0.2468, Accuracy = 0.8300 Test Loss = 0.2446, Test Accuracy = 0.8377\n",
      "Iteration 3479: Loss = 0.2430, Accuracy = 0.8430 Test Loss = 0.2446, Test Accuracy = 0.8378\n",
      "Iteration 3480: Loss = 0.2369, Accuracy = 0.8420 Test Loss = 0.2447, Test Accuracy = 0.8377\n",
      "Iteration 3481: Loss = 0.2418, Accuracy = 0.8270 Test Loss = 0.2445, Test Accuracy = 0.8387\n",
      "Iteration 3482: Loss = 0.2549, Accuracy = 0.8460 Test Loss = 0.2446, Test Accuracy = 0.8376\n",
      "Iteration 3483: Loss = 0.2434, Accuracy = 0.8200 Test Loss = 0.2446, Test Accuracy = 0.8380\n",
      "Iteration 3484: Loss = 0.2586, Accuracy = 0.8360 Test Loss = 0.2446, Test Accuracy = 0.8380\n",
      "Iteration 3485: Loss = 0.2446, Accuracy = 0.8430 Test Loss = 0.2446, Test Accuracy = 0.8384\n",
      "Iteration 3486: Loss = 0.2409, Accuracy = 0.8090 Test Loss = 0.2444, Test Accuracy = 0.8386\n",
      "Iteration 3487: Loss = 0.2339, Accuracy = 0.8430 Test Loss = 0.2445, Test Accuracy = 0.8376\n",
      "Iteration 3488: Loss = 0.2408, Accuracy = 0.8350 Test Loss = 0.2445, Test Accuracy = 0.8366\n",
      "Iteration 3489: Loss = 0.2510, Accuracy = 0.8370 Test Loss = 0.2445, Test Accuracy = 0.8374\n",
      "Iteration 3490: Loss = 0.2391, Accuracy = 0.8300 Test Loss = 0.2444, Test Accuracy = 0.8378\n",
      "Iteration 3491: Loss = 0.2414, Accuracy = 0.8370 Test Loss = 0.2444, Test Accuracy = 0.8383\n",
      "Iteration 3492: Loss = 0.2472, Accuracy = 0.8310 Test Loss = 0.2444, Test Accuracy = 0.8377\n",
      "Iteration 3493: Loss = 0.2386, Accuracy = 0.8290 Test Loss = 0.2444, Test Accuracy = 0.8385\n",
      "Iteration 3494: Loss = 0.2307, Accuracy = 0.8410 Test Loss = 0.2443, Test Accuracy = 0.8388\n",
      "Iteration 3495: Loss = 0.2672, Accuracy = 0.8160 Test Loss = 0.2443, Test Accuracy = 0.8384\n",
      "Iteration 3496: Loss = 0.2367, Accuracy = 0.8570 Test Loss = 0.2443, Test Accuracy = 0.8371\n",
      "Iteration 3497: Loss = 0.2483, Accuracy = 0.8330 Test Loss = 0.2444, Test Accuracy = 0.8385\n",
      "Iteration 3498: Loss = 0.2436, Accuracy = 0.8340 Test Loss = 0.2443, Test Accuracy = 0.8383\n",
      "Iteration 3499: Loss = 0.2429, Accuracy = 0.8290 Test Loss = 0.2443, Test Accuracy = 0.8384\n",
      "Iteration 3500: Loss = 0.2387, Accuracy = 0.8220 Test Loss = 0.2443, Test Accuracy = 0.8373\n",
      "Iteration 3501: Loss = 0.2567, Accuracy = 0.8200 Test Loss = 0.2443, Test Accuracy = 0.8380\n",
      "Iteration 3502: Loss = 0.2402, Accuracy = 0.8410 Test Loss = 0.2443, Test Accuracy = 0.8380\n",
      "Iteration 3503: Loss = 0.2575, Accuracy = 0.8360 Test Loss = 0.2444, Test Accuracy = 0.8377\n",
      "Iteration 3504: Loss = 0.2348, Accuracy = 0.8370 Test Loss = 0.2442, Test Accuracy = 0.8382\n",
      "Iteration 3505: Loss = 0.2450, Accuracy = 0.8180 Test Loss = 0.2442, Test Accuracy = 0.8380\n",
      "Iteration 3506: Loss = 0.2351, Accuracy = 0.8540 Test Loss = 0.2442, Test Accuracy = 0.8382\n",
      "Iteration 3507: Loss = 0.2247, Accuracy = 0.8430 Test Loss = 0.2441, Test Accuracy = 0.8385\n",
      "Iteration 3508: Loss = 0.2571, Accuracy = 0.8280 Test Loss = 0.2441, Test Accuracy = 0.8388\n",
      "Iteration 3509: Loss = 0.2237, Accuracy = 0.8450 Test Loss = 0.2440, Test Accuracy = 0.8376\n",
      "Iteration 3510: Loss = 0.2369, Accuracy = 0.8360 Test Loss = 0.2441, Test Accuracy = 0.8385\n",
      "Iteration 3511: Loss = 0.2469, Accuracy = 0.8320 Test Loss = 0.2441, Test Accuracy = 0.8389\n",
      "Iteration 3512: Loss = 0.2474, Accuracy = 0.8270 Test Loss = 0.2440, Test Accuracy = 0.8372\n",
      "Iteration 3513: Loss = 0.2440, Accuracy = 0.8310 Test Loss = 0.2441, Test Accuracy = 0.8378\n",
      "Iteration 3514: Loss = 0.2476, Accuracy = 0.8290 Test Loss = 0.2441, Test Accuracy = 0.8365\n",
      "Iteration 3515: Loss = 0.2436, Accuracy = 0.8240 Test Loss = 0.2440, Test Accuracy = 0.8382\n",
      "Iteration 3516: Loss = 0.2394, Accuracy = 0.8310 Test Loss = 0.2439, Test Accuracy = 0.8383\n",
      "Iteration 3517: Loss = 0.2501, Accuracy = 0.8210 Test Loss = 0.2440, Test Accuracy = 0.8379\n",
      "Iteration 3518: Loss = 0.2324, Accuracy = 0.8490 Test Loss = 0.2441, Test Accuracy = 0.8374\n",
      "Iteration 3519: Loss = 0.2447, Accuracy = 0.8350 Test Loss = 0.2440, Test Accuracy = 0.8377\n",
      "Iteration 3520: Loss = 0.2631, Accuracy = 0.8230 Test Loss = 0.2439, Test Accuracy = 0.8385\n",
      "Iteration 3521: Loss = 0.2315, Accuracy = 0.8400 Test Loss = 0.2440, Test Accuracy = 0.8380\n",
      "Iteration 3522: Loss = 0.2300, Accuracy = 0.8290 Test Loss = 0.2439, Test Accuracy = 0.8389\n",
      "Iteration 3523: Loss = 0.2345, Accuracy = 0.8500 Test Loss = 0.2438, Test Accuracy = 0.8381\n",
      "Iteration 3524: Loss = 0.2452, Accuracy = 0.8210 Test Loss = 0.2439, Test Accuracy = 0.8389\n",
      "Iteration 3525: Loss = 0.2412, Accuracy = 0.8310 Test Loss = 0.2439, Test Accuracy = 0.8384\n",
      "Iteration 3526: Loss = 0.2567, Accuracy = 0.8090 Test Loss = 0.2438, Test Accuracy = 0.8386\n",
      "Iteration 3527: Loss = 0.2330, Accuracy = 0.8570 Test Loss = 0.2438, Test Accuracy = 0.8377\n",
      "Iteration 3528: Loss = 0.2442, Accuracy = 0.8410 Test Loss = 0.2439, Test Accuracy = 0.8386\n",
      "Iteration 3529: Loss = 0.2403, Accuracy = 0.8420 Test Loss = 0.2438, Test Accuracy = 0.8388\n",
      "Iteration 3530: Loss = 0.2401, Accuracy = 0.8330 Test Loss = 0.2439, Test Accuracy = 0.8382\n",
      "Iteration 3531: Loss = 0.2420, Accuracy = 0.8390 Test Loss = 0.2439, Test Accuracy = 0.8379\n",
      "Iteration 3532: Loss = 0.2391, Accuracy = 0.8420 Test Loss = 0.2437, Test Accuracy = 0.8373\n",
      "Iteration 3533: Loss = 0.2447, Accuracy = 0.8430 Test Loss = 0.2437, Test Accuracy = 0.8386\n",
      "Iteration 3534: Loss = 0.2283, Accuracy = 0.8480 Test Loss = 0.2438, Test Accuracy = 0.8384\n",
      "Iteration 3535: Loss = 0.2707, Accuracy = 0.8240 Test Loss = 0.2437, Test Accuracy = 0.8383\n",
      "Iteration 3536: Loss = 0.2442, Accuracy = 0.8410 Test Loss = 0.2437, Test Accuracy = 0.8380\n",
      "Iteration 3537: Loss = 0.2355, Accuracy = 0.8300 Test Loss = 0.2436, Test Accuracy = 0.8375\n",
      "Iteration 3538: Loss = 0.2509, Accuracy = 0.8240 Test Loss = 0.2437, Test Accuracy = 0.8379\n",
      "Iteration 3539: Loss = 0.2369, Accuracy = 0.8500 Test Loss = 0.2437, Test Accuracy = 0.8387\n",
      "Iteration 3540: Loss = 0.2489, Accuracy = 0.8090 Test Loss = 0.2436, Test Accuracy = 0.8383\n",
      "Iteration 3541: Loss = 0.2462, Accuracy = 0.8300 Test Loss = 0.2436, Test Accuracy = 0.8388\n",
      "Iteration 3542: Loss = 0.2374, Accuracy = 0.8270 Test Loss = 0.2435, Test Accuracy = 0.8390\n",
      "Iteration 3543: Loss = 0.2355, Accuracy = 0.8230 Test Loss = 0.2436, Test Accuracy = 0.8375\n",
      "Iteration 3544: Loss = 0.2615, Accuracy = 0.8020 Test Loss = 0.2435, Test Accuracy = 0.8376\n",
      "Iteration 3545: Loss = 0.2441, Accuracy = 0.8460 Test Loss = 0.2436, Test Accuracy = 0.8383\n",
      "Iteration 3546: Loss = 0.2341, Accuracy = 0.8280 Test Loss = 0.2435, Test Accuracy = 0.8400\n",
      "Iteration 3547: Loss = 0.2399, Accuracy = 0.8070 Test Loss = 0.2435, Test Accuracy = 0.8379\n",
      "Iteration 3548: Loss = 0.2513, Accuracy = 0.8320 Test Loss = 0.2435, Test Accuracy = 0.8370\n",
      "Iteration 3549: Loss = 0.2411, Accuracy = 0.8250 Test Loss = 0.2436, Test Accuracy = 0.8387\n",
      "Iteration 3550: Loss = 0.2283, Accuracy = 0.8350 Test Loss = 0.2434, Test Accuracy = 0.8382\n",
      "Iteration 3551: Loss = 0.2469, Accuracy = 0.8340 Test Loss = 0.2434, Test Accuracy = 0.8385\n",
      "Iteration 3552: Loss = 0.2364, Accuracy = 0.8450 Test Loss = 0.2433, Test Accuracy = 0.8393\n",
      "Iteration 3553: Loss = 0.2418, Accuracy = 0.8280 Test Loss = 0.2434, Test Accuracy = 0.8379\n",
      "Iteration 3554: Loss = 0.2435, Accuracy = 0.8170 Test Loss = 0.2433, Test Accuracy = 0.8381\n",
      "Iteration 3555: Loss = 0.2382, Accuracy = 0.8360 Test Loss = 0.2434, Test Accuracy = 0.8389\n",
      "Iteration 3556: Loss = 0.2456, Accuracy = 0.8450 Test Loss = 0.2433, Test Accuracy = 0.8380\n",
      "Iteration 3557: Loss = 0.2389, Accuracy = 0.8430 Test Loss = 0.2434, Test Accuracy = 0.8376\n",
      "Iteration 3558: Loss = 0.2338, Accuracy = 0.8360 Test Loss = 0.2434, Test Accuracy = 0.8381\n",
      "Iteration 3559: Loss = 0.2332, Accuracy = 0.8310 Test Loss = 0.2433, Test Accuracy = 0.8388\n",
      "Iteration 3560: Loss = 0.2383, Accuracy = 0.8440 Test Loss = 0.2433, Test Accuracy = 0.8391\n",
      "Iteration 3561: Loss = 0.2335, Accuracy = 0.8460 Test Loss = 0.2433, Test Accuracy = 0.8392\n",
      "Iteration 3562: Loss = 0.2295, Accuracy = 0.8390 Test Loss = 0.2433, Test Accuracy = 0.8383\n",
      "Iteration 3563: Loss = 0.2428, Accuracy = 0.8310 Test Loss = 0.2433, Test Accuracy = 0.8391\n",
      "Iteration 3564: Loss = 0.2422, Accuracy = 0.8460 Test Loss = 0.2432, Test Accuracy = 0.8390\n",
      "Iteration 3565: Loss = 0.2449, Accuracy = 0.8240 Test Loss = 0.2432, Test Accuracy = 0.8384\n",
      "Iteration 3566: Loss = 0.2385, Accuracy = 0.8360 Test Loss = 0.2432, Test Accuracy = 0.8390\n",
      "Iteration 3567: Loss = 0.2374, Accuracy = 0.8440 Test Loss = 0.2432, Test Accuracy = 0.8387\n",
      "Iteration 3568: Loss = 0.2353, Accuracy = 0.8550 Test Loss = 0.2431, Test Accuracy = 0.8383\n",
      "Iteration 3569: Loss = 0.2555, Accuracy = 0.8300 Test Loss = 0.2432, Test Accuracy = 0.8371\n",
      "Iteration 3570: Loss = 0.2416, Accuracy = 0.8320 Test Loss = 0.2432, Test Accuracy = 0.8376\n",
      "Iteration 3571: Loss = 0.2449, Accuracy = 0.8390 Test Loss = 0.2432, Test Accuracy = 0.8386\n",
      "Iteration 3572: Loss = 0.2361, Accuracy = 0.8330 Test Loss = 0.2430, Test Accuracy = 0.8384\n",
      "Iteration 3573: Loss = 0.2469, Accuracy = 0.8190 Test Loss = 0.2431, Test Accuracy = 0.8389\n",
      "Iteration 3574: Loss = 0.2334, Accuracy = 0.8410 Test Loss = 0.2431, Test Accuracy = 0.8391\n",
      "Iteration 3575: Loss = 0.2365, Accuracy = 0.8370 Test Loss = 0.2431, Test Accuracy = 0.8386\n",
      "Iteration 3576: Loss = 0.2380, Accuracy = 0.8320 Test Loss = 0.2430, Test Accuracy = 0.8377\n",
      "Iteration 3577: Loss = 0.2310, Accuracy = 0.8220 Test Loss = 0.2430, Test Accuracy = 0.8380\n",
      "Iteration 3578: Loss = 0.2440, Accuracy = 0.8430 Test Loss = 0.2430, Test Accuracy = 0.8388\n",
      "Iteration 3579: Loss = 0.2290, Accuracy = 0.8440 Test Loss = 0.2430, Test Accuracy = 0.8385\n",
      "Iteration 3580: Loss = 0.2542, Accuracy = 0.8470 Test Loss = 0.2430, Test Accuracy = 0.8380\n",
      "Iteration 3581: Loss = 0.2464, Accuracy = 0.8300 Test Loss = 0.2430, Test Accuracy = 0.8385\n",
      "Iteration 3582: Loss = 0.2311, Accuracy = 0.8250 Test Loss = 0.2429, Test Accuracy = 0.8389\n",
      "Iteration 3583: Loss = 0.2268, Accuracy = 0.8610 Test Loss = 0.2429, Test Accuracy = 0.8378\n",
      "Iteration 3584: Loss = 0.2585, Accuracy = 0.8240 Test Loss = 0.2429, Test Accuracy = 0.8383\n",
      "Iteration 3585: Loss = 0.2584, Accuracy = 0.8180 Test Loss = 0.2429, Test Accuracy = 0.8380\n",
      "Iteration 3586: Loss = 0.2390, Accuracy = 0.8400 Test Loss = 0.2430, Test Accuracy = 0.8381\n",
      "Iteration 3587: Loss = 0.2365, Accuracy = 0.8260 Test Loss = 0.2429, Test Accuracy = 0.8390\n",
      "Iteration 3588: Loss = 0.2292, Accuracy = 0.8490 Test Loss = 0.2428, Test Accuracy = 0.8377\n",
      "Iteration 3589: Loss = 0.2286, Accuracy = 0.8490 Test Loss = 0.2428, Test Accuracy = 0.8389\n",
      "Iteration 3590: Loss = 0.2581, Accuracy = 0.8220 Test Loss = 0.2429, Test Accuracy = 0.8390\n",
      "Iteration 3591: Loss = 0.2337, Accuracy = 0.8360 Test Loss = 0.2428, Test Accuracy = 0.8389\n",
      "Iteration 3592: Loss = 0.2455, Accuracy = 0.8300 Test Loss = 0.2428, Test Accuracy = 0.8388\n",
      "Iteration 3593: Loss = 0.2479, Accuracy = 0.8520 Test Loss = 0.2428, Test Accuracy = 0.8379\n",
      "Iteration 3594: Loss = 0.2345, Accuracy = 0.8510 Test Loss = 0.2428, Test Accuracy = 0.8385\n",
      "Iteration 3595: Loss = 0.2372, Accuracy = 0.8350 Test Loss = 0.2427, Test Accuracy = 0.8378\n",
      "Iteration 3596: Loss = 0.2259, Accuracy = 0.8620 Test Loss = 0.2427, Test Accuracy = 0.8386\n",
      "Iteration 3597: Loss = 0.2373, Accuracy = 0.8400 Test Loss = 0.2427, Test Accuracy = 0.8383\n",
      "Iteration 3598: Loss = 0.2451, Accuracy = 0.8420 Test Loss = 0.2427, Test Accuracy = 0.8366\n",
      "Iteration 3599: Loss = 0.2467, Accuracy = 0.8090 Test Loss = 0.2427, Test Accuracy = 0.8390\n",
      "Iteration 3600: Loss = 0.2245, Accuracy = 0.8530 Test Loss = 0.2427, Test Accuracy = 0.8385\n",
      "Iteration 3601: Loss = 0.2344, Accuracy = 0.8350 Test Loss = 0.2427, Test Accuracy = 0.8374\n",
      "Iteration 3602: Loss = 0.2400, Accuracy = 0.8400 Test Loss = 0.2426, Test Accuracy = 0.8379\n",
      "Iteration 3603: Loss = 0.2388, Accuracy = 0.8300 Test Loss = 0.2427, Test Accuracy = 0.8379\n",
      "Iteration 3604: Loss = 0.2394, Accuracy = 0.8310 Test Loss = 0.2426, Test Accuracy = 0.8387\n",
      "Iteration 3605: Loss = 0.2351, Accuracy = 0.8450 Test Loss = 0.2427, Test Accuracy = 0.8387\n",
      "Iteration 3606: Loss = 0.2341, Accuracy = 0.8300 Test Loss = 0.2427, Test Accuracy = 0.8379\n",
      "Iteration 3607: Loss = 0.2436, Accuracy = 0.8430 Test Loss = 0.2426, Test Accuracy = 0.8385\n",
      "Iteration 3608: Loss = 0.2430, Accuracy = 0.8360 Test Loss = 0.2426, Test Accuracy = 0.8391\n",
      "Iteration 3609: Loss = 0.2512, Accuracy = 0.8300 Test Loss = 0.2425, Test Accuracy = 0.8388\n",
      "Iteration 3610: Loss = 0.2321, Accuracy = 0.8510 Test Loss = 0.2424, Test Accuracy = 0.8397\n",
      "Iteration 3611: Loss = 0.2436, Accuracy = 0.8340 Test Loss = 0.2425, Test Accuracy = 0.8386\n",
      "Iteration 3612: Loss = 0.2535, Accuracy = 0.8160 Test Loss = 0.2425, Test Accuracy = 0.8388\n",
      "Iteration 3613: Loss = 0.2469, Accuracy = 0.8310 Test Loss = 0.2424, Test Accuracy = 0.8393\n",
      "Iteration 3614: Loss = 0.2572, Accuracy = 0.7940 Test Loss = 0.2425, Test Accuracy = 0.8384\n",
      "Iteration 3615: Loss = 0.2386, Accuracy = 0.8310 Test Loss = 0.2424, Test Accuracy = 0.8387\n",
      "Iteration 3616: Loss = 0.2348, Accuracy = 0.8290 Test Loss = 0.2424, Test Accuracy = 0.8393\n",
      "Iteration 3617: Loss = 0.2546, Accuracy = 0.8060 Test Loss = 0.2423, Test Accuracy = 0.8380\n",
      "Iteration 3618: Loss = 0.2510, Accuracy = 0.8400 Test Loss = 0.2424, Test Accuracy = 0.8391\n",
      "Iteration 3619: Loss = 0.2314, Accuracy = 0.8420 Test Loss = 0.2423, Test Accuracy = 0.8405\n",
      "Iteration 3620: Loss = 0.2325, Accuracy = 0.8240 Test Loss = 0.2424, Test Accuracy = 0.8378\n",
      "Iteration 3621: Loss = 0.2424, Accuracy = 0.8400 Test Loss = 0.2424, Test Accuracy = 0.8385\n",
      "Iteration 3622: Loss = 0.2589, Accuracy = 0.8180 Test Loss = 0.2424, Test Accuracy = 0.8388\n",
      "Iteration 3623: Loss = 0.2459, Accuracy = 0.8350 Test Loss = 0.2424, Test Accuracy = 0.8373\n",
      "Iteration 3624: Loss = 0.2502, Accuracy = 0.8190 Test Loss = 0.2423, Test Accuracy = 0.8383\n",
      "Iteration 3625: Loss = 0.2373, Accuracy = 0.8310 Test Loss = 0.2423, Test Accuracy = 0.8395\n",
      "Iteration 3626: Loss = 0.2446, Accuracy = 0.8190 Test Loss = 0.2422, Test Accuracy = 0.8395\n",
      "Iteration 3627: Loss = 0.2345, Accuracy = 0.8260 Test Loss = 0.2423, Test Accuracy = 0.8392\n",
      "Iteration 3628: Loss = 0.2293, Accuracy = 0.8410 Test Loss = 0.2422, Test Accuracy = 0.8394\n",
      "Iteration 3629: Loss = 0.2264, Accuracy = 0.8570 Test Loss = 0.2423, Test Accuracy = 0.8383\n",
      "Iteration 3630: Loss = 0.2237, Accuracy = 0.8400 Test Loss = 0.2422, Test Accuracy = 0.8379\n",
      "Iteration 3631: Loss = 0.2414, Accuracy = 0.8270 Test Loss = 0.2422, Test Accuracy = 0.8382\n",
      "Iteration 3632: Loss = 0.2392, Accuracy = 0.8150 Test Loss = 0.2421, Test Accuracy = 0.8388\n",
      "Iteration 3633: Loss = 0.2267, Accuracy = 0.8430 Test Loss = 0.2422, Test Accuracy = 0.8371\n",
      "Iteration 3634: Loss = 0.2417, Accuracy = 0.8240 Test Loss = 0.2422, Test Accuracy = 0.8376\n",
      "Iteration 3635: Loss = 0.2491, Accuracy = 0.8300 Test Loss = 0.2421, Test Accuracy = 0.8383\n",
      "Iteration 3636: Loss = 0.2413, Accuracy = 0.8330 Test Loss = 0.2421, Test Accuracy = 0.8391\n",
      "Iteration 3637: Loss = 0.2313, Accuracy = 0.8450 Test Loss = 0.2422, Test Accuracy = 0.8378\n",
      "Iteration 3638: Loss = 0.2493, Accuracy = 0.8220 Test Loss = 0.2421, Test Accuracy = 0.8388\n",
      "Iteration 3639: Loss = 0.2460, Accuracy = 0.8180 Test Loss = 0.2421, Test Accuracy = 0.8386\n",
      "Iteration 3640: Loss = 0.2535, Accuracy = 0.8210 Test Loss = 0.2422, Test Accuracy = 0.8378\n",
      "Iteration 3641: Loss = 0.2477, Accuracy = 0.8250 Test Loss = 0.2420, Test Accuracy = 0.8380\n",
      "Iteration 3642: Loss = 0.2381, Accuracy = 0.8380 Test Loss = 0.2420, Test Accuracy = 0.8385\n",
      "Iteration 3643: Loss = 0.2460, Accuracy = 0.8180 Test Loss = 0.2420, Test Accuracy = 0.8383\n",
      "Iteration 3644: Loss = 0.2384, Accuracy = 0.8320 Test Loss = 0.2420, Test Accuracy = 0.8377\n",
      "Iteration 3645: Loss = 0.2412, Accuracy = 0.8350 Test Loss = 0.2419, Test Accuracy = 0.8388\n",
      "Iteration 3646: Loss = 0.2428, Accuracy = 0.8300 Test Loss = 0.2421, Test Accuracy = 0.8373\n",
      "Iteration 3647: Loss = 0.2290, Accuracy = 0.8440 Test Loss = 0.2419, Test Accuracy = 0.8384\n",
      "Iteration 3648: Loss = 0.2374, Accuracy = 0.8340 Test Loss = 0.2420, Test Accuracy = 0.8400\n",
      "Iteration 3649: Loss = 0.2431, Accuracy = 0.8250 Test Loss = 0.2420, Test Accuracy = 0.8376\n",
      "Iteration 3650: Loss = 0.2322, Accuracy = 0.8280 Test Loss = 0.2419, Test Accuracy = 0.8388\n",
      "Iteration 3651: Loss = 0.2255, Accuracy = 0.8320 Test Loss = 0.2421, Test Accuracy = 0.8390\n",
      "Iteration 3652: Loss = 0.2503, Accuracy = 0.8440 Test Loss = 0.2419, Test Accuracy = 0.8392\n",
      "Iteration 3653: Loss = 0.2440, Accuracy = 0.8360 Test Loss = 0.2419, Test Accuracy = 0.8388\n",
      "Iteration 3654: Loss = 0.2472, Accuracy = 0.8330 Test Loss = 0.2419, Test Accuracy = 0.8381\n",
      "Iteration 3655: Loss = 0.2476, Accuracy = 0.8310 Test Loss = 0.2418, Test Accuracy = 0.8382\n",
      "Iteration 3656: Loss = 0.2478, Accuracy = 0.8040 Test Loss = 0.2418, Test Accuracy = 0.8390\n",
      "Iteration 3657: Loss = 0.2353, Accuracy = 0.8470 Test Loss = 0.2417, Test Accuracy = 0.8393\n",
      "Iteration 3658: Loss = 0.2341, Accuracy = 0.8490 Test Loss = 0.2417, Test Accuracy = 0.8391\n",
      "Iteration 3659: Loss = 0.2404, Accuracy = 0.8360 Test Loss = 0.2417, Test Accuracy = 0.8389\n",
      "Iteration 3660: Loss = 0.2385, Accuracy = 0.8370 Test Loss = 0.2417, Test Accuracy = 0.8380\n",
      "Iteration 3661: Loss = 0.2467, Accuracy = 0.8130 Test Loss = 0.2418, Test Accuracy = 0.8386\n",
      "Iteration 3662: Loss = 0.2494, Accuracy = 0.8340 Test Loss = 0.2417, Test Accuracy = 0.8388\n",
      "Iteration 3663: Loss = 0.2475, Accuracy = 0.8100 Test Loss = 0.2417, Test Accuracy = 0.8390\n",
      "Iteration 3664: Loss = 0.2566, Accuracy = 0.8360 Test Loss = 0.2417, Test Accuracy = 0.8389\n",
      "Iteration 3665: Loss = 0.2462, Accuracy = 0.8230 Test Loss = 0.2418, Test Accuracy = 0.8387\n",
      "Iteration 3666: Loss = 0.2185, Accuracy = 0.8520 Test Loss = 0.2417, Test Accuracy = 0.8391\n",
      "Iteration 3667: Loss = 0.2443, Accuracy = 0.8250 Test Loss = 0.2416, Test Accuracy = 0.8394\n",
      "Iteration 3668: Loss = 0.2274, Accuracy = 0.8460 Test Loss = 0.2416, Test Accuracy = 0.8389\n",
      "Iteration 3669: Loss = 0.2483, Accuracy = 0.8360 Test Loss = 0.2416, Test Accuracy = 0.8375\n",
      "Iteration 3670: Loss = 0.2374, Accuracy = 0.8470 Test Loss = 0.2417, Test Accuracy = 0.8386\n",
      "Iteration 3671: Loss = 0.2281, Accuracy = 0.8480 Test Loss = 0.2416, Test Accuracy = 0.8377\n",
      "Iteration 3672: Loss = 0.2352, Accuracy = 0.8430 Test Loss = 0.2415, Test Accuracy = 0.8382\n",
      "Iteration 3673: Loss = 0.2461, Accuracy = 0.8270 Test Loss = 0.2416, Test Accuracy = 0.8379\n",
      "Iteration 3674: Loss = 0.2534, Accuracy = 0.8450 Test Loss = 0.2416, Test Accuracy = 0.8389\n",
      "Iteration 3675: Loss = 0.2451, Accuracy = 0.8270 Test Loss = 0.2416, Test Accuracy = 0.8385\n",
      "Iteration 3676: Loss = 0.2429, Accuracy = 0.8210 Test Loss = 0.2414, Test Accuracy = 0.8397\n",
      "Iteration 3677: Loss = 0.2447, Accuracy = 0.8290 Test Loss = 0.2415, Test Accuracy = 0.8388\n",
      "Iteration 3678: Loss = 0.2496, Accuracy = 0.8290 Test Loss = 0.2415, Test Accuracy = 0.8391\n",
      "Iteration 3679: Loss = 0.2399, Accuracy = 0.8180 Test Loss = 0.2416, Test Accuracy = 0.8386\n",
      "Iteration 3680: Loss = 0.2324, Accuracy = 0.8490 Test Loss = 0.2415, Test Accuracy = 0.8391\n",
      "Iteration 3681: Loss = 0.2512, Accuracy = 0.8320 Test Loss = 0.2415, Test Accuracy = 0.8385\n",
      "Iteration 3682: Loss = 0.2214, Accuracy = 0.8380 Test Loss = 0.2414, Test Accuracy = 0.8381\n",
      "Iteration 3683: Loss = 0.2274, Accuracy = 0.8300 Test Loss = 0.2414, Test Accuracy = 0.8393\n",
      "Iteration 3684: Loss = 0.2373, Accuracy = 0.8380 Test Loss = 0.2414, Test Accuracy = 0.8395\n",
      "Iteration 3685: Loss = 0.2363, Accuracy = 0.8570 Test Loss = 0.2414, Test Accuracy = 0.8385\n",
      "Iteration 3686: Loss = 0.2381, Accuracy = 0.8390 Test Loss = 0.2414, Test Accuracy = 0.8389\n",
      "Iteration 3687: Loss = 0.2378, Accuracy = 0.8270 Test Loss = 0.2414, Test Accuracy = 0.8390\n",
      "Iteration 3688: Loss = 0.2336, Accuracy = 0.8270 Test Loss = 0.2413, Test Accuracy = 0.8390\n",
      "Iteration 3689: Loss = 0.2397, Accuracy = 0.8490 Test Loss = 0.2413, Test Accuracy = 0.8393\n",
      "Iteration 3690: Loss = 0.2429, Accuracy = 0.8140 Test Loss = 0.2413, Test Accuracy = 0.8393\n",
      "Iteration 3691: Loss = 0.2512, Accuracy = 0.8410 Test Loss = 0.2414, Test Accuracy = 0.8379\n",
      "Iteration 3692: Loss = 0.2458, Accuracy = 0.8310 Test Loss = 0.2413, Test Accuracy = 0.8395\n",
      "Iteration 3693: Loss = 0.2292, Accuracy = 0.8180 Test Loss = 0.2413, Test Accuracy = 0.8386\n",
      "Iteration 3694: Loss = 0.2432, Accuracy = 0.8250 Test Loss = 0.2413, Test Accuracy = 0.8384\n",
      "Iteration 3695: Loss = 0.2384, Accuracy = 0.8310 Test Loss = 0.2413, Test Accuracy = 0.8389\n",
      "Iteration 3696: Loss = 0.2602, Accuracy = 0.8280 Test Loss = 0.2412, Test Accuracy = 0.8387\n",
      "Iteration 3697: Loss = 0.2412, Accuracy = 0.8200 Test Loss = 0.2412, Test Accuracy = 0.8383\n",
      "Iteration 3698: Loss = 0.2464, Accuracy = 0.8290 Test Loss = 0.2412, Test Accuracy = 0.8375\n",
      "Iteration 3699: Loss = 0.2428, Accuracy = 0.8440 Test Loss = 0.2412, Test Accuracy = 0.8390\n",
      "Iteration 3700: Loss = 0.2423, Accuracy = 0.8280 Test Loss = 0.2412, Test Accuracy = 0.8385\n",
      "Iteration 3701: Loss = 0.2531, Accuracy = 0.8380 Test Loss = 0.2412, Test Accuracy = 0.8378\n",
      "Iteration 3702: Loss = 0.2445, Accuracy = 0.8110 Test Loss = 0.2411, Test Accuracy = 0.8398\n",
      "Iteration 3703: Loss = 0.2393, Accuracy = 0.8380 Test Loss = 0.2412, Test Accuracy = 0.8393\n",
      "Iteration 3704: Loss = 0.2521, Accuracy = 0.8160 Test Loss = 0.2411, Test Accuracy = 0.8399\n",
      "Iteration 3705: Loss = 0.2288, Accuracy = 0.8330 Test Loss = 0.2412, Test Accuracy = 0.8381\n",
      "Iteration 3706: Loss = 0.2419, Accuracy = 0.8180 Test Loss = 0.2411, Test Accuracy = 0.8405\n",
      "Iteration 3707: Loss = 0.2428, Accuracy = 0.8320 Test Loss = 0.2411, Test Accuracy = 0.8379\n",
      "Iteration 3708: Loss = 0.2448, Accuracy = 0.8220 Test Loss = 0.2410, Test Accuracy = 0.8395\n",
      "Iteration 3709: Loss = 0.2384, Accuracy = 0.8470 Test Loss = 0.2410, Test Accuracy = 0.8392\n",
      "Iteration 3710: Loss = 0.2414, Accuracy = 0.8420 Test Loss = 0.2410, Test Accuracy = 0.8390\n",
      "Iteration 3711: Loss = 0.2325, Accuracy = 0.8350 Test Loss = 0.2410, Test Accuracy = 0.8394\n",
      "Iteration 3712: Loss = 0.2421, Accuracy = 0.8260 Test Loss = 0.2410, Test Accuracy = 0.8385\n",
      "Iteration 3713: Loss = 0.2364, Accuracy = 0.8430 Test Loss = 0.2410, Test Accuracy = 0.8389\n",
      "Iteration 3714: Loss = 0.2432, Accuracy = 0.8290 Test Loss = 0.2409, Test Accuracy = 0.8396\n",
      "Iteration 3715: Loss = 0.2404, Accuracy = 0.8460 Test Loss = 0.2409, Test Accuracy = 0.8397\n",
      "Iteration 3716: Loss = 0.2231, Accuracy = 0.8410 Test Loss = 0.2409, Test Accuracy = 0.8393\n",
      "Iteration 3717: Loss = 0.2237, Accuracy = 0.8470 Test Loss = 0.2409, Test Accuracy = 0.8386\n",
      "Iteration 3718: Loss = 0.2277, Accuracy = 0.8470 Test Loss = 0.2409, Test Accuracy = 0.8389\n",
      "Iteration 3719: Loss = 0.2443, Accuracy = 0.8220 Test Loss = 0.2409, Test Accuracy = 0.8406\n",
      "Iteration 3720: Loss = 0.2289, Accuracy = 0.8290 Test Loss = 0.2409, Test Accuracy = 0.8391\n",
      "Iteration 3721: Loss = 0.2544, Accuracy = 0.7970 Test Loss = 0.2409, Test Accuracy = 0.8403\n",
      "Iteration 3722: Loss = 0.2281, Accuracy = 0.8350 Test Loss = 0.2409, Test Accuracy = 0.8398\n",
      "Iteration 3723: Loss = 0.2306, Accuracy = 0.8530 Test Loss = 0.2408, Test Accuracy = 0.8400\n",
      "Iteration 3724: Loss = 0.2333, Accuracy = 0.8170 Test Loss = 0.2409, Test Accuracy = 0.8385\n",
      "Iteration 3725: Loss = 0.2489, Accuracy = 0.8420 Test Loss = 0.2408, Test Accuracy = 0.8393\n",
      "Iteration 3726: Loss = 0.2360, Accuracy = 0.8250 Test Loss = 0.2408, Test Accuracy = 0.8399\n",
      "Iteration 3727: Loss = 0.2362, Accuracy = 0.8400 Test Loss = 0.2408, Test Accuracy = 0.8399\n",
      "Iteration 3728: Loss = 0.2364, Accuracy = 0.8370 Test Loss = 0.2407, Test Accuracy = 0.8392\n",
      "Iteration 3729: Loss = 0.2641, Accuracy = 0.8290 Test Loss = 0.2408, Test Accuracy = 0.8382\n",
      "Iteration 3730: Loss = 0.2315, Accuracy = 0.8400 Test Loss = 0.2407, Test Accuracy = 0.8387\n",
      "Iteration 3731: Loss = 0.2406, Accuracy = 0.8330 Test Loss = 0.2408, Test Accuracy = 0.8384\n",
      "Iteration 3732: Loss = 0.2357, Accuracy = 0.8480 Test Loss = 0.2407, Test Accuracy = 0.8385\n",
      "Iteration 3733: Loss = 0.2423, Accuracy = 0.8120 Test Loss = 0.2407, Test Accuracy = 0.8409\n",
      "Iteration 3734: Loss = 0.2517, Accuracy = 0.8270 Test Loss = 0.2407, Test Accuracy = 0.8391\n",
      "Iteration 3735: Loss = 0.2295, Accuracy = 0.8410 Test Loss = 0.2406, Test Accuracy = 0.8397\n",
      "Iteration 3736: Loss = 0.2276, Accuracy = 0.8300 Test Loss = 0.2406, Test Accuracy = 0.8399\n",
      "Iteration 3737: Loss = 0.2338, Accuracy = 0.8450 Test Loss = 0.2406, Test Accuracy = 0.8402\n",
      "Iteration 3738: Loss = 0.2252, Accuracy = 0.8480 Test Loss = 0.2406, Test Accuracy = 0.8401\n",
      "Iteration 3739: Loss = 0.2359, Accuracy = 0.8440 Test Loss = 0.2406, Test Accuracy = 0.8391\n",
      "Iteration 3740: Loss = 0.2468, Accuracy = 0.8330 Test Loss = 0.2406, Test Accuracy = 0.8383\n",
      "Iteration 3741: Loss = 0.2383, Accuracy = 0.8460 Test Loss = 0.2406, Test Accuracy = 0.8390\n",
      "Iteration 3742: Loss = 0.2536, Accuracy = 0.8210 Test Loss = 0.2406, Test Accuracy = 0.8373\n",
      "Iteration 3743: Loss = 0.2323, Accuracy = 0.8620 Test Loss = 0.2405, Test Accuracy = 0.8395\n",
      "Iteration 3744: Loss = 0.2391, Accuracy = 0.8330 Test Loss = 0.2405, Test Accuracy = 0.8395\n",
      "Iteration 3745: Loss = 0.2282, Accuracy = 0.8480 Test Loss = 0.2405, Test Accuracy = 0.8385\n",
      "Iteration 3746: Loss = 0.2374, Accuracy = 0.8210 Test Loss = 0.2404, Test Accuracy = 0.8401\n",
      "Iteration 3747: Loss = 0.2557, Accuracy = 0.8070 Test Loss = 0.2405, Test Accuracy = 0.8404\n",
      "Iteration 3748: Loss = 0.2394, Accuracy = 0.8440 Test Loss = 0.2406, Test Accuracy = 0.8397\n",
      "Iteration 3749: Loss = 0.2518, Accuracy = 0.8120 Test Loss = 0.2404, Test Accuracy = 0.8387\n",
      "Iteration 3750: Loss = 0.2288, Accuracy = 0.8410 Test Loss = 0.2404, Test Accuracy = 0.8398\n",
      "Iteration 3751: Loss = 0.2440, Accuracy = 0.8390 Test Loss = 0.2404, Test Accuracy = 0.8401\n",
      "Iteration 3752: Loss = 0.2388, Accuracy = 0.8470 Test Loss = 0.2404, Test Accuracy = 0.8381\n",
      "Iteration 3753: Loss = 0.2390, Accuracy = 0.8430 Test Loss = 0.2403, Test Accuracy = 0.8395\n",
      "Iteration 3754: Loss = 0.2387, Accuracy = 0.8340 Test Loss = 0.2404, Test Accuracy = 0.8396\n",
      "Iteration 3755: Loss = 0.2421, Accuracy = 0.8280 Test Loss = 0.2404, Test Accuracy = 0.8394\n",
      "Iteration 3756: Loss = 0.2494, Accuracy = 0.8250 Test Loss = 0.2403, Test Accuracy = 0.8392\n",
      "Iteration 3757: Loss = 0.2447, Accuracy = 0.8340 Test Loss = 0.2403, Test Accuracy = 0.8396\n",
      "Iteration 3758: Loss = 0.2399, Accuracy = 0.8280 Test Loss = 0.2405, Test Accuracy = 0.8391\n",
      "Iteration 3759: Loss = 0.2406, Accuracy = 0.8370 Test Loss = 0.2404, Test Accuracy = 0.8400\n",
      "Iteration 3760: Loss = 0.2206, Accuracy = 0.8420 Test Loss = 0.2403, Test Accuracy = 0.8393\n",
      "Iteration 3761: Loss = 0.2449, Accuracy = 0.8350 Test Loss = 0.2402, Test Accuracy = 0.8398\n",
      "Iteration 3762: Loss = 0.2350, Accuracy = 0.8450 Test Loss = 0.2403, Test Accuracy = 0.8397\n",
      "Iteration 3763: Loss = 0.2355, Accuracy = 0.8320 Test Loss = 0.2403, Test Accuracy = 0.8396\n",
      "Iteration 3764: Loss = 0.2581, Accuracy = 0.8300 Test Loss = 0.2403, Test Accuracy = 0.8398\n",
      "Iteration 3765: Loss = 0.2500, Accuracy = 0.8080 Test Loss = 0.2402, Test Accuracy = 0.8398\n",
      "Iteration 3766: Loss = 0.2514, Accuracy = 0.8280 Test Loss = 0.2402, Test Accuracy = 0.8396\n",
      "Iteration 3767: Loss = 0.2458, Accuracy = 0.8300 Test Loss = 0.2402, Test Accuracy = 0.8399\n",
      "Iteration 3768: Loss = 0.2346, Accuracy = 0.8310 Test Loss = 0.2402, Test Accuracy = 0.8404\n",
      "Iteration 3769: Loss = 0.2264, Accuracy = 0.8520 Test Loss = 0.2401, Test Accuracy = 0.8406\n",
      "Iteration 3770: Loss = 0.2425, Accuracy = 0.8580 Test Loss = 0.2401, Test Accuracy = 0.8391\n",
      "Iteration 3771: Loss = 0.2488, Accuracy = 0.8380 Test Loss = 0.2401, Test Accuracy = 0.8395\n",
      "Iteration 3772: Loss = 0.2498, Accuracy = 0.8090 Test Loss = 0.2401, Test Accuracy = 0.8396\n",
      "Iteration 3773: Loss = 0.2331, Accuracy = 0.8400 Test Loss = 0.2401, Test Accuracy = 0.8406\n",
      "Iteration 3774: Loss = 0.2341, Accuracy = 0.8230 Test Loss = 0.2401, Test Accuracy = 0.8400\n",
      "Iteration 3775: Loss = 0.2309, Accuracy = 0.8310 Test Loss = 0.2401, Test Accuracy = 0.8406\n",
      "Iteration 3776: Loss = 0.2277, Accuracy = 0.8400 Test Loss = 0.2400, Test Accuracy = 0.8390\n",
      "Iteration 3777: Loss = 0.2376, Accuracy = 0.8390 Test Loss = 0.2400, Test Accuracy = 0.8401\n",
      "Iteration 3778: Loss = 0.2413, Accuracy = 0.8280 Test Loss = 0.2401, Test Accuracy = 0.8390\n",
      "Iteration 3779: Loss = 0.2419, Accuracy = 0.8380 Test Loss = 0.2400, Test Accuracy = 0.8402\n",
      "Iteration 3780: Loss = 0.2342, Accuracy = 0.8470 Test Loss = 0.2400, Test Accuracy = 0.8394\n",
      "Iteration 3781: Loss = 0.2447, Accuracy = 0.8360 Test Loss = 0.2400, Test Accuracy = 0.8399\n",
      "Iteration 3782: Loss = 0.2586, Accuracy = 0.8250 Test Loss = 0.2400, Test Accuracy = 0.8394\n",
      "Iteration 3783: Loss = 0.2437, Accuracy = 0.8230 Test Loss = 0.2399, Test Accuracy = 0.8399\n",
      "Iteration 3784: Loss = 0.2347, Accuracy = 0.8340 Test Loss = 0.2399, Test Accuracy = 0.8400\n",
      "Iteration 3785: Loss = 0.2356, Accuracy = 0.8380 Test Loss = 0.2400, Test Accuracy = 0.8377\n",
      "Iteration 3786: Loss = 0.2528, Accuracy = 0.8170 Test Loss = 0.2399, Test Accuracy = 0.8408\n",
      "Iteration 3787: Loss = 0.2254, Accuracy = 0.8550 Test Loss = 0.2400, Test Accuracy = 0.8391\n",
      "Iteration 3788: Loss = 0.2339, Accuracy = 0.8420 Test Loss = 0.2399, Test Accuracy = 0.8398\n",
      "Iteration 3789: Loss = 0.2455, Accuracy = 0.8110 Test Loss = 0.2400, Test Accuracy = 0.8407\n",
      "Iteration 3790: Loss = 0.2274, Accuracy = 0.8360 Test Loss = 0.2398, Test Accuracy = 0.8402\n",
      "Iteration 3791: Loss = 0.2237, Accuracy = 0.8440 Test Loss = 0.2400, Test Accuracy = 0.8391\n",
      "Iteration 3792: Loss = 0.2397, Accuracy = 0.8340 Test Loss = 0.2399, Test Accuracy = 0.8398\n",
      "Iteration 3793: Loss = 0.2286, Accuracy = 0.8370 Test Loss = 0.2399, Test Accuracy = 0.8391\n",
      "Iteration 3794: Loss = 0.2359, Accuracy = 0.8400 Test Loss = 0.2398, Test Accuracy = 0.8382\n",
      "Iteration 3795: Loss = 0.2408, Accuracy = 0.8400 Test Loss = 0.2397, Test Accuracy = 0.8402\n",
      "Iteration 3796: Loss = 0.2353, Accuracy = 0.8270 Test Loss = 0.2398, Test Accuracy = 0.8404\n",
      "Iteration 3797: Loss = 0.2364, Accuracy = 0.8450 Test Loss = 0.2398, Test Accuracy = 0.8395\n",
      "Iteration 3798: Loss = 0.2351, Accuracy = 0.8380 Test Loss = 0.2398, Test Accuracy = 0.8389\n",
      "Iteration 3799: Loss = 0.2419, Accuracy = 0.8260 Test Loss = 0.2398, Test Accuracy = 0.8395\n",
      "Iteration 3800: Loss = 0.2498, Accuracy = 0.8360 Test Loss = 0.2397, Test Accuracy = 0.8396\n",
      "Iteration 3801: Loss = 0.2385, Accuracy = 0.8320 Test Loss = 0.2398, Test Accuracy = 0.8383\n",
      "Iteration 3802: Loss = 0.2423, Accuracy = 0.8260 Test Loss = 0.2398, Test Accuracy = 0.8395\n",
      "Iteration 3803: Loss = 0.2350, Accuracy = 0.8310 Test Loss = 0.2397, Test Accuracy = 0.8412\n",
      "Iteration 3804: Loss = 0.2381, Accuracy = 0.8330 Test Loss = 0.2397, Test Accuracy = 0.8404\n",
      "Iteration 3805: Loss = 0.2329, Accuracy = 0.8420 Test Loss = 0.2397, Test Accuracy = 0.8394\n",
      "Iteration 3806: Loss = 0.2319, Accuracy = 0.8310 Test Loss = 0.2397, Test Accuracy = 0.8401\n",
      "Iteration 3807: Loss = 0.2437, Accuracy = 0.8160 Test Loss = 0.2396, Test Accuracy = 0.8391\n",
      "Iteration 3808: Loss = 0.2386, Accuracy = 0.8360 Test Loss = 0.2396, Test Accuracy = 0.8386\n",
      "Iteration 3809: Loss = 0.2460, Accuracy = 0.8340 Test Loss = 0.2396, Test Accuracy = 0.8400\n",
      "Iteration 3810: Loss = 0.2267, Accuracy = 0.8330 Test Loss = 0.2396, Test Accuracy = 0.8395\n",
      "Iteration 3811: Loss = 0.2433, Accuracy = 0.8260 Test Loss = 0.2396, Test Accuracy = 0.8386\n",
      "Iteration 3812: Loss = 0.2477, Accuracy = 0.8210 Test Loss = 0.2396, Test Accuracy = 0.8401\n",
      "Iteration 3813: Loss = 0.2346, Accuracy = 0.8330 Test Loss = 0.2395, Test Accuracy = 0.8406\n",
      "Iteration 3814: Loss = 0.2489, Accuracy = 0.8460 Test Loss = 0.2396, Test Accuracy = 0.8405\n",
      "Iteration 3815: Loss = 0.2446, Accuracy = 0.8260 Test Loss = 0.2395, Test Accuracy = 0.8392\n",
      "Iteration 3816: Loss = 0.2414, Accuracy = 0.8230 Test Loss = 0.2396, Test Accuracy = 0.8407\n",
      "Iteration 3817: Loss = 0.2403, Accuracy = 0.8400 Test Loss = 0.2395, Test Accuracy = 0.8394\n",
      "Iteration 3818: Loss = 0.2400, Accuracy = 0.8280 Test Loss = 0.2395, Test Accuracy = 0.8395\n",
      "Iteration 3819: Loss = 0.2228, Accuracy = 0.8330 Test Loss = 0.2395, Test Accuracy = 0.8403\n",
      "Iteration 3820: Loss = 0.2240, Accuracy = 0.8470 Test Loss = 0.2397, Test Accuracy = 0.8388\n",
      "Iteration 3821: Loss = 0.2339, Accuracy = 0.8230 Test Loss = 0.2395, Test Accuracy = 0.8405\n",
      "Iteration 3822: Loss = 0.2279, Accuracy = 0.8490 Test Loss = 0.2395, Test Accuracy = 0.8390\n",
      "Iteration 3823: Loss = 0.2340, Accuracy = 0.8310 Test Loss = 0.2395, Test Accuracy = 0.8409\n",
      "Iteration 3824: Loss = 0.2455, Accuracy = 0.8080 Test Loss = 0.2394, Test Accuracy = 0.8399\n",
      "Iteration 3825: Loss = 0.2503, Accuracy = 0.8330 Test Loss = 0.2395, Test Accuracy = 0.8396\n",
      "Iteration 3826: Loss = 0.2303, Accuracy = 0.8370 Test Loss = 0.2394, Test Accuracy = 0.8399\n",
      "Iteration 3827: Loss = 0.2433, Accuracy = 0.8380 Test Loss = 0.2394, Test Accuracy = 0.8400\n",
      "Iteration 3828: Loss = 0.2415, Accuracy = 0.8400 Test Loss = 0.2393, Test Accuracy = 0.8407\n",
      "Iteration 3829: Loss = 0.2443, Accuracy = 0.8190 Test Loss = 0.2394, Test Accuracy = 0.8402\n",
      "Iteration 3830: Loss = 0.2271, Accuracy = 0.8400 Test Loss = 0.2394, Test Accuracy = 0.8389\n",
      "Iteration 3831: Loss = 0.2321, Accuracy = 0.8450 Test Loss = 0.2395, Test Accuracy = 0.8392\n",
      "Iteration 3832: Loss = 0.2421, Accuracy = 0.8370 Test Loss = 0.2393, Test Accuracy = 0.8395\n",
      "Iteration 3833: Loss = 0.2332, Accuracy = 0.8290 Test Loss = 0.2393, Test Accuracy = 0.8405\n",
      "Iteration 3834: Loss = 0.2458, Accuracy = 0.8170 Test Loss = 0.2392, Test Accuracy = 0.8408\n",
      "Iteration 3835: Loss = 0.2452, Accuracy = 0.8150 Test Loss = 0.2392, Test Accuracy = 0.8394\n",
      "Iteration 3836: Loss = 0.2349, Accuracy = 0.8250 Test Loss = 0.2393, Test Accuracy = 0.8396\n",
      "Iteration 3837: Loss = 0.2423, Accuracy = 0.8270 Test Loss = 0.2392, Test Accuracy = 0.8400\n",
      "Iteration 3838: Loss = 0.2416, Accuracy = 0.8360 Test Loss = 0.2392, Test Accuracy = 0.8395\n",
      "Iteration 3839: Loss = 0.2345, Accuracy = 0.8360 Test Loss = 0.2392, Test Accuracy = 0.8397\n",
      "Iteration 3840: Loss = 0.2363, Accuracy = 0.8290 Test Loss = 0.2393, Test Accuracy = 0.8403\n",
      "Iteration 3841: Loss = 0.2397, Accuracy = 0.8340 Test Loss = 0.2393, Test Accuracy = 0.8386\n",
      "Iteration 3842: Loss = 0.2382, Accuracy = 0.8360 Test Loss = 0.2392, Test Accuracy = 0.8383\n",
      "Iteration 3843: Loss = 0.2376, Accuracy = 0.8530 Test Loss = 0.2392, Test Accuracy = 0.8395\n",
      "Iteration 3844: Loss = 0.2392, Accuracy = 0.8480 Test Loss = 0.2391, Test Accuracy = 0.8407\n",
      "Iteration 3845: Loss = 0.2363, Accuracy = 0.8460 Test Loss = 0.2391, Test Accuracy = 0.8398\n",
      "Iteration 3846: Loss = 0.2446, Accuracy = 0.8120 Test Loss = 0.2391, Test Accuracy = 0.8402\n",
      "Iteration 3847: Loss = 0.2469, Accuracy = 0.8430 Test Loss = 0.2391, Test Accuracy = 0.8394\n",
      "Iteration 3848: Loss = 0.2481, Accuracy = 0.8240 Test Loss = 0.2390, Test Accuracy = 0.8414\n",
      "Iteration 3849: Loss = 0.2504, Accuracy = 0.8090 Test Loss = 0.2391, Test Accuracy = 0.8396\n",
      "Iteration 3850: Loss = 0.2396, Accuracy = 0.8350 Test Loss = 0.2390, Test Accuracy = 0.8399\n",
      "Iteration 3851: Loss = 0.2260, Accuracy = 0.8460 Test Loss = 0.2390, Test Accuracy = 0.8408\n",
      "Iteration 3852: Loss = 0.2312, Accuracy = 0.8340 Test Loss = 0.2391, Test Accuracy = 0.8400\n",
      "Iteration 3853: Loss = 0.2419, Accuracy = 0.8260 Test Loss = 0.2390, Test Accuracy = 0.8408\n",
      "Iteration 3854: Loss = 0.2347, Accuracy = 0.8370 Test Loss = 0.2390, Test Accuracy = 0.8408\n",
      "Iteration 3855: Loss = 0.2364, Accuracy = 0.8380 Test Loss = 0.2391, Test Accuracy = 0.8397\n",
      "Iteration 3856: Loss = 0.2410, Accuracy = 0.8290 Test Loss = 0.2390, Test Accuracy = 0.8400\n",
      "Iteration 3857: Loss = 0.2441, Accuracy = 0.8230 Test Loss = 0.2389, Test Accuracy = 0.8407\n",
      "Iteration 3858: Loss = 0.2422, Accuracy = 0.8190 Test Loss = 0.2389, Test Accuracy = 0.8393\n",
      "Iteration 3859: Loss = 0.2355, Accuracy = 0.8250 Test Loss = 0.2390, Test Accuracy = 0.8403\n",
      "Iteration 3860: Loss = 0.2490, Accuracy = 0.8170 Test Loss = 0.2390, Test Accuracy = 0.8411\n",
      "Iteration 3861: Loss = 0.2349, Accuracy = 0.8070 Test Loss = 0.2390, Test Accuracy = 0.8396\n",
      "Iteration 3862: Loss = 0.2479, Accuracy = 0.8420 Test Loss = 0.2390, Test Accuracy = 0.8398\n",
      "Iteration 3863: Loss = 0.2238, Accuracy = 0.8510 Test Loss = 0.2389, Test Accuracy = 0.8397\n",
      "Iteration 3864: Loss = 0.2361, Accuracy = 0.8340 Test Loss = 0.2388, Test Accuracy = 0.8409\n",
      "Iteration 3865: Loss = 0.2398, Accuracy = 0.8350 Test Loss = 0.2389, Test Accuracy = 0.8408\n",
      "Iteration 3866: Loss = 0.2437, Accuracy = 0.8320 Test Loss = 0.2388, Test Accuracy = 0.8407\n",
      "Iteration 3867: Loss = 0.2396, Accuracy = 0.8350 Test Loss = 0.2389, Test Accuracy = 0.8400\n",
      "Iteration 3868: Loss = 0.2364, Accuracy = 0.8350 Test Loss = 0.2388, Test Accuracy = 0.8387\n",
      "Iteration 3869: Loss = 0.2460, Accuracy = 0.8240 Test Loss = 0.2388, Test Accuracy = 0.8404\n",
      "Iteration 3870: Loss = 0.2420, Accuracy = 0.8360 Test Loss = 0.2388, Test Accuracy = 0.8406\n",
      "Iteration 3871: Loss = 0.2293, Accuracy = 0.8470 Test Loss = 0.2388, Test Accuracy = 0.8400\n",
      "Iteration 3872: Loss = 0.2306, Accuracy = 0.8460 Test Loss = 0.2387, Test Accuracy = 0.8415\n",
      "Iteration 3873: Loss = 0.2199, Accuracy = 0.8510 Test Loss = 0.2388, Test Accuracy = 0.8401\n",
      "Iteration 3874: Loss = 0.2508, Accuracy = 0.8240 Test Loss = 0.2388, Test Accuracy = 0.8414\n",
      "Iteration 3875: Loss = 0.2278, Accuracy = 0.8330 Test Loss = 0.2387, Test Accuracy = 0.8398\n",
      "Iteration 3876: Loss = 0.2285, Accuracy = 0.8370 Test Loss = 0.2388, Test Accuracy = 0.8411\n",
      "Iteration 3877: Loss = 0.2488, Accuracy = 0.8310 Test Loss = 0.2388, Test Accuracy = 0.8398\n",
      "Iteration 3878: Loss = 0.2614, Accuracy = 0.8210 Test Loss = 0.2388, Test Accuracy = 0.8405\n",
      "Iteration 3879: Loss = 0.2485, Accuracy = 0.8260 Test Loss = 0.2387, Test Accuracy = 0.8392\n",
      "Iteration 3880: Loss = 0.2335, Accuracy = 0.8360 Test Loss = 0.2387, Test Accuracy = 0.8393\n",
      "Iteration 3881: Loss = 0.2239, Accuracy = 0.8350 Test Loss = 0.2387, Test Accuracy = 0.8392\n",
      "Iteration 3882: Loss = 0.2582, Accuracy = 0.8390 Test Loss = 0.2387, Test Accuracy = 0.8392\n",
      "Iteration 3883: Loss = 0.2389, Accuracy = 0.8290 Test Loss = 0.2387, Test Accuracy = 0.8396\n",
      "Iteration 3884: Loss = 0.2351, Accuracy = 0.8240 Test Loss = 0.2386, Test Accuracy = 0.8396\n",
      "Iteration 3885: Loss = 0.2360, Accuracy = 0.8240 Test Loss = 0.2386, Test Accuracy = 0.8397\n",
      "Iteration 3886: Loss = 0.2481, Accuracy = 0.8090 Test Loss = 0.2386, Test Accuracy = 0.8384\n",
      "Iteration 3887: Loss = 0.2419, Accuracy = 0.8400 Test Loss = 0.2386, Test Accuracy = 0.8405\n",
      "Iteration 3888: Loss = 0.2395, Accuracy = 0.8300 Test Loss = 0.2385, Test Accuracy = 0.8410\n",
      "Iteration 3889: Loss = 0.2367, Accuracy = 0.8230 Test Loss = 0.2386, Test Accuracy = 0.8401\n",
      "Iteration 3890: Loss = 0.2488, Accuracy = 0.8170 Test Loss = 0.2385, Test Accuracy = 0.8399\n",
      "Iteration 3891: Loss = 0.2288, Accuracy = 0.8530 Test Loss = 0.2385, Test Accuracy = 0.8404\n",
      "Iteration 3892: Loss = 0.2587, Accuracy = 0.8370 Test Loss = 0.2385, Test Accuracy = 0.8402\n",
      "Iteration 3893: Loss = 0.2403, Accuracy = 0.8150 Test Loss = 0.2385, Test Accuracy = 0.8398\n",
      "Iteration 3894: Loss = 0.2362, Accuracy = 0.8540 Test Loss = 0.2385, Test Accuracy = 0.8397\n",
      "Iteration 3895: Loss = 0.2301, Accuracy = 0.8530 Test Loss = 0.2386, Test Accuracy = 0.8384\n",
      "Iteration 3896: Loss = 0.2270, Accuracy = 0.8370 Test Loss = 0.2385, Test Accuracy = 0.8397\n",
      "Iteration 3897: Loss = 0.2374, Accuracy = 0.8350 Test Loss = 0.2385, Test Accuracy = 0.8409\n",
      "Iteration 3898: Loss = 0.2437, Accuracy = 0.8180 Test Loss = 0.2384, Test Accuracy = 0.8391\n",
      "Iteration 3899: Loss = 0.2328, Accuracy = 0.8590 Test Loss = 0.2384, Test Accuracy = 0.8407\n",
      "Iteration 3900: Loss = 0.2327, Accuracy = 0.8250 Test Loss = 0.2384, Test Accuracy = 0.8416\n",
      "Iteration 3901: Loss = 0.2360, Accuracy = 0.8390 Test Loss = 0.2384, Test Accuracy = 0.8409\n",
      "Iteration 3902: Loss = 0.2394, Accuracy = 0.8310 Test Loss = 0.2384, Test Accuracy = 0.8399\n",
      "Iteration 3903: Loss = 0.2144, Accuracy = 0.8360 Test Loss = 0.2383, Test Accuracy = 0.8391\n",
      "Iteration 3904: Loss = 0.2312, Accuracy = 0.8220 Test Loss = 0.2384, Test Accuracy = 0.8414\n",
      "Iteration 3905: Loss = 0.2319, Accuracy = 0.8450 Test Loss = 0.2384, Test Accuracy = 0.8409\n",
      "Iteration 3906: Loss = 0.2345, Accuracy = 0.8280 Test Loss = 0.2384, Test Accuracy = 0.8411\n",
      "Iteration 3907: Loss = 0.2296, Accuracy = 0.8520 Test Loss = 0.2384, Test Accuracy = 0.8402\n",
      "Iteration 3908: Loss = 0.2221, Accuracy = 0.8530 Test Loss = 0.2384, Test Accuracy = 0.8398\n",
      "Iteration 3909: Loss = 0.2314, Accuracy = 0.8370 Test Loss = 0.2384, Test Accuracy = 0.8407\n",
      "Iteration 3910: Loss = 0.2425, Accuracy = 0.8230 Test Loss = 0.2383, Test Accuracy = 0.8395\n",
      "Iteration 3911: Loss = 0.2420, Accuracy = 0.8200 Test Loss = 0.2383, Test Accuracy = 0.8397\n",
      "Iteration 3912: Loss = 0.2331, Accuracy = 0.8520 Test Loss = 0.2382, Test Accuracy = 0.8400\n",
      "Iteration 3913: Loss = 0.2372, Accuracy = 0.8540 Test Loss = 0.2383, Test Accuracy = 0.8397\n",
      "Iteration 3914: Loss = 0.2318, Accuracy = 0.8320 Test Loss = 0.2382, Test Accuracy = 0.8401\n",
      "Iteration 3915: Loss = 0.2339, Accuracy = 0.8320 Test Loss = 0.2383, Test Accuracy = 0.8403\n",
      "Iteration 3916: Loss = 0.2280, Accuracy = 0.8350 Test Loss = 0.2383, Test Accuracy = 0.8385\n",
      "Iteration 3917: Loss = 0.2321, Accuracy = 0.8250 Test Loss = 0.2382, Test Accuracy = 0.8404\n",
      "Iteration 3918: Loss = 0.2375, Accuracy = 0.8360 Test Loss = 0.2382, Test Accuracy = 0.8400\n",
      "Iteration 3919: Loss = 0.2304, Accuracy = 0.8350 Test Loss = 0.2383, Test Accuracy = 0.8394\n",
      "Iteration 3920: Loss = 0.2356, Accuracy = 0.8430 Test Loss = 0.2381, Test Accuracy = 0.8412\n",
      "Iteration 3921: Loss = 0.2408, Accuracy = 0.8300 Test Loss = 0.2382, Test Accuracy = 0.8402\n",
      "Iteration 3922: Loss = 0.2421, Accuracy = 0.8250 Test Loss = 0.2381, Test Accuracy = 0.8403\n",
      "Iteration 3923: Loss = 0.2293, Accuracy = 0.8460 Test Loss = 0.2381, Test Accuracy = 0.8412\n",
      "Iteration 3924: Loss = 0.2279, Accuracy = 0.8360 Test Loss = 0.2381, Test Accuracy = 0.8401\n",
      "Iteration 3925: Loss = 0.2451, Accuracy = 0.8130 Test Loss = 0.2381, Test Accuracy = 0.8402\n",
      "Iteration 3926: Loss = 0.2280, Accuracy = 0.8470 Test Loss = 0.2381, Test Accuracy = 0.8404\n",
      "Iteration 3927: Loss = 0.2359, Accuracy = 0.8260 Test Loss = 0.2381, Test Accuracy = 0.8416\n",
      "Iteration 3928: Loss = 0.2447, Accuracy = 0.8280 Test Loss = 0.2380, Test Accuracy = 0.8412\n",
      "Iteration 3929: Loss = 0.2548, Accuracy = 0.8110 Test Loss = 0.2381, Test Accuracy = 0.8415\n",
      "Iteration 3930: Loss = 0.2310, Accuracy = 0.8400 Test Loss = 0.2380, Test Accuracy = 0.8408\n",
      "Iteration 3931: Loss = 0.2397, Accuracy = 0.8450 Test Loss = 0.2381, Test Accuracy = 0.8390\n",
      "Iteration 3932: Loss = 0.2225, Accuracy = 0.8460 Test Loss = 0.2381, Test Accuracy = 0.8405\n",
      "Iteration 3933: Loss = 0.2443, Accuracy = 0.8490 Test Loss = 0.2381, Test Accuracy = 0.8393\n",
      "Iteration 3934: Loss = 0.2277, Accuracy = 0.8360 Test Loss = 0.2380, Test Accuracy = 0.8416\n",
      "Iteration 3935: Loss = 0.2383, Accuracy = 0.8490 Test Loss = 0.2380, Test Accuracy = 0.8410\n",
      "Iteration 3936: Loss = 0.2391, Accuracy = 0.8350 Test Loss = 0.2379, Test Accuracy = 0.8414\n",
      "Iteration 3937: Loss = 0.2393, Accuracy = 0.8290 Test Loss = 0.2379, Test Accuracy = 0.8417\n",
      "Iteration 3938: Loss = 0.2406, Accuracy = 0.8310 Test Loss = 0.2380, Test Accuracy = 0.8393\n",
      "Iteration 3939: Loss = 0.2252, Accuracy = 0.8500 Test Loss = 0.2380, Test Accuracy = 0.8391\n",
      "Iteration 3940: Loss = 0.2248, Accuracy = 0.8400 Test Loss = 0.2379, Test Accuracy = 0.8406\n",
      "Iteration 3941: Loss = 0.2454, Accuracy = 0.8200 Test Loss = 0.2379, Test Accuracy = 0.8410\n",
      "Iteration 3942: Loss = 0.2329, Accuracy = 0.8440 Test Loss = 0.2379, Test Accuracy = 0.8392\n",
      "Iteration 3943: Loss = 0.2369, Accuracy = 0.8230 Test Loss = 0.2379, Test Accuracy = 0.8414\n",
      "Iteration 3944: Loss = 0.2252, Accuracy = 0.8320 Test Loss = 0.2379, Test Accuracy = 0.8408\n",
      "Iteration 3945: Loss = 0.2547, Accuracy = 0.8210 Test Loss = 0.2379, Test Accuracy = 0.8396\n",
      "Iteration 3946: Loss = 0.2327, Accuracy = 0.8490 Test Loss = 0.2379, Test Accuracy = 0.8411\n",
      "Iteration 3947: Loss = 0.2367, Accuracy = 0.8370 Test Loss = 0.2378, Test Accuracy = 0.8404\n",
      "Iteration 3948: Loss = 0.2282, Accuracy = 0.8530 Test Loss = 0.2379, Test Accuracy = 0.8411\n",
      "Iteration 3949: Loss = 0.2401, Accuracy = 0.8560 Test Loss = 0.2378, Test Accuracy = 0.8408\n",
      "Iteration 3950: Loss = 0.2301, Accuracy = 0.8500 Test Loss = 0.2378, Test Accuracy = 0.8409\n",
      "Iteration 3951: Loss = 0.2459, Accuracy = 0.8260 Test Loss = 0.2378, Test Accuracy = 0.8400\n",
      "Iteration 3952: Loss = 0.2640, Accuracy = 0.8300 Test Loss = 0.2377, Test Accuracy = 0.8411\n",
      "Iteration 3953: Loss = 0.2313, Accuracy = 0.8530 Test Loss = 0.2378, Test Accuracy = 0.8408\n",
      "Iteration 3954: Loss = 0.2319, Accuracy = 0.8570 Test Loss = 0.2378, Test Accuracy = 0.8406\n",
      "Iteration 3955: Loss = 0.2281, Accuracy = 0.8430 Test Loss = 0.2377, Test Accuracy = 0.8395\n",
      "Iteration 3956: Loss = 0.2291, Accuracy = 0.8390 Test Loss = 0.2377, Test Accuracy = 0.8406\n",
      "Iteration 3957: Loss = 0.2319, Accuracy = 0.8490 Test Loss = 0.2377, Test Accuracy = 0.8394\n",
      "Iteration 3958: Loss = 0.2322, Accuracy = 0.8320 Test Loss = 0.2377, Test Accuracy = 0.8401\n",
      "Iteration 3959: Loss = 0.2380, Accuracy = 0.8400 Test Loss = 0.2377, Test Accuracy = 0.8404\n",
      "Iteration 3960: Loss = 0.2187, Accuracy = 0.8430 Test Loss = 0.2377, Test Accuracy = 0.8407\n",
      "Iteration 3961: Loss = 0.2409, Accuracy = 0.8320 Test Loss = 0.2376, Test Accuracy = 0.8402\n",
      "Iteration 3962: Loss = 0.2407, Accuracy = 0.8320 Test Loss = 0.2376, Test Accuracy = 0.8403\n",
      "Iteration 3963: Loss = 0.2233, Accuracy = 0.8520 Test Loss = 0.2376, Test Accuracy = 0.8407\n",
      "Iteration 3964: Loss = 0.2337, Accuracy = 0.8230 Test Loss = 0.2376, Test Accuracy = 0.8405\n",
      "Iteration 3965: Loss = 0.2316, Accuracy = 0.8440 Test Loss = 0.2376, Test Accuracy = 0.8409\n",
      "Iteration 3966: Loss = 0.2395, Accuracy = 0.8300 Test Loss = 0.2376, Test Accuracy = 0.8418\n",
      "Iteration 3967: Loss = 0.2438, Accuracy = 0.8450 Test Loss = 0.2375, Test Accuracy = 0.8402\n",
      "Iteration 3968: Loss = 0.2408, Accuracy = 0.8260 Test Loss = 0.2376, Test Accuracy = 0.8408\n",
      "Iteration 3969: Loss = 0.2322, Accuracy = 0.8390 Test Loss = 0.2376, Test Accuracy = 0.8408\n",
      "Iteration 3970: Loss = 0.2380, Accuracy = 0.8340 Test Loss = 0.2375, Test Accuracy = 0.8400\n",
      "Iteration 3971: Loss = 0.2350, Accuracy = 0.8360 Test Loss = 0.2375, Test Accuracy = 0.8413\n",
      "Iteration 3972: Loss = 0.2276, Accuracy = 0.8530 Test Loss = 0.2376, Test Accuracy = 0.8400\n",
      "Iteration 3973: Loss = 0.2309, Accuracy = 0.8440 Test Loss = 0.2375, Test Accuracy = 0.8411\n",
      "Iteration 3974: Loss = 0.2310, Accuracy = 0.8450 Test Loss = 0.2375, Test Accuracy = 0.8417\n",
      "Iteration 3975: Loss = 0.2354, Accuracy = 0.8380 Test Loss = 0.2375, Test Accuracy = 0.8399\n",
      "Iteration 3976: Loss = 0.2446, Accuracy = 0.8480 Test Loss = 0.2374, Test Accuracy = 0.8423\n",
      "Iteration 3977: Loss = 0.2401, Accuracy = 0.8360 Test Loss = 0.2374, Test Accuracy = 0.8409\n",
      "Iteration 3978: Loss = 0.2218, Accuracy = 0.8450 Test Loss = 0.2375, Test Accuracy = 0.8406\n",
      "Iteration 3979: Loss = 0.2339, Accuracy = 0.8470 Test Loss = 0.2374, Test Accuracy = 0.8403\n",
      "Iteration 3980: Loss = 0.2363, Accuracy = 0.8360 Test Loss = 0.2375, Test Accuracy = 0.8408\n",
      "Iteration 3981: Loss = 0.2371, Accuracy = 0.8420 Test Loss = 0.2374, Test Accuracy = 0.8416\n",
      "Iteration 3982: Loss = 0.2449, Accuracy = 0.8250 Test Loss = 0.2373, Test Accuracy = 0.8419\n",
      "Iteration 3983: Loss = 0.2591, Accuracy = 0.8200 Test Loss = 0.2373, Test Accuracy = 0.8409\n",
      "Iteration 3984: Loss = 0.2405, Accuracy = 0.8470 Test Loss = 0.2374, Test Accuracy = 0.8399\n",
      "Iteration 3985: Loss = 0.2394, Accuracy = 0.8300 Test Loss = 0.2374, Test Accuracy = 0.8421\n",
      "Iteration 3986: Loss = 0.2499, Accuracy = 0.8280 Test Loss = 0.2373, Test Accuracy = 0.8407\n",
      "Iteration 3987: Loss = 0.2278, Accuracy = 0.8480 Test Loss = 0.2373, Test Accuracy = 0.8414\n",
      "Iteration 3988: Loss = 0.2325, Accuracy = 0.8490 Test Loss = 0.2373, Test Accuracy = 0.8403\n",
      "Iteration 3989: Loss = 0.2163, Accuracy = 0.8390 Test Loss = 0.2373, Test Accuracy = 0.8410\n",
      "Iteration 3990: Loss = 0.2304, Accuracy = 0.8280 Test Loss = 0.2373, Test Accuracy = 0.8416\n",
      "Iteration 3991: Loss = 0.2469, Accuracy = 0.8350 Test Loss = 0.2373, Test Accuracy = 0.8411\n",
      "Iteration 3992: Loss = 0.2376, Accuracy = 0.8400 Test Loss = 0.2372, Test Accuracy = 0.8414\n",
      "Iteration 3993: Loss = 0.2301, Accuracy = 0.8370 Test Loss = 0.2372, Test Accuracy = 0.8412\n",
      "Iteration 3994: Loss = 0.2377, Accuracy = 0.8360 Test Loss = 0.2372, Test Accuracy = 0.8402\n",
      "Iteration 3995: Loss = 0.2258, Accuracy = 0.8410 Test Loss = 0.2372, Test Accuracy = 0.8403\n",
      "Iteration 3996: Loss = 0.2368, Accuracy = 0.8400 Test Loss = 0.2372, Test Accuracy = 0.8411\n",
      "Iteration 3997: Loss = 0.2215, Accuracy = 0.8470 Test Loss = 0.2371, Test Accuracy = 0.8408\n",
      "Iteration 3998: Loss = 0.2350, Accuracy = 0.8300 Test Loss = 0.2372, Test Accuracy = 0.8415\n",
      "Iteration 3999: Loss = 0.2218, Accuracy = 0.8400 Test Loss = 0.2372, Test Accuracy = 0.8410\n",
      "Total training time: 260.99s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history4 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=4000, B = 1000)\n",
    "plot_history(history4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Total training time`: 260.99s for 4000 epochs. `0.065`s per epoch. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Comment on the role of batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history1['loss'], label='Batch Size = 1')\n",
    "plt.plot(history2['loss'], label='Batch Size = 10')\n",
    "plt.plot(history3['loss'], label='Batch Size = 100')\n",
    "plt.plot(history4['loss'], label='Batch Size = 1000')\n",
    "plt.legend()\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Train Loss')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Training Loss`:**\n",
    " This plot shows the training loss over the iterations for different batch sizes. We can see that, when the batch size increases, it takes comparatively more time to converge to the minimum loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAFACAYAAACRAFk6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwtklEQVR4nO3deXxU9b3/8fdnspCFEBIIaxBQBJE9xH1pXepWrfuGvb+2t623V3C3tlqttdpqF3ext7bW9t4CbsWqFRfcl6oYwiooIqCAKGHfEgjJ5/dHBgwhCRMyJ2cy83o+HueRzMyZc96x5+r7nvM952vuLgAAAMRHJOwAAAAAyYRyBQAAEEeUKwAAgDiiXAEAAMQR5QoAACCOKFcAAABxFGi5MrMrzewDM5trZpPMLCvI/QEAAIQtsHJlZr0lXSap1N2HSkqTdEFQ+wMAAEgEQV8WTJeUbWbpknIkfR7w/gAAAEKVHtSG3X25mf1e0meSKiW96O4vNlzPzC6WdLEk5ebmjj7ggAOCigQAABA306dPX+XuRQ3ft6CmvzGzAkn/kHS+pHWSHpf0hLv/vanvlJaWellZWSB5AAAA4snMprt7acP3g7wseLykxe5e4e7VkiZLOjzA/QEAAIQuyHL1maRDzSzHzEzScZLmB7g/AACA0AVWrtz9PUlPSCqXNCe6rweD2h8AAEAiCGxAuyS5+02SbgpyHwAAAImEJ7QDAADEEeUKAAAgjihXAAAAcUS5AgAAiCPKFQAAQBylVLl68+MKvbdoddgxAABAEkuZcrW9plY3PzNP4ybNUMXGrWHHAQAASSplylV6WkT3XThKGyqrdcWjM1RTG8ycigAAILWlTLmSpME9O+mXpw/R2wtX675XPg47DgAASEIpVa4k6bzSPjprVG/d8/LHenvhqrDjAACAJJNy5crMdOuZQ7VfUUdd/sgMrdxQFXYkAACQRFKuXElSTma6/nBRiTZvrdGlk2Zoe01t2JEAAECSSMlyJUn7d8/TrWcM1XuL1+julxh/BQAA4iNly5UknT26WOeVFmv8awv1+oKKsOMAAIAkkNLlSpJu/tZQDeyWpysfnakV6yvDjgMAANq5lC9X2ZlpGn9Riaqqa3TpxBmqZvwVAABohZQvV5I0oFtH3XbWMJV9ula/f/GjsOMAAIB2jHIVdfrI3hpzyD764+uL9PL8L8OOAwAA2inKVT0/P/VAHdizk65+fJaWr2P8FQAAaDnKVT1ZGWl64KISba9xjZtYrm3bGX8FAABahnLVQL+uufrN2cM147N1+s3zH4YdBwAAtDOUq0Z8c3hPfeewvnrorcV64YMvwo4DAADaEcpVE67/5mANL87XNY/P0tI1W8KOAwAA2gnKVRM6pKdp/JgSSdLYieXaur0m5EQAAKA9CKxcmdkgM5tZb9lgZlcEtb8g9CnM0e/OGaHZy9brtimMvwIAAHsWWLly94/cfaS7j5Q0WtIWSU8Gtb+gnDS0h/7ziP7667+XaMqcFWHHAQAACa6tLgseJ+kTd/+0jfYXVz89+QCN7NNZ1z4xW0tWbQ47DgAASGBtVa4ukDSpsQ/M7GIzKzOzsoqKijaK0zKZ6RHdP2aU0iKmSyaUq6qa8VcAAKBxgZcrM8uU9C1Jjzf2ubs/6O6l7l5aVFQUdJy9VlyQozvPG6F5Kzboln/NCzsOAABIUG1x5upkSeXu3u4n7DtucHf919H7asJ7n+mpmcvDjgMAABJQW5SrC9XEJcH26JoTB2l03wJdP3mOPqnYFHYcAACQYAItV2aWK+kbkiYHuZ+2lJFWN/4qMz2isRPKVbmN8VcAAOArgZYrd9/s7l3cfX2Q+2lrPfOzddf5I/XhFxv1i6c/CDsOAABIIDyhfS99fVA3jT1mPz1atlSTy5eFHQcAACQIylUrXHn8QB3Sv1A/e3KuPv5yY9hxAABAAqBctUJ6WkT3XjhKOZlpumRCubZs2x52JAAAEDLKVSt175Sley4YpYUVm3TDP+fK3cOOBAAAQkS5ioMj9++qy47dX5PLl+vxMsZfAQCQyihXcXLZcfvriAFddONTc/XhFxvCjgMAAEJCuYqTtIjp7vNHqVN2hi6ZUK5NWxl/BQBAKqJcxVFRXgfde8EoLVm1WT97cg7jrwAASEGUqzg7bL8uuvL4gXpq5ueaOO2zsOMAAIA2RrkKwNhjBujogUW6+Zl5mrs8qR5ODwAA9oByFYBIxHTXeSNUmJOpcRPLtbGqOuxIAACgjVCuAtKlYwfdN2aUlq6t1E//wfgrAABSBeUqQAf1K9Q1JwzSs3NW6P/e/TTsOAAAoA1QrgL2X0fvq2MGFenWf83X7GXrwo4DAAACRrkKWCRiuvO8keraMVNjJ5ZrfSXjrwAASGaUqzZQkJup+y8q0Yp1Vbr2iVmMvwIAIIlRrtpIyT4F+unJB+iFD77UX95eEnYcAAAQEMpVG/r+kf31jQO767Yp8zXjs7VhxwEAAAGgXLUhM9PvzxmhHvlZGjdxhtZt2RZ2JAAAEGeUqzaWn5Oh8WNKtHJjla5+bJZqaxl/BQBAMqFchWBEn8762SmD9fKHK/WnNxeFHQcAAMQR5Sok3zm8n04Z1kO/feEjlS1ZE3YcAAAQJ5SrkJiZbj97uIoLsjVu4gyt2cz4KwAAkgHlKkSdsurGX63ZvE1XPjqT8VcAACSBQMuVmXU2syfM7EMzm29mhwW5v/ZoaO983XjagXp9QYX+8PonYccBAACtFPSZq3skPe/uB0gaIWl+wPtrl759yD46bUQv3fHiR3p30eqw4wAAgFbYY7kysyPMbKqZLTCzRWa22Mz2eIubmeVLOlrSQ5Lk7tvcfV2rEychM9NtZw1Tvy65umzSDFVs3Bp2JAAAsJdiOXP1kKQ7JR0p6SBJpdGfe9JfUoWkh81shpn92cxyG65kZhebWZmZlVVUVLQgenLp2CFd4y8q0frKal356EzVMP4KAIB2KZZytd7dn3P3le6+escSw/fSJZVI+oO7j5K0WdJPG67k7g+6e6m7lxYVFbUsfZIZ3LOTbv7WEL21cJXuf2Vh2HEAAMBeSG/qAzMrif76qpn9TtJkSTuvV7l7+R62vUzSMnd/L/r6CTVSrrCr8w/qo/cWr9HdLy9Qab8CHTGga9iRAABACzRZriTd0eB1ab3fXdKxzW3Y3b8ws6VmNsjdP5J0nKR5exczdZiZbj1jqOYsX6/LH5mhKZcdpW6dssKOBQAAYmTuwY3tMbORkv4sKVPSIknfc/e1Ta1fWlrqZWVlgeVpTxZ8uVGn3/+2RvTJ19+/f4jS03gkGQAAicTMprt7acP3Y7lb8Ndm1rne6wIzuzWWnbr7zOh4quHufkZzxQq7Gtg9T7ecMVTvLlqje17+OOw4AAAgRrGcDjm5/iMUogXplMASYadzRhfr3NHFuv/VhXpjQereSQkAQHsSS7lKM7MOO16YWbakDs2sjzj65elDNbBbnq54dKa+WF8VdhwAALAHsZSrCZJeNrPvm9n3JU2V9LdgY2GH7Mw0jb+oRFXVNbp0Urm219SGHQkAADRjj+XK3X8j6VZJg6PLLe7+26CD4SsDunXUbWcN0/tL1ur3Ly4IOw4AAGhGc49iqG+GpAzVPYJhRnBx0JTTR/bWu4vW6H9e/0QH9y/QsQd0DzsSAABoRCx3C54naZqkcySdJ+k9Mzsn6GDY3U2nHajBPTvpqsdmafm6yrDjAACARsQy5upnkg5y9++4+/+TdLCkG4ONhcZkZaTpgYtKtL3GNW5iubZtZ/wVAACJJpZyFXH3lfVer47xewhA/665uv3sYZrx2Tr99vkPw44DAAAaiGXM1fNm9oKkSdHX50uaElwk7Mmpw3tp2uI1+vNbi3Vw/0KdMKRH2JEAAEBULHcL/ljSHyUNjy4PuvtPgg6G5v3sm4M1rHe+rnl8lpau2RJ2HAAAEBXr5b1/S3pd0quS3gkuDmLVIT1N48eUyCXGXwEAkEBiuVvwB6q7W/BM1d0x+K6Z/WfQwbBn+3TJ0e/OGaFZy9br11Pmhx0HAAAotjFXP5Y0yt1XS5KZdVHdmay/BBkMsTlpaA9974h+evjtJTq4f6FOGdYz7EgAAKS0WC4Lrpa0sd7rjdH3kCCuO3mwRvTprJ88MVufrt4cdhwAAFJaLOVqoeoeHPoLM7tJ0ruSFpjZVWZ2VbDxEIvM9IjGjxmlSMR0yYRyVVXXhB0JAICUFUu5+kTSP1U39Y0kPSVpsaS86IIEUFyQozvOHaEPPt+gW5+dF3YcAABS1h7HXLn7zZJkZjnuzj3/Cez4A7vr4qP31YNvLNLB/bvoWyN6hR0JAICUE8vdgoeZ2TxJH0ZfjzCzBwJPhr3y4xMHaXTfAl33j9n6pGJT2HEAAEg5sVwWvFvSiYoOYnf3WZKODjATWiEjLaL7LhylzPSIxjL+CgCANhfTQ0TdfWmDt/gvdgLr1Tlbd54/Uh9+sVG/ePqDsOMAAJBSYilXS83scEluZhlmdo0knliZ4I4Z1E2XfH0/PfL+Uj05Y1nYcQAASBmxlKsfSRorqbek5ZJGRl8jwV31jYE6uH+hrp88VwtXbtzzFwAAQKvFMnHzKne/yN27u3s3d//2jqe1I7GlR8df5WSm6ZIJ5dqybXvYkQAASHqxTty8V8xsiZnNMbOZZlYW5L7QuO6dsnT3BSP18cpNuvGfjL8CACBogZarqGPcfaS7l7bBvtCIo/Yv0qXH7q9/lC/TY2UN700AAADx1Gy5MrOImZ3XVmEQnMuP21+H79dFP39qrj76gvFXAAAEpdly5e61kq5txfZd0otmNt3MLm5sBTO72MzKzKysoqKiFbtCc9IiprsvGKmOHTJ0yYTp2ryV8VcAAAQhlsuCL5nZNWbWx8wKdywxbv9Idy+RdLKksWa228NH3f1Bdy9199KioqKWZEcLdcvL0r0XjtTiVZt1/ZNz5O57/hIAAGiRWMrV+ap79MIbkqZHl5gGp7v78ujPlZKelHTw3sVEvBy+X1ddcfxAPTXzc02axvgrAADiLZaJm/vvzYbNLFdSxN03Rn8/QdIv92ZbiK9xxwzQ+0vW6BfPfKARffI1pFd+2JEAAEgasUzcnGNmN5jZg9HX+5vZqTFsu7ukt8xslqRpkp519+dbFxfxEImY7j5/pApyMjR2Qrk2VlWHHQkAgKQRy2XBhyVtk3R49PVySbfu6UvuvsjdR0SXIe7+q1bkRJx16dhB911YoqVrK/XTyYy/AgAgXmIpV/u5+28lVUuSu2+RZIGmQps4uH+hrj5hoJ6dvUJ/f/fTsOMAAJAUYilX28wsW3WPVZCZ7Sdpa6Cp0GZ+dPR+OmZQkW7513zNWbY+7DgAALR7sZSrmyQ9L6mPmU2Q9LJa9+wrJJBIxHTneSPVtWOmLpk4XesrGX8FAEBrxDJx81RJZ0n6rqRJkkrd/bVgY6EtFeRm6r4xJVqxrkrXPjGL8VcAALRCrHMLfk3ScZKOkXRUcHEQltF9C/STkw7QCx98qYffXhJ2HAAA2q1YHsXwgKQfSZojaa6k/zKz8UEHQ9v7wVH9dfzg7rrtufma8dnasOMAANAuxXLm6lhJJ7r7w+7+sKRTou8hyZiZ7jh3hLrlZWncxBlat2Vb2JEAAGh3YilXCyXtU+91n+h7SEL5ORkaf1GJVm6s0jWPM/4KAICWiqVc5Umab2avmdmrkuZJ6mRmT5vZ08HGQxhG9ums608ZrJfmr9Sf3lwUdhwAANqVPc4tKOnngadAwvnu4f00bfEa/eb5jzS6b4FG9y0MOxIAAO2CJdJln9LSUi8rKws7BqI2VFXr1HvfUnVNrZ697CgV5maGHQkAgIRhZtPdvbTh+7E+igEpqFNWhh64qESrN23TVY/NVG1t4hRxAAASFeUKzRraO183nnagXvuoQn94/ZOw4wAAkPAoV9ijbx+yj04d3lN3vPiR3lu0Ouw4AAAktFgeInqEmU01swVmtsjMFpsZt5ClEDPTbWcNU98uubp00gyt2sS83QAANCWWM1cPSbpT0pGSDpJUGv2JFJKXlaHxY0q0vrJaVz46UzWMvwIAoFGxlKv17v6cu69099U7lsCTIeEc2KuTfvGtIXrz41Ua/yrPkQUAoDGxPOfqVTP7naTJknZeD3L38sBSIWFdcFAfvbdote56aYFK+xbo8AFdw44EAEBCiaVcHRL9Wf85Di7mF0xJZqZfnTlMc5av12WPzNSUy49Ut7yssGMBAJAw9nhZ0N2PaWShWKWw3A7peuCi0dq0tVqXT2L8FQAA9TV55srMvu3ufzezqxr73N3vDC4WEt2gHnm65fSh+vETs3XPSwt01QmDwo4EAEBCaO6yYG70Z15bBEH7c25pH723eI3ue3WhSvsV6uiBRWFHAgAgdMwtiFap3Faj08e/pVWbtmnKZUepRz7jrwAAqWGv5xY0sywzG2tmD5jZX3YswcREe5OdmaYHLipRVXWNLps0Q9trasOOBABAqGJ5ztX/Seoh6URJr0sqlrQx1h2YWZqZzTCzf+1dRCS6Ad3y9Oszh2nakjW6Y+qCsOMAABCqWMrVAHe/UdJmd/+bpG/qq8czxOJySfP3JhzajzNG9daFB/fRH177RK9+uDLsOAAAhCaWclUd/bnOzIZKypfULZaNm1mx6srYn/cuHtqTm04bosE9O+nKx2bq83WVYccBACAUsZSrB82sQNINkp6WNE/Sb2Lc/t2SrpXU5EAcM7vYzMrMrKyioiLGzSIRZWWkafyYUareXqtxE8tVzfgrAEAKarZcmVlE0gZ3X+vub7j7vu7ezd3/uKcNm9mpkla6+/Tm1nP3B9291N1Li4q4lb+927eoo24/e7jKP1un3z7/YdhxAABoc82WK3evVd2Zp71xhKRvmdkSSY9IOtbM/r6X20I7ctqIXvqPQ/vqT28u1tR5X4YdBwCANhXLZcGXzOwaM+tjZoU7lj19yd2vc/did+8n6QJJr7j7t1sbGO3DDacO1tDenXT1YzO1dM2WsOMAANBmYilX50saK+kNSdOjC0/6RLM6pKdp/JgSuUvjJs3Qtu2MvwIApIZYytVgd+9ff5F0YEt24u6vufupexcR7VXfLrn67TnDNWvpOt32HE/jAACkhljK1b9jfA/YzcnDeup7R/TTw28v0XNzVoQdBwCAwDU5cbOZ9ZDUW1K2mY2SZNGPOknKaYNsSBLXnTxY5Z+t07VPzNaBvTqpb5fcPX8JAIB2qrkzVydK+r3qpru5o95ypaTrg4+GZJGZHtH9F46SmTR2YrmqqmvCjgQAQGCaLFfu/jd3P0bSd939WHc/Jrqc7u6T2zAjkkCfwhzdcd5IzV2+Qb96lvFXAIDktccxV+7+j7YIguT3jQO764dH9df/vfupnpn1edhxAAAIRCwD2oG4ufakA1SyT2f99B+ztahiU9hxAACIO8oV2lRGWkT3jylRZnpEl0xg/BUAIPnssVyZWYaZXWZmT0SXS80soy3CITn16pytO88fqQ+/2Kibn/kg7DgAAMRVLGeu/iBptKQHoktJ9D1grx0zqJv+++v7adK0pfrnjOVhxwEAIG6afM5VPQe5+4h6r18xs1lBBULquPobAzV9yVpd/+QcDe3dSQO65YUdCQCAVovlzFWNme2344WZ7SuJgTJotfS0iO69cJSyM9J0yYRybdm2PexIAAC0Wizl6seSXjWz18zsdUmvSLom2FhIFT3ys3TX+SP18cpN+vlTjL8CALR/sVwWfEvS/pIGRV9/FFwcpKKjBxbp0mMG6N5XFuqQ/oU6t7RP2JEAANhrsZy5esfdt7r77OiyVdI7QQdDarn8+IE6bN8uuvGpufroi41hxwEAYK81Wa7MrIeZjVZ04mYzK4kuXxcTNyPO0iKmey4cqY4dMnTJhOnavJXxVwCA9omJm5EwuuVl6d4LRmrxqs362ZNz5O5hRwIAoMWaHHPl7n+T9DczO5v5BdFWDh/QVVccP1B3Tl2gQ/btogsP3ifsSAAAtAgTNyPhjD1mgI7av6tuevoDzft8Q9hxAABoEeYWRMJJi5juOn+kCnIyNHZiuTZWVYcdCQCAmFGukJC6duygey8YpU9Xb9Z1kxl/BQBoP2KZuPlcM8uL/n6DmU02s5LgoyHVHbJvF119wiD9a/YK/f3dT8OOAwBATGI5c3Wju280syMlHS/pITFxM9rIf39tP319UJFu+dd8zVm2Puw4AADsUUxzC0Z/flPSg+7+rKTM4CIBX4lETHeeN1JdOmZq7MRybWD8FQAgwcVSrpab2R8lnS9pipl1iPF7QFwU5mbq/jGj9Pm6Sl37+GzGXwEAElosJek8SS9IOtHd10kqVN1kzs0ysywzm2Zms8zsAzO7uXVRkcpG9y3UtScN0vMffKG//ntJ2HEAAGhSLM+52iJppaQjo29tl/RxDNveKulYdx8haaSkk8zs0L3MCeiHR+2r4wd306+nzNfMpevCjgMAQKNiuVvwJkk/kXRd9K0MSX/f0/e8zqZ638mQxPUc7DUz0+/PHaFueVkaO6Fc67ZsCzsSAAC7ieWy4JmSviVpsyS5++eS8mLZuJmlmdlM1Z35muru7zWyzsVmVmZmZRUVFTEHR2rqnFM3/mrlxipdw/grAEACiqVcbfO6/4K5JJlZbqwbd/cadx+pusmfDzazoY2s86C7l7p7aVFRUaybRgobtU+Brjt5sF6a/6X+/ObisOMAALCLWMrVY9G7BTub2Q8lvSTpzy3ZSXQg/KuSTmpxQqAR3zuin04a0kO/ef5DTf90bdhxAADYKZZydYekJyT9Q9IgST+X9Mc9fcnMisysc/T3bEnfkPThXicF6jEz/eac4erZOUvjJpZrzWbGXwEAEkMs5eohd5/q7j9292skvSNpSgzf6ynpVTObLel91Y25+lcrsgK7yM/O0ANjRmv1pm266rGZqq1l/BUAIHyxPkT0AUkyswJJLyq2uwVnu/sodx/u7kPd/ZetzArsZlhxvm48dbBe+6hC//PGJ2HHAQAgpudc3Shpk5n9j+qK1R3u/nDgyYAYffvQvjp1eE/d8eICTVu8Juw4AIAU12S5MrOzdiyS3pN0qKQZkjz6HpAQzEy3nTVM+xTm6NJJ5Vq1aWvYkQAAKay5M1en1VtOVV2xyqj3GkgYeVkZun/MKK3dUq0rH52pGsZfAQBCkt7UB+7+vbYMArTWkF75+sVpQ3T9k3M0/tWFuuy4/cOOBABIQU2Wqx3MLEvS9yUNkZS14313/88AcwF75cKD+2ja4tW6+6UFKu1XoMP36xp2JABAionlbsH/k9RD0omSXlfd09Y3BhkK2Ftmpl+dOUz9u+bqskkztXJjVdiRAAApJpZyNSB6x+Bmd/+bpG9KOiTYWMDey+2QrgcuGq1NW6t1+STGXwEA2lYs5ao6+nNddG7AfEndgosEtN6gHnn65elD9c6i1brn5Y/DjgMASCGxlKsHow8PvUHS05LmSfpNoKmAODivtI/OLinWfa98rDcWVIQdBwCQImIpVy+7+1p3f8Pd93X3bqp7mCiQ8G45Y4j279ZRVz46U19uYPwVACB4sZSrfzTy3hPxDgIEISczXQ9cVKLK6hpdOnGGttfUhh0JAJDkmntC+wFmdrak/PpPazez76reIxmARDegW55+deZQTVuyRndOXRB2HABAkmvuOVeDVPck9s6qeyr7Dhsl/TDATEDcnTmqWO8tWqMHXvtEB/Uv1DGDuCcDABAMc2/+NnUzO8zd32mLMKWlpV5WVtYWu0IKqqqu0Rnj39aXG6r07GVHqVfn7LAjAQDaMTOb7u6lDd/f45irtipWQNCyMtL0wEUl2ra9VuMmlqua8VcAgADEMqAdSBr7FnXU7WcPV/ln6/S7Fz4KOw4AIAlRrpByThvRS98+dB89+MYivTTvy7DjAACSzB7LlZl1N7OHzOy56OsDzez7wUcDgnPDNw/UkF6ddPXjs7Rs7Zaw4wAAkkgsZ67+KukFSb2irxdIuiKgPECb2DH+qrbWNXbiDG3bzvgrAEB8xFKuurr7Y5JqJcndt0uqCTQV0Ab6dsnVb88ZrllL1+m25+aHHQcAkCRiKVebzayLJJckMztU0vpAUwFt5ORhPfXdw/vp4beX6Pm5K8KOAwBIAs09RHSHq1Q3YfN+Zva2pCJJ5wSaCmhD158yWDM+W6sfPzFbB/bM1z5dcsKOBABox2J5zlW5pK9JOlzSf0ka4u6zgw4GtJXM9IjuH1MikzR2Yrm2bueqNwBg78Vyt2CapFMkHSfpBEmXmtlVMXyvj5m9ambzzOwDM7u89XGBYPQpzNHvzx2hOcvX61fPMv4KALD3Yrks+IykKklzFB3UHqPtkq5293Izy5M03cymuvu8vcgJBO6EIT30gyP7689vLdZB/Qp12ohee/4SAAANxFKuit19eEs37O4rJK2I/r7RzOZL6i2JcoWE9ZOTD1D5Z2t13eQ5Gto7X/275oYdCQDQzsRyt+BzZnZCa3ZiZv0kjZL0XiOfXWxmZWZWVlFR0ZrdAK2WkVY3/io9zXTJhHJVVTP+CgDQMrGUq3clPWlmlWa2wcw2mtmGWHdgZh0l/UPSFe6+2/fc/UF3L3X30qKiotiTAwHp1Tlbd503UvNXbNDNz3CiFQDQMrGUqzslHSYpx907uXueu3eKZeNmlqG6YjXB3Se3IifQpo45oJt+9LX9NGnaZ/rnjOVhxwEAtCOxlKulkua6u7dkw2Zmkh6SNN/d79ybcECYrjlhoA7qV6Drn5yjhSs3hR0HANBOxFKuFkl6zcyuM7OrdiwxfO8ISf8h6VgzmxldTmlVWqANpadFdN+FJcrKSNPYCeWq3Mb4KwDAnsVSrhZLellSpqS8ekuz3P0tdzd3H+7uI6PLlNbFBdpWj/ws3X3+SC1YuVE/f2pu2HEAAO3AHh/F4O43t0UQIFEdPbBI444ZoPteWahD9u2ic0YXhx0JAJDAmixXZna/u48zs2cUnbS5Pnf/VqDJgARyxfED9f6SNbrhn3M0vDhfA7vv8eQtACBFWVPj1M1sg7t3MrOvNfa5u78e7zClpaVeVlYW780CcbFyQ5VOufctdc7J0FNjj1Buh1iewQsASFZmNt3dSxu+39yYq0+kuhLV2BJYUiBBdeuUpXsuGKlPKjbphn/OVQtvoAUApIjm/l/voubuCuTxCkhFRwzoqiuOG6i7XlqgQ/oX6oKD9wk7EgAgwTR35ipNUkfteodgzHcLAslq3LEDdOSArrrp6Q80f0XMkxUAAFJEc2Ouyt29pC3DMOYK7cWqTVt1yj1vqmOHdD196ZHqyPgrAEg5ezPmygLMA7RrXTt20L0XjtKS1Zt13eQ5jL8CAOzUXLk6rs1SAO3Qoft20dUnDNIzsz7X39/7LOw4AIAE0WS5cvc1bRkEaI/++2v76WsDi3TLM/M0d/n6sOMAABJALNPfAGhCJGK66/yR6tIxU5dMKNeGquqwIwEAQka5AlqpMDdT9104SsvXVeonT8xm/BUApDjKFRAHpf0Kde2Jg/Tc3C/0t38vCTsOACBElCsgTn541L467oBu+tWU+Zq5dF3YcQAAIaFcAXESiZjuOG+EuuVlaeyEcq3fwvgrAEhFlCsgjjrnZOr+MaO0cmOVrnliFuOvACAFUa6AOBu1T4F+evJgTZ33pR56a3HYcQAAbYxyBQTgP4/opxOHdNftz32o6Z+uDTsOAKANUa6AAJiZfnvOCPXsnKVLJ5Zr7eZtYUcCALQRyhUQkPzsDI0fU6JVm7bpqsdmqraW8VcAkAooV0CAhhd31g2nDtarH1Xoj28sCjsOAKANUK6AgP3HoX31zWE99fsXP9L7S5iyEwCSHeUKCJiZ6fazh6lPQbbGTSzX6k1bw44EAAgQ5QpoA3lZGRp/UYnWbqnWFY8y/goAkllg5crM/mJmK81sblD7ANqTIb3yddNpB+rNj1dp/KsLw44DAAhIkGeu/irppAC3D7Q7Yw7eR6eP7KW7Xlqgf3+yKuw4AIAABFau3P0NSYzeBeoxM/36zGHq1zVXlz8yUxUbGX8FAMkm9DFXZnaxmZWZWVlFRUXYcYDA5XZI1wMXlWhjVbUuf2SGahh/BQBJJfRy5e4Punupu5cWFRWFHQdoEwf06KRffmuo/v3Jat378sdhxwEAxFHo5QpIVeeWFuuskt6695WP9ebHnLUFgGRBuQJCYma69YyhGlDUUVc8MlNfbqgKOxIAIA6CfBTDJEnvSBpkZsvM7PtB7Qtor3Iy68ZfbdlWo0snzdD2mtqwIwEAWinIuwUvdPee7p7h7sXu/lBQ+wLas/275+lXZw7VtMVrdNdLC8KOAwBopfSwAwCQziop1nuL1mj8q5+ouCBHB/UrVHFBtrIy0sKOBgBoIcoVkCBuPn2I5ixfr+smz9n5XteOmepdkKPigmwVd86u+1mQo94F2erdOVu5Hfg/YQBINPybGUgQWRlpmnzJ4Zq7fL2Wra3UsrVbtHxdpZatrdS8zzdo6rwvtW37rmOyCnIyVBwtX70blK/igmzlZWWE9NcAQOqiXAEJJCsjTaX9ClXab/fPamtdqzZt1dK1ldHStUXL1lZq+dpKLfhyo175cKW2Nihf+dkZjZauujNhOeqUnS4za5s/DgBSBOUKaCciEVO3Tlnq1ilLo/sW7Pa5u2v15m07C9fO8rWuUktWb9ZbC1dpy7aaXb6T1yG9XuHK2a2IFeRkUL4AoIUoV0CSMDN17dhBXTt20Mg+nXf73N21bkv1bpccd5Swdxet0aat23f5Tk5mWr1LjtHLjwVf/d4lN5PyBQANUK6AFGFmKsjNVEFupoYV5+/2ubtrQ+V2LVu3JVq6vjoDtnxdpco/W6f1ldW7fCcrI7KzeO04A7bjdZ+CbHXt2EGRCOULQGqhXAGQVFe+8nMylJ+TryG9di9fkrSxqrrujNeahme/KjVn+Xqt2bxtl/Uz0yINSteuRaxbXpbSKF8AkgzlCkDM8rIydECPDB3Qo1Ojn2/eul3L1+065mtZtIDNn79SqzZt3WX9jDRTz/zsJi49ZqtHpyylpzFLF4D2hXIFIG5yO6RrYPc8Deye1+jnldtq6spXg7sdl63dotcXVGjlxl3LV1rE1KNTVpN3O/bsnKUMyheABEO5AtBmsjPTNKBbRw3o1rHRz6uqa7RifVXdJccd476iRezfn6zSFxuq5P7V+hGTenTK2mWQff0xYL06Z6lDOk+5B9C2KFcAEkZWRpr6d81V/665jX6+bXutvoiWr2X17nZcvrZS0xav0dOzqlRT+1X7MpO65XVo8m7H3p2ZYghA/FGuALQbmekR7dMlR/t0yWn08+01tfpiQ1W9y41fDbyfuXSdpsxZoe31ypckde3YYZdxXsUNilhOJv+aBNAy/FsDQNJIT4tEi1Hj5aum1rVyY9UuZ7x23O047/MNmvrBl9pWs+tT7gtzM3e/27FztooL695jiiEADVGuAKSMtEjd3Yk987N1UL/C3T6vrXVVbNrayINWm59iqHjn4yZyvvo9WsTysylfQKqhXAFAVCRi6t4pS92bmWJo1aZtjd7tuKhis978uJEphrLSdxnz1bCIdWaKISDpUK4AIEZmpqK8DirKa3qKobVbqneb27Hu9y16d9Hq3aYYys1Ma/Ruxx1nv5hiCGh/KFcAECdmpsLcTBXuYYqhpQ3mdtwx9qtsyRptqNq1fNWfYqjh3Y7FnZliCEhElCsAaCP1pxga2rvxKYY2VFV/9YyvXc5+VWr2snVau2XX+R0z0yMq7lzvbscdA+6jRYwphoC2R7kCgATSKStDnXpmaHDP5qcYani347J1lZo670ut2rTr/I4ZaaZenRu527EgW8WFOeqe14EphoA4o1wBQDsS6xRDyxqc9Vq+dote+6jxKYZ65mc1erdjn4Ic9chniiGgpShXAJBEWjLFUP27HZetrWx2iqH6czt2yc1UWsSUFokoLSJFzKKvo4uZItGf9d9vfL26gpde7/MdP9MjX20nErFG1hOD/ZGQKFcAkEJimWJoxfp6T7ivdxZs2uI1empmpRo85D5Uu5S0aAlLb1DmImZKT9u19EV2KW/aZb2dJbBeGdytLO4sfIq+Hy2aTa7XoBhGP9uZoV5JbX49a3S9tIjqMtQrrLHkRzACLVdmdpKkeySlSfqzu98e5P4AAK2TmR5R3y656tul8fJVXVOrjVXbVVPrdYu7auv9vvP9Wldtg9d16yq6Xq1qarVzve21u26ntjb6nu+6va/WU5PrNZfrq/VUl8G1y3pV1bXNZI9uq2bHNtXkeg2nWUpUu5WwaNHcURbrl8P66zZ3FrKu5DVdWHctttbIeopxvaYKpJSRFtFxg7uH9s81sHJlZmmSxkv6hqRlkt43s6fdfV5Q+wQABCsjLaLC3MywY7QLtfWKXbNFs2bX9bbX1Fu/foGsbWo9NbnebqWy3v6+Wk87y27z6+2+vfrFtra2rnxvr63ZWVh3+bt3rtfY9rTbeq2RlRHRh7ecHKf/JVsuyDNXB0ta6O6LJMnMHpF0uiTKFQAg6UUipohMGWlhJ2mfdjsr2VTRrJW219Z+VTRrXa5wzxwGWa56S1pa7/UySYcEuD8AAJAkIhFTZjsdFxb6/bVmdrGZlZlZWUVFRdhxAAAAWiXIcrVcUp96r4uj7+3C3R9091J3Ly0qKgowDgAAQPCCLFfvS9rfzPqbWaakCyQ9HeD+AAAAQhfYmCt3325m4yS9oLpHMfzF3T8Ian8AAACJINDnXLn7FElTgtwHAABAIgl9QDsAAEAyoVwBAADEEeUKAAAgjihXAAAAcUS5AgAAiCNzT5yZu82sQtKnAe+mq6RVAe8DaA2OUSQ6jlEkurY6Rvu6+25PQE+octUWzKzM3UvDzgE0hWMUiY5jFIku7GOUy4IAAABxRLkCAACIo1QsVw+GHQDYA45RJDqOUSS6UI/RlBtzBQAAEKRUPHMFAAAQGMoVAABAHCVNuTKzGjObaWazzKzczA5vwXfHmdlCM3Mz6xpkTqSWII5Lq3Nv9LPZZlYSTHokq7Y+Ls3sO2b2cXT5Trz/HiSHRDkuzWy0mc2JfudeM7MW/zHunhSLpE31fj9R0ust+O4oSf0kLZHUNey/hSV5liCOS0mnSHpOkkk6VNJ7Yf+dLO1racvjUlKhpEXRnwXR3wvC/mfAknhLohyXkqZF17Xod09u6d+SNGeuGugkaW2sK7v7DHdfElwcQFL8jsvTJf2v13lXUmcz6xmnjEg9QR+XJ0qa6u5r3H2tpKmSTopDbiS3UI7L6Ged3P1dr2ta/yvpjJaGT2/pFxJYtpnNlJQlqaekYyXJzPIkvdnEd8a4+7y2iYcUFcRx2VvS0nqvl0XfW9HqtEgVbXlcNvU+0FAiHJe9o783fL9FkqlcVbr7SEkys8Mk/a+ZDXX3jZJGhhkMKY3jEomI4xKJKGmOy2QqVzu5+zvRAW1FZlYpzlwhAcTxuFwuqU+918XR94AWa4Pjcrmkrzd4/7W9DoyUEOJxuTz6e8P1WyQpy5WZHSApTdJqd69RO2u8SE5xPC6fljTOzB6RdIik9e7OJUHslaCPSzN7QdKvzawgut4Jkq5rZWwkubCOS3dfY2YbzOxQSe9J+n+S7mvpTpOpXO24VivVjfD/TvR/kD0ys8skXSuph6TZZjbF3X8QTEykmCCOyymquwNmoaQtkr4X99RIdm12XEb/Y3WLpPejm/ilu6+J21+CZJIox+Ulkv4qKVt1dws+19I/hOlvAAAA4ihZH8UAAAAQCsoVAABAHFGuAAAA4ohyBQAAEEeUKwAAgDiiXAEIjZnVmNlMM5tlZuVmdvge1u9sZpfEsN3XzKx0D+tEojPezzWzOWb2vpn1j342xcw6t+iPAYCoZHrOFYD2p/50FydKuk3S15pZv7PqnkHzQBz2fb6kXpKGu3utmRVL2ixJ7n5KHLYPIEVx5gpAougkaa0kmVlHM3s5ejZrjpmdHl3ndkn7Rc92/S667k+i68wys9vrbe9cM5tmZgvM7KhG9tdT0gp3r5Ukd1/m7jv2v8TMuprZj6L7mmlmi83s1ejnJ5jZO9F8j5tZx2D+kQBoj3iIKIDQmFmNpDmSslRXdo519+lmli4px903ROcXe1fS/pL6SvqXuw+Nfv9kSTdKOt7dt5hZYfTJy69Jmu7uV5vZKZKucvfjG+y7WNJbktZJelnS3919RvSzJZJK3X1V9HWGpFck/VbSO5ImSzrZ3Teb2U8kdXD3Xwb0jwlAO8NlQQBhqn9Z8DBJ/2tmQ1U39cWvzexoSbWSekvq3sj3j5f0sLtvkeqmtKj32eToz+mS+jX8orsvM7NBko6NLi+b2bnu/nIj+7lH0ivu/oyZnSrpQElvm5kkZaqucAGAJMoVgATh7u9Ez1IVqW4usCJJo929OnomKauFm9wa/VmjJv5d5+5bFZ07zMy+lHSG6s5i7WRm31XdGbNxO96SNNXdL2xhHgApgjFXABKCmR0gKU3Sakn5klZGi9Uxqis3krRRUl69r02V9D0zy4luo7AF+ysxs17R3yOShkv6tME6oyVdI+nbO8Zmqe4S5RFmNiC6Tq6ZDWzRHwsgqXHmCkCYss1sZvR3k/Qdd68xswmSnjGzOZLKJH0oSe6+2szeNrO5kp5z9x+b2UhJZWa2TdIUSdfHuO9ukv5kZh2ir6dJur/BOuMkFUp6NXoJsMzdfxA9mzWp3ndvkLSgJX84gOTFgHYAAIA44rIgAABAHFGuAAAA4ohyBQAAEEeUKwAAgDiiXAEAAMQR5QoAACCOKFcAAABx9P8BtYpFbDAv/HoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = {'B=1':7.63, 'B=10':0.77, 'B=100':0.13, 'B=1000':0.065} \n",
    "plt.figure(figsize=(10,5)) \n",
    "plt.plot(time.keys(), time.values())\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Time takes to train per epoch')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Training Time`:** I have plotted the training time per epoch for each batch size. When batch time is low it take a lot of time to train. On the other hand, increasing batch size reduces training time in each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = list()\n",
    "train_acc  = list()\n",
    "test_loss  = list()\n",
    "test_acc0   = list() \n",
    "\n",
    "histories = [history1, history2, history3, history4]\n",
    "for h in histories:\n",
    "    best_score_idx = torch.argmax(torch.Tensor(h['test_acc'])).item()\n",
    "    train_loss.append(h['loss'][best_score_idx])\n",
    "    train_acc.append(h['acc'][best_score_idx])\n",
    "    test_loss.append(h['test_loss'][best_score_idx])\n",
    "    test_acc0.append(h['test_acc'][best_score_idx]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "x_tick = ['1', '10', '100', '1000']\n",
    "x_pos = np.arange(len(x_tick)) \n",
    "width = 0.2\n",
    "plt.bar(x_pos - 1.5 * width, train_loss, width, label='Train Loss')\n",
    "plt.bar(x_pos - 0.5 * width, train_acc, width, label='Train Accuracy')\n",
    "plt.bar(x_pos + 0.5 * width, test_loss, width, label='Test Loss')\n",
    "plt.bar(x_pos + 1.5 * width, test_acc0, width, label='Test Accuracy')\n",
    "\n",
    "plt.xticks(x_pos, x_tick)\n",
    "plt.legend()\n",
    "plt.xlabel('Batch Size')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Observer Performance`:** I searched for the highest test performance and the other parameters in that iteration. I did this for all batch sizes. Then, plotted this bar chart to see the best test accuracy vs batch size. It looks like, choice of batch size is important. B=100 seems like work better than others in terms of all the 4 metrics - train/test accuracy and train/test loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history1['test_acc'], label='Batch Size = 1')\n",
    "plt.plot(history2['test_acc'], label='Batch Size = 10')\n",
    "plt.plot(history3['test_acc'], label='Batch Size = 100')\n",
    "plt.plot(history4['test_acc'], label='Batch Size = 1000')\n",
    "plt.legend()\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Test Accuracy:`** This plot shows the test accuracy for each batch size. B=1 performs worst. It does not increase performance over the iterations. On the contrary, other batch size choices increas test accuracy over iterations. However, a larger batch size takes time to reach to the best test accuracy. We can see from this plot that, B=100 reaches to best test accuracy reasonably faster and the test accuracy is also higher. We can say the similar for B=10 just for the test accuracy. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Overall Conclusion`:** Considering all the factors - Train loss, Time to train, Time to reach optimized point, Test accuracy, B=100 is the best choice for batch size in this problem. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. The role of training dataset size:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training Data = 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "torch.Size([100, 28, 28]) torch.Size([10000, 28, 28])\n",
      "Iteration 0: Loss = 582.9546, Accuracy = 0.0800 Test Loss = 362.4759, Test Accuracy = 0.1140\n",
      "Iteration 1: Loss = 391.3271, Accuracy = 0.1200 Test Loss = 289.5626, Test Accuracy = 0.1107\n",
      "Iteration 2: Loss = 311.2824, Accuracy = 0.1200 Test Loss = 257.8577, Test Accuracy = 0.1056\n",
      "Iteration 3: Loss = 274.1873, Accuracy = 0.1200 Test Loss = 241.7553, Test Accuracy = 0.1060\n",
      "Iteration 4: Loss = 253.8801, Accuracy = 0.1400 Test Loss = 231.6591, Test Accuracy = 0.1061\n",
      "Iteration 5: Loss = 240.3681, Accuracy = 0.1500 Test Loss = 223.9949, Test Accuracy = 0.1051\n",
      "Iteration 6: Loss = 229.8164, Accuracy = 0.1600 Test Loss = 217.4391, Test Accuracy = 0.1037\n",
      "Iteration 7: Loss = 220.7364, Accuracy = 0.1600 Test Loss = 211.5018, Test Accuracy = 0.1028\n",
      "Iteration 8: Loss = 212.5350, Accuracy = 0.1700 Test Loss = 205.9974, Test Accuracy = 0.1032\n",
      "Iteration 9: Loss = 204.9622, Accuracy = 0.1700 Test Loss = 200.8497, Test Accuracy = 0.1042\n",
      "Iteration 10: Loss = 197.9006, Accuracy = 0.1700 Test Loss = 196.0201, Test Accuracy = 0.1038\n",
      "Iteration 11: Loss = 191.2852, Accuracy = 0.1700 Test Loss = 191.4832, Test Accuracy = 0.1044\n",
      "Iteration 12: Loss = 185.0724, Accuracy = 0.1700 Test Loss = 187.2181, Test Accuracy = 0.1042\n",
      "Iteration 13: Loss = 179.2284, Accuracy = 0.1700 Test Loss = 183.2058, Test Accuracy = 0.1043\n",
      "Iteration 14: Loss = 173.7245, Accuracy = 0.1700 Test Loss = 179.4285, Test Accuracy = 0.1047\n",
      "Iteration 15: Loss = 168.5352, Accuracy = 0.1700 Test Loss = 175.8694, Test Accuracy = 0.1047\n",
      "Iteration 16: Loss = 163.6376, Accuracy = 0.1700 Test Loss = 172.5128, Test Accuracy = 0.1048\n",
      "Iteration 17: Loss = 159.0105, Accuracy = 0.1700 Test Loss = 169.3441, Test Accuracy = 0.1053\n",
      "Iteration 18: Loss = 154.6346, Accuracy = 0.1800 Test Loss = 166.3498, Test Accuracy = 0.1050\n",
      "Iteration 19: Loss = 150.4920, Accuracy = 0.1900 Test Loss = 163.5174, Test Accuracy = 0.1048\n",
      "Iteration 20: Loss = 146.5666, Accuracy = 0.1900 Test Loss = 160.8353, Test Accuracy = 0.1049\n",
      "Iteration 21: Loss = 142.8430, Accuracy = 0.1900 Test Loss = 158.2929, Test Accuracy = 0.1055\n",
      "Iteration 22: Loss = 139.3076, Accuracy = 0.1900 Test Loss = 155.8804, Test Accuracy = 0.1060\n",
      "Iteration 23: Loss = 135.9474, Accuracy = 0.1900 Test Loss = 153.5888, Test Accuracy = 0.1063\n",
      "Iteration 24: Loss = 132.7507, Accuracy = 0.2000 Test Loss = 151.4097, Test Accuracy = 0.1060\n",
      "Iteration 25: Loss = 129.7065, Accuracy = 0.2000 Test Loss = 149.3354, Test Accuracy = 0.1063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor(train_dataset.data, dtype=torch.float32) / 255\n",
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = torch.tensor(test_dataset.data, dtype=torch.float32) / 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26: Loss = 126.8049, Accuracy = 0.2000 Test Loss = 147.3589, Test Accuracy = 0.1061\n",
      "Iteration 27: Loss = 124.0364, Accuracy = 0.2000 Test Loss = 145.4736, Test Accuracy = 0.1057\n",
      "Iteration 28: Loss = 121.3926, Accuracy = 0.2000 Test Loss = 143.6736, Test Accuracy = 0.1059\n",
      "Iteration 29: Loss = 118.8655, Accuracy = 0.2000 Test Loss = 141.9532, Test Accuracy = 0.1064\n",
      "Iteration 30: Loss = 116.4476, Accuracy = 0.2000 Test Loss = 140.3074, Test Accuracy = 0.1069\n",
      "Iteration 31: Loss = 114.1323, Accuracy = 0.2000 Test Loss = 138.7313, Test Accuracy = 0.1068\n",
      "Iteration 32: Loss = 111.9132, Accuracy = 0.2100 Test Loss = 137.2206, Test Accuracy = 0.1074\n",
      "Iteration 33: Loss = 109.7846, Accuracy = 0.2100 Test Loss = 135.7713, Test Accuracy = 0.1068\n",
      "Iteration 34: Loss = 107.7408, Accuracy = 0.2100 Test Loss = 134.3795, Test Accuracy = 0.1067\n",
      "Iteration 35: Loss = 105.7771, Accuracy = 0.2100 Test Loss = 133.0418, Test Accuracy = 0.1071\n",
      "Iteration 36: Loss = 103.8886, Accuracy = 0.2100 Test Loss = 131.7550, Test Accuracy = 0.1068\n",
      "Iteration 37: Loss = 102.0711, Accuracy = 0.2100 Test Loss = 130.5161, Test Accuracy = 0.1062\n",
      "Iteration 38: Loss = 100.3205, Accuracy = 0.2100 Test Loss = 129.3223, Test Accuracy = 0.1053\n",
      "Iteration 39: Loss = 98.6331, Accuracy = 0.2000 Test Loss = 128.1710, Test Accuracy = 0.1055\n",
      "Iteration 40: Loss = 97.0054, Accuracy = 0.2000 Test Loss = 127.0599, Test Accuracy = 0.1059\n",
      "Iteration 41: Loss = 95.4341, Accuracy = 0.2000 Test Loss = 125.9866, Test Accuracy = 0.1061\n",
      "Iteration 42: Loss = 93.9163, Accuracy = 0.2100 Test Loss = 124.9492, Test Accuracy = 0.1064\n",
      "Iteration 43: Loss = 92.4492, Accuracy = 0.2100 Test Loss = 123.9458, Test Accuracy = 0.1067\n",
      "Iteration 44: Loss = 91.0300, Accuracy = 0.2200 Test Loss = 122.9744, Test Accuracy = 0.1069\n",
      "Iteration 45: Loss = 89.6563, Accuracy = 0.2200 Test Loss = 122.0336, Test Accuracy = 0.1066\n",
      "Iteration 46: Loss = 88.3259, Accuracy = 0.2200 Test Loss = 121.1216, Test Accuracy = 0.1063\n",
      "Iteration 47: Loss = 87.0365, Accuracy = 0.2200 Test Loss = 120.2370, Test Accuracy = 0.1069\n",
      "Iteration 48: Loss = 85.7862, Accuracy = 0.2200 Test Loss = 119.3786, Test Accuracy = 0.1066\n",
      "Iteration 49: Loss = 84.5732, Accuracy = 0.2200 Test Loss = 118.5449, Test Accuracy = 0.1073\n",
      "Iteration 50: Loss = 83.3956, Accuracy = 0.2200 Test Loss = 117.7349, Test Accuracy = 0.1077\n",
      "Iteration 51: Loss = 82.2518, Accuracy = 0.2100 Test Loss = 116.9473, Test Accuracy = 0.1072\n",
      "Iteration 52: Loss = 81.1402, Accuracy = 0.2100 Test Loss = 116.1813, Test Accuracy = 0.1069\n",
      "Iteration 53: Loss = 80.0594, Accuracy = 0.2000 Test Loss = 115.4357, Test Accuracy = 0.1066\n",
      "Iteration 54: Loss = 79.0080, Accuracy = 0.2000 Test Loss = 114.7097, Test Accuracy = 0.1065\n",
      "Iteration 55: Loss = 77.9847, Accuracy = 0.2000 Test Loss = 114.0024, Test Accuracy = 0.1064\n",
      "Iteration 56: Loss = 76.9884, Accuracy = 0.2000 Test Loss = 113.3130, Test Accuracy = 0.1064\n",
      "Iteration 57: Loss = 76.0178, Accuracy = 0.2000 Test Loss = 112.6407, Test Accuracy = 0.1068\n",
      "Iteration 58: Loss = 75.0720, Accuracy = 0.2000 Test Loss = 111.9848, Test Accuracy = 0.1072\n",
      "Iteration 59: Loss = 74.1498, Accuracy = 0.2000 Test Loss = 111.3447, Test Accuracy = 0.1065\n",
      "Iteration 60: Loss = 73.2504, Accuracy = 0.2000 Test Loss = 110.7197, Test Accuracy = 0.1062\n",
      "Iteration 61: Loss = 72.3728, Accuracy = 0.2100 Test Loss = 110.1092, Test Accuracy = 0.1060\n",
      "Iteration 62: Loss = 71.5162, Accuracy = 0.1900 Test Loss = 109.5127, Test Accuracy = 0.1061\n",
      "Iteration 63: Loss = 70.6798, Accuracy = 0.1900 Test Loss = 108.9295, Test Accuracy = 0.1059\n",
      "Iteration 64: Loss = 69.8628, Accuracy = 0.1900 Test Loss = 108.3593, Test Accuracy = 0.1057\n",
      "Iteration 65: Loss = 69.0645, Accuracy = 0.1900 Test Loss = 107.8014, Test Accuracy = 0.1059\n",
      "Iteration 66: Loss = 68.2841, Accuracy = 0.1900 Test Loss = 107.2555, Test Accuracy = 0.1060\n",
      "Iteration 67: Loss = 67.5211, Accuracy = 0.1800 Test Loss = 106.7212, Test Accuracy = 0.1057\n",
      "Iteration 68: Loss = 66.7749, Accuracy = 0.1800 Test Loss = 106.1980, Test Accuracy = 0.1057\n",
      "Iteration 69: Loss = 66.0448, Accuracy = 0.1800 Test Loss = 105.6855, Test Accuracy = 0.1055\n",
      "Iteration 70: Loss = 65.3302, Accuracy = 0.1800 Test Loss = 105.1834, Test Accuracy = 0.1059\n",
      "Iteration 71: Loss = 64.6307, Accuracy = 0.1800 Test Loss = 104.6913, Test Accuracy = 0.1061\n",
      "Iteration 72: Loss = 63.9458, Accuracy = 0.1800 Test Loss = 104.2089, Test Accuracy = 0.1065\n",
      "Iteration 73: Loss = 63.2749, Accuracy = 0.1800 Test Loss = 103.7358, Test Accuracy = 0.1061\n",
      "Iteration 74: Loss = 62.6177, Accuracy = 0.1900 Test Loss = 103.2719, Test Accuracy = 0.1062\n",
      "Iteration 75: Loss = 61.9736, Accuracy = 0.1900 Test Loss = 102.8167, Test Accuracy = 0.1061\n",
      "Iteration 76: Loss = 61.3422, Accuracy = 0.1900 Test Loss = 102.3700, Test Accuracy = 0.1061\n",
      "Iteration 77: Loss = 60.7232, Accuracy = 0.1900 Test Loss = 101.9315, Test Accuracy = 0.1062\n",
      "Iteration 78: Loss = 60.1162, Accuracy = 0.1900 Test Loss = 101.5010, Test Accuracy = 0.1063\n",
      "Iteration 79: Loss = 59.5208, Accuracy = 0.1900 Test Loss = 101.0783, Test Accuracy = 0.1064\n",
      "Iteration 80: Loss = 58.9367, Accuracy = 0.1900 Test Loss = 100.6631, Test Accuracy = 0.1062\n",
      "Iteration 81: Loss = 58.3635, Accuracy = 0.1900 Test Loss = 100.2552, Test Accuracy = 0.1064\n",
      "Iteration 82: Loss = 57.8008, Accuracy = 0.1900 Test Loss = 99.8544, Test Accuracy = 0.1063\n",
      "Iteration 83: Loss = 57.2485, Accuracy = 0.2000 Test Loss = 99.4605, Test Accuracy = 0.1064\n",
      "Iteration 84: Loss = 56.7062, Accuracy = 0.2000 Test Loss = 99.0733, Test Accuracy = 0.1063\n",
      "Iteration 85: Loss = 56.1736, Accuracy = 0.2000 Test Loss = 98.6926, Test Accuracy = 0.1063\n",
      "Iteration 86: Loss = 55.6505, Accuracy = 0.2100 Test Loss = 98.3182, Test Accuracy = 0.1064\n",
      "Iteration 87: Loss = 55.1366, Accuracy = 0.2100 Test Loss = 97.9500, Test Accuracy = 0.1063\n",
      "Iteration 88: Loss = 54.6316, Accuracy = 0.2000 Test Loss = 97.5878, Test Accuracy = 0.1063\n",
      "Iteration 89: Loss = 54.1353, Accuracy = 0.2000 Test Loss = 97.2314, Test Accuracy = 0.1063\n",
      "Iteration 90: Loss = 53.6475, Accuracy = 0.2000 Test Loss = 96.8807, Test Accuracy = 0.1064\n",
      "Iteration 91: Loss = 53.1679, Accuracy = 0.2000 Test Loss = 96.5356, Test Accuracy = 0.1062\n",
      "Iteration 92: Loss = 52.6964, Accuracy = 0.2000 Test Loss = 96.1959, Test Accuracy = 0.1059\n",
      "Iteration 93: Loss = 52.2327, Accuracy = 0.2000 Test Loss = 95.8614, Test Accuracy = 0.1063\n",
      "Iteration 94: Loss = 51.7766, Accuracy = 0.2000 Test Loss = 95.5320, Test Accuracy = 0.1061\n",
      "Iteration 95: Loss = 51.3279, Accuracy = 0.2000 Test Loss = 95.2077, Test Accuracy = 0.1061\n",
      "Iteration 96: Loss = 50.8866, Accuracy = 0.2000 Test Loss = 94.8882, Test Accuracy = 0.1061\n",
      "Iteration 97: Loss = 50.4523, Accuracy = 0.2000 Test Loss = 94.5735, Test Accuracy = 0.1055\n",
      "Iteration 98: Loss = 50.0249, Accuracy = 0.2000 Test Loss = 94.2635, Test Accuracy = 0.1053\n",
      "Iteration 99: Loss = 49.6042, Accuracy = 0.2000 Test Loss = 93.9580, Test Accuracy = 0.1050\n",
      "Iteration 100: Loss = 49.1901, Accuracy = 0.2000 Test Loss = 93.6570, Test Accuracy = 0.1050\n",
      "Iteration 101: Loss = 48.7824, Accuracy = 0.2000 Test Loss = 93.3603, Test Accuracy = 0.1045\n",
      "Iteration 102: Loss = 48.3810, Accuracy = 0.2000 Test Loss = 93.0678, Test Accuracy = 0.1046\n",
      "Iteration 103: Loss = 47.9858, Accuracy = 0.2100 Test Loss = 92.7794, Test Accuracy = 0.1045\n",
      "Iteration 104: Loss = 47.5965, Accuracy = 0.2200 Test Loss = 92.4951, Test Accuracy = 0.1045\n",
      "Iteration 105: Loss = 47.2130, Accuracy = 0.2200 Test Loss = 92.2148, Test Accuracy = 0.1047\n",
      "Iteration 106: Loss = 46.8353, Accuracy = 0.2200 Test Loss = 91.9383, Test Accuracy = 0.1049\n",
      "Iteration 107: Loss = 46.4632, Accuracy = 0.2200 Test Loss = 91.6656, Test Accuracy = 0.1049\n",
      "Iteration 108: Loss = 46.0965, Accuracy = 0.2100 Test Loss = 91.3967, Test Accuracy = 0.1047\n",
      "Iteration 109: Loss = 45.7352, Accuracy = 0.2100 Test Loss = 91.1313, Test Accuracy = 0.1046\n",
      "Iteration 110: Loss = 45.3791, Accuracy = 0.2100 Test Loss = 90.8695, Test Accuracy = 0.1051\n",
      "Iteration 111: Loss = 45.0281, Accuracy = 0.2100 Test Loss = 90.6111, Test Accuracy = 0.1058\n",
      "Iteration 112: Loss = 44.6821, Accuracy = 0.2100 Test Loss = 90.3562, Test Accuracy = 0.1057\n",
      "Iteration 113: Loss = 44.3410, Accuracy = 0.2100 Test Loss = 90.1046, Test Accuracy = 0.1057\n",
      "Iteration 114: Loss = 44.0047, Accuracy = 0.2100 Test Loss = 89.8562, Test Accuracy = 0.1049\n",
      "Iteration 115: Loss = 43.6731, Accuracy = 0.2100 Test Loss = 89.6110, Test Accuracy = 0.1047\n",
      "Iteration 116: Loss = 43.3461, Accuracy = 0.2100 Test Loss = 89.3690, Test Accuracy = 0.1047\n",
      "Iteration 117: Loss = 43.0236, Accuracy = 0.2100 Test Loss = 89.1300, Test Accuracy = 0.1047\n",
      "Iteration 118: Loss = 42.7056, Accuracy = 0.2100 Test Loss = 88.8940, Test Accuracy = 0.1047\n",
      "Iteration 119: Loss = 42.3918, Accuracy = 0.2100 Test Loss = 88.6610, Test Accuracy = 0.1047\n",
      "Iteration 120: Loss = 42.0823, Accuracy = 0.2100 Test Loss = 88.4308, Test Accuracy = 0.1047\n",
      "Iteration 121: Loss = 41.7769, Accuracy = 0.2100 Test Loss = 88.2035, Test Accuracy = 0.1048\n",
      "Iteration 122: Loss = 41.4756, Accuracy = 0.2200 Test Loss = 87.9790, Test Accuracy = 0.1046\n",
      "Iteration 123: Loss = 41.1783, Accuracy = 0.2100 Test Loss = 87.7572, Test Accuracy = 0.1045\n",
      "Iteration 124: Loss = 40.8849, Accuracy = 0.2100 Test Loss = 87.5380, Test Accuracy = 0.1044\n",
      "Iteration 125: Loss = 40.5953, Accuracy = 0.2100 Test Loss = 87.3215, Test Accuracy = 0.1041\n",
      "Iteration 126: Loss = 40.3095, Accuracy = 0.2100 Test Loss = 87.1075, Test Accuracy = 0.1044\n",
      "Iteration 127: Loss = 40.0274, Accuracy = 0.2100 Test Loss = 86.8961, Test Accuracy = 0.1040\n",
      "Iteration 128: Loss = 39.7488, Accuracy = 0.2100 Test Loss = 86.6871, Test Accuracy = 0.1038\n",
      "Iteration 129: Loss = 39.4739, Accuracy = 0.2100 Test Loss = 86.4806, Test Accuracy = 0.1038\n",
      "Iteration 130: Loss = 39.2024, Accuracy = 0.2000 Test Loss = 86.2764, Test Accuracy = 0.1041\n",
      "Iteration 131: Loss = 38.9344, Accuracy = 0.2000 Test Loss = 86.0746, Test Accuracy = 0.1043\n",
      "Iteration 132: Loss = 38.6696, Accuracy = 0.2100 Test Loss = 85.8751, Test Accuracy = 0.1041\n",
      "Iteration 133: Loss = 38.4082, Accuracy = 0.2100 Test Loss = 85.6779, Test Accuracy = 0.1039\n",
      "Iteration 134: Loss = 38.1501, Accuracy = 0.2100 Test Loss = 85.4828, Test Accuracy = 0.1039\n",
      "Iteration 135: Loss = 37.8951, Accuracy = 0.2100 Test Loss = 85.2900, Test Accuracy = 0.1039\n",
      "Iteration 136: Loss = 37.6432, Accuracy = 0.2100 Test Loss = 85.0993, Test Accuracy = 0.1042\n",
      "Iteration 137: Loss = 37.3943, Accuracy = 0.2100 Test Loss = 84.9107, Test Accuracy = 0.1042\n",
      "Iteration 138: Loss = 37.1485, Accuracy = 0.2100 Test Loss = 84.7241, Test Accuracy = 0.1040\n",
      "Iteration 139: Loss = 36.9057, Accuracy = 0.2200 Test Loss = 84.5396, Test Accuracy = 0.1037\n",
      "Iteration 140: Loss = 36.6657, Accuracy = 0.2200 Test Loss = 84.3571, Test Accuracy = 0.1037\n",
      "Iteration 141: Loss = 36.4286, Accuracy = 0.2200 Test Loss = 84.1765, Test Accuracy = 0.1037\n",
      "Iteration 142: Loss = 36.1943, Accuracy = 0.2200 Test Loss = 83.9979, Test Accuracy = 0.1037\n",
      "Iteration 143: Loss = 35.9627, Accuracy = 0.2200 Test Loss = 83.8212, Test Accuracy = 0.1035\n",
      "Iteration 144: Loss = 35.7338, Accuracy = 0.2200 Test Loss = 83.6463, Test Accuracy = 0.1031\n",
      "Iteration 145: Loss = 35.5076, Accuracy = 0.2200 Test Loss = 83.4733, Test Accuracy = 0.1029\n",
      "Iteration 146: Loss = 35.2841, Accuracy = 0.2300 Test Loss = 83.3021, Test Accuracy = 0.1030\n",
      "Iteration 147: Loss = 35.0630, Accuracy = 0.2300 Test Loss = 83.1326, Test Accuracy = 0.1030\n",
      "Iteration 148: Loss = 34.8446, Accuracy = 0.2300 Test Loss = 82.9649, Test Accuracy = 0.1031\n",
      "Iteration 149: Loss = 34.6285, Accuracy = 0.2200 Test Loss = 82.7990, Test Accuracy = 0.1030\n",
      "Iteration 150: Loss = 34.4150, Accuracy = 0.2200 Test Loss = 82.6347, Test Accuracy = 0.1028\n",
      "Iteration 151: Loss = 34.2038, Accuracy = 0.2200 Test Loss = 82.4720, Test Accuracy = 0.1027\n",
      "Iteration 152: Loss = 33.9950, Accuracy = 0.2200 Test Loss = 82.3110, Test Accuracy = 0.1025\n",
      "Iteration 153: Loss = 33.7885, Accuracy = 0.2200 Test Loss = 82.1516, Test Accuracy = 0.1026\n",
      "Iteration 154: Loss = 33.5843, Accuracy = 0.2200 Test Loss = 81.9938, Test Accuracy = 0.1024\n",
      "Iteration 155: Loss = 33.3824, Accuracy = 0.2100 Test Loss = 81.8376, Test Accuracy = 0.1028\n",
      "Iteration 156: Loss = 33.1827, Accuracy = 0.2100 Test Loss = 81.6829, Test Accuracy = 0.1028\n",
      "Iteration 157: Loss = 32.9851, Accuracy = 0.2100 Test Loss = 81.5297, Test Accuracy = 0.1025\n",
      "Iteration 158: Loss = 32.7897, Accuracy = 0.2100 Test Loss = 81.3780, Test Accuracy = 0.1027\n",
      "Iteration 159: Loss = 32.5964, Accuracy = 0.2100 Test Loss = 81.2278, Test Accuracy = 0.1027\n",
      "Iteration 160: Loss = 32.4052, Accuracy = 0.2100 Test Loss = 81.0789, Test Accuracy = 0.1025\n",
      "Iteration 161: Loss = 32.2160, Accuracy = 0.2100 Test Loss = 80.9316, Test Accuracy = 0.1026\n",
      "Iteration 162: Loss = 32.0288, Accuracy = 0.2100 Test Loss = 80.7856, Test Accuracy = 0.1023\n",
      "Iteration 163: Loss = 31.8436, Accuracy = 0.2100 Test Loss = 80.6410, Test Accuracy = 0.1024\n",
      "Iteration 164: Loss = 31.6604, Accuracy = 0.2000 Test Loss = 80.4978, Test Accuracy = 0.1023\n",
      "Iteration 165: Loss = 31.4790, Accuracy = 0.2000 Test Loss = 80.3559, Test Accuracy = 0.1023\n",
      "Iteration 166: Loss = 31.2996, Accuracy = 0.2000 Test Loss = 80.2153, Test Accuracy = 0.1024\n",
      "Iteration 167: Loss = 31.1220, Accuracy = 0.2000 Test Loss = 80.0760, Test Accuracy = 0.1022\n",
      "Iteration 168: Loss = 30.9463, Accuracy = 0.2000 Test Loss = 79.9380, Test Accuracy = 0.1021\n",
      "Iteration 169: Loss = 30.7723, Accuracy = 0.2000 Test Loss = 79.8013, Test Accuracy = 0.1021\n",
      "Iteration 170: Loss = 30.6001, Accuracy = 0.2000 Test Loss = 79.6658, Test Accuracy = 0.1023\n",
      "Iteration 171: Loss = 30.4297, Accuracy = 0.2000 Test Loss = 79.5315, Test Accuracy = 0.1022\n",
      "Iteration 172: Loss = 30.2610, Accuracy = 0.2000 Test Loss = 79.3985, Test Accuracy = 0.1024\n",
      "Iteration 173: Loss = 30.0940, Accuracy = 0.2000 Test Loss = 79.2666, Test Accuracy = 0.1025\n",
      "Iteration 174: Loss = 29.9287, Accuracy = 0.2000 Test Loss = 79.1359, Test Accuracy = 0.1025\n",
      "Iteration 175: Loss = 29.7651, Accuracy = 0.2000 Test Loss = 79.0064, Test Accuracy = 0.1025\n",
      "Iteration 176: Loss = 29.6030, Accuracy = 0.2000 Test Loss = 78.8780, Test Accuracy = 0.1027\n",
      "Iteration 177: Loss = 29.4426, Accuracy = 0.2000 Test Loss = 78.7507, Test Accuracy = 0.1026\n",
      "Iteration 178: Loss = 29.2837, Accuracy = 0.2000 Test Loss = 78.6245, Test Accuracy = 0.1029\n",
      "Iteration 179: Loss = 29.1264, Accuracy = 0.2000 Test Loss = 78.4995, Test Accuracy = 0.1030\n",
      "Iteration 180: Loss = 28.9706, Accuracy = 0.2000 Test Loss = 78.3755, Test Accuracy = 0.1029\n",
      "Iteration 181: Loss = 28.8163, Accuracy = 0.2000 Test Loss = 78.2526, Test Accuracy = 0.1029\n",
      "Iteration 182: Loss = 28.6636, Accuracy = 0.2000 Test Loss = 78.1307, Test Accuracy = 0.1031\n",
      "Iteration 183: Loss = 28.5123, Accuracy = 0.2000 Test Loss = 78.0099, Test Accuracy = 0.1029\n",
      "Iteration 184: Loss = 28.3624, Accuracy = 0.2000 Test Loss = 77.8901, Test Accuracy = 0.1031\n",
      "Iteration 185: Loss = 28.2140, Accuracy = 0.2000 Test Loss = 77.7713, Test Accuracy = 0.1028\n",
      "Iteration 186: Loss = 28.0669, Accuracy = 0.2000 Test Loss = 77.6535, Test Accuracy = 0.1029\n",
      "Iteration 187: Loss = 27.9213, Accuracy = 0.2000 Test Loss = 77.5367, Test Accuracy = 0.1029\n",
      "Iteration 188: Loss = 27.7770, Accuracy = 0.2000 Test Loss = 77.4208, Test Accuracy = 0.1030\n",
      "Iteration 189: Loss = 27.6341, Accuracy = 0.2000 Test Loss = 77.3059, Test Accuracy = 0.1028\n",
      "Iteration 190: Loss = 27.4925, Accuracy = 0.2000 Test Loss = 77.1920, Test Accuracy = 0.1026\n",
      "Iteration 191: Loss = 27.3523, Accuracy = 0.2000 Test Loss = 77.0790, Test Accuracy = 0.1023\n",
      "Iteration 192: Loss = 27.2133, Accuracy = 0.2000 Test Loss = 76.9669, Test Accuracy = 0.1022\n",
      "Iteration 193: Loss = 27.0756, Accuracy = 0.2000 Test Loss = 76.8557, Test Accuracy = 0.1019\n",
      "Iteration 194: Loss = 26.9391, Accuracy = 0.2000 Test Loss = 76.7454, Test Accuracy = 0.1016\n",
      "Iteration 195: Loss = 26.8039, Accuracy = 0.2000 Test Loss = 76.6360, Test Accuracy = 0.1015\n",
      "Iteration 196: Loss = 26.6700, Accuracy = 0.2000 Test Loss = 76.5274, Test Accuracy = 0.1015\n",
      "Iteration 197: Loss = 26.5372, Accuracy = 0.2000 Test Loss = 76.4198, Test Accuracy = 0.1017\n",
      "Iteration 198: Loss = 26.4056, Accuracy = 0.2000 Test Loss = 76.3130, Test Accuracy = 0.1015\n",
      "Iteration 199: Loss = 26.2752, Accuracy = 0.2000 Test Loss = 76.2070, Test Accuracy = 0.1017\n",
      "Iteration 200: Loss = 26.1460, Accuracy = 0.2000 Test Loss = 76.1018, Test Accuracy = 0.1015\n",
      "Iteration 201: Loss = 26.0179, Accuracy = 0.2000 Test Loss = 75.9975, Test Accuracy = 0.1014\n",
      "Iteration 202: Loss = 25.8910, Accuracy = 0.2000 Test Loss = 75.8940, Test Accuracy = 0.1016\n",
      "Iteration 203: Loss = 25.7652, Accuracy = 0.2000 Test Loss = 75.7913, Test Accuracy = 0.1017\n",
      "Iteration 204: Loss = 25.6404, Accuracy = 0.2000 Test Loss = 75.6894, Test Accuracy = 0.1017\n",
      "Iteration 205: Loss = 25.5168, Accuracy = 0.2000 Test Loss = 75.5882, Test Accuracy = 0.1018\n",
      "Iteration 206: Loss = 25.3942, Accuracy = 0.2000 Test Loss = 75.4878, Test Accuracy = 0.1018\n",
      "Iteration 207: Loss = 25.2727, Accuracy = 0.2000 Test Loss = 75.3882, Test Accuracy = 0.1016\n",
      "Iteration 208: Loss = 25.1523, Accuracy = 0.2000 Test Loss = 75.2894, Test Accuracy = 0.1016\n",
      "Iteration 209: Loss = 25.0329, Accuracy = 0.2000 Test Loss = 75.1913, Test Accuracy = 0.1017\n",
      "Iteration 210: Loss = 24.9145, Accuracy = 0.2000 Test Loss = 75.0939, Test Accuracy = 0.1019\n",
      "Iteration 211: Loss = 24.7971, Accuracy = 0.2000 Test Loss = 74.9973, Test Accuracy = 0.1021\n",
      "Iteration 212: Loss = 24.6807, Accuracy = 0.2000 Test Loss = 74.9013, Test Accuracy = 0.1021\n",
      "Iteration 213: Loss = 24.5653, Accuracy = 0.2100 Test Loss = 74.8061, Test Accuracy = 0.1019\n",
      "Iteration 214: Loss = 24.4508, Accuracy = 0.2100 Test Loss = 74.7116, Test Accuracy = 0.1020\n",
      "Iteration 215: Loss = 24.3373, Accuracy = 0.2100 Test Loss = 74.6178, Test Accuracy = 0.1020\n",
      "Iteration 216: Loss = 24.2248, Accuracy = 0.2100 Test Loss = 74.5246, Test Accuracy = 0.1020\n",
      "Iteration 217: Loss = 24.1132, Accuracy = 0.2100 Test Loss = 74.4322, Test Accuracy = 0.1020\n",
      "Iteration 218: Loss = 24.0025, Accuracy = 0.2100 Test Loss = 74.3404, Test Accuracy = 0.1019\n",
      "Iteration 219: Loss = 23.8927, Accuracy = 0.2000 Test Loss = 74.2492, Test Accuracy = 0.1020\n",
      "Iteration 220: Loss = 23.7839, Accuracy = 0.2000 Test Loss = 74.1588, Test Accuracy = 0.1019\n",
      "Iteration 221: Loss = 23.6759, Accuracy = 0.2000 Test Loss = 74.0689, Test Accuracy = 0.1018\n",
      "Iteration 222: Loss = 23.5688, Accuracy = 0.2000 Test Loss = 73.9797, Test Accuracy = 0.1018\n",
      "Iteration 223: Loss = 23.4626, Accuracy = 0.2000 Test Loss = 73.8912, Test Accuracy = 0.1020\n",
      "Iteration 224: Loss = 23.3572, Accuracy = 0.2000 Test Loss = 73.8032, Test Accuracy = 0.1019\n",
      "Iteration 225: Loss = 23.2527, Accuracy = 0.2100 Test Loss = 73.7159, Test Accuracy = 0.1020\n",
      "Iteration 226: Loss = 23.1490, Accuracy = 0.2100 Test Loss = 73.6292, Test Accuracy = 0.1020\n",
      "Iteration 227: Loss = 23.0462, Accuracy = 0.2000 Test Loss = 73.5431, Test Accuracy = 0.1019\n",
      "Iteration 228: Loss = 22.9441, Accuracy = 0.2000 Test Loss = 73.4576, Test Accuracy = 0.1021\n",
      "Iteration 229: Loss = 22.8429, Accuracy = 0.2000 Test Loss = 73.3727, Test Accuracy = 0.1023\n",
      "Iteration 230: Loss = 22.7425, Accuracy = 0.2000 Test Loss = 73.2884, Test Accuracy = 0.1024\n",
      "Iteration 231: Loss = 22.6428, Accuracy = 0.2000 Test Loss = 73.2046, Test Accuracy = 0.1023\n",
      "Iteration 232: Loss = 22.5440, Accuracy = 0.2000 Test Loss = 73.1214, Test Accuracy = 0.1021\n",
      "Iteration 233: Loss = 22.4459, Accuracy = 0.2000 Test Loss = 73.0388, Test Accuracy = 0.1022\n",
      "Iteration 234: Loss = 22.3485, Accuracy = 0.2000 Test Loss = 72.9568, Test Accuracy = 0.1022\n",
      "Iteration 235: Loss = 22.2520, Accuracy = 0.2000 Test Loss = 72.8753, Test Accuracy = 0.1022\n",
      "Iteration 236: Loss = 22.1561, Accuracy = 0.2000 Test Loss = 72.7943, Test Accuracy = 0.1020\n",
      "Iteration 237: Loss = 22.0610, Accuracy = 0.2000 Test Loss = 72.7139, Test Accuracy = 0.1021\n",
      "Iteration 238: Loss = 21.9667, Accuracy = 0.2000 Test Loss = 72.6340, Test Accuracy = 0.1022\n",
      "Iteration 239: Loss = 21.8730, Accuracy = 0.2000 Test Loss = 72.5547, Test Accuracy = 0.1022\n",
      "Iteration 240: Loss = 21.7801, Accuracy = 0.2000 Test Loss = 72.4759, Test Accuracy = 0.1017\n",
      "Iteration 241: Loss = 21.6879, Accuracy = 0.2000 Test Loss = 72.3976, Test Accuracy = 0.1015\n",
      "Iteration 242: Loss = 21.5963, Accuracy = 0.2000 Test Loss = 72.3198, Test Accuracy = 0.1016\n",
      "Iteration 243: Loss = 21.5055, Accuracy = 0.2000 Test Loss = 72.2426, Test Accuracy = 0.1017\n",
      "Iteration 244: Loss = 21.4153, Accuracy = 0.2000 Test Loss = 72.1658, Test Accuracy = 0.1019\n",
      "Iteration 245: Loss = 21.3258, Accuracy = 0.2000 Test Loss = 72.0895, Test Accuracy = 0.1019\n",
      "Iteration 246: Loss = 21.2370, Accuracy = 0.2000 Test Loss = 72.0137, Test Accuracy = 0.1018\n",
      "Iteration 247: Loss = 21.1488, Accuracy = 0.2000 Test Loss = 71.9385, Test Accuracy = 0.1019\n",
      "Iteration 248: Loss = 21.0613, Accuracy = 0.2000 Test Loss = 71.8637, Test Accuracy = 0.1017\n",
      "Iteration 249: Loss = 20.9744, Accuracy = 0.2000 Test Loss = 71.7893, Test Accuracy = 0.1018\n",
      "Iteration 250: Loss = 20.8882, Accuracy = 0.2000 Test Loss = 71.7155, Test Accuracy = 0.1018\n",
      "Iteration 251: Loss = 20.8025, Accuracy = 0.2000 Test Loss = 71.6421, Test Accuracy = 0.1019\n",
      "Iteration 252: Loss = 20.7175, Accuracy = 0.2000 Test Loss = 71.5692, Test Accuracy = 0.1020\n",
      "Iteration 253: Loss = 20.6332, Accuracy = 0.2100 Test Loss = 71.4967, Test Accuracy = 0.1020\n",
      "Iteration 254: Loss = 20.5494, Accuracy = 0.2100 Test Loss = 71.4247, Test Accuracy = 0.1018\n",
      "Iteration 255: Loss = 20.4662, Accuracy = 0.2100 Test Loss = 71.3532, Test Accuracy = 0.1020\n",
      "Iteration 256: Loss = 20.3836, Accuracy = 0.2100 Test Loss = 71.2821, Test Accuracy = 0.1019\n",
      "Iteration 257: Loss = 20.3017, Accuracy = 0.2100 Test Loss = 71.2114, Test Accuracy = 0.1020\n",
      "Iteration 258: Loss = 20.2203, Accuracy = 0.2100 Test Loss = 71.1412, Test Accuracy = 0.1021\n",
      "Iteration 259: Loss = 20.1394, Accuracy = 0.2100 Test Loss = 71.0714, Test Accuracy = 0.1022\n",
      "Iteration 260: Loss = 20.0592, Accuracy = 0.2100 Test Loss = 71.0020, Test Accuracy = 0.1023\n",
      "Iteration 261: Loss = 19.9795, Accuracy = 0.2100 Test Loss = 70.9331, Test Accuracy = 0.1025\n",
      "Iteration 262: Loss = 19.9004, Accuracy = 0.2100 Test Loss = 70.8646, Test Accuracy = 0.1025\n",
      "Iteration 263: Loss = 19.8218, Accuracy = 0.2100 Test Loss = 70.7965, Test Accuracy = 0.1027\n",
      "Iteration 264: Loss = 19.7438, Accuracy = 0.2100 Test Loss = 70.7288, Test Accuracy = 0.1026\n",
      "Iteration 265: Loss = 19.6663, Accuracy = 0.2100 Test Loss = 70.6615, Test Accuracy = 0.1025\n",
      "Iteration 266: Loss = 19.5893, Accuracy = 0.2100 Test Loss = 70.5946, Test Accuracy = 0.1026\n",
      "Iteration 267: Loss = 19.5129, Accuracy = 0.2100 Test Loss = 70.5282, Test Accuracy = 0.1024\n",
      "Iteration 268: Loss = 19.4370, Accuracy = 0.2100 Test Loss = 70.4621, Test Accuracy = 0.1024\n",
      "Iteration 269: Loss = 19.3616, Accuracy = 0.2100 Test Loss = 70.3964, Test Accuracy = 0.1024\n",
      "Iteration 270: Loss = 19.2868, Accuracy = 0.2100 Test Loss = 70.3311, Test Accuracy = 0.1022\n",
      "Iteration 271: Loss = 19.2124, Accuracy = 0.2100 Test Loss = 70.2662, Test Accuracy = 0.1021\n",
      "Iteration 272: Loss = 19.1386, Accuracy = 0.2100 Test Loss = 70.2017, Test Accuracy = 0.1021\n",
      "Iteration 273: Loss = 19.0652, Accuracy = 0.2100 Test Loss = 70.1375, Test Accuracy = 0.1021\n",
      "Iteration 274: Loss = 18.9923, Accuracy = 0.2200 Test Loss = 70.0738, Test Accuracy = 0.1020\n",
      "Iteration 275: Loss = 18.9200, Accuracy = 0.2200 Test Loss = 70.0104, Test Accuracy = 0.1021\n",
      "Iteration 276: Loss = 18.8481, Accuracy = 0.2200 Test Loss = 69.9473, Test Accuracy = 0.1021\n",
      "Iteration 277: Loss = 18.7767, Accuracy = 0.2200 Test Loss = 69.8847, Test Accuracy = 0.1021\n",
      "Iteration 278: Loss = 18.7057, Accuracy = 0.2200 Test Loss = 69.8224, Test Accuracy = 0.1021\n",
      "Iteration 279: Loss = 18.6353, Accuracy = 0.2200 Test Loss = 69.7604, Test Accuracy = 0.1020\n",
      "Iteration 280: Loss = 18.5653, Accuracy = 0.2200 Test Loss = 69.6988, Test Accuracy = 0.1021\n",
      "Iteration 281: Loss = 18.4957, Accuracy = 0.2200 Test Loss = 69.6376, Test Accuracy = 0.1020\n",
      "Iteration 282: Loss = 18.4266, Accuracy = 0.2200 Test Loss = 69.5767, Test Accuracy = 0.1020\n",
      "Iteration 283: Loss = 18.3580, Accuracy = 0.2200 Test Loss = 69.5162, Test Accuracy = 0.1022\n",
      "Iteration 284: Loss = 18.2898, Accuracy = 0.2200 Test Loss = 69.4560, Test Accuracy = 0.1023\n",
      "Iteration 285: Loss = 18.2221, Accuracy = 0.2200 Test Loss = 69.3961, Test Accuracy = 0.1023\n",
      "Iteration 286: Loss = 18.1548, Accuracy = 0.2200 Test Loss = 69.3366, Test Accuracy = 0.1024\n",
      "Iteration 287: Loss = 18.0879, Accuracy = 0.2200 Test Loss = 69.2774, Test Accuracy = 0.1024\n",
      "Iteration 288: Loss = 18.0215, Accuracy = 0.2200 Test Loss = 69.2186, Test Accuracy = 0.1026\n",
      "Iteration 289: Loss = 17.9554, Accuracy = 0.2200 Test Loss = 69.1600, Test Accuracy = 0.1026\n",
      "Iteration 290: Loss = 17.8898, Accuracy = 0.2200 Test Loss = 69.1018, Test Accuracy = 0.1027\n",
      "Iteration 291: Loss = 17.8246, Accuracy = 0.2200 Test Loss = 69.0440, Test Accuracy = 0.1027\n",
      "Iteration 292: Loss = 17.7599, Accuracy = 0.2200 Test Loss = 68.9864, Test Accuracy = 0.1028\n",
      "Iteration 293: Loss = 17.6955, Accuracy = 0.2200 Test Loss = 68.9291, Test Accuracy = 0.1028\n",
      "Iteration 294: Loss = 17.6316, Accuracy = 0.2200 Test Loss = 68.8722, Test Accuracy = 0.1030\n",
      "Iteration 295: Loss = 17.5680, Accuracy = 0.2200 Test Loss = 68.8156, Test Accuracy = 0.1032\n",
      "Iteration 296: Loss = 17.5049, Accuracy = 0.2200 Test Loss = 68.7593, Test Accuracy = 0.1033\n",
      "Iteration 297: Loss = 17.4421, Accuracy = 0.2200 Test Loss = 68.7033, Test Accuracy = 0.1035\n",
      "Iteration 298: Loss = 17.3797, Accuracy = 0.2200 Test Loss = 68.6476, Test Accuracy = 0.1036\n",
      "Iteration 299: Loss = 17.3177, Accuracy = 0.2200 Test Loss = 68.5922, Test Accuracy = 0.1035\n",
      "Iteration 300: Loss = 17.2561, Accuracy = 0.2200 Test Loss = 68.5371, Test Accuracy = 0.1036\n",
      "Iteration 301: Loss = 17.1949, Accuracy = 0.2200 Test Loss = 68.4823, Test Accuracy = 0.1035\n",
      "Iteration 302: Loss = 17.1341, Accuracy = 0.2200 Test Loss = 68.4278, Test Accuracy = 0.1036\n",
      "Iteration 303: Loss = 17.0736, Accuracy = 0.2200 Test Loss = 68.3736, Test Accuracy = 0.1032\n",
      "Iteration 304: Loss = 17.0135, Accuracy = 0.2200 Test Loss = 68.3196, Test Accuracy = 0.1031\n",
      "Iteration 305: Loss = 16.9537, Accuracy = 0.2200 Test Loss = 68.2660, Test Accuracy = 0.1032\n",
      "Iteration 306: Loss = 16.8944, Accuracy = 0.2200 Test Loss = 68.2126, Test Accuracy = 0.1030\n",
      "Iteration 307: Loss = 16.8353, Accuracy = 0.2200 Test Loss = 68.1596, Test Accuracy = 0.1030\n",
      "Iteration 308: Loss = 16.7767, Accuracy = 0.2200 Test Loss = 68.1068, Test Accuracy = 0.1031\n",
      "Iteration 309: Loss = 16.7184, Accuracy = 0.2200 Test Loss = 68.0542, Test Accuracy = 0.1032\n",
      "Iteration 310: Loss = 16.6604, Accuracy = 0.2200 Test Loss = 68.0020, Test Accuracy = 0.1034\n",
      "Iteration 311: Loss = 16.6028, Accuracy = 0.2200 Test Loss = 67.9500, Test Accuracy = 0.1036\n",
      "Iteration 312: Loss = 16.5455, Accuracy = 0.2200 Test Loss = 67.8983, Test Accuracy = 0.1036\n",
      "Iteration 313: Loss = 16.4886, Accuracy = 0.2200 Test Loss = 67.8469, Test Accuracy = 0.1034\n",
      "Iteration 314: Loss = 16.4320, Accuracy = 0.2200 Test Loss = 67.7957, Test Accuracy = 0.1033\n",
      "Iteration 315: Loss = 16.3757, Accuracy = 0.2200 Test Loss = 67.7448, Test Accuracy = 0.1034\n",
      "Iteration 316: Loss = 16.3198, Accuracy = 0.2200 Test Loss = 67.6941, Test Accuracy = 0.1035\n",
      "Iteration 317: Loss = 16.2642, Accuracy = 0.2200 Test Loss = 67.6438, Test Accuracy = 0.1034\n",
      "Iteration 318: Loss = 16.2089, Accuracy = 0.2200 Test Loss = 67.5936, Test Accuracy = 0.1032\n",
      "Iteration 319: Loss = 16.1540, Accuracy = 0.2200 Test Loss = 67.5437, Test Accuracy = 0.1030\n",
      "Iteration 320: Loss = 16.0993, Accuracy = 0.2200 Test Loss = 67.4941, Test Accuracy = 0.1029\n",
      "Iteration 321: Loss = 16.0450, Accuracy = 0.2200 Test Loss = 67.4448, Test Accuracy = 0.1029\n",
      "Iteration 322: Loss = 15.9910, Accuracy = 0.2200 Test Loss = 67.3957, Test Accuracy = 0.1030\n",
      "Iteration 323: Loss = 15.9373, Accuracy = 0.2200 Test Loss = 67.3468, Test Accuracy = 0.1029\n",
      "Iteration 324: Loss = 15.8839, Accuracy = 0.2200 Test Loss = 67.2981, Test Accuracy = 0.1028\n",
      "Iteration 325: Loss = 15.8309, Accuracy = 0.2200 Test Loss = 67.2498, Test Accuracy = 0.1027\n",
      "Iteration 326: Loss = 15.7781, Accuracy = 0.2200 Test Loss = 67.2016, Test Accuracy = 0.1028\n",
      "Iteration 327: Loss = 15.7256, Accuracy = 0.2200 Test Loss = 67.1537, Test Accuracy = 0.1029\n",
      "Iteration 328: Loss = 15.6734, Accuracy = 0.2200 Test Loss = 67.1061, Test Accuracy = 0.1030\n",
      "Iteration 329: Loss = 15.6215, Accuracy = 0.2200 Test Loss = 67.0586, Test Accuracy = 0.1029\n",
      "Iteration 330: Loss = 15.5700, Accuracy = 0.2200 Test Loss = 67.0114, Test Accuracy = 0.1029\n",
      "Iteration 331: Loss = 15.5187, Accuracy = 0.2200 Test Loss = 66.9645, Test Accuracy = 0.1031\n",
      "Iteration 332: Loss = 15.4676, Accuracy = 0.2200 Test Loss = 66.9178, Test Accuracy = 0.1031\n",
      "Iteration 333: Loss = 15.4169, Accuracy = 0.2300 Test Loss = 66.8713, Test Accuracy = 0.1030\n",
      "Iteration 334: Loss = 15.3665, Accuracy = 0.2300 Test Loss = 66.8250, Test Accuracy = 0.1032\n",
      "Iteration 335: Loss = 15.3163, Accuracy = 0.2300 Test Loss = 66.7790, Test Accuracy = 0.1033\n",
      "Iteration 336: Loss = 15.2664, Accuracy = 0.2300 Test Loss = 66.7331, Test Accuracy = 0.1031\n",
      "Iteration 337: Loss = 15.2168, Accuracy = 0.2300 Test Loss = 66.6875, Test Accuracy = 0.1031\n",
      "Iteration 338: Loss = 15.1675, Accuracy = 0.2300 Test Loss = 66.6422, Test Accuracy = 0.1031\n",
      "Iteration 339: Loss = 15.1184, Accuracy = 0.2300 Test Loss = 66.5970, Test Accuracy = 0.1031\n",
      "Iteration 340: Loss = 15.0696, Accuracy = 0.2300 Test Loss = 66.5520, Test Accuracy = 0.1034\n",
      "Iteration 341: Loss = 15.0211, Accuracy = 0.2300 Test Loss = 66.5073, Test Accuracy = 0.1034\n",
      "Iteration 342: Loss = 14.9728, Accuracy = 0.2300 Test Loss = 66.4628, Test Accuracy = 0.1033\n",
      "Iteration 343: Loss = 14.9248, Accuracy = 0.2300 Test Loss = 66.4185, Test Accuracy = 0.1034\n",
      "Iteration 344: Loss = 14.8771, Accuracy = 0.2400 Test Loss = 66.3744, Test Accuracy = 0.1033\n",
      "Iteration 345: Loss = 14.8296, Accuracy = 0.2400 Test Loss = 66.3305, Test Accuracy = 0.1035\n",
      "Iteration 346: Loss = 14.7824, Accuracy = 0.2400 Test Loss = 66.2869, Test Accuracy = 0.1037\n",
      "Iteration 347: Loss = 14.7354, Accuracy = 0.2400 Test Loss = 66.2434, Test Accuracy = 0.1036\n",
      "Iteration 348: Loss = 14.6887, Accuracy = 0.2400 Test Loss = 66.2001, Test Accuracy = 0.1036\n",
      "Iteration 349: Loss = 14.6422, Accuracy = 0.2400 Test Loss = 66.1571, Test Accuracy = 0.1038\n",
      "Iteration 350: Loss = 14.5960, Accuracy = 0.2400 Test Loss = 66.1142, Test Accuracy = 0.1039\n",
      "Iteration 351: Loss = 14.5500, Accuracy = 0.2400 Test Loss = 66.0716, Test Accuracy = 0.1038\n",
      "Iteration 352: Loss = 14.5043, Accuracy = 0.2400 Test Loss = 66.0291, Test Accuracy = 0.1039\n",
      "Iteration 353: Loss = 14.4588, Accuracy = 0.2400 Test Loss = 65.9869, Test Accuracy = 0.1041\n",
      "Iteration 354: Loss = 14.4136, Accuracy = 0.2400 Test Loss = 65.9448, Test Accuracy = 0.1041\n",
      "Iteration 355: Loss = 14.3686, Accuracy = 0.2400 Test Loss = 65.9029, Test Accuracy = 0.1042\n",
      "Iteration 356: Loss = 14.3238, Accuracy = 0.2400 Test Loss = 65.8613, Test Accuracy = 0.1043\n",
      "Iteration 357: Loss = 14.2793, Accuracy = 0.2400 Test Loss = 65.8198, Test Accuracy = 0.1043\n",
      "Iteration 358: Loss = 14.2350, Accuracy = 0.2400 Test Loss = 65.7785, Test Accuracy = 0.1042\n",
      "Iteration 359: Loss = 14.1909, Accuracy = 0.2400 Test Loss = 65.7374, Test Accuracy = 0.1043\n",
      "Iteration 360: Loss = 14.1470, Accuracy = 0.2400 Test Loss = 65.6965, Test Accuracy = 0.1043\n",
      "Iteration 361: Loss = 14.1034, Accuracy = 0.2400 Test Loss = 65.6558, Test Accuracy = 0.1046\n",
      "Iteration 362: Loss = 14.0600, Accuracy = 0.2400 Test Loss = 65.6152, Test Accuracy = 0.1046\n",
      "Iteration 363: Loss = 14.0169, Accuracy = 0.2400 Test Loss = 65.5749, Test Accuracy = 0.1045\n",
      "Iteration 364: Loss = 13.9739, Accuracy = 0.2400 Test Loss = 65.5347, Test Accuracy = 0.1043\n",
      "Iteration 365: Loss = 13.9312, Accuracy = 0.2400 Test Loss = 65.4947, Test Accuracy = 0.1045\n",
      "Iteration 366: Loss = 13.8887, Accuracy = 0.2400 Test Loss = 65.4549, Test Accuracy = 0.1043\n",
      "Iteration 367: Loss = 13.8464, Accuracy = 0.2400 Test Loss = 65.4153, Test Accuracy = 0.1043\n",
      "Iteration 368: Loss = 13.8043, Accuracy = 0.2400 Test Loss = 65.3758, Test Accuracy = 0.1043\n",
      "Iteration 369: Loss = 13.7624, Accuracy = 0.2400 Test Loss = 65.3365, Test Accuracy = 0.1045\n",
      "Iteration 370: Loss = 13.7208, Accuracy = 0.2400 Test Loss = 65.2974, Test Accuracy = 0.1044\n",
      "Iteration 371: Loss = 13.6794, Accuracy = 0.2400 Test Loss = 65.2585, Test Accuracy = 0.1044\n",
      "Iteration 372: Loss = 13.6381, Accuracy = 0.2400 Test Loss = 65.2197, Test Accuracy = 0.1045\n",
      "Iteration 373: Loss = 13.5971, Accuracy = 0.2400 Test Loss = 65.1812, Test Accuracy = 0.1046\n",
      "Iteration 374: Loss = 13.5563, Accuracy = 0.2400 Test Loss = 65.1428, Test Accuracy = 0.1046\n",
      "Iteration 375: Loss = 13.5157, Accuracy = 0.2400 Test Loss = 65.1045, Test Accuracy = 0.1049\n",
      "Iteration 376: Loss = 13.4753, Accuracy = 0.2400 Test Loss = 65.0664, Test Accuracy = 0.1049\n",
      "Iteration 377: Loss = 13.4350, Accuracy = 0.2400 Test Loss = 65.0285, Test Accuracy = 0.1051\n",
      "Iteration 378: Loss = 13.3950, Accuracy = 0.2400 Test Loss = 64.9908, Test Accuracy = 0.1052\n",
      "Iteration 379: Loss = 13.3552, Accuracy = 0.2400 Test Loss = 64.9532, Test Accuracy = 0.1051\n",
      "Iteration 380: Loss = 13.3156, Accuracy = 0.2400 Test Loss = 64.9158, Test Accuracy = 0.1052\n",
      "Iteration 381: Loss = 13.2762, Accuracy = 0.2400 Test Loss = 64.8786, Test Accuracy = 0.1055\n",
      "Iteration 382: Loss = 13.2370, Accuracy = 0.2400 Test Loss = 64.8415, Test Accuracy = 0.1055\n",
      "Iteration 383: Loss = 13.1979, Accuracy = 0.2400 Test Loss = 64.8046, Test Accuracy = 0.1057\n",
      "Iteration 384: Loss = 13.1591, Accuracy = 0.2400 Test Loss = 64.7678, Test Accuracy = 0.1058\n",
      "Iteration 385: Loss = 13.1204, Accuracy = 0.2400 Test Loss = 64.7312, Test Accuracy = 0.1057\n",
      "Iteration 386: Loss = 13.0820, Accuracy = 0.2400 Test Loss = 64.6947, Test Accuracy = 0.1057\n",
      "Iteration 387: Loss = 13.0437, Accuracy = 0.2400 Test Loss = 64.6584, Test Accuracy = 0.1058\n",
      "Iteration 388: Loss = 13.0056, Accuracy = 0.2400 Test Loss = 64.6223, Test Accuracy = 0.1058\n",
      "Iteration 389: Loss = 12.9677, Accuracy = 0.2400 Test Loss = 64.5863, Test Accuracy = 0.1057\n",
      "Iteration 390: Loss = 12.9299, Accuracy = 0.2400 Test Loss = 64.5505, Test Accuracy = 0.1057\n",
      "Iteration 391: Loss = 12.8924, Accuracy = 0.2400 Test Loss = 64.5148, Test Accuracy = 0.1057\n",
      "Iteration 392: Loss = 12.8550, Accuracy = 0.2400 Test Loss = 64.4793, Test Accuracy = 0.1058\n",
      "Iteration 393: Loss = 12.8178, Accuracy = 0.2400 Test Loss = 64.4439, Test Accuracy = 0.1059\n",
      "Iteration 394: Loss = 12.7808, Accuracy = 0.2400 Test Loss = 64.4087, Test Accuracy = 0.1058\n",
      "Iteration 395: Loss = 12.7440, Accuracy = 0.2400 Test Loss = 64.3737, Test Accuracy = 0.1058\n",
      "Iteration 396: Loss = 12.7073, Accuracy = 0.2400 Test Loss = 64.3387, Test Accuracy = 0.1057\n",
      "Iteration 397: Loss = 12.6708, Accuracy = 0.2400 Test Loss = 64.3039, Test Accuracy = 0.1058\n",
      "Iteration 398: Loss = 12.6345, Accuracy = 0.2400 Test Loss = 64.2693, Test Accuracy = 0.1058\n",
      "Iteration 399: Loss = 12.5984, Accuracy = 0.2400 Test Loss = 64.2348, Test Accuracy = 0.1059\n",
      "Iteration 400: Loss = 12.5624, Accuracy = 0.2400 Test Loss = 64.2005, Test Accuracy = 0.1058\n",
      "Iteration 401: Loss = 12.5266, Accuracy = 0.2400 Test Loss = 64.1663, Test Accuracy = 0.1058\n",
      "Iteration 402: Loss = 12.4910, Accuracy = 0.2400 Test Loss = 64.1322, Test Accuracy = 0.1059\n",
      "Iteration 403: Loss = 12.4555, Accuracy = 0.2400 Test Loss = 64.0983, Test Accuracy = 0.1058\n",
      "Iteration 404: Loss = 12.4202, Accuracy = 0.2400 Test Loss = 64.0646, Test Accuracy = 0.1058\n",
      "Iteration 405: Loss = 12.3851, Accuracy = 0.2400 Test Loss = 64.0309, Test Accuracy = 0.1058\n",
      "Iteration 406: Loss = 12.3501, Accuracy = 0.2400 Test Loss = 63.9974, Test Accuracy = 0.1058\n",
      "Iteration 407: Loss = 12.3153, Accuracy = 0.2400 Test Loss = 63.9641, Test Accuracy = 0.1058\n",
      "Iteration 408: Loss = 12.2806, Accuracy = 0.2400 Test Loss = 63.9308, Test Accuracy = 0.1059\n",
      "Iteration 409: Loss = 12.2461, Accuracy = 0.2400 Test Loss = 63.8978, Test Accuracy = 0.1060\n",
      "Iteration 410: Loss = 12.2118, Accuracy = 0.2400 Test Loss = 63.8648, Test Accuracy = 0.1059\n",
      "Iteration 411: Loss = 12.1776, Accuracy = 0.2400 Test Loss = 63.8320, Test Accuracy = 0.1060\n",
      "Iteration 412: Loss = 12.1436, Accuracy = 0.2400 Test Loss = 63.7993, Test Accuracy = 0.1061\n",
      "Iteration 413: Loss = 12.1097, Accuracy = 0.2400 Test Loss = 63.7668, Test Accuracy = 0.1059\n",
      "Iteration 414: Loss = 12.0760, Accuracy = 0.2400 Test Loss = 63.7343, Test Accuracy = 0.1060\n",
      "Iteration 415: Loss = 12.0424, Accuracy = 0.2400 Test Loss = 63.7021, Test Accuracy = 0.1060\n",
      "Iteration 416: Loss = 12.0090, Accuracy = 0.2400 Test Loss = 63.6699, Test Accuracy = 0.1059\n",
      "Iteration 417: Loss = 11.9758, Accuracy = 0.2400 Test Loss = 63.6379, Test Accuracy = 0.1061\n",
      "Iteration 418: Loss = 11.9427, Accuracy = 0.2400 Test Loss = 63.6060, Test Accuracy = 0.1060\n",
      "Iteration 419: Loss = 11.9097, Accuracy = 0.2400 Test Loss = 63.5742, Test Accuracy = 0.1060\n",
      "Iteration 420: Loss = 11.8769, Accuracy = 0.2400 Test Loss = 63.5426, Test Accuracy = 0.1061\n",
      "Iteration 421: Loss = 11.8443, Accuracy = 0.2400 Test Loss = 63.5111, Test Accuracy = 0.1061\n",
      "Iteration 422: Loss = 11.8117, Accuracy = 0.2400 Test Loss = 63.4797, Test Accuracy = 0.1060\n",
      "Iteration 423: Loss = 11.7794, Accuracy = 0.2400 Test Loss = 63.4484, Test Accuracy = 0.1061\n",
      "Iteration 424: Loss = 11.7471, Accuracy = 0.2400 Test Loss = 63.4173, Test Accuracy = 0.1062\n",
      "Iteration 425: Loss = 11.7151, Accuracy = 0.2400 Test Loss = 63.3863, Test Accuracy = 0.1062\n",
      "Iteration 426: Loss = 11.6831, Accuracy = 0.2400 Test Loss = 63.3554, Test Accuracy = 0.1064\n",
      "Iteration 427: Loss = 11.6513, Accuracy = 0.2400 Test Loss = 63.3246, Test Accuracy = 0.1065\n",
      "Iteration 428: Loss = 11.6197, Accuracy = 0.2400 Test Loss = 63.2940, Test Accuracy = 0.1063\n",
      "Iteration 429: Loss = 11.5881, Accuracy = 0.2400 Test Loss = 63.2635, Test Accuracy = 0.1063\n",
      "Iteration 430: Loss = 11.5568, Accuracy = 0.2400 Test Loss = 63.2331, Test Accuracy = 0.1062\n",
      "Iteration 431: Loss = 11.5255, Accuracy = 0.2400 Test Loss = 63.2028, Test Accuracy = 0.1063\n",
      "Iteration 432: Loss = 11.4944, Accuracy = 0.2400 Test Loss = 63.1726, Test Accuracy = 0.1064\n",
      "Iteration 433: Loss = 11.4634, Accuracy = 0.2400 Test Loss = 63.1426, Test Accuracy = 0.1065\n",
      "Iteration 434: Loss = 11.4326, Accuracy = 0.2400 Test Loss = 63.1126, Test Accuracy = 0.1064\n",
      "Iteration 435: Loss = 11.4019, Accuracy = 0.2400 Test Loss = 63.0828, Test Accuracy = 0.1064\n",
      "Iteration 436: Loss = 11.3713, Accuracy = 0.2400 Test Loss = 63.0531, Test Accuracy = 0.1064\n",
      "Iteration 437: Loss = 11.3409, Accuracy = 0.2400 Test Loss = 63.0235, Test Accuracy = 0.1064\n",
      "Iteration 438: Loss = 11.3106, Accuracy = 0.2400 Test Loss = 62.9941, Test Accuracy = 0.1066\n",
      "Iteration 439: Loss = 11.2804, Accuracy = 0.2400 Test Loss = 62.9647, Test Accuracy = 0.1066\n",
      "Iteration 440: Loss = 11.2504, Accuracy = 0.2400 Test Loss = 62.9355, Test Accuracy = 0.1068\n",
      "Iteration 441: Loss = 11.2205, Accuracy = 0.2400 Test Loss = 62.9063, Test Accuracy = 0.1068\n",
      "Iteration 442: Loss = 11.1907, Accuracy = 0.2400 Test Loss = 62.8773, Test Accuracy = 0.1068\n",
      "Iteration 443: Loss = 11.1610, Accuracy = 0.2400 Test Loss = 62.8484, Test Accuracy = 0.1068\n",
      "Iteration 444: Loss = 11.1315, Accuracy = 0.2400 Test Loss = 62.8196, Test Accuracy = 0.1068\n",
      "Iteration 445: Loss = 11.1021, Accuracy = 0.2400 Test Loss = 62.7910, Test Accuracy = 0.1069\n",
      "Iteration 446: Loss = 11.0728, Accuracy = 0.2400 Test Loss = 62.7624, Test Accuracy = 0.1071\n",
      "Iteration 447: Loss = 11.0436, Accuracy = 0.2400 Test Loss = 62.7339, Test Accuracy = 0.1071\n",
      "Iteration 448: Loss = 11.0146, Accuracy = 0.2400 Test Loss = 62.7056, Test Accuracy = 0.1074\n",
      "Iteration 449: Loss = 10.9857, Accuracy = 0.2400 Test Loss = 62.6773, Test Accuracy = 0.1074\n",
      "Iteration 450: Loss = 10.9569, Accuracy = 0.2400 Test Loss = 62.6492, Test Accuracy = 0.1075\n",
      "Iteration 451: Loss = 10.9282, Accuracy = 0.2400 Test Loss = 62.6211, Test Accuracy = 0.1075\n",
      "Iteration 452: Loss = 10.8997, Accuracy = 0.2400 Test Loss = 62.5932, Test Accuracy = 0.1075\n",
      "Iteration 453: Loss = 10.8713, Accuracy = 0.2400 Test Loss = 62.5654, Test Accuracy = 0.1076\n",
      "Iteration 454: Loss = 10.8430, Accuracy = 0.2400 Test Loss = 62.5377, Test Accuracy = 0.1076\n",
      "Iteration 455: Loss = 10.8148, Accuracy = 0.2400 Test Loss = 62.5101, Test Accuracy = 0.1075\n",
      "Iteration 456: Loss = 10.7867, Accuracy = 0.2400 Test Loss = 62.4825, Test Accuracy = 0.1075\n",
      "Iteration 457: Loss = 10.7587, Accuracy = 0.2400 Test Loss = 62.4551, Test Accuracy = 0.1074\n",
      "Iteration 458: Loss = 10.7309, Accuracy = 0.2400 Test Loss = 62.4278, Test Accuracy = 0.1075\n",
      "Iteration 459: Loss = 10.7032, Accuracy = 0.2400 Test Loss = 62.4006, Test Accuracy = 0.1076\n",
      "Iteration 460: Loss = 10.6756, Accuracy = 0.2300 Test Loss = 62.3735, Test Accuracy = 0.1075\n",
      "Iteration 461: Loss = 10.6481, Accuracy = 0.2300 Test Loss = 62.3465, Test Accuracy = 0.1076\n",
      "Iteration 462: Loss = 10.6207, Accuracy = 0.2300 Test Loss = 62.3196, Test Accuracy = 0.1076\n",
      "Iteration 463: Loss = 10.5934, Accuracy = 0.2300 Test Loss = 62.2928, Test Accuracy = 0.1078\n",
      "Iteration 464: Loss = 10.5663, Accuracy = 0.2300 Test Loss = 62.2661, Test Accuracy = 0.1080\n",
      "Iteration 465: Loss = 10.5392, Accuracy = 0.2300 Test Loss = 62.2395, Test Accuracy = 0.1081\n",
      "Iteration 466: Loss = 10.5123, Accuracy = 0.2200 Test Loss = 62.2130, Test Accuracy = 0.1082\n",
      "Iteration 467: Loss = 10.4854, Accuracy = 0.2200 Test Loss = 62.1866, Test Accuracy = 0.1082\n",
      "Iteration 468: Loss = 10.4587, Accuracy = 0.2200 Test Loss = 62.1603, Test Accuracy = 0.1082\n",
      "Iteration 469: Loss = 10.4321, Accuracy = 0.2200 Test Loss = 62.1341, Test Accuracy = 0.1082\n",
      "Iteration 470: Loss = 10.4056, Accuracy = 0.2200 Test Loss = 62.1079, Test Accuracy = 0.1082\n",
      "Iteration 471: Loss = 10.3792, Accuracy = 0.2200 Test Loss = 62.0819, Test Accuracy = 0.1080\n",
      "Iteration 472: Loss = 10.3529, Accuracy = 0.2200 Test Loss = 62.0560, Test Accuracy = 0.1080\n",
      "Iteration 473: Loss = 10.3267, Accuracy = 0.2200 Test Loss = 62.0302, Test Accuracy = 0.1081\n",
      "Iteration 474: Loss = 10.3007, Accuracy = 0.2200 Test Loss = 62.0044, Test Accuracy = 0.1080\n",
      "Iteration 475: Loss = 10.2747, Accuracy = 0.2200 Test Loss = 61.9788, Test Accuracy = 0.1078\n",
      "Iteration 476: Loss = 10.2488, Accuracy = 0.2200 Test Loss = 61.9532, Test Accuracy = 0.1078\n",
      "Iteration 477: Loss = 10.2231, Accuracy = 0.2200 Test Loss = 61.9278, Test Accuracy = 0.1077\n",
      "Iteration 478: Loss = 10.1974, Accuracy = 0.2200 Test Loss = 61.9024, Test Accuracy = 0.1077\n",
      "Iteration 479: Loss = 10.1718, Accuracy = 0.2200 Test Loss = 61.8771, Test Accuracy = 0.1077\n",
      "Iteration 480: Loss = 10.1464, Accuracy = 0.2200 Test Loss = 61.8519, Test Accuracy = 0.1075\n",
      "Iteration 481: Loss = 10.1210, Accuracy = 0.2200 Test Loss = 61.8268, Test Accuracy = 0.1075\n",
      "Iteration 482: Loss = 10.0958, Accuracy = 0.2200 Test Loss = 61.8018, Test Accuracy = 0.1076\n",
      "Iteration 483: Loss = 10.0706, Accuracy = 0.2200 Test Loss = 61.7769, Test Accuracy = 0.1077\n",
      "Iteration 484: Loss = 10.0455, Accuracy = 0.2200 Test Loss = 61.7521, Test Accuracy = 0.1077\n",
      "Iteration 485: Loss = 10.0206, Accuracy = 0.2200 Test Loss = 61.7274, Test Accuracy = 0.1079\n",
      "Iteration 486: Loss = 9.9957, Accuracy = 0.2200 Test Loss = 61.7027, Test Accuracy = 0.1078\n",
      "Iteration 487: Loss = 9.9709, Accuracy = 0.2200 Test Loss = 61.6782, Test Accuracy = 0.1078\n",
      "Iteration 488: Loss = 9.9463, Accuracy = 0.2200 Test Loss = 61.6537, Test Accuracy = 0.1080\n",
      "Iteration 489: Loss = 9.9217, Accuracy = 0.2200 Test Loss = 61.6293, Test Accuracy = 0.1079\n",
      "Iteration 490: Loss = 9.8972, Accuracy = 0.2200 Test Loss = 61.6050, Test Accuracy = 0.1079\n",
      "Iteration 491: Loss = 9.8729, Accuracy = 0.2200 Test Loss = 61.5808, Test Accuracy = 0.1079\n",
      "Iteration 492: Loss = 9.8486, Accuracy = 0.2200 Test Loss = 61.5566, Test Accuracy = 0.1081\n",
      "Iteration 493: Loss = 9.8244, Accuracy = 0.2200 Test Loss = 61.5326, Test Accuracy = 0.1081\n",
      "Iteration 494: Loss = 9.8003, Accuracy = 0.2200 Test Loss = 61.5086, Test Accuracy = 0.1080\n",
      "Iteration 495: Loss = 9.7763, Accuracy = 0.2200 Test Loss = 61.4848, Test Accuracy = 0.1081\n",
      "Iteration 496: Loss = 9.7524, Accuracy = 0.2200 Test Loss = 61.4610, Test Accuracy = 0.1083\n",
      "Iteration 497: Loss = 9.7285, Accuracy = 0.2200 Test Loss = 61.4373, Test Accuracy = 0.1083\n",
      "Iteration 498: Loss = 9.7048, Accuracy = 0.2200 Test Loss = 61.4136, Test Accuracy = 0.1084\n",
      "Iteration 499: Loss = 9.6812, Accuracy = 0.2200 Test Loss = 61.3901, Test Accuracy = 0.1084\n",
      "Iteration 500: Loss = 9.6576, Accuracy = 0.2200 Test Loss = 61.3666, Test Accuracy = 0.1084\n",
      "Iteration 501: Loss = 9.6342, Accuracy = 0.2200 Test Loss = 61.3433, Test Accuracy = 0.1084\n",
      "Iteration 502: Loss = 9.6108, Accuracy = 0.2200 Test Loss = 61.3200, Test Accuracy = 0.1084\n",
      "Iteration 503: Loss = 9.5875, Accuracy = 0.2200 Test Loss = 61.2967, Test Accuracy = 0.1086\n",
      "Iteration 504: Loss = 9.5643, Accuracy = 0.2200 Test Loss = 61.2736, Test Accuracy = 0.1085\n",
      "Iteration 505: Loss = 9.5412, Accuracy = 0.2200 Test Loss = 61.2505, Test Accuracy = 0.1084\n",
      "Iteration 506: Loss = 9.5182, Accuracy = 0.2200 Test Loss = 61.2276, Test Accuracy = 0.1084\n",
      "Iteration 507: Loss = 9.4953, Accuracy = 0.2200 Test Loss = 61.2047, Test Accuracy = 0.1083\n",
      "Iteration 508: Loss = 9.4725, Accuracy = 0.2200 Test Loss = 61.1819, Test Accuracy = 0.1083\n",
      "Iteration 509: Loss = 9.4497, Accuracy = 0.2200 Test Loss = 61.1591, Test Accuracy = 0.1085\n",
      "Iteration 510: Loss = 9.4270, Accuracy = 0.2200 Test Loss = 61.1365, Test Accuracy = 0.1085\n",
      "Iteration 511: Loss = 9.4045, Accuracy = 0.2300 Test Loss = 61.1139, Test Accuracy = 0.1085\n",
      "Iteration 512: Loss = 9.3820, Accuracy = 0.2300 Test Loss = 61.0914, Test Accuracy = 0.1085\n",
      "Iteration 513: Loss = 9.3595, Accuracy = 0.2300 Test Loss = 61.0689, Test Accuracy = 0.1085\n",
      "Iteration 514: Loss = 9.3372, Accuracy = 0.2300 Test Loss = 61.0466, Test Accuracy = 0.1085\n",
      "Iteration 515: Loss = 9.3150, Accuracy = 0.2300 Test Loss = 61.0243, Test Accuracy = 0.1086\n",
      "Iteration 516: Loss = 9.2928, Accuracy = 0.2300 Test Loss = 61.0021, Test Accuracy = 0.1083\n",
      "Iteration 517: Loss = 9.2707, Accuracy = 0.2300 Test Loss = 60.9800, Test Accuracy = 0.1083\n",
      "Iteration 518: Loss = 9.2487, Accuracy = 0.2300 Test Loss = 60.9579, Test Accuracy = 0.1084\n",
      "Iteration 519: Loss = 9.2268, Accuracy = 0.2300 Test Loss = 60.9359, Test Accuracy = 0.1084\n",
      "Iteration 520: Loss = 9.2050, Accuracy = 0.2300 Test Loss = 60.9140, Test Accuracy = 0.1084\n",
      "Iteration 521: Loss = 9.1832, Accuracy = 0.2300 Test Loss = 60.8922, Test Accuracy = 0.1084\n",
      "Iteration 522: Loss = 9.1615, Accuracy = 0.2300 Test Loss = 60.8705, Test Accuracy = 0.1084\n",
      "Iteration 523: Loss = 9.1399, Accuracy = 0.2300 Test Loss = 60.8488, Test Accuracy = 0.1083\n",
      "Iteration 524: Loss = 9.1184, Accuracy = 0.2300 Test Loss = 60.8272, Test Accuracy = 0.1083\n",
      "Iteration 525: Loss = 9.0970, Accuracy = 0.2300 Test Loss = 60.8056, Test Accuracy = 0.1083\n",
      "Iteration 526: Loss = 9.0756, Accuracy = 0.2300 Test Loss = 60.7842, Test Accuracy = 0.1082\n",
      "Iteration 527: Loss = 9.0543, Accuracy = 0.2300 Test Loss = 60.7628, Test Accuracy = 0.1082\n",
      "Iteration 528: Loss = 9.0331, Accuracy = 0.2300 Test Loss = 60.7415, Test Accuracy = 0.1084\n",
      "Iteration 529: Loss = 9.0120, Accuracy = 0.2300 Test Loss = 60.7202, Test Accuracy = 0.1084\n",
      "Iteration 530: Loss = 8.9909, Accuracy = 0.2300 Test Loss = 60.6990, Test Accuracy = 0.1085\n",
      "Iteration 531: Loss = 8.9700, Accuracy = 0.2300 Test Loss = 60.6779, Test Accuracy = 0.1085\n",
      "Iteration 532: Loss = 8.9491, Accuracy = 0.2300 Test Loss = 60.6569, Test Accuracy = 0.1085\n",
      "Iteration 533: Loss = 8.9282, Accuracy = 0.2300 Test Loss = 60.6359, Test Accuracy = 0.1085\n",
      "Iteration 534: Loss = 8.9075, Accuracy = 0.2300 Test Loss = 60.6150, Test Accuracy = 0.1084\n",
      "Iteration 535: Loss = 8.8868, Accuracy = 0.2300 Test Loss = 60.5942, Test Accuracy = 0.1085\n",
      "Iteration 536: Loss = 8.8662, Accuracy = 0.2300 Test Loss = 60.5734, Test Accuracy = 0.1087\n",
      "Iteration 537: Loss = 8.8457, Accuracy = 0.2300 Test Loss = 60.5527, Test Accuracy = 0.1085\n",
      "Iteration 538: Loss = 8.8253, Accuracy = 0.2300 Test Loss = 60.5321, Test Accuracy = 0.1083\n",
      "Iteration 539: Loss = 8.8049, Accuracy = 0.2300 Test Loss = 60.5116, Test Accuracy = 0.1082\n",
      "Iteration 540: Loss = 8.7846, Accuracy = 0.2300 Test Loss = 60.4911, Test Accuracy = 0.1081\n",
      "Iteration 541: Loss = 8.7643, Accuracy = 0.2300 Test Loss = 60.4707, Test Accuracy = 0.1080\n",
      "Iteration 542: Loss = 8.7442, Accuracy = 0.2300 Test Loss = 60.4503, Test Accuracy = 0.1081\n",
      "Iteration 543: Loss = 8.7241, Accuracy = 0.2300 Test Loss = 60.4300, Test Accuracy = 0.1082\n",
      "Iteration 544: Loss = 8.7041, Accuracy = 0.2300 Test Loss = 60.4098, Test Accuracy = 0.1083\n",
      "Iteration 545: Loss = 8.6841, Accuracy = 0.2300 Test Loss = 60.3896, Test Accuracy = 0.1083\n",
      "Iteration 546: Loss = 8.6643, Accuracy = 0.2300 Test Loss = 60.3696, Test Accuracy = 0.1083\n",
      "Iteration 547: Loss = 8.6445, Accuracy = 0.2300 Test Loss = 60.3495, Test Accuracy = 0.1083\n",
      "Iteration 548: Loss = 8.6247, Accuracy = 0.2300 Test Loss = 60.3296, Test Accuracy = 0.1082\n",
      "Iteration 549: Loss = 8.6050, Accuracy = 0.2300 Test Loss = 60.3097, Test Accuracy = 0.1083\n",
      "Iteration 550: Loss = 8.5855, Accuracy = 0.2300 Test Loss = 60.2898, Test Accuracy = 0.1083\n",
      "Iteration 551: Loss = 8.5659, Accuracy = 0.2300 Test Loss = 60.2701, Test Accuracy = 0.1086\n",
      "Iteration 552: Loss = 8.5465, Accuracy = 0.2300 Test Loss = 60.2504, Test Accuracy = 0.1086\n",
      "Iteration 553: Loss = 8.5271, Accuracy = 0.2300 Test Loss = 60.2307, Test Accuracy = 0.1087\n",
      "Iteration 554: Loss = 8.5078, Accuracy = 0.2300 Test Loss = 60.2112, Test Accuracy = 0.1088\n",
      "Iteration 555: Loss = 8.4885, Accuracy = 0.2300 Test Loss = 60.1917, Test Accuracy = 0.1088\n",
      "Iteration 556: Loss = 8.4693, Accuracy = 0.2300 Test Loss = 60.1722, Test Accuracy = 0.1088\n",
      "Iteration 557: Loss = 8.4502, Accuracy = 0.2300 Test Loss = 60.1528, Test Accuracy = 0.1088\n",
      "Iteration 558: Loss = 8.4311, Accuracy = 0.2300 Test Loss = 60.1335, Test Accuracy = 0.1088\n",
      "Iteration 559: Loss = 8.4121, Accuracy = 0.2300 Test Loss = 60.1142, Test Accuracy = 0.1087\n",
      "Iteration 560: Loss = 8.3932, Accuracy = 0.2300 Test Loss = 60.0950, Test Accuracy = 0.1088\n",
      "Iteration 561: Loss = 8.3744, Accuracy = 0.2300 Test Loss = 60.0759, Test Accuracy = 0.1086\n",
      "Iteration 562: Loss = 8.3556, Accuracy = 0.2300 Test Loss = 60.0568, Test Accuracy = 0.1084\n",
      "Iteration 563: Loss = 8.3368, Accuracy = 0.2300 Test Loss = 60.0378, Test Accuracy = 0.1082\n",
      "Iteration 564: Loss = 8.3182, Accuracy = 0.2400 Test Loss = 60.0188, Test Accuracy = 0.1082\n",
      "Iteration 565: Loss = 8.2996, Accuracy = 0.2400 Test Loss = 59.9999, Test Accuracy = 0.1082\n",
      "Iteration 566: Loss = 8.2810, Accuracy = 0.2400 Test Loss = 59.9811, Test Accuracy = 0.1082\n",
      "Iteration 567: Loss = 8.2626, Accuracy = 0.2400 Test Loss = 59.9623, Test Accuracy = 0.1080\n",
      "Iteration 568: Loss = 8.2442, Accuracy = 0.2400 Test Loss = 59.9436, Test Accuracy = 0.1080\n",
      "Iteration 569: Loss = 8.2258, Accuracy = 0.2400 Test Loss = 59.9249, Test Accuracy = 0.1079\n",
      "Iteration 570: Loss = 8.2075, Accuracy = 0.2400 Test Loss = 59.9063, Test Accuracy = 0.1079\n",
      "Iteration 571: Loss = 8.1893, Accuracy = 0.2400 Test Loss = 59.8878, Test Accuracy = 0.1078\n",
      "Iteration 572: Loss = 8.1712, Accuracy = 0.2400 Test Loss = 59.8693, Test Accuracy = 0.1078\n",
      "Iteration 573: Loss = 8.1531, Accuracy = 0.2400 Test Loss = 59.8509, Test Accuracy = 0.1078\n",
      "Iteration 574: Loss = 8.1350, Accuracy = 0.2400 Test Loss = 59.8325, Test Accuracy = 0.1078\n",
      "Iteration 575: Loss = 8.1170, Accuracy = 0.2400 Test Loss = 59.8142, Test Accuracy = 0.1078\n",
      "Iteration 576: Loss = 8.0991, Accuracy = 0.2400 Test Loss = 59.7960, Test Accuracy = 0.1076\n",
      "Iteration 577: Loss = 8.0813, Accuracy = 0.2400 Test Loss = 59.7778, Test Accuracy = 0.1076\n",
      "Iteration 578: Loss = 8.0635, Accuracy = 0.2400 Test Loss = 59.7597, Test Accuracy = 0.1076\n",
      "Iteration 579: Loss = 8.0458, Accuracy = 0.2400 Test Loss = 59.7416, Test Accuracy = 0.1077\n",
      "Iteration 580: Loss = 8.0281, Accuracy = 0.2400 Test Loss = 59.7235, Test Accuracy = 0.1078\n",
      "Iteration 581: Loss = 8.0105, Accuracy = 0.2400 Test Loss = 59.7056, Test Accuracy = 0.1079\n",
      "Iteration 582: Loss = 7.9929, Accuracy = 0.2400 Test Loss = 59.6876, Test Accuracy = 0.1080\n",
      "Iteration 583: Loss = 7.9754, Accuracy = 0.2400 Test Loss = 59.6698, Test Accuracy = 0.1081\n",
      "Iteration 584: Loss = 7.9580, Accuracy = 0.2400 Test Loss = 59.6520, Test Accuracy = 0.1081\n",
      "Iteration 585: Loss = 7.9406, Accuracy = 0.2400 Test Loss = 59.6342, Test Accuracy = 0.1082\n",
      "Iteration 586: Loss = 7.9233, Accuracy = 0.2400 Test Loss = 59.6166, Test Accuracy = 0.1082\n",
      "Iteration 587: Loss = 7.9060, Accuracy = 0.2400 Test Loss = 59.5989, Test Accuracy = 0.1082\n",
      "Iteration 588: Loss = 7.8888, Accuracy = 0.2400 Test Loss = 59.5813, Test Accuracy = 0.1081\n",
      "Iteration 589: Loss = 7.8716, Accuracy = 0.2400 Test Loss = 59.5638, Test Accuracy = 0.1081\n",
      "Iteration 590: Loss = 7.8545, Accuracy = 0.2400 Test Loss = 59.5463, Test Accuracy = 0.1081\n",
      "Iteration 591: Loss = 7.8375, Accuracy = 0.2400 Test Loss = 59.5289, Test Accuracy = 0.1081\n",
      "Iteration 592: Loss = 7.8205, Accuracy = 0.2400 Test Loss = 59.5115, Test Accuracy = 0.1081\n",
      "Iteration 593: Loss = 7.8036, Accuracy = 0.2400 Test Loss = 59.4942, Test Accuracy = 0.1083\n",
      "Iteration 594: Loss = 7.7867, Accuracy = 0.2400 Test Loss = 59.4770, Test Accuracy = 0.1084\n",
      "Iteration 595: Loss = 7.7699, Accuracy = 0.2400 Test Loss = 59.4598, Test Accuracy = 0.1084\n",
      "Iteration 596: Loss = 7.7532, Accuracy = 0.2400 Test Loss = 59.4426, Test Accuracy = 0.1084\n",
      "Iteration 597: Loss = 7.7365, Accuracy = 0.2400 Test Loss = 59.4255, Test Accuracy = 0.1085\n",
      "Iteration 598: Loss = 7.7198, Accuracy = 0.2400 Test Loss = 59.4084, Test Accuracy = 0.1086\n",
      "Iteration 599: Loss = 7.7032, Accuracy = 0.2400 Test Loss = 59.3914, Test Accuracy = 0.1085\n",
      "Iteration 600: Loss = 7.6867, Accuracy = 0.2400 Test Loss = 59.3745, Test Accuracy = 0.1085\n",
      "Iteration 601: Loss = 7.6702, Accuracy = 0.2400 Test Loss = 59.3576, Test Accuracy = 0.1085\n",
      "Iteration 602: Loss = 7.6538, Accuracy = 0.2400 Test Loss = 59.3407, Test Accuracy = 0.1086\n",
      "Iteration 603: Loss = 7.6374, Accuracy = 0.2400 Test Loss = 59.3239, Test Accuracy = 0.1085\n",
      "Iteration 604: Loss = 7.6210, Accuracy = 0.2500 Test Loss = 59.3072, Test Accuracy = 0.1085\n",
      "Iteration 605: Loss = 7.6048, Accuracy = 0.2500 Test Loss = 59.2905, Test Accuracy = 0.1085\n",
      "Iteration 606: Loss = 7.5885, Accuracy = 0.2500 Test Loss = 59.2739, Test Accuracy = 0.1085\n",
      "Iteration 607: Loss = 7.5724, Accuracy = 0.2500 Test Loss = 59.2573, Test Accuracy = 0.1087\n",
      "Iteration 608: Loss = 7.5563, Accuracy = 0.2500 Test Loss = 59.2407, Test Accuracy = 0.1088\n",
      "Iteration 609: Loss = 7.5402, Accuracy = 0.2500 Test Loss = 59.2242, Test Accuracy = 0.1088\n",
      "Iteration 610: Loss = 7.5242, Accuracy = 0.2500 Test Loss = 59.2078, Test Accuracy = 0.1088\n",
      "Iteration 611: Loss = 7.5082, Accuracy = 0.2500 Test Loss = 59.1914, Test Accuracy = 0.1087\n",
      "Iteration 612: Loss = 7.4923, Accuracy = 0.2600 Test Loss = 59.1750, Test Accuracy = 0.1089\n",
      "Iteration 613: Loss = 7.4765, Accuracy = 0.2600 Test Loss = 59.1587, Test Accuracy = 0.1088\n",
      "Iteration 614: Loss = 7.4606, Accuracy = 0.2600 Test Loss = 59.1425, Test Accuracy = 0.1088\n",
      "Iteration 615: Loss = 7.4449, Accuracy = 0.2600 Test Loss = 59.1263, Test Accuracy = 0.1089\n",
      "Iteration 616: Loss = 7.4292, Accuracy = 0.2600 Test Loss = 59.1101, Test Accuracy = 0.1089\n",
      "Iteration 617: Loss = 7.4135, Accuracy = 0.2600 Test Loss = 59.0940, Test Accuracy = 0.1089\n",
      "Iteration 618: Loss = 7.3979, Accuracy = 0.2600 Test Loss = 59.0780, Test Accuracy = 0.1089\n",
      "Iteration 619: Loss = 7.3823, Accuracy = 0.2600 Test Loss = 59.0620, Test Accuracy = 0.1089\n",
      "Iteration 620: Loss = 7.3668, Accuracy = 0.2600 Test Loss = 59.0460, Test Accuracy = 0.1089\n",
      "Iteration 621: Loss = 7.3514, Accuracy = 0.2600 Test Loss = 59.0301, Test Accuracy = 0.1089\n",
      "Iteration 622: Loss = 7.3360, Accuracy = 0.2600 Test Loss = 59.0142, Test Accuracy = 0.1090\n",
      "Iteration 623: Loss = 7.3206, Accuracy = 0.2600 Test Loss = 58.9984, Test Accuracy = 0.1090\n",
      "Iteration 624: Loss = 7.3053, Accuracy = 0.2600 Test Loss = 58.9826, Test Accuracy = 0.1090\n",
      "Iteration 625: Loss = 7.2900, Accuracy = 0.2600 Test Loss = 58.9669, Test Accuracy = 0.1090\n",
      "Iteration 626: Loss = 7.2748, Accuracy = 0.2600 Test Loss = 58.9512, Test Accuracy = 0.1090\n",
      "Iteration 627: Loss = 7.2596, Accuracy = 0.2600 Test Loss = 58.9356, Test Accuracy = 0.1090\n",
      "Iteration 628: Loss = 7.2445, Accuracy = 0.2600 Test Loss = 58.9200, Test Accuracy = 0.1091\n",
      "Iteration 629: Loss = 7.2294, Accuracy = 0.2600 Test Loss = 58.9045, Test Accuracy = 0.1090\n",
      "Iteration 630: Loss = 7.2144, Accuracy = 0.2600 Test Loss = 58.8890, Test Accuracy = 0.1090\n",
      "Iteration 631: Loss = 7.1994, Accuracy = 0.2700 Test Loss = 58.8735, Test Accuracy = 0.1090\n",
      "Iteration 632: Loss = 7.1845, Accuracy = 0.2700 Test Loss = 58.8581, Test Accuracy = 0.1090\n",
      "Iteration 633: Loss = 7.1696, Accuracy = 0.2700 Test Loss = 58.8427, Test Accuracy = 0.1090\n",
      "Iteration 634: Loss = 7.1548, Accuracy = 0.2700 Test Loss = 58.8274, Test Accuracy = 0.1092\n",
      "Iteration 635: Loss = 7.1400, Accuracy = 0.2700 Test Loss = 58.8121, Test Accuracy = 0.1091\n",
      "Iteration 636: Loss = 7.1252, Accuracy = 0.2600 Test Loss = 58.7969, Test Accuracy = 0.1091\n",
      "Iteration 637: Loss = 7.1105, Accuracy = 0.2600 Test Loss = 58.7817, Test Accuracy = 0.1092\n",
      "Iteration 638: Loss = 7.0959, Accuracy = 0.2600 Test Loss = 58.7666, Test Accuracy = 0.1092\n",
      "Iteration 639: Loss = 7.0812, Accuracy = 0.2600 Test Loss = 58.7515, Test Accuracy = 0.1092\n",
      "Iteration 640: Loss = 7.0667, Accuracy = 0.2600 Test Loss = 58.7365, Test Accuracy = 0.1093\n",
      "Iteration 641: Loss = 7.0522, Accuracy = 0.2600 Test Loss = 58.7214, Test Accuracy = 0.1092\n",
      "Iteration 642: Loss = 7.0377, Accuracy = 0.2600 Test Loss = 58.7065, Test Accuracy = 0.1092\n",
      "Iteration 643: Loss = 7.0232, Accuracy = 0.2600 Test Loss = 58.6916, Test Accuracy = 0.1091\n",
      "Iteration 644: Loss = 7.0089, Accuracy = 0.2600 Test Loss = 58.6767, Test Accuracy = 0.1090\n",
      "Iteration 645: Loss = 6.9945, Accuracy = 0.2600 Test Loss = 58.6618, Test Accuracy = 0.1090\n",
      "Iteration 646: Loss = 6.9802, Accuracy = 0.2600 Test Loss = 58.6470, Test Accuracy = 0.1089\n",
      "Iteration 647: Loss = 6.9660, Accuracy = 0.2600 Test Loss = 58.6323, Test Accuracy = 0.1089\n",
      "Iteration 648: Loss = 6.9517, Accuracy = 0.2600 Test Loss = 58.6176, Test Accuracy = 0.1089\n",
      "Iteration 649: Loss = 6.9376, Accuracy = 0.2600 Test Loss = 58.6029, Test Accuracy = 0.1089\n",
      "Iteration 650: Loss = 6.9234, Accuracy = 0.2600 Test Loss = 58.5883, Test Accuracy = 0.1089\n",
      "Iteration 651: Loss = 6.9094, Accuracy = 0.2600 Test Loss = 58.5737, Test Accuracy = 0.1089\n",
      "Iteration 652: Loss = 6.8953, Accuracy = 0.2600 Test Loss = 58.5592, Test Accuracy = 0.1089\n",
      "Iteration 653: Loss = 6.8813, Accuracy = 0.2600 Test Loss = 58.5447, Test Accuracy = 0.1089\n",
      "Iteration 654: Loss = 6.8674, Accuracy = 0.2600 Test Loss = 58.5302, Test Accuracy = 0.1088\n",
      "Iteration 655: Loss = 6.8534, Accuracy = 0.2600 Test Loss = 58.5158, Test Accuracy = 0.1089\n",
      "Iteration 656: Loss = 6.8396, Accuracy = 0.2600 Test Loss = 58.5014, Test Accuracy = 0.1090\n",
      "Iteration 657: Loss = 6.8257, Accuracy = 0.2600 Test Loss = 58.4871, Test Accuracy = 0.1091\n",
      "Iteration 658: Loss = 6.8120, Accuracy = 0.2600 Test Loss = 58.4728, Test Accuracy = 0.1091\n",
      "Iteration 659: Loss = 6.7982, Accuracy = 0.2600 Test Loss = 58.4585, Test Accuracy = 0.1091\n",
      "Iteration 660: Loss = 6.7845, Accuracy = 0.2600 Test Loss = 58.4443, Test Accuracy = 0.1091\n",
      "Iteration 661: Loss = 6.7708, Accuracy = 0.2600 Test Loss = 58.4301, Test Accuracy = 0.1092\n",
      "Iteration 662: Loss = 6.7572, Accuracy = 0.2600 Test Loss = 58.4160, Test Accuracy = 0.1094\n",
      "Iteration 663: Loss = 6.7436, Accuracy = 0.2600 Test Loss = 58.4019, Test Accuracy = 0.1096\n",
      "Iteration 664: Loss = 6.7301, Accuracy = 0.2600 Test Loss = 58.3879, Test Accuracy = 0.1096\n",
      "Iteration 665: Loss = 6.7166, Accuracy = 0.2600 Test Loss = 58.3738, Test Accuracy = 0.1096\n",
      "Iteration 666: Loss = 6.7031, Accuracy = 0.2600 Test Loss = 58.3599, Test Accuracy = 0.1095\n",
      "Iteration 667: Loss = 6.6897, Accuracy = 0.2600 Test Loss = 58.3459, Test Accuracy = 0.1097\n",
      "Iteration 668: Loss = 6.6763, Accuracy = 0.2600 Test Loss = 58.3320, Test Accuracy = 0.1098\n",
      "Iteration 669: Loss = 6.6630, Accuracy = 0.2600 Test Loss = 58.3182, Test Accuracy = 0.1098\n",
      "Iteration 670: Loss = 6.6497, Accuracy = 0.2600 Test Loss = 58.3044, Test Accuracy = 0.1098\n",
      "Iteration 671: Loss = 6.6364, Accuracy = 0.2600 Test Loss = 58.2906, Test Accuracy = 0.1098\n",
      "Iteration 672: Loss = 6.6232, Accuracy = 0.2600 Test Loss = 58.2768, Test Accuracy = 0.1099\n",
      "Iteration 673: Loss = 6.6100, Accuracy = 0.2600 Test Loss = 58.2631, Test Accuracy = 0.1100\n",
      "Iteration 674: Loss = 6.5969, Accuracy = 0.2600 Test Loss = 58.2495, Test Accuracy = 0.1100\n",
      "Iteration 675: Loss = 6.5838, Accuracy = 0.2600 Test Loss = 58.2359, Test Accuracy = 0.1100\n",
      "Iteration 676: Loss = 6.5707, Accuracy = 0.2600 Test Loss = 58.2223, Test Accuracy = 0.1098\n",
      "Iteration 677: Loss = 6.5577, Accuracy = 0.2600 Test Loss = 58.2087, Test Accuracy = 0.1098\n",
      "Iteration 678: Loss = 6.5447, Accuracy = 0.2600 Test Loss = 58.1952, Test Accuracy = 0.1098\n",
      "Iteration 679: Loss = 6.5317, Accuracy = 0.2600 Test Loss = 58.1817, Test Accuracy = 0.1098\n",
      "Iteration 680: Loss = 6.5188, Accuracy = 0.2600 Test Loss = 58.1683, Test Accuracy = 0.1099\n",
      "Iteration 681: Loss = 6.5059, Accuracy = 0.2600 Test Loss = 58.1549, Test Accuracy = 0.1099\n",
      "Iteration 682: Loss = 6.4931, Accuracy = 0.2600 Test Loss = 58.1415, Test Accuracy = 0.1099\n",
      "Iteration 683: Loss = 6.4803, Accuracy = 0.2600 Test Loss = 58.1282, Test Accuracy = 0.1099\n",
      "Iteration 684: Loss = 6.4675, Accuracy = 0.2600 Test Loss = 58.1149, Test Accuracy = 0.1099\n",
      "Iteration 685: Loss = 6.4548, Accuracy = 0.2600 Test Loss = 58.1016, Test Accuracy = 0.1099\n",
      "Iteration 686: Loss = 6.4421, Accuracy = 0.2600 Test Loss = 58.0884, Test Accuracy = 0.1100\n",
      "Iteration 687: Loss = 6.4294, Accuracy = 0.2600 Test Loss = 58.0752, Test Accuracy = 0.1101\n",
      "Iteration 688: Loss = 6.4168, Accuracy = 0.2600 Test Loss = 58.0621, Test Accuracy = 0.1101\n",
      "Iteration 689: Loss = 6.4043, Accuracy = 0.2600 Test Loss = 58.0490, Test Accuracy = 0.1102\n",
      "Iteration 690: Loss = 6.3917, Accuracy = 0.2600 Test Loss = 58.0359, Test Accuracy = 0.1102\n",
      "Iteration 691: Loss = 6.3792, Accuracy = 0.2600 Test Loss = 58.0229, Test Accuracy = 0.1103\n",
      "Iteration 692: Loss = 6.3667, Accuracy = 0.2600 Test Loss = 58.0099, Test Accuracy = 0.1103\n",
      "Iteration 693: Loss = 6.3543, Accuracy = 0.2600 Test Loss = 57.9969, Test Accuracy = 0.1104\n",
      "Iteration 694: Loss = 6.3419, Accuracy = 0.2600 Test Loss = 57.9840, Test Accuracy = 0.1104\n",
      "Iteration 695: Loss = 6.3295, Accuracy = 0.2600 Test Loss = 57.9711, Test Accuracy = 0.1105\n",
      "Iteration 696: Loss = 6.3172, Accuracy = 0.2600 Test Loss = 57.9582, Test Accuracy = 0.1105\n",
      "Iteration 697: Loss = 6.3049, Accuracy = 0.2700 Test Loss = 57.9454, Test Accuracy = 0.1105\n",
      "Iteration 698: Loss = 6.2927, Accuracy = 0.2700 Test Loss = 57.9326, Test Accuracy = 0.1106\n",
      "Iteration 699: Loss = 6.2804, Accuracy = 0.2700 Test Loss = 57.9199, Test Accuracy = 0.1106\n",
      "Iteration 700: Loss = 6.2683, Accuracy = 0.2700 Test Loss = 57.9071, Test Accuracy = 0.1106\n",
      "Iteration 701: Loss = 6.2561, Accuracy = 0.2700 Test Loss = 57.8945, Test Accuracy = 0.1107\n",
      "Iteration 702: Loss = 6.2440, Accuracy = 0.2700 Test Loss = 57.8818, Test Accuracy = 0.1108\n",
      "Iteration 703: Loss = 6.2319, Accuracy = 0.2700 Test Loss = 57.8692, Test Accuracy = 0.1108\n",
      "Iteration 704: Loss = 6.2199, Accuracy = 0.2700 Test Loss = 57.8566, Test Accuracy = 0.1109\n",
      "Iteration 705: Loss = 6.2078, Accuracy = 0.2700 Test Loss = 57.8441, Test Accuracy = 0.1108\n",
      "Iteration 706: Loss = 6.1959, Accuracy = 0.2700 Test Loss = 57.8315, Test Accuracy = 0.1108\n",
      "Iteration 707: Loss = 6.1839, Accuracy = 0.2700 Test Loss = 57.8190, Test Accuracy = 0.1110\n",
      "Iteration 708: Loss = 6.1720, Accuracy = 0.2800 Test Loss = 57.8066, Test Accuracy = 0.1110\n",
      "Iteration 709: Loss = 6.1601, Accuracy = 0.2800 Test Loss = 57.7942, Test Accuracy = 0.1111\n",
      "Iteration 710: Loss = 6.1483, Accuracy = 0.2800 Test Loss = 57.7818, Test Accuracy = 0.1113\n",
      "Iteration 711: Loss = 6.1365, Accuracy = 0.2800 Test Loss = 57.7695, Test Accuracy = 0.1114\n",
      "Iteration 712: Loss = 6.1247, Accuracy = 0.2800 Test Loss = 57.7571, Test Accuracy = 0.1114\n",
      "Iteration 713: Loss = 6.1129, Accuracy = 0.2800 Test Loss = 57.7449, Test Accuracy = 0.1115\n",
      "Iteration 714: Loss = 6.1012, Accuracy = 0.2800 Test Loss = 57.7326, Test Accuracy = 0.1116\n",
      "Iteration 715: Loss = 6.0896, Accuracy = 0.2800 Test Loss = 57.7204, Test Accuracy = 0.1117\n",
      "Iteration 716: Loss = 6.0779, Accuracy = 0.2800 Test Loss = 57.7082, Test Accuracy = 0.1117\n",
      "Iteration 717: Loss = 6.0663, Accuracy = 0.2800 Test Loss = 57.6961, Test Accuracy = 0.1118\n",
      "Iteration 718: Loss = 6.0547, Accuracy = 0.2900 Test Loss = 57.6839, Test Accuracy = 0.1118\n",
      "Iteration 719: Loss = 6.0432, Accuracy = 0.2900 Test Loss = 57.6719, Test Accuracy = 0.1119\n",
      "Iteration 720: Loss = 6.0317, Accuracy = 0.2900 Test Loss = 57.6598, Test Accuracy = 0.1117\n",
      "Iteration 721: Loss = 6.0202, Accuracy = 0.2900 Test Loss = 57.6478, Test Accuracy = 0.1116\n",
      "Iteration 722: Loss = 6.0087, Accuracy = 0.2900 Test Loss = 57.6358, Test Accuracy = 0.1116\n",
      "Iteration 723: Loss = 5.9973, Accuracy = 0.2900 Test Loss = 57.6238, Test Accuracy = 0.1116\n",
      "Iteration 724: Loss = 5.9859, Accuracy = 0.2900 Test Loss = 57.6119, Test Accuracy = 0.1117\n",
      "Iteration 725: Loss = 5.9746, Accuracy = 0.2900 Test Loss = 57.6000, Test Accuracy = 0.1117\n",
      "Iteration 726: Loss = 5.9632, Accuracy = 0.2900 Test Loss = 57.5881, Test Accuracy = 0.1117\n",
      "Iteration 727: Loss = 5.9519, Accuracy = 0.2900 Test Loss = 57.5763, Test Accuracy = 0.1117\n",
      "Iteration 728: Loss = 5.9407, Accuracy = 0.2900 Test Loss = 57.5645, Test Accuracy = 0.1118\n",
      "Iteration 729: Loss = 5.9294, Accuracy = 0.2900 Test Loss = 57.5527, Test Accuracy = 0.1117\n",
      "Iteration 730: Loss = 5.9182, Accuracy = 0.2900 Test Loss = 57.5410, Test Accuracy = 0.1117\n",
      "Iteration 731: Loss = 5.9071, Accuracy = 0.2900 Test Loss = 57.5293, Test Accuracy = 0.1117\n",
      "Iteration 732: Loss = 5.8959, Accuracy = 0.2900 Test Loss = 57.5176, Test Accuracy = 0.1117\n",
      "Iteration 733: Loss = 5.8848, Accuracy = 0.2900 Test Loss = 57.5060, Test Accuracy = 0.1117\n",
      "Iteration 734: Loss = 5.8738, Accuracy = 0.2900 Test Loss = 57.4944, Test Accuracy = 0.1117\n",
      "Iteration 735: Loss = 5.8627, Accuracy = 0.2900 Test Loss = 57.4828, Test Accuracy = 0.1117\n",
      "Iteration 736: Loss = 5.8517, Accuracy = 0.2900 Test Loss = 57.4712, Test Accuracy = 0.1116\n",
      "Iteration 737: Loss = 5.8407, Accuracy = 0.2900 Test Loss = 57.4597, Test Accuracy = 0.1116\n",
      "Iteration 738: Loss = 5.8298, Accuracy = 0.2900 Test Loss = 57.4482, Test Accuracy = 0.1117\n",
      "Iteration 739: Loss = 5.8188, Accuracy = 0.2900 Test Loss = 57.4367, Test Accuracy = 0.1117\n",
      "Iteration 740: Loss = 5.8079, Accuracy = 0.3000 Test Loss = 57.4253, Test Accuracy = 0.1118\n",
      "Iteration 741: Loss = 5.7971, Accuracy = 0.3000 Test Loss = 57.4139, Test Accuracy = 0.1118\n",
      "Iteration 742: Loss = 5.7862, Accuracy = 0.3000 Test Loss = 57.4025, Test Accuracy = 0.1118\n",
      "Iteration 743: Loss = 5.7754, Accuracy = 0.3000 Test Loss = 57.3912, Test Accuracy = 0.1118\n",
      "Iteration 744: Loss = 5.7647, Accuracy = 0.3000 Test Loss = 57.3798, Test Accuracy = 0.1118\n",
      "Iteration 745: Loss = 5.7539, Accuracy = 0.3000 Test Loss = 57.3686, Test Accuracy = 0.1118\n",
      "Iteration 746: Loss = 5.7432, Accuracy = 0.3000 Test Loss = 57.3573, Test Accuracy = 0.1118\n",
      "Iteration 747: Loss = 5.7325, Accuracy = 0.3000 Test Loss = 57.3461, Test Accuracy = 0.1119\n",
      "Iteration 748: Loss = 5.7218, Accuracy = 0.3000 Test Loss = 57.3349, Test Accuracy = 0.1119\n",
      "Iteration 749: Loss = 5.7112, Accuracy = 0.3000 Test Loss = 57.3237, Test Accuracy = 0.1117\n",
      "Iteration 750: Loss = 5.7006, Accuracy = 0.3000 Test Loss = 57.3126, Test Accuracy = 0.1117\n",
      "Iteration 751: Loss = 5.6900, Accuracy = 0.3100 Test Loss = 57.3014, Test Accuracy = 0.1117\n",
      "Iteration 752: Loss = 5.6795, Accuracy = 0.3100 Test Loss = 57.2904, Test Accuracy = 0.1117\n",
      "Iteration 753: Loss = 5.6690, Accuracy = 0.3100 Test Loss = 57.2793, Test Accuracy = 0.1118\n",
      "Iteration 754: Loss = 5.6585, Accuracy = 0.3100 Test Loss = 57.2683, Test Accuracy = 0.1118\n",
      "Iteration 755: Loss = 5.6480, Accuracy = 0.3100 Test Loss = 57.2573, Test Accuracy = 0.1117\n",
      "Iteration 756: Loss = 5.6376, Accuracy = 0.3100 Test Loss = 57.2463, Test Accuracy = 0.1117\n",
      "Iteration 757: Loss = 5.6272, Accuracy = 0.3100 Test Loss = 57.2354, Test Accuracy = 0.1117\n",
      "Iteration 758: Loss = 5.6168, Accuracy = 0.3100 Test Loss = 57.2245, Test Accuracy = 0.1117\n",
      "Iteration 759: Loss = 5.6065, Accuracy = 0.3100 Test Loss = 57.2136, Test Accuracy = 0.1117\n",
      "Iteration 760: Loss = 5.5961, Accuracy = 0.3100 Test Loss = 57.2027, Test Accuracy = 0.1117\n",
      "Iteration 761: Loss = 5.5858, Accuracy = 0.3100 Test Loss = 57.1919, Test Accuracy = 0.1116\n",
      "Iteration 762: Loss = 5.5756, Accuracy = 0.3100 Test Loss = 57.1811, Test Accuracy = 0.1115\n",
      "Iteration 763: Loss = 5.5653, Accuracy = 0.3100 Test Loss = 57.1703, Test Accuracy = 0.1113\n",
      "Iteration 764: Loss = 5.5551, Accuracy = 0.3100 Test Loss = 57.1596, Test Accuracy = 0.1113\n",
      "Iteration 765: Loss = 5.5449, Accuracy = 0.3100 Test Loss = 57.1488, Test Accuracy = 0.1113\n",
      "Iteration 766: Loss = 5.5348, Accuracy = 0.3100 Test Loss = 57.1381, Test Accuracy = 0.1113\n",
      "Iteration 767: Loss = 5.5247, Accuracy = 0.3100 Test Loss = 57.1275, Test Accuracy = 0.1113\n",
      "Iteration 768: Loss = 5.5146, Accuracy = 0.3100 Test Loss = 57.1168, Test Accuracy = 0.1113\n",
      "Iteration 769: Loss = 5.5045, Accuracy = 0.3100 Test Loss = 57.1062, Test Accuracy = 0.1114\n",
      "Iteration 770: Loss = 5.4944, Accuracy = 0.3100 Test Loss = 57.0956, Test Accuracy = 0.1115\n",
      "Iteration 771: Loss = 5.4844, Accuracy = 0.3100 Test Loss = 57.0851, Test Accuracy = 0.1116\n",
      "Iteration 772: Loss = 5.4744, Accuracy = 0.3100 Test Loss = 57.0746, Test Accuracy = 0.1116\n",
      "Iteration 773: Loss = 5.4644, Accuracy = 0.3000 Test Loss = 57.0640, Test Accuracy = 0.1115\n",
      "Iteration 774: Loss = 5.4545, Accuracy = 0.3000 Test Loss = 57.0536, Test Accuracy = 0.1115\n",
      "Iteration 775: Loss = 5.4446, Accuracy = 0.3000 Test Loss = 57.0431, Test Accuracy = 0.1115\n",
      "Iteration 776: Loss = 5.4347, Accuracy = 0.3100 Test Loss = 57.0327, Test Accuracy = 0.1115\n",
      "Iteration 777: Loss = 5.4248, Accuracy = 0.3100 Test Loss = 57.0223, Test Accuracy = 0.1116\n",
      "Iteration 778: Loss = 5.4150, Accuracy = 0.3100 Test Loss = 57.0119, Test Accuracy = 0.1116\n",
      "Iteration 779: Loss = 5.4052, Accuracy = 0.3100 Test Loss = 57.0016, Test Accuracy = 0.1117\n",
      "Iteration 780: Loss = 5.3954, Accuracy = 0.3100 Test Loss = 56.9912, Test Accuracy = 0.1116\n",
      "Iteration 781: Loss = 5.3856, Accuracy = 0.3100 Test Loss = 56.9810, Test Accuracy = 0.1115\n",
      "Iteration 782: Loss = 5.3759, Accuracy = 0.3100 Test Loss = 56.9707, Test Accuracy = 0.1114\n",
      "Iteration 783: Loss = 5.3662, Accuracy = 0.3100 Test Loss = 56.9604, Test Accuracy = 0.1114\n",
      "Iteration 784: Loss = 5.3565, Accuracy = 0.3100 Test Loss = 56.9502, Test Accuracy = 0.1114\n",
      "Iteration 785: Loss = 5.3468, Accuracy = 0.3100 Test Loss = 56.9400, Test Accuracy = 0.1117\n",
      "Iteration 786: Loss = 5.3372, Accuracy = 0.3100 Test Loss = 56.9299, Test Accuracy = 0.1118\n",
      "Iteration 787: Loss = 5.3276, Accuracy = 0.3100 Test Loss = 56.9197, Test Accuracy = 0.1118\n",
      "Iteration 788: Loss = 5.3180, Accuracy = 0.3100 Test Loss = 56.9096, Test Accuracy = 0.1117\n",
      "Iteration 789: Loss = 5.3084, Accuracy = 0.3100 Test Loss = 56.8995, Test Accuracy = 0.1117\n",
      "Iteration 790: Loss = 5.2989, Accuracy = 0.3100 Test Loss = 56.8895, Test Accuracy = 0.1119\n",
      "Iteration 791: Loss = 5.2894, Accuracy = 0.3200 Test Loss = 56.8794, Test Accuracy = 0.1120\n",
      "Iteration 792: Loss = 5.2799, Accuracy = 0.3200 Test Loss = 56.8694, Test Accuracy = 0.1121\n",
      "Iteration 793: Loss = 5.2704, Accuracy = 0.3200 Test Loss = 56.8594, Test Accuracy = 0.1120\n",
      "Iteration 794: Loss = 5.2610, Accuracy = 0.3200 Test Loss = 56.8494, Test Accuracy = 0.1120\n",
      "Iteration 795: Loss = 5.2516, Accuracy = 0.3200 Test Loss = 56.8395, Test Accuracy = 0.1120\n",
      "Iteration 796: Loss = 5.2422, Accuracy = 0.3200 Test Loss = 56.8296, Test Accuracy = 0.1120\n",
      "Iteration 797: Loss = 5.2328, Accuracy = 0.3200 Test Loss = 56.8197, Test Accuracy = 0.1120\n",
      "Iteration 798: Loss = 5.2235, Accuracy = 0.3300 Test Loss = 56.8098, Test Accuracy = 0.1120\n",
      "Iteration 799: Loss = 5.2142, Accuracy = 0.3300 Test Loss = 56.8000, Test Accuracy = 0.1120\n",
      "Iteration 800: Loss = 5.2049, Accuracy = 0.3300 Test Loss = 56.7902, Test Accuracy = 0.1121\n",
      "Iteration 801: Loss = 5.1956, Accuracy = 0.3300 Test Loss = 56.7804, Test Accuracy = 0.1120\n",
      "Iteration 802: Loss = 5.1864, Accuracy = 0.3300 Test Loss = 56.7706, Test Accuracy = 0.1120\n",
      "Iteration 803: Loss = 5.1771, Accuracy = 0.3300 Test Loss = 56.7609, Test Accuracy = 0.1120\n",
      "Iteration 804: Loss = 5.1679, Accuracy = 0.3300 Test Loss = 56.7511, Test Accuracy = 0.1120\n",
      "Iteration 805: Loss = 5.1588, Accuracy = 0.3300 Test Loss = 56.7414, Test Accuracy = 0.1120\n",
      "Iteration 806: Loss = 5.1496, Accuracy = 0.3300 Test Loss = 56.7318, Test Accuracy = 0.1120\n",
      "Iteration 807: Loss = 5.1405, Accuracy = 0.3300 Test Loss = 56.7221, Test Accuracy = 0.1119\n",
      "Iteration 808: Loss = 5.1314, Accuracy = 0.3300 Test Loss = 56.7125, Test Accuracy = 0.1121\n",
      "Iteration 809: Loss = 5.1223, Accuracy = 0.3300 Test Loss = 56.7029, Test Accuracy = 0.1121\n",
      "Iteration 810: Loss = 5.1132, Accuracy = 0.3300 Test Loss = 56.6933, Test Accuracy = 0.1121\n",
      "Iteration 811: Loss = 5.1042, Accuracy = 0.3300 Test Loss = 56.6838, Test Accuracy = 0.1123\n",
      "Iteration 812: Loss = 5.0952, Accuracy = 0.3300 Test Loss = 56.6742, Test Accuracy = 0.1123\n",
      "Iteration 813: Loss = 5.0862, Accuracy = 0.3300 Test Loss = 56.6647, Test Accuracy = 0.1123\n",
      "Iteration 814: Loss = 5.0772, Accuracy = 0.3300 Test Loss = 56.6552, Test Accuracy = 0.1122\n",
      "Iteration 815: Loss = 5.0683, Accuracy = 0.3300 Test Loss = 56.6458, Test Accuracy = 0.1122\n",
      "Iteration 816: Loss = 5.0594, Accuracy = 0.3300 Test Loss = 56.6363, Test Accuracy = 0.1121\n",
      "Iteration 817: Loss = 5.0505, Accuracy = 0.3300 Test Loss = 56.6269, Test Accuracy = 0.1121\n",
      "Iteration 818: Loss = 5.0416, Accuracy = 0.3300 Test Loss = 56.6175, Test Accuracy = 0.1121\n",
      "Iteration 819: Loss = 5.0327, Accuracy = 0.3300 Test Loss = 56.6081, Test Accuracy = 0.1121\n",
      "Iteration 820: Loss = 5.0239, Accuracy = 0.3300 Test Loss = 56.5988, Test Accuracy = 0.1121\n",
      "Iteration 821: Loss = 5.0151, Accuracy = 0.3300 Test Loss = 56.5895, Test Accuracy = 0.1121\n",
      "Iteration 822: Loss = 5.0063, Accuracy = 0.3300 Test Loss = 56.5802, Test Accuracy = 0.1118\n",
      "Iteration 823: Loss = 4.9976, Accuracy = 0.3300 Test Loss = 56.5709, Test Accuracy = 0.1118\n",
      "Iteration 824: Loss = 4.9888, Accuracy = 0.3300 Test Loss = 56.5616, Test Accuracy = 0.1117\n",
      "Iteration 825: Loss = 4.9801, Accuracy = 0.3300 Test Loss = 56.5524, Test Accuracy = 0.1117\n",
      "Iteration 826: Loss = 4.9714, Accuracy = 0.3300 Test Loss = 56.5432, Test Accuracy = 0.1117\n",
      "Iteration 827: Loss = 4.9627, Accuracy = 0.3400 Test Loss = 56.5340, Test Accuracy = 0.1117\n",
      "Iteration 828: Loss = 4.9541, Accuracy = 0.3400 Test Loss = 56.5248, Test Accuracy = 0.1119\n",
      "Iteration 829: Loss = 4.9454, Accuracy = 0.3400 Test Loss = 56.5157, Test Accuracy = 0.1119\n",
      "Iteration 830: Loss = 4.9368, Accuracy = 0.3400 Test Loss = 56.5065, Test Accuracy = 0.1119\n",
      "Iteration 831: Loss = 4.9282, Accuracy = 0.3400 Test Loss = 56.4974, Test Accuracy = 0.1119\n",
      "Iteration 832: Loss = 4.9196, Accuracy = 0.3400 Test Loss = 56.4883, Test Accuracy = 0.1119\n",
      "Iteration 833: Loss = 4.9111, Accuracy = 0.3400 Test Loss = 56.4793, Test Accuracy = 0.1120\n",
      "Iteration 834: Loss = 4.9026, Accuracy = 0.3400 Test Loss = 56.4702, Test Accuracy = 0.1121\n",
      "Iteration 835: Loss = 4.8941, Accuracy = 0.3400 Test Loss = 56.4612, Test Accuracy = 0.1120\n",
      "Iteration 836: Loss = 4.8856, Accuracy = 0.3400 Test Loss = 56.4522, Test Accuracy = 0.1119\n",
      "Iteration 837: Loss = 4.8771, Accuracy = 0.3400 Test Loss = 56.4433, Test Accuracy = 0.1119\n",
      "Iteration 838: Loss = 4.8687, Accuracy = 0.3400 Test Loss = 56.4343, Test Accuracy = 0.1119\n",
      "Iteration 839: Loss = 4.8602, Accuracy = 0.3400 Test Loss = 56.4254, Test Accuracy = 0.1120\n",
      "Iteration 840: Loss = 4.8518, Accuracy = 0.3400 Test Loss = 56.4165, Test Accuracy = 0.1120\n",
      "Iteration 841: Loss = 4.8435, Accuracy = 0.3400 Test Loss = 56.4076, Test Accuracy = 0.1121\n",
      "Iteration 842: Loss = 4.8351, Accuracy = 0.3400 Test Loss = 56.3987, Test Accuracy = 0.1121\n",
      "Iteration 843: Loss = 4.8268, Accuracy = 0.3400 Test Loss = 56.3899, Test Accuracy = 0.1121\n",
      "Iteration 844: Loss = 4.8184, Accuracy = 0.3300 Test Loss = 56.3811, Test Accuracy = 0.1122\n",
      "Iteration 845: Loss = 4.8101, Accuracy = 0.3300 Test Loss = 56.3722, Test Accuracy = 0.1123\n",
      "Iteration 846: Loss = 4.8019, Accuracy = 0.3300 Test Loss = 56.3635, Test Accuracy = 0.1123\n",
      "Iteration 847: Loss = 4.7936, Accuracy = 0.3300 Test Loss = 56.3547, Test Accuracy = 0.1123\n",
      "Iteration 848: Loss = 4.7854, Accuracy = 0.3200 Test Loss = 56.3460, Test Accuracy = 0.1122\n",
      "Iteration 849: Loss = 4.7771, Accuracy = 0.3200 Test Loss = 56.3372, Test Accuracy = 0.1122\n",
      "Iteration 850: Loss = 4.7689, Accuracy = 0.3200 Test Loss = 56.3285, Test Accuracy = 0.1123\n",
      "Iteration 851: Loss = 4.7608, Accuracy = 0.3200 Test Loss = 56.3199, Test Accuracy = 0.1124\n",
      "Iteration 852: Loss = 4.7526, Accuracy = 0.3200 Test Loss = 56.3112, Test Accuracy = 0.1125\n",
      "Iteration 853: Loss = 4.7445, Accuracy = 0.3200 Test Loss = 56.3026, Test Accuracy = 0.1125\n",
      "Iteration 854: Loss = 4.7364, Accuracy = 0.3200 Test Loss = 56.2940, Test Accuracy = 0.1125\n",
      "Iteration 855: Loss = 4.7283, Accuracy = 0.3200 Test Loss = 56.2854, Test Accuracy = 0.1124\n",
      "Iteration 856: Loss = 4.7202, Accuracy = 0.3200 Test Loss = 56.2768, Test Accuracy = 0.1124\n",
      "Iteration 857: Loss = 4.7121, Accuracy = 0.3200 Test Loss = 56.2682, Test Accuracy = 0.1124\n",
      "Iteration 858: Loss = 4.7041, Accuracy = 0.3200 Test Loss = 56.2597, Test Accuracy = 0.1125\n",
      "Iteration 859: Loss = 4.6961, Accuracy = 0.3200 Test Loss = 56.2512, Test Accuracy = 0.1125\n",
      "Iteration 860: Loss = 4.6881, Accuracy = 0.3200 Test Loss = 56.2427, Test Accuracy = 0.1125\n",
      "Iteration 861: Loss = 4.6801, Accuracy = 0.3200 Test Loss = 56.2342, Test Accuracy = 0.1125\n",
      "Iteration 862: Loss = 4.6721, Accuracy = 0.3200 Test Loss = 56.2257, Test Accuracy = 0.1125\n",
      "Iteration 863: Loss = 4.6642, Accuracy = 0.3200 Test Loss = 56.2173, Test Accuracy = 0.1125\n",
      "Iteration 864: Loss = 4.6562, Accuracy = 0.3200 Test Loss = 56.2089, Test Accuracy = 0.1127\n",
      "Iteration 865: Loss = 4.6483, Accuracy = 0.3200 Test Loss = 56.2005, Test Accuracy = 0.1127\n",
      "Iteration 866: Loss = 4.6405, Accuracy = 0.3200 Test Loss = 56.1921, Test Accuracy = 0.1126\n",
      "Iteration 867: Loss = 4.6326, Accuracy = 0.3200 Test Loss = 56.1838, Test Accuracy = 0.1126\n",
      "Iteration 868: Loss = 4.6247, Accuracy = 0.3200 Test Loss = 56.1754, Test Accuracy = 0.1125\n",
      "Iteration 869: Loss = 4.6169, Accuracy = 0.3200 Test Loss = 56.1671, Test Accuracy = 0.1125\n",
      "Iteration 870: Loss = 4.6091, Accuracy = 0.3200 Test Loss = 56.1588, Test Accuracy = 0.1126\n",
      "Iteration 871: Loss = 4.6013, Accuracy = 0.3200 Test Loss = 56.1505, Test Accuracy = 0.1126\n",
      "Iteration 872: Loss = 4.5935, Accuracy = 0.3200 Test Loss = 56.1423, Test Accuracy = 0.1126\n",
      "Iteration 873: Loss = 4.5858, Accuracy = 0.3200 Test Loss = 56.1340, Test Accuracy = 0.1126\n",
      "Iteration 874: Loss = 4.5781, Accuracy = 0.3200 Test Loss = 56.1258, Test Accuracy = 0.1125\n",
      "Iteration 875: Loss = 4.5703, Accuracy = 0.3200 Test Loss = 56.1176, Test Accuracy = 0.1126\n",
      "Iteration 876: Loss = 4.5626, Accuracy = 0.3200 Test Loss = 56.1094, Test Accuracy = 0.1125\n",
      "Iteration 877: Loss = 4.5550, Accuracy = 0.3200 Test Loss = 56.1012, Test Accuracy = 0.1124\n",
      "Iteration 878: Loss = 4.5473, Accuracy = 0.3200 Test Loss = 56.0931, Test Accuracy = 0.1125\n",
      "Iteration 879: Loss = 4.5397, Accuracy = 0.3200 Test Loss = 56.0850, Test Accuracy = 0.1125\n",
      "Iteration 880: Loss = 4.5320, Accuracy = 0.3200 Test Loss = 56.0769, Test Accuracy = 0.1125\n",
      "Iteration 881: Loss = 4.5244, Accuracy = 0.3200 Test Loss = 56.0688, Test Accuracy = 0.1125\n",
      "Iteration 882: Loss = 4.5168, Accuracy = 0.3200 Test Loss = 56.0607, Test Accuracy = 0.1124\n",
      "Iteration 883: Loss = 4.5093, Accuracy = 0.3200 Test Loss = 56.0527, Test Accuracy = 0.1126\n",
      "Iteration 884: Loss = 4.5017, Accuracy = 0.3200 Test Loss = 56.0446, Test Accuracy = 0.1125\n",
      "Iteration 885: Loss = 4.4942, Accuracy = 0.3200 Test Loss = 56.0366, Test Accuracy = 0.1125\n",
      "Iteration 886: Loss = 4.4867, Accuracy = 0.3200 Test Loss = 56.0286, Test Accuracy = 0.1125\n",
      "Iteration 887: Loss = 4.4792, Accuracy = 0.3200 Test Loss = 56.0206, Test Accuracy = 0.1125\n",
      "Iteration 888: Loss = 4.4717, Accuracy = 0.3200 Test Loss = 56.0127, Test Accuracy = 0.1124\n",
      "Iteration 889: Loss = 4.4642, Accuracy = 0.3200 Test Loss = 56.0047, Test Accuracy = 0.1124\n",
      "Iteration 890: Loss = 4.4568, Accuracy = 0.3200 Test Loss = 55.9968, Test Accuracy = 0.1125\n",
      "Iteration 891: Loss = 4.4493, Accuracy = 0.3200 Test Loss = 55.9889, Test Accuracy = 0.1125\n",
      "Iteration 892: Loss = 4.4419, Accuracy = 0.3200 Test Loss = 55.9810, Test Accuracy = 0.1125\n",
      "Iteration 893: Loss = 4.4345, Accuracy = 0.3200 Test Loss = 55.9731, Test Accuracy = 0.1125\n",
      "Iteration 894: Loss = 4.4272, Accuracy = 0.3200 Test Loss = 55.9653, Test Accuracy = 0.1126\n",
      "Iteration 895: Loss = 4.4198, Accuracy = 0.3200 Test Loss = 55.9575, Test Accuracy = 0.1127\n",
      "Iteration 896: Loss = 4.4125, Accuracy = 0.3200 Test Loss = 55.9496, Test Accuracy = 0.1129\n",
      "Iteration 897: Loss = 4.4051, Accuracy = 0.3200 Test Loss = 55.9418, Test Accuracy = 0.1130\n",
      "Iteration 898: Loss = 4.3978, Accuracy = 0.3200 Test Loss = 55.9341, Test Accuracy = 0.1131\n",
      "Iteration 899: Loss = 4.3905, Accuracy = 0.3200 Test Loss = 55.9263, Test Accuracy = 0.1131\n",
      "Iteration 900: Loss = 4.3833, Accuracy = 0.3200 Test Loss = 55.9185, Test Accuracy = 0.1131\n",
      "Iteration 901: Loss = 4.3760, Accuracy = 0.3200 Test Loss = 55.9108, Test Accuracy = 0.1130\n",
      "Iteration 902: Loss = 4.3688, Accuracy = 0.3200 Test Loss = 55.9031, Test Accuracy = 0.1127\n",
      "Iteration 903: Loss = 4.3615, Accuracy = 0.3200 Test Loss = 55.8954, Test Accuracy = 0.1126\n",
      "Iteration 904: Loss = 4.3543, Accuracy = 0.3200 Test Loss = 55.8877, Test Accuracy = 0.1127\n",
      "Iteration 905: Loss = 4.3471, Accuracy = 0.3200 Test Loss = 55.8801, Test Accuracy = 0.1127\n",
      "Iteration 906: Loss = 4.3400, Accuracy = 0.3200 Test Loss = 55.8725, Test Accuracy = 0.1125\n",
      "Iteration 907: Loss = 4.3328, Accuracy = 0.3200 Test Loss = 55.8648, Test Accuracy = 0.1126\n",
      "Iteration 908: Loss = 4.3257, Accuracy = 0.3200 Test Loss = 55.8572, Test Accuracy = 0.1126\n",
      "Iteration 909: Loss = 4.3186, Accuracy = 0.3200 Test Loss = 55.8496, Test Accuracy = 0.1127\n",
      "Iteration 910: Loss = 4.3114, Accuracy = 0.3200 Test Loss = 55.8421, Test Accuracy = 0.1129\n",
      "Iteration 911: Loss = 4.3044, Accuracy = 0.3200 Test Loss = 55.8345, Test Accuracy = 0.1129\n",
      "Iteration 912: Loss = 4.2973, Accuracy = 0.3200 Test Loss = 55.8270, Test Accuracy = 0.1130\n",
      "Iteration 913: Loss = 4.2902, Accuracy = 0.3200 Test Loss = 55.8194, Test Accuracy = 0.1130\n",
      "Iteration 914: Loss = 4.2832, Accuracy = 0.3200 Test Loss = 55.8119, Test Accuracy = 0.1130\n",
      "Iteration 915: Loss = 4.2762, Accuracy = 0.3200 Test Loss = 55.8045, Test Accuracy = 0.1130\n",
      "Iteration 916: Loss = 4.2692, Accuracy = 0.3200 Test Loss = 55.7970, Test Accuracy = 0.1130\n",
      "Iteration 917: Loss = 4.2622, Accuracy = 0.3200 Test Loss = 55.7895, Test Accuracy = 0.1129\n",
      "Iteration 918: Loss = 4.2552, Accuracy = 0.3200 Test Loss = 55.7821, Test Accuracy = 0.1130\n",
      "Iteration 919: Loss = 4.2482, Accuracy = 0.3200 Test Loss = 55.7747, Test Accuracy = 0.1130\n",
      "Iteration 920: Loss = 4.2413, Accuracy = 0.3200 Test Loss = 55.7673, Test Accuracy = 0.1131\n",
      "Iteration 921: Loss = 4.2344, Accuracy = 0.3200 Test Loss = 55.7599, Test Accuracy = 0.1132\n",
      "Iteration 922: Loss = 4.2274, Accuracy = 0.3200 Test Loss = 55.7525, Test Accuracy = 0.1132\n",
      "Iteration 923: Loss = 4.2205, Accuracy = 0.3200 Test Loss = 55.7452, Test Accuracy = 0.1132\n",
      "Iteration 924: Loss = 4.2137, Accuracy = 0.3200 Test Loss = 55.7378, Test Accuracy = 0.1132\n",
      "Iteration 925: Loss = 4.2068, Accuracy = 0.3200 Test Loss = 55.7305, Test Accuracy = 0.1130\n",
      "Iteration 926: Loss = 4.1999, Accuracy = 0.3200 Test Loss = 55.7232, Test Accuracy = 0.1130\n",
      "Iteration 927: Loss = 4.1931, Accuracy = 0.3200 Test Loss = 55.7159, Test Accuracy = 0.1130\n",
      "Iteration 928: Loss = 4.1863, Accuracy = 0.3200 Test Loss = 55.7087, Test Accuracy = 0.1130\n",
      "Iteration 929: Loss = 4.1795, Accuracy = 0.3200 Test Loss = 55.7014, Test Accuracy = 0.1130\n",
      "Iteration 930: Loss = 4.1727, Accuracy = 0.3200 Test Loss = 55.6942, Test Accuracy = 0.1131\n",
      "Iteration 931: Loss = 4.1659, Accuracy = 0.3200 Test Loss = 55.6869, Test Accuracy = 0.1131\n",
      "Iteration 932: Loss = 4.1592, Accuracy = 0.3200 Test Loss = 55.6797, Test Accuracy = 0.1131\n",
      "Iteration 933: Loss = 4.1524, Accuracy = 0.3200 Test Loss = 55.6726, Test Accuracy = 0.1133\n",
      "Iteration 934: Loss = 4.1457, Accuracy = 0.3200 Test Loss = 55.6654, Test Accuracy = 0.1134\n",
      "Iteration 935: Loss = 4.1390, Accuracy = 0.3200 Test Loss = 55.6582, Test Accuracy = 0.1134\n",
      "Iteration 936: Loss = 4.1323, Accuracy = 0.3200 Test Loss = 55.6511, Test Accuracy = 0.1134\n",
      "Iteration 937: Loss = 4.1256, Accuracy = 0.3200 Test Loss = 55.6439, Test Accuracy = 0.1134\n",
      "Iteration 938: Loss = 4.1190, Accuracy = 0.3200 Test Loss = 55.6368, Test Accuracy = 0.1134\n",
      "Iteration 939: Loss = 4.1123, Accuracy = 0.3200 Test Loss = 55.6297, Test Accuracy = 0.1136\n",
      "Iteration 940: Loss = 4.1057, Accuracy = 0.3200 Test Loss = 55.6227, Test Accuracy = 0.1136\n",
      "Iteration 941: Loss = 4.0991, Accuracy = 0.3200 Test Loss = 55.6156, Test Accuracy = 0.1136\n",
      "Iteration 942: Loss = 4.0925, Accuracy = 0.3200 Test Loss = 55.6085, Test Accuracy = 0.1136\n",
      "Iteration 943: Loss = 4.0859, Accuracy = 0.3200 Test Loss = 55.6015, Test Accuracy = 0.1135\n",
      "Iteration 944: Loss = 4.0793, Accuracy = 0.3200 Test Loss = 55.5945, Test Accuracy = 0.1136\n",
      "Iteration 945: Loss = 4.0727, Accuracy = 0.3300 Test Loss = 55.5875, Test Accuracy = 0.1136\n",
      "Iteration 946: Loss = 4.0662, Accuracy = 0.3300 Test Loss = 55.5805, Test Accuracy = 0.1137\n",
      "Iteration 947: Loss = 4.0597, Accuracy = 0.3300 Test Loss = 55.5735, Test Accuracy = 0.1137\n",
      "Iteration 948: Loss = 4.0531, Accuracy = 0.3300 Test Loss = 55.5666, Test Accuracy = 0.1137\n",
      "Iteration 949: Loss = 4.0466, Accuracy = 0.3300 Test Loss = 55.5596, Test Accuracy = 0.1136\n",
      "Iteration 950: Loss = 4.0402, Accuracy = 0.3300 Test Loss = 55.5527, Test Accuracy = 0.1135\n",
      "Iteration 951: Loss = 4.0337, Accuracy = 0.3300 Test Loss = 55.5458, Test Accuracy = 0.1135\n",
      "Iteration 952: Loss = 4.0272, Accuracy = 0.3300 Test Loss = 55.5389, Test Accuracy = 0.1135\n",
      "Iteration 953: Loss = 4.0208, Accuracy = 0.3300 Test Loss = 55.5320, Test Accuracy = 0.1135\n",
      "Iteration 954: Loss = 4.0144, Accuracy = 0.3300 Test Loss = 55.5252, Test Accuracy = 0.1137\n",
      "Iteration 955: Loss = 4.0079, Accuracy = 0.3300 Test Loss = 55.5183, Test Accuracy = 0.1137\n",
      "Iteration 956: Loss = 4.0015, Accuracy = 0.3300 Test Loss = 55.5115, Test Accuracy = 0.1137\n",
      "Iteration 957: Loss = 3.9952, Accuracy = 0.3300 Test Loss = 55.5047, Test Accuracy = 0.1137\n",
      "Iteration 958: Loss = 3.9888, Accuracy = 0.3300 Test Loss = 55.4979, Test Accuracy = 0.1138\n",
      "Iteration 959: Loss = 3.9824, Accuracy = 0.3300 Test Loss = 55.4911, Test Accuracy = 0.1138\n",
      "Iteration 960: Loss = 3.9761, Accuracy = 0.3300 Test Loss = 55.4843, Test Accuracy = 0.1137\n",
      "Iteration 961: Loss = 3.9698, Accuracy = 0.3300 Test Loss = 55.4775, Test Accuracy = 0.1138\n",
      "Iteration 962: Loss = 3.9634, Accuracy = 0.3300 Test Loss = 55.4708, Test Accuracy = 0.1137\n",
      "Iteration 963: Loss = 3.9571, Accuracy = 0.3300 Test Loss = 55.4641, Test Accuracy = 0.1137\n",
      "Iteration 964: Loss = 3.9509, Accuracy = 0.3300 Test Loss = 55.4574, Test Accuracy = 0.1139\n",
      "Iteration 965: Loss = 3.9446, Accuracy = 0.3300 Test Loss = 55.4506, Test Accuracy = 0.1140\n",
      "Iteration 966: Loss = 3.9383, Accuracy = 0.3300 Test Loss = 55.4440, Test Accuracy = 0.1140\n",
      "Iteration 967: Loss = 3.9321, Accuracy = 0.3300 Test Loss = 55.4373, Test Accuracy = 0.1141\n",
      "Iteration 968: Loss = 3.9258, Accuracy = 0.3300 Test Loss = 55.4306, Test Accuracy = 0.1141\n",
      "Iteration 969: Loss = 3.9196, Accuracy = 0.3400 Test Loss = 55.4240, Test Accuracy = 0.1141\n",
      "Iteration 970: Loss = 3.9134, Accuracy = 0.3400 Test Loss = 55.4174, Test Accuracy = 0.1143\n",
      "Iteration 971: Loss = 3.9072, Accuracy = 0.3400 Test Loss = 55.4107, Test Accuracy = 0.1143\n",
      "Iteration 972: Loss = 3.9011, Accuracy = 0.3400 Test Loss = 55.4041, Test Accuracy = 0.1142\n",
      "Iteration 973: Loss = 3.8949, Accuracy = 0.3400 Test Loss = 55.3975, Test Accuracy = 0.1143\n",
      "Iteration 974: Loss = 3.8887, Accuracy = 0.3400 Test Loss = 55.3910, Test Accuracy = 0.1144\n",
      "Iteration 975: Loss = 3.8826, Accuracy = 0.3400 Test Loss = 55.3844, Test Accuracy = 0.1144\n",
      "Iteration 976: Loss = 3.8765, Accuracy = 0.3400 Test Loss = 55.3779, Test Accuracy = 0.1144\n",
      "Iteration 977: Loss = 3.8704, Accuracy = 0.3400 Test Loss = 55.3713, Test Accuracy = 0.1144\n",
      "Iteration 978: Loss = 3.8643, Accuracy = 0.3400 Test Loss = 55.3648, Test Accuracy = 0.1144\n",
      "Iteration 979: Loss = 3.8582, Accuracy = 0.3400 Test Loss = 55.3583, Test Accuracy = 0.1142\n",
      "Iteration 980: Loss = 3.8521, Accuracy = 0.3400 Test Loss = 55.3518, Test Accuracy = 0.1141\n",
      "Iteration 981: Loss = 3.8461, Accuracy = 0.3400 Test Loss = 55.3454, Test Accuracy = 0.1139\n",
      "Iteration 982: Loss = 3.8400, Accuracy = 0.3400 Test Loss = 55.3389, Test Accuracy = 0.1139\n",
      "Iteration 983: Loss = 3.8340, Accuracy = 0.3400 Test Loss = 55.3325, Test Accuracy = 0.1140\n",
      "Iteration 984: Loss = 3.8280, Accuracy = 0.3400 Test Loss = 55.3260, Test Accuracy = 0.1140\n",
      "Iteration 985: Loss = 3.8220, Accuracy = 0.3400 Test Loss = 55.3196, Test Accuracy = 0.1140\n",
      "Iteration 986: Loss = 3.8160, Accuracy = 0.3400 Test Loss = 55.3132, Test Accuracy = 0.1140\n",
      "Iteration 987: Loss = 3.8100, Accuracy = 0.3400 Test Loss = 55.3068, Test Accuracy = 0.1141\n",
      "Iteration 988: Loss = 3.8041, Accuracy = 0.3400 Test Loss = 55.3004, Test Accuracy = 0.1140\n",
      "Iteration 989: Loss = 3.7981, Accuracy = 0.3400 Test Loss = 55.2941, Test Accuracy = 0.1142\n",
      "Iteration 990: Loss = 3.7922, Accuracy = 0.3400 Test Loss = 55.2877, Test Accuracy = 0.1142\n",
      "Iteration 991: Loss = 3.7862, Accuracy = 0.3400 Test Loss = 55.2814, Test Accuracy = 0.1142\n",
      "Iteration 992: Loss = 3.7803, Accuracy = 0.3400 Test Loss = 55.2751, Test Accuracy = 0.1143\n",
      "Iteration 993: Loss = 3.7744, Accuracy = 0.3400 Test Loss = 55.2687, Test Accuracy = 0.1144\n",
      "Iteration 994: Loss = 3.7685, Accuracy = 0.3400 Test Loss = 55.2625, Test Accuracy = 0.1144\n",
      "Iteration 995: Loss = 3.7627, Accuracy = 0.3400 Test Loss = 55.2562, Test Accuracy = 0.1144\n",
      "Iteration 996: Loss = 3.7568, Accuracy = 0.3500 Test Loss = 55.2499, Test Accuracy = 0.1144\n",
      "Iteration 997: Loss = 3.7510, Accuracy = 0.3500 Test Loss = 55.2436, Test Accuracy = 0.1143\n",
      "Iteration 998: Loss = 3.7451, Accuracy = 0.3500 Test Loss = 55.2374, Test Accuracy = 0.1143\n",
      "Iteration 999: Loss = 3.7393, Accuracy = 0.3500 Test Loss = 55.2312, Test Accuracy = 0.1143\n",
      "Iteration 1000: Loss = 3.7335, Accuracy = 0.3500 Test Loss = 55.2250, Test Accuracy = 0.1143\n",
      "Iteration 1001: Loss = 3.7277, Accuracy = 0.3500 Test Loss = 55.2188, Test Accuracy = 0.1145\n",
      "Iteration 1002: Loss = 3.7219, Accuracy = 0.3500 Test Loss = 55.2126, Test Accuracy = 0.1145\n",
      "Iteration 1003: Loss = 3.7161, Accuracy = 0.3500 Test Loss = 55.2064, Test Accuracy = 0.1145\n",
      "Iteration 1004: Loss = 3.7104, Accuracy = 0.3500 Test Loss = 55.2002, Test Accuracy = 0.1145\n",
      "Iteration 1005: Loss = 3.7046, Accuracy = 0.3500 Test Loss = 55.1941, Test Accuracy = 0.1146\n",
      "Iteration 1006: Loss = 3.6989, Accuracy = 0.3500 Test Loss = 55.1879, Test Accuracy = 0.1147\n",
      "Iteration 1007: Loss = 3.6932, Accuracy = 0.3500 Test Loss = 55.1818, Test Accuracy = 0.1147\n",
      "Iteration 1008: Loss = 3.6874, Accuracy = 0.3500 Test Loss = 55.1757, Test Accuracy = 0.1147\n",
      "Iteration 1009: Loss = 3.6817, Accuracy = 0.3500 Test Loss = 55.1696, Test Accuracy = 0.1147\n",
      "Iteration 1010: Loss = 3.6761, Accuracy = 0.3500 Test Loss = 55.1635, Test Accuracy = 0.1149\n",
      "Iteration 1011: Loss = 3.6704, Accuracy = 0.3500 Test Loss = 55.1574, Test Accuracy = 0.1149\n",
      "Iteration 1012: Loss = 3.6647, Accuracy = 0.3500 Test Loss = 55.1514, Test Accuracy = 0.1149\n",
      "Iteration 1013: Loss = 3.6591, Accuracy = 0.3500 Test Loss = 55.1453, Test Accuracy = 0.1149\n",
      "Iteration 1014: Loss = 3.6534, Accuracy = 0.3500 Test Loss = 55.1393, Test Accuracy = 0.1148\n",
      "Iteration 1015: Loss = 3.6478, Accuracy = 0.3500 Test Loss = 55.1333, Test Accuracy = 0.1147\n",
      "Iteration 1016: Loss = 3.6422, Accuracy = 0.3500 Test Loss = 55.1273, Test Accuracy = 0.1147\n",
      "Iteration 1017: Loss = 3.6366, Accuracy = 0.3500 Test Loss = 55.1213, Test Accuracy = 0.1147\n",
      "Iteration 1018: Loss = 3.6310, Accuracy = 0.3500 Test Loss = 55.1153, Test Accuracy = 0.1147\n",
      "Iteration 1019: Loss = 3.6254, Accuracy = 0.3500 Test Loss = 55.1093, Test Accuracy = 0.1146\n",
      "Iteration 1020: Loss = 3.6199, Accuracy = 0.3500 Test Loss = 55.1034, Test Accuracy = 0.1146\n",
      "Iteration 1021: Loss = 3.6143, Accuracy = 0.3500 Test Loss = 55.0974, Test Accuracy = 0.1146\n",
      "Iteration 1022: Loss = 3.6088, Accuracy = 0.3500 Test Loss = 55.0915, Test Accuracy = 0.1146\n",
      "Iteration 1023: Loss = 3.6032, Accuracy = 0.3500 Test Loss = 55.0855, Test Accuracy = 0.1146\n",
      "Iteration 1024: Loss = 3.5977, Accuracy = 0.3500 Test Loss = 55.0796, Test Accuracy = 0.1146\n",
      "Iteration 1025: Loss = 3.5922, Accuracy = 0.3500 Test Loss = 55.0737, Test Accuracy = 0.1147\n",
      "Iteration 1026: Loss = 3.5867, Accuracy = 0.3500 Test Loss = 55.0679, Test Accuracy = 0.1147\n",
      "Iteration 1027: Loss = 3.5812, Accuracy = 0.3500 Test Loss = 55.0620, Test Accuracy = 0.1147\n",
      "Iteration 1028: Loss = 3.5757, Accuracy = 0.3500 Test Loss = 55.0561, Test Accuracy = 0.1147\n",
      "Iteration 1029: Loss = 3.5703, Accuracy = 0.3500 Test Loss = 55.0503, Test Accuracy = 0.1148\n",
      "Iteration 1030: Loss = 3.5648, Accuracy = 0.3500 Test Loss = 55.0444, Test Accuracy = 0.1148\n",
      "Iteration 1031: Loss = 3.5594, Accuracy = 0.3500 Test Loss = 55.0386, Test Accuracy = 0.1148\n",
      "Iteration 1032: Loss = 3.5540, Accuracy = 0.3500 Test Loss = 55.0328, Test Accuracy = 0.1147\n",
      "Iteration 1033: Loss = 3.5485, Accuracy = 0.3500 Test Loss = 55.0270, Test Accuracy = 0.1146\n",
      "Iteration 1034: Loss = 3.5431, Accuracy = 0.3500 Test Loss = 55.0212, Test Accuracy = 0.1145\n",
      "Iteration 1035: Loss = 3.5377, Accuracy = 0.3500 Test Loss = 55.0154, Test Accuracy = 0.1145\n",
      "Iteration 1036: Loss = 3.5324, Accuracy = 0.3500 Test Loss = 55.0097, Test Accuracy = 0.1145\n",
      "Iteration 1037: Loss = 3.5270, Accuracy = 0.3500 Test Loss = 55.0039, Test Accuracy = 0.1145\n",
      "Iteration 1038: Loss = 3.5216, Accuracy = 0.3500 Test Loss = 54.9982, Test Accuracy = 0.1144\n",
      "Iteration 1039: Loss = 3.5163, Accuracy = 0.3500 Test Loss = 54.9925, Test Accuracy = 0.1144\n",
      "Iteration 1040: Loss = 3.5109, Accuracy = 0.3500 Test Loss = 54.9867, Test Accuracy = 0.1144\n",
      "Iteration 1041: Loss = 3.5056, Accuracy = 0.3500 Test Loss = 54.9810, Test Accuracy = 0.1143\n",
      "Iteration 1042: Loss = 3.5003, Accuracy = 0.3500 Test Loss = 54.9753, Test Accuracy = 0.1143\n",
      "Iteration 1043: Loss = 3.4950, Accuracy = 0.3500 Test Loss = 54.9697, Test Accuracy = 0.1144\n",
      "Iteration 1044: Loss = 3.4897, Accuracy = 0.3500 Test Loss = 54.9640, Test Accuracy = 0.1144\n",
      "Iteration 1045: Loss = 3.4844, Accuracy = 0.3500 Test Loss = 54.9583, Test Accuracy = 0.1144\n",
      "Iteration 1046: Loss = 3.4791, Accuracy = 0.3500 Test Loss = 54.9527, Test Accuracy = 0.1143\n",
      "Iteration 1047: Loss = 3.4739, Accuracy = 0.3500 Test Loss = 54.9470, Test Accuracy = 0.1143\n",
      "Iteration 1048: Loss = 3.4686, Accuracy = 0.3500 Test Loss = 54.9414, Test Accuracy = 0.1143\n",
      "Iteration 1049: Loss = 3.4634, Accuracy = 0.3500 Test Loss = 54.9358, Test Accuracy = 0.1144\n",
      "Iteration 1050: Loss = 3.4582, Accuracy = 0.3500 Test Loss = 54.9302, Test Accuracy = 0.1144\n",
      "Iteration 1051: Loss = 3.4530, Accuracy = 0.3500 Test Loss = 54.9246, Test Accuracy = 0.1144\n",
      "Iteration 1052: Loss = 3.4478, Accuracy = 0.3500 Test Loss = 54.9190, Test Accuracy = 0.1144\n",
      "Iteration 1053: Loss = 3.4426, Accuracy = 0.3500 Test Loss = 54.9135, Test Accuracy = 0.1144\n",
      "Iteration 1054: Loss = 3.4374, Accuracy = 0.3500 Test Loss = 54.9079, Test Accuracy = 0.1144\n",
      "Iteration 1055: Loss = 3.4322, Accuracy = 0.3500 Test Loss = 54.9024, Test Accuracy = 0.1143\n",
      "Iteration 1056: Loss = 3.4270, Accuracy = 0.3500 Test Loss = 54.8969, Test Accuracy = 0.1143\n",
      "Iteration 1057: Loss = 3.4219, Accuracy = 0.3500 Test Loss = 54.8913, Test Accuracy = 0.1142\n",
      "Iteration 1058: Loss = 3.4167, Accuracy = 0.3500 Test Loss = 54.8858, Test Accuracy = 0.1142\n",
      "Iteration 1059: Loss = 3.4116, Accuracy = 0.3500 Test Loss = 54.8803, Test Accuracy = 0.1142\n",
      "Iteration 1060: Loss = 3.4065, Accuracy = 0.3500 Test Loss = 54.8748, Test Accuracy = 0.1143\n",
      "Iteration 1061: Loss = 3.4014, Accuracy = 0.3500 Test Loss = 54.8694, Test Accuracy = 0.1145\n",
      "Iteration 1062: Loss = 3.3963, Accuracy = 0.3500 Test Loss = 54.8639, Test Accuracy = 0.1144\n",
      "Iteration 1063: Loss = 3.3912, Accuracy = 0.3500 Test Loss = 54.8585, Test Accuracy = 0.1144\n",
      "Iteration 1064: Loss = 3.3861, Accuracy = 0.3500 Test Loss = 54.8530, Test Accuracy = 0.1144\n",
      "Iteration 1065: Loss = 3.3810, Accuracy = 0.3500 Test Loss = 54.8476, Test Accuracy = 0.1144\n",
      "Iteration 1066: Loss = 3.3760, Accuracy = 0.3500 Test Loss = 54.8422, Test Accuracy = 0.1143\n",
      "Iteration 1067: Loss = 3.3709, Accuracy = 0.3500 Test Loss = 54.8368, Test Accuracy = 0.1142\n",
      "Iteration 1068: Loss = 3.3659, Accuracy = 0.3500 Test Loss = 54.8313, Test Accuracy = 0.1141\n",
      "Iteration 1069: Loss = 3.3609, Accuracy = 0.3500 Test Loss = 54.8260, Test Accuracy = 0.1141\n",
      "Iteration 1070: Loss = 3.3559, Accuracy = 0.3500 Test Loss = 54.8206, Test Accuracy = 0.1141\n",
      "Iteration 1071: Loss = 3.3509, Accuracy = 0.3500 Test Loss = 54.8152, Test Accuracy = 0.1140\n",
      "Iteration 1072: Loss = 3.3459, Accuracy = 0.3500 Test Loss = 54.8099, Test Accuracy = 0.1142\n",
      "Iteration 1073: Loss = 3.3409, Accuracy = 0.3500 Test Loss = 54.8045, Test Accuracy = 0.1142\n",
      "Iteration 1074: Loss = 3.3359, Accuracy = 0.3500 Test Loss = 54.7992, Test Accuracy = 0.1142\n",
      "Iteration 1075: Loss = 3.3309, Accuracy = 0.3500 Test Loss = 54.7939, Test Accuracy = 0.1142\n",
      "Iteration 1076: Loss = 3.3260, Accuracy = 0.3500 Test Loss = 54.7886, Test Accuracy = 0.1141\n",
      "Iteration 1077: Loss = 3.3210, Accuracy = 0.3500 Test Loss = 54.7833, Test Accuracy = 0.1141\n",
      "Iteration 1078: Loss = 3.3161, Accuracy = 0.3500 Test Loss = 54.7780, Test Accuracy = 0.1141\n",
      "Iteration 1079: Loss = 3.3112, Accuracy = 0.3500 Test Loss = 54.7727, Test Accuracy = 0.1141\n",
      "Iteration 1080: Loss = 3.3063, Accuracy = 0.3500 Test Loss = 54.7674, Test Accuracy = 0.1140\n",
      "Iteration 1081: Loss = 3.3014, Accuracy = 0.3500 Test Loss = 54.7622, Test Accuracy = 0.1140\n",
      "Iteration 1082: Loss = 3.2965, Accuracy = 0.3500 Test Loss = 54.7569, Test Accuracy = 0.1141\n",
      "Iteration 1083: Loss = 3.2916, Accuracy = 0.3500 Test Loss = 54.7517, Test Accuracy = 0.1141\n",
      "Iteration 1084: Loss = 3.2867, Accuracy = 0.3500 Test Loss = 54.7465, Test Accuracy = 0.1141\n",
      "Iteration 1085: Loss = 3.2818, Accuracy = 0.3500 Test Loss = 54.7412, Test Accuracy = 0.1140\n",
      "Iteration 1086: Loss = 3.2770, Accuracy = 0.3500 Test Loss = 54.7360, Test Accuracy = 0.1140\n",
      "Iteration 1087: Loss = 3.2721, Accuracy = 0.3500 Test Loss = 54.7309, Test Accuracy = 0.1141\n",
      "Iteration 1088: Loss = 3.2673, Accuracy = 0.3500 Test Loss = 54.7257, Test Accuracy = 0.1141\n",
      "Iteration 1089: Loss = 3.2625, Accuracy = 0.3500 Test Loss = 54.7205, Test Accuracy = 0.1141\n",
      "Iteration 1090: Loss = 3.2577, Accuracy = 0.3500 Test Loss = 54.7153, Test Accuracy = 0.1141\n",
      "Iteration 1091: Loss = 3.2529, Accuracy = 0.3500 Test Loss = 54.7102, Test Accuracy = 0.1141\n",
      "Iteration 1092: Loss = 3.2481, Accuracy = 0.3500 Test Loss = 54.7050, Test Accuracy = 0.1143\n",
      "Iteration 1093: Loss = 3.2433, Accuracy = 0.3500 Test Loss = 54.6999, Test Accuracy = 0.1144\n",
      "Iteration 1094: Loss = 3.2385, Accuracy = 0.3500 Test Loss = 54.6948, Test Accuracy = 0.1144\n",
      "Iteration 1095: Loss = 3.2337, Accuracy = 0.3500 Test Loss = 54.6897, Test Accuracy = 0.1143\n",
      "Iteration 1096: Loss = 3.2290, Accuracy = 0.3500 Test Loss = 54.6846, Test Accuracy = 0.1143\n",
      "Iteration 1097: Loss = 3.2242, Accuracy = 0.3500 Test Loss = 54.6795, Test Accuracy = 0.1143\n",
      "Iteration 1098: Loss = 3.2195, Accuracy = 0.3500 Test Loss = 54.6744, Test Accuracy = 0.1143\n",
      "Iteration 1099: Loss = 3.2148, Accuracy = 0.3500 Test Loss = 54.6693, Test Accuracy = 0.1144\n",
      "Iteration 1100: Loss = 3.2100, Accuracy = 0.3500 Test Loss = 54.6643, Test Accuracy = 0.1144\n",
      "Iteration 1101: Loss = 3.2053, Accuracy = 0.3600 Test Loss = 54.6592, Test Accuracy = 0.1142\n",
      "Iteration 1102: Loss = 3.2006, Accuracy = 0.3600 Test Loss = 54.6542, Test Accuracy = 0.1143\n",
      "Iteration 1103: Loss = 3.1959, Accuracy = 0.3600 Test Loss = 54.6491, Test Accuracy = 0.1143\n",
      "Iteration 1104: Loss = 3.1913, Accuracy = 0.3600 Test Loss = 54.6441, Test Accuracy = 0.1143\n",
      "Iteration 1105: Loss = 3.1866, Accuracy = 0.3600 Test Loss = 54.6391, Test Accuracy = 0.1143\n",
      "Iteration 1106: Loss = 3.1819, Accuracy = 0.3600 Test Loss = 54.6341, Test Accuracy = 0.1142\n",
      "Iteration 1107: Loss = 3.1773, Accuracy = 0.3600 Test Loss = 54.6291, Test Accuracy = 0.1142\n",
      "Iteration 1108: Loss = 3.1726, Accuracy = 0.3600 Test Loss = 54.6241, Test Accuracy = 0.1143\n",
      "Iteration 1109: Loss = 3.1680, Accuracy = 0.3600 Test Loss = 54.6192, Test Accuracy = 0.1142\n",
      "Iteration 1110: Loss = 3.1634, Accuracy = 0.3600 Test Loss = 54.6142, Test Accuracy = 0.1142\n",
      "Iteration 1111: Loss = 3.1587, Accuracy = 0.3600 Test Loss = 54.6092, Test Accuracy = 0.1143\n",
      "Iteration 1112: Loss = 3.1541, Accuracy = 0.3600 Test Loss = 54.6043, Test Accuracy = 0.1143\n",
      "Iteration 1113: Loss = 3.1495, Accuracy = 0.3600 Test Loss = 54.5994, Test Accuracy = 0.1143\n",
      "Iteration 1114: Loss = 3.1449, Accuracy = 0.3600 Test Loss = 54.5945, Test Accuracy = 0.1143\n",
      "Iteration 1115: Loss = 3.1404, Accuracy = 0.3600 Test Loss = 54.5895, Test Accuracy = 0.1143\n",
      "Iteration 1116: Loss = 3.1358, Accuracy = 0.3600 Test Loss = 54.5846, Test Accuracy = 0.1143\n",
      "Iteration 1117: Loss = 3.1312, Accuracy = 0.3600 Test Loss = 54.5798, Test Accuracy = 0.1143\n",
      "Iteration 1118: Loss = 3.1267, Accuracy = 0.3600 Test Loss = 54.5749, Test Accuracy = 0.1144\n",
      "Iteration 1119: Loss = 3.1221, Accuracy = 0.3600 Test Loss = 54.5700, Test Accuracy = 0.1144\n",
      "Iteration 1120: Loss = 3.1176, Accuracy = 0.3600 Test Loss = 54.5651, Test Accuracy = 0.1144\n",
      "Iteration 1121: Loss = 3.1131, Accuracy = 0.3600 Test Loss = 54.5603, Test Accuracy = 0.1144\n",
      "Iteration 1122: Loss = 3.1086, Accuracy = 0.3600 Test Loss = 54.5554, Test Accuracy = 0.1144\n",
      "Iteration 1123: Loss = 3.1040, Accuracy = 0.3600 Test Loss = 54.5506, Test Accuracy = 0.1144\n",
      "Iteration 1124: Loss = 3.0995, Accuracy = 0.3600 Test Loss = 54.5458, Test Accuracy = 0.1143\n",
      "Iteration 1125: Loss = 3.0951, Accuracy = 0.3600 Test Loss = 54.5410, Test Accuracy = 0.1143\n",
      "Iteration 1126: Loss = 3.0906, Accuracy = 0.3600 Test Loss = 54.5362, Test Accuracy = 0.1143\n",
      "Iteration 1127: Loss = 3.0861, Accuracy = 0.3600 Test Loss = 54.5313, Test Accuracy = 0.1143\n",
      "Iteration 1128: Loss = 3.0816, Accuracy = 0.3600 Test Loss = 54.5266, Test Accuracy = 0.1143\n",
      "Iteration 1129: Loss = 3.0772, Accuracy = 0.3600 Test Loss = 54.5218, Test Accuracy = 0.1143\n",
      "Iteration 1130: Loss = 3.0727, Accuracy = 0.3600 Test Loss = 54.5170, Test Accuracy = 0.1143\n",
      "Iteration 1131: Loss = 3.0683, Accuracy = 0.3600 Test Loss = 54.5122, Test Accuracy = 0.1143\n",
      "Iteration 1132: Loss = 3.0639, Accuracy = 0.3600 Test Loss = 54.5075, Test Accuracy = 0.1143\n",
      "Iteration 1133: Loss = 3.0595, Accuracy = 0.3600 Test Loss = 54.5028, Test Accuracy = 0.1142\n",
      "Iteration 1134: Loss = 3.0550, Accuracy = 0.3600 Test Loss = 54.4980, Test Accuracy = 0.1142\n",
      "Iteration 1135: Loss = 3.0506, Accuracy = 0.3600 Test Loss = 54.4933, Test Accuracy = 0.1142\n",
      "Iteration 1136: Loss = 3.0462, Accuracy = 0.3600 Test Loss = 54.4886, Test Accuracy = 0.1142\n",
      "Iteration 1137: Loss = 3.0419, Accuracy = 0.3600 Test Loss = 54.4839, Test Accuracy = 0.1141\n",
      "Iteration 1138: Loss = 3.0375, Accuracy = 0.3600 Test Loss = 54.4792, Test Accuracy = 0.1142\n",
      "Iteration 1139: Loss = 3.0331, Accuracy = 0.3600 Test Loss = 54.4745, Test Accuracy = 0.1142\n",
      "Iteration 1140: Loss = 3.0287, Accuracy = 0.3600 Test Loss = 54.4698, Test Accuracy = 0.1142\n",
      "Iteration 1141: Loss = 3.0244, Accuracy = 0.3600 Test Loss = 54.4652, Test Accuracy = 0.1143\n",
      "Iteration 1142: Loss = 3.0201, Accuracy = 0.3600 Test Loss = 54.4605, Test Accuracy = 0.1143\n",
      "Iteration 1143: Loss = 3.0157, Accuracy = 0.3600 Test Loss = 54.4558, Test Accuracy = 0.1143\n",
      "Iteration 1144: Loss = 3.0114, Accuracy = 0.3600 Test Loss = 54.4512, Test Accuracy = 0.1143\n",
      "Iteration 1145: Loss = 3.0071, Accuracy = 0.3600 Test Loss = 54.4466, Test Accuracy = 0.1142\n",
      "Iteration 1146: Loss = 3.0028, Accuracy = 0.3600 Test Loss = 54.4420, Test Accuracy = 0.1142\n",
      "Iteration 1147: Loss = 2.9985, Accuracy = 0.3600 Test Loss = 54.4373, Test Accuracy = 0.1142\n",
      "Iteration 1148: Loss = 2.9942, Accuracy = 0.3600 Test Loss = 54.4327, Test Accuracy = 0.1142\n",
      "Iteration 1149: Loss = 2.9899, Accuracy = 0.3600 Test Loss = 54.4281, Test Accuracy = 0.1141\n",
      "Iteration 1150: Loss = 2.9856, Accuracy = 0.3600 Test Loss = 54.4235, Test Accuracy = 0.1141\n",
      "Iteration 1151: Loss = 2.9813, Accuracy = 0.3600 Test Loss = 54.4190, Test Accuracy = 0.1142\n",
      "Iteration 1152: Loss = 2.9771, Accuracy = 0.3600 Test Loss = 54.4144, Test Accuracy = 0.1143\n",
      "Iteration 1153: Loss = 2.9728, Accuracy = 0.3600 Test Loss = 54.4098, Test Accuracy = 0.1144\n",
      "Iteration 1154: Loss = 2.9686, Accuracy = 0.3600 Test Loss = 54.4053, Test Accuracy = 0.1144\n",
      "Iteration 1155: Loss = 2.9644, Accuracy = 0.3600 Test Loss = 54.4007, Test Accuracy = 0.1144\n",
      "Iteration 1156: Loss = 2.9601, Accuracy = 0.3600 Test Loss = 54.3962, Test Accuracy = 0.1144\n",
      "Iteration 1157: Loss = 2.9559, Accuracy = 0.3600 Test Loss = 54.3917, Test Accuracy = 0.1144\n",
      "Iteration 1158: Loss = 2.9517, Accuracy = 0.3600 Test Loss = 54.3872, Test Accuracy = 0.1144\n",
      "Iteration 1159: Loss = 2.9475, Accuracy = 0.3600 Test Loss = 54.3827, Test Accuracy = 0.1144\n",
      "Iteration 1160: Loss = 2.9433, Accuracy = 0.3600 Test Loss = 54.3782, Test Accuracy = 0.1144\n",
      "Iteration 1161: Loss = 2.9391, Accuracy = 0.3600 Test Loss = 54.3737, Test Accuracy = 0.1143\n",
      "Iteration 1162: Loss = 2.9349, Accuracy = 0.3600 Test Loss = 54.3692, Test Accuracy = 0.1143\n",
      "Iteration 1163: Loss = 2.9308, Accuracy = 0.3600 Test Loss = 54.3647, Test Accuracy = 0.1142\n",
      "Iteration 1164: Loss = 2.9266, Accuracy = 0.3600 Test Loss = 54.3602, Test Accuracy = 0.1142\n",
      "Iteration 1165: Loss = 2.9225, Accuracy = 0.3600 Test Loss = 54.3558, Test Accuracy = 0.1141\n",
      "Iteration 1166: Loss = 2.9183, Accuracy = 0.3600 Test Loss = 54.3513, Test Accuracy = 0.1141\n",
      "Iteration 1167: Loss = 2.9142, Accuracy = 0.3600 Test Loss = 54.3469, Test Accuracy = 0.1142\n",
      "Iteration 1168: Loss = 2.9100, Accuracy = 0.3700 Test Loss = 54.3425, Test Accuracy = 0.1142\n",
      "Iteration 1169: Loss = 2.9059, Accuracy = 0.3700 Test Loss = 54.3381, Test Accuracy = 0.1142\n",
      "Iteration 1170: Loss = 2.9018, Accuracy = 0.3700 Test Loss = 54.3336, Test Accuracy = 0.1142\n",
      "Iteration 1171: Loss = 2.8977, Accuracy = 0.3700 Test Loss = 54.3292, Test Accuracy = 0.1142\n",
      "Iteration 1172: Loss = 2.8936, Accuracy = 0.3700 Test Loss = 54.3248, Test Accuracy = 0.1142\n",
      "Iteration 1173: Loss = 2.8895, Accuracy = 0.3700 Test Loss = 54.3204, Test Accuracy = 0.1142\n",
      "Iteration 1174: Loss = 2.8854, Accuracy = 0.3700 Test Loss = 54.3161, Test Accuracy = 0.1142\n",
      "Iteration 1175: Loss = 2.8814, Accuracy = 0.3700 Test Loss = 54.3117, Test Accuracy = 0.1142\n",
      "Iteration 1176: Loss = 2.8773, Accuracy = 0.3700 Test Loss = 54.3073, Test Accuracy = 0.1142\n",
      "Iteration 1177: Loss = 2.8732, Accuracy = 0.3700 Test Loss = 54.3030, Test Accuracy = 0.1142\n",
      "Iteration 1178: Loss = 2.8692, Accuracy = 0.3700 Test Loss = 54.2986, Test Accuracy = 0.1143\n",
      "Iteration 1179: Loss = 2.8651, Accuracy = 0.3700 Test Loss = 54.2943, Test Accuracy = 0.1143\n",
      "Iteration 1180: Loss = 2.8611, Accuracy = 0.3700 Test Loss = 54.2900, Test Accuracy = 0.1144\n",
      "Iteration 1181: Loss = 2.8571, Accuracy = 0.3700 Test Loss = 54.2856, Test Accuracy = 0.1144\n",
      "Iteration 1182: Loss = 2.8530, Accuracy = 0.3700 Test Loss = 54.2813, Test Accuracy = 0.1144\n",
      "Iteration 1183: Loss = 2.8490, Accuracy = 0.3700 Test Loss = 54.2770, Test Accuracy = 0.1144\n",
      "Iteration 1184: Loss = 2.8450, Accuracy = 0.3700 Test Loss = 54.2727, Test Accuracy = 0.1145\n",
      "Iteration 1185: Loss = 2.8410, Accuracy = 0.3700 Test Loss = 54.2684, Test Accuracy = 0.1145\n",
      "Iteration 1186: Loss = 2.8370, Accuracy = 0.3700 Test Loss = 54.2642, Test Accuracy = 0.1145\n",
      "Iteration 1187: Loss = 2.8331, Accuracy = 0.3700 Test Loss = 54.2599, Test Accuracy = 0.1145\n",
      "Iteration 1188: Loss = 2.8291, Accuracy = 0.3700 Test Loss = 54.2556, Test Accuracy = 0.1146\n",
      "Iteration 1189: Loss = 2.8251, Accuracy = 0.3700 Test Loss = 54.2514, Test Accuracy = 0.1146\n",
      "Iteration 1190: Loss = 2.8212, Accuracy = 0.3700 Test Loss = 54.2471, Test Accuracy = 0.1145\n",
      "Iteration 1191: Loss = 2.8172, Accuracy = 0.3700 Test Loss = 54.2429, Test Accuracy = 0.1146\n",
      "Iteration 1192: Loss = 2.8133, Accuracy = 0.3700 Test Loss = 54.2386, Test Accuracy = 0.1146\n",
      "Iteration 1193: Loss = 2.8093, Accuracy = 0.3700 Test Loss = 54.2344, Test Accuracy = 0.1147\n",
      "Iteration 1194: Loss = 2.8054, Accuracy = 0.3700 Test Loss = 54.2302, Test Accuracy = 0.1148\n",
      "Iteration 1195: Loss = 2.8015, Accuracy = 0.3700 Test Loss = 54.2260, Test Accuracy = 0.1148\n",
      "Iteration 1196: Loss = 2.7975, Accuracy = 0.3700 Test Loss = 54.2218, Test Accuracy = 0.1148\n",
      "Iteration 1197: Loss = 2.7936, Accuracy = 0.3700 Test Loss = 54.2176, Test Accuracy = 0.1146\n",
      "Iteration 1198: Loss = 2.7897, Accuracy = 0.3700 Test Loss = 54.2134, Test Accuracy = 0.1145\n",
      "Iteration 1199: Loss = 2.7858, Accuracy = 0.3700 Test Loss = 54.2092, Test Accuracy = 0.1145\n",
      "Iteration 1200: Loss = 2.7820, Accuracy = 0.3700 Test Loss = 54.2051, Test Accuracy = 0.1144\n",
      "Iteration 1201: Loss = 2.7781, Accuracy = 0.3700 Test Loss = 54.2009, Test Accuracy = 0.1143\n",
      "Iteration 1202: Loss = 2.7742, Accuracy = 0.3700 Test Loss = 54.1968, Test Accuracy = 0.1143\n",
      "Iteration 1203: Loss = 2.7703, Accuracy = 0.3700 Test Loss = 54.1926, Test Accuracy = 0.1142\n",
      "Iteration 1204: Loss = 2.7665, Accuracy = 0.3700 Test Loss = 54.1885, Test Accuracy = 0.1141\n",
      "Iteration 1205: Loss = 2.7626, Accuracy = 0.3700 Test Loss = 54.1843, Test Accuracy = 0.1141\n",
      "Iteration 1206: Loss = 2.7588, Accuracy = 0.3700 Test Loss = 54.1802, Test Accuracy = 0.1141\n",
      "Iteration 1207: Loss = 2.7550, Accuracy = 0.3700 Test Loss = 54.1761, Test Accuracy = 0.1142\n",
      "Iteration 1208: Loss = 2.7511, Accuracy = 0.3700 Test Loss = 54.1720, Test Accuracy = 0.1142\n",
      "Iteration 1209: Loss = 2.7473, Accuracy = 0.3700 Test Loss = 54.1679, Test Accuracy = 0.1143\n",
      "Iteration 1210: Loss = 2.7435, Accuracy = 0.3700 Test Loss = 54.1638, Test Accuracy = 0.1142\n",
      "Iteration 1211: Loss = 2.7397, Accuracy = 0.3700 Test Loss = 54.1597, Test Accuracy = 0.1141\n",
      "Iteration 1212: Loss = 2.7359, Accuracy = 0.3700 Test Loss = 54.1557, Test Accuracy = 0.1139\n",
      "Iteration 1213: Loss = 2.7321, Accuracy = 0.3800 Test Loss = 54.1516, Test Accuracy = 0.1139\n",
      "Iteration 1214: Loss = 2.7283, Accuracy = 0.3800 Test Loss = 54.1475, Test Accuracy = 0.1140\n",
      "Iteration 1215: Loss = 2.7245, Accuracy = 0.3800 Test Loss = 54.1435, Test Accuracy = 0.1140\n",
      "Iteration 1216: Loss = 2.7208, Accuracy = 0.3900 Test Loss = 54.1394, Test Accuracy = 0.1140\n",
      "Iteration 1217: Loss = 2.7170, Accuracy = 0.3900 Test Loss = 54.1354, Test Accuracy = 0.1140\n",
      "Iteration 1218: Loss = 2.7132, Accuracy = 0.3900 Test Loss = 54.1314, Test Accuracy = 0.1140\n",
      "Iteration 1219: Loss = 2.7095, Accuracy = 0.3900 Test Loss = 54.1273, Test Accuracy = 0.1140\n",
      "Iteration 1220: Loss = 2.7058, Accuracy = 0.3900 Test Loss = 54.1233, Test Accuracy = 0.1140\n",
      "Iteration 1221: Loss = 2.7020, Accuracy = 0.3900 Test Loss = 54.1193, Test Accuracy = 0.1140\n",
      "Iteration 1222: Loss = 2.6983, Accuracy = 0.3900 Test Loss = 54.1153, Test Accuracy = 0.1140\n",
      "Iteration 1223: Loss = 2.6946, Accuracy = 0.3900 Test Loss = 54.1113, Test Accuracy = 0.1140\n",
      "Iteration 1224: Loss = 2.6908, Accuracy = 0.3900 Test Loss = 54.1073, Test Accuracy = 0.1140\n",
      "Iteration 1225: Loss = 2.6871, Accuracy = 0.4000 Test Loss = 54.1034, Test Accuracy = 0.1141\n",
      "Iteration 1226: Loss = 2.6834, Accuracy = 0.4000 Test Loss = 54.0994, Test Accuracy = 0.1141\n",
      "Iteration 1227: Loss = 2.6797, Accuracy = 0.4000 Test Loss = 54.0954, Test Accuracy = 0.1141\n",
      "Iteration 1228: Loss = 2.6761, Accuracy = 0.4000 Test Loss = 54.0915, Test Accuracy = 0.1141\n",
      "Iteration 1229: Loss = 2.6724, Accuracy = 0.4000 Test Loss = 54.0875, Test Accuracy = 0.1141\n",
      "Iteration 1230: Loss = 2.6687, Accuracy = 0.4000 Test Loss = 54.0836, Test Accuracy = 0.1141\n",
      "Iteration 1231: Loss = 2.6650, Accuracy = 0.4000 Test Loss = 54.0796, Test Accuracy = 0.1141\n",
      "Iteration 1232: Loss = 2.6614, Accuracy = 0.4100 Test Loss = 54.0757, Test Accuracy = 0.1142\n",
      "Iteration 1233: Loss = 2.6577, Accuracy = 0.4100 Test Loss = 54.0718, Test Accuracy = 0.1142\n",
      "Iteration 1234: Loss = 2.6541, Accuracy = 0.4100 Test Loss = 54.0679, Test Accuracy = 0.1142\n",
      "Iteration 1235: Loss = 2.6504, Accuracy = 0.4100 Test Loss = 54.0640, Test Accuracy = 0.1142\n",
      "Iteration 1236: Loss = 2.6468, Accuracy = 0.4100 Test Loss = 54.0601, Test Accuracy = 0.1142\n",
      "Iteration 1237: Loss = 2.6432, Accuracy = 0.4100 Test Loss = 54.0562, Test Accuracy = 0.1142\n",
      "Iteration 1238: Loss = 2.6395, Accuracy = 0.4100 Test Loss = 54.0523, Test Accuracy = 0.1142\n",
      "Iteration 1239: Loss = 2.6359, Accuracy = 0.4100 Test Loss = 54.0484, Test Accuracy = 0.1143\n",
      "Iteration 1240: Loss = 2.6323, Accuracy = 0.4100 Test Loss = 54.0446, Test Accuracy = 0.1143\n",
      "Iteration 1241: Loss = 2.6287, Accuracy = 0.4100 Test Loss = 54.0407, Test Accuracy = 0.1144\n",
      "Iteration 1242: Loss = 2.6251, Accuracy = 0.4100 Test Loss = 54.0368, Test Accuracy = 0.1144\n",
      "Iteration 1243: Loss = 2.6215, Accuracy = 0.4100 Test Loss = 54.0330, Test Accuracy = 0.1146\n",
      "Iteration 1244: Loss = 2.6180, Accuracy = 0.4100 Test Loss = 54.0292, Test Accuracy = 0.1146\n",
      "Iteration 1245: Loss = 2.6144, Accuracy = 0.4100 Test Loss = 54.0253, Test Accuracy = 0.1146\n",
      "Iteration 1246: Loss = 2.6108, Accuracy = 0.4100 Test Loss = 54.0215, Test Accuracy = 0.1148\n",
      "Iteration 1247: Loss = 2.6073, Accuracy = 0.4100 Test Loss = 54.0177, Test Accuracy = 0.1148\n",
      "Iteration 1248: Loss = 2.6037, Accuracy = 0.4100 Test Loss = 54.0139, Test Accuracy = 0.1148\n",
      "Iteration 1249: Loss = 2.6002, Accuracy = 0.4100 Test Loss = 54.0101, Test Accuracy = 0.1148\n",
      "Iteration 1250: Loss = 2.5966, Accuracy = 0.4100 Test Loss = 54.0062, Test Accuracy = 0.1150\n",
      "Iteration 1251: Loss = 2.5931, Accuracy = 0.4100 Test Loss = 54.0025, Test Accuracy = 0.1150\n",
      "Iteration 1252: Loss = 2.5895, Accuracy = 0.4100 Test Loss = 53.9987, Test Accuracy = 0.1152\n",
      "Iteration 1253: Loss = 2.5860, Accuracy = 0.4100 Test Loss = 53.9949, Test Accuracy = 0.1152\n",
      "Iteration 1254: Loss = 2.5825, Accuracy = 0.4100 Test Loss = 53.9911, Test Accuracy = 0.1152\n",
      "Iteration 1255: Loss = 2.5790, Accuracy = 0.4200 Test Loss = 53.9874, Test Accuracy = 0.1152\n",
      "Iteration 1256: Loss = 2.5755, Accuracy = 0.4200 Test Loss = 53.9836, Test Accuracy = 0.1151\n",
      "Iteration 1257: Loss = 2.5720, Accuracy = 0.4200 Test Loss = 53.9799, Test Accuracy = 0.1150\n",
      "Iteration 1258: Loss = 2.5685, Accuracy = 0.4200 Test Loss = 53.9761, Test Accuracy = 0.1149\n",
      "Iteration 1259: Loss = 2.5650, Accuracy = 0.4200 Test Loss = 53.9724, Test Accuracy = 0.1150\n",
      "Iteration 1260: Loss = 2.5615, Accuracy = 0.4200 Test Loss = 53.9687, Test Accuracy = 0.1149\n",
      "Iteration 1261: Loss = 2.5581, Accuracy = 0.4200 Test Loss = 53.9649, Test Accuracy = 0.1149\n",
      "Iteration 1262: Loss = 2.5546, Accuracy = 0.4200 Test Loss = 53.9612, Test Accuracy = 0.1149\n",
      "Iteration 1263: Loss = 2.5512, Accuracy = 0.4200 Test Loss = 53.9575, Test Accuracy = 0.1149\n",
      "Iteration 1264: Loss = 2.5477, Accuracy = 0.4200 Test Loss = 53.9538, Test Accuracy = 0.1150\n",
      "Iteration 1265: Loss = 2.5443, Accuracy = 0.4200 Test Loss = 53.9501, Test Accuracy = 0.1150\n",
      "Iteration 1266: Loss = 2.5408, Accuracy = 0.4200 Test Loss = 53.9464, Test Accuracy = 0.1150\n",
      "Iteration 1267: Loss = 2.5374, Accuracy = 0.4200 Test Loss = 53.9427, Test Accuracy = 0.1150\n",
      "Iteration 1268: Loss = 2.5340, Accuracy = 0.4200 Test Loss = 53.9391, Test Accuracy = 0.1151\n",
      "Iteration 1269: Loss = 2.5305, Accuracy = 0.4300 Test Loss = 53.9354, Test Accuracy = 0.1151\n",
      "Iteration 1270: Loss = 2.5271, Accuracy = 0.4300 Test Loss = 53.9317, Test Accuracy = 0.1151\n",
      "Iteration 1271: Loss = 2.5237, Accuracy = 0.4300 Test Loss = 53.9281, Test Accuracy = 0.1150\n",
      "Iteration 1272: Loss = 2.5203, Accuracy = 0.4300 Test Loss = 53.9244, Test Accuracy = 0.1151\n",
      "Iteration 1273: Loss = 2.5169, Accuracy = 0.4300 Test Loss = 53.9208, Test Accuracy = 0.1151\n",
      "Iteration 1274: Loss = 2.5135, Accuracy = 0.4300 Test Loss = 53.9172, Test Accuracy = 0.1151\n",
      "Iteration 1275: Loss = 2.5101, Accuracy = 0.4300 Test Loss = 53.9135, Test Accuracy = 0.1151\n",
      "Iteration 1276: Loss = 2.5068, Accuracy = 0.4300 Test Loss = 53.9099, Test Accuracy = 0.1151\n",
      "Iteration 1277: Loss = 2.5034, Accuracy = 0.4300 Test Loss = 53.9063, Test Accuracy = 0.1151\n",
      "Iteration 1278: Loss = 2.5000, Accuracy = 0.4300 Test Loss = 53.9027, Test Accuracy = 0.1150\n",
      "Iteration 1279: Loss = 2.4967, Accuracy = 0.4300 Test Loss = 53.8991, Test Accuracy = 0.1149\n",
      "Iteration 1280: Loss = 2.4933, Accuracy = 0.4300 Test Loss = 53.8955, Test Accuracy = 0.1149\n",
      "Iteration 1281: Loss = 2.4900, Accuracy = 0.4300 Test Loss = 53.8919, Test Accuracy = 0.1149\n",
      "Iteration 1282: Loss = 2.4866, Accuracy = 0.4300 Test Loss = 53.8883, Test Accuracy = 0.1149\n",
      "Iteration 1283: Loss = 2.4833, Accuracy = 0.4300 Test Loss = 53.8847, Test Accuracy = 0.1149\n",
      "Iteration 1284: Loss = 2.4799, Accuracy = 0.4300 Test Loss = 53.8812, Test Accuracy = 0.1150\n",
      "Iteration 1285: Loss = 2.4766, Accuracy = 0.4300 Test Loss = 53.8776, Test Accuracy = 0.1151\n",
      "Iteration 1286: Loss = 2.4733, Accuracy = 0.4300 Test Loss = 53.8740, Test Accuracy = 0.1152\n",
      "Iteration 1287: Loss = 2.4700, Accuracy = 0.4300 Test Loss = 53.8705, Test Accuracy = 0.1152\n",
      "Iteration 1288: Loss = 2.4667, Accuracy = 0.4300 Test Loss = 53.8670, Test Accuracy = 0.1152\n",
      "Iteration 1289: Loss = 2.4634, Accuracy = 0.4300 Test Loss = 53.8634, Test Accuracy = 0.1152\n",
      "Iteration 1290: Loss = 2.4601, Accuracy = 0.4300 Test Loss = 53.8599, Test Accuracy = 0.1152\n",
      "Iteration 1291: Loss = 2.4568, Accuracy = 0.4300 Test Loss = 53.8564, Test Accuracy = 0.1152\n",
      "Iteration 1292: Loss = 2.4535, Accuracy = 0.4300 Test Loss = 53.8528, Test Accuracy = 0.1153\n",
      "Iteration 1293: Loss = 2.4502, Accuracy = 0.4300 Test Loss = 53.8493, Test Accuracy = 0.1153\n",
      "Iteration 1294: Loss = 2.4470, Accuracy = 0.4300 Test Loss = 53.8458, Test Accuracy = 0.1154\n",
      "Iteration 1295: Loss = 2.4437, Accuracy = 0.4300 Test Loss = 53.8423, Test Accuracy = 0.1154\n",
      "Iteration 1296: Loss = 2.4404, Accuracy = 0.4300 Test Loss = 53.8388, Test Accuracy = 0.1156\n",
      "Iteration 1297: Loss = 2.4372, Accuracy = 0.4300 Test Loss = 53.8353, Test Accuracy = 0.1156\n",
      "Iteration 1298: Loss = 2.4339, Accuracy = 0.4300 Test Loss = 53.8319, Test Accuracy = 0.1154\n",
      "Iteration 1299: Loss = 2.4307, Accuracy = 0.4300 Test Loss = 53.8284, Test Accuracy = 0.1154\n",
      "Iteration 1300: Loss = 2.4275, Accuracy = 0.4300 Test Loss = 53.8249, Test Accuracy = 0.1155\n",
      "Iteration 1301: Loss = 2.4242, Accuracy = 0.4300 Test Loss = 53.8214, Test Accuracy = 0.1156\n",
      "Iteration 1302: Loss = 2.4210, Accuracy = 0.4300 Test Loss = 53.8180, Test Accuracy = 0.1157\n",
      "Iteration 1303: Loss = 2.4178, Accuracy = 0.4300 Test Loss = 53.8145, Test Accuracy = 0.1157\n",
      "Iteration 1304: Loss = 2.4146, Accuracy = 0.4300 Test Loss = 53.8111, Test Accuracy = 0.1157\n",
      "Iteration 1305: Loss = 2.4114, Accuracy = 0.4300 Test Loss = 53.8077, Test Accuracy = 0.1158\n",
      "Iteration 1306: Loss = 2.4082, Accuracy = 0.4300 Test Loss = 53.8042, Test Accuracy = 0.1158\n",
      "Iteration 1307: Loss = 2.4050, Accuracy = 0.4300 Test Loss = 53.8008, Test Accuracy = 0.1158\n",
      "Iteration 1308: Loss = 2.4018, Accuracy = 0.4300 Test Loss = 53.7974, Test Accuracy = 0.1157\n",
      "Iteration 1309: Loss = 2.3986, Accuracy = 0.4300 Test Loss = 53.7940, Test Accuracy = 0.1157\n",
      "Iteration 1310: Loss = 2.3954, Accuracy = 0.4300 Test Loss = 53.7906, Test Accuracy = 0.1157\n",
      "Iteration 1311: Loss = 2.3922, Accuracy = 0.4300 Test Loss = 53.7872, Test Accuracy = 0.1157\n",
      "Iteration 1312: Loss = 2.3891, Accuracy = 0.4300 Test Loss = 53.7838, Test Accuracy = 0.1157\n",
      "Iteration 1313: Loss = 2.3859, Accuracy = 0.4300 Test Loss = 53.7804, Test Accuracy = 0.1157\n",
      "Iteration 1314: Loss = 2.3828, Accuracy = 0.4300 Test Loss = 53.7770, Test Accuracy = 0.1157\n",
      "Iteration 1315: Loss = 2.3796, Accuracy = 0.4300 Test Loss = 53.7736, Test Accuracy = 0.1157\n",
      "Iteration 1316: Loss = 2.3765, Accuracy = 0.4300 Test Loss = 53.7703, Test Accuracy = 0.1157\n",
      "Iteration 1317: Loss = 2.3733, Accuracy = 0.4300 Test Loss = 53.7669, Test Accuracy = 0.1157\n",
      "Iteration 1318: Loss = 2.3702, Accuracy = 0.4300 Test Loss = 53.7635, Test Accuracy = 0.1157\n",
      "Iteration 1319: Loss = 2.3671, Accuracy = 0.4300 Test Loss = 53.7602, Test Accuracy = 0.1157\n",
      "Iteration 1320: Loss = 2.3639, Accuracy = 0.4300 Test Loss = 53.7568, Test Accuracy = 0.1157\n",
      "Iteration 1321: Loss = 2.3608, Accuracy = 0.4300 Test Loss = 53.7535, Test Accuracy = 0.1157\n",
      "Iteration 1322: Loss = 2.3577, Accuracy = 0.4300 Test Loss = 53.7502, Test Accuracy = 0.1157\n",
      "Iteration 1323: Loss = 2.3546, Accuracy = 0.4300 Test Loss = 53.7468, Test Accuracy = 0.1157\n",
      "Iteration 1324: Loss = 2.3515, Accuracy = 0.4300 Test Loss = 53.7435, Test Accuracy = 0.1158\n",
      "Iteration 1325: Loss = 2.3484, Accuracy = 0.4300 Test Loss = 53.7402, Test Accuracy = 0.1160\n",
      "Iteration 1326: Loss = 2.3453, Accuracy = 0.4300 Test Loss = 53.7369, Test Accuracy = 0.1160\n",
      "Iteration 1327: Loss = 2.3422, Accuracy = 0.4300 Test Loss = 53.7336, Test Accuracy = 0.1160\n",
      "Iteration 1328: Loss = 2.3391, Accuracy = 0.4300 Test Loss = 53.7303, Test Accuracy = 0.1160\n",
      "Iteration 1329: Loss = 2.3361, Accuracy = 0.4300 Test Loss = 53.7270, Test Accuracy = 0.1161\n",
      "Iteration 1330: Loss = 2.3330, Accuracy = 0.4300 Test Loss = 53.7237, Test Accuracy = 0.1162\n",
      "Iteration 1331: Loss = 2.3299, Accuracy = 0.4300 Test Loss = 53.7204, Test Accuracy = 0.1162\n",
      "Iteration 1332: Loss = 2.3269, Accuracy = 0.4300 Test Loss = 53.7171, Test Accuracy = 0.1162\n",
      "Iteration 1333: Loss = 2.3238, Accuracy = 0.4300 Test Loss = 53.7139, Test Accuracy = 0.1163\n",
      "Iteration 1334: Loss = 2.3208, Accuracy = 0.4300 Test Loss = 53.7106, Test Accuracy = 0.1162\n",
      "Iteration 1335: Loss = 2.3177, Accuracy = 0.4300 Test Loss = 53.7073, Test Accuracy = 0.1162\n",
      "Iteration 1336: Loss = 2.3147, Accuracy = 0.4300 Test Loss = 53.7041, Test Accuracy = 0.1162\n",
      "Iteration 1337: Loss = 2.3117, Accuracy = 0.4300 Test Loss = 53.7008, Test Accuracy = 0.1162\n",
      "Iteration 1338: Loss = 2.3086, Accuracy = 0.4300 Test Loss = 53.6976, Test Accuracy = 0.1162\n",
      "Iteration 1339: Loss = 2.3056, Accuracy = 0.4300 Test Loss = 53.6944, Test Accuracy = 0.1162\n",
      "Iteration 1340: Loss = 2.3026, Accuracy = 0.4300 Test Loss = 53.6911, Test Accuracy = 0.1162\n",
      "Iteration 1341: Loss = 2.2996, Accuracy = 0.4300 Test Loss = 53.6879, Test Accuracy = 0.1162\n",
      "Iteration 1342: Loss = 2.2966, Accuracy = 0.4300 Test Loss = 53.6847, Test Accuracy = 0.1161\n",
      "Iteration 1343: Loss = 2.2936, Accuracy = 0.4300 Test Loss = 53.6815, Test Accuracy = 0.1161\n",
      "Iteration 1344: Loss = 2.2906, Accuracy = 0.4300 Test Loss = 53.6783, Test Accuracy = 0.1161\n",
      "Iteration 1345: Loss = 2.2876, Accuracy = 0.4300 Test Loss = 53.6751, Test Accuracy = 0.1160\n",
      "Iteration 1346: Loss = 2.2846, Accuracy = 0.4300 Test Loss = 53.6719, Test Accuracy = 0.1160\n",
      "Iteration 1347: Loss = 2.2816, Accuracy = 0.4300 Test Loss = 53.6687, Test Accuracy = 0.1160\n",
      "Iteration 1348: Loss = 2.2786, Accuracy = 0.4300 Test Loss = 53.6655, Test Accuracy = 0.1160\n",
      "Iteration 1349: Loss = 2.2757, Accuracy = 0.4300 Test Loss = 53.6623, Test Accuracy = 0.1160\n",
      "Iteration 1350: Loss = 2.2727, Accuracy = 0.4300 Test Loss = 53.6591, Test Accuracy = 0.1160\n",
      "Iteration 1351: Loss = 2.2698, Accuracy = 0.4300 Test Loss = 53.6560, Test Accuracy = 0.1160\n",
      "Iteration 1352: Loss = 2.2668, Accuracy = 0.4300 Test Loss = 53.6528, Test Accuracy = 0.1160\n",
      "Iteration 1353: Loss = 2.2638, Accuracy = 0.4300 Test Loss = 53.6497, Test Accuracy = 0.1160\n",
      "Iteration 1354: Loss = 2.2609, Accuracy = 0.4300 Test Loss = 53.6465, Test Accuracy = 0.1161\n",
      "Iteration 1355: Loss = 2.2580, Accuracy = 0.4300 Test Loss = 53.6434, Test Accuracy = 0.1162\n",
      "Iteration 1356: Loss = 2.2550, Accuracy = 0.4300 Test Loss = 53.6402, Test Accuracy = 0.1161\n",
      "Iteration 1357: Loss = 2.2521, Accuracy = 0.4300 Test Loss = 53.6371, Test Accuracy = 0.1161\n",
      "Iteration 1358: Loss = 2.2492, Accuracy = 0.4300 Test Loss = 53.6340, Test Accuracy = 0.1161\n",
      "Iteration 1359: Loss = 2.2463, Accuracy = 0.4300 Test Loss = 53.6308, Test Accuracy = 0.1161\n",
      "Iteration 1360: Loss = 2.2433, Accuracy = 0.4300 Test Loss = 53.6277, Test Accuracy = 0.1161\n",
      "Iteration 1361: Loss = 2.2404, Accuracy = 0.4300 Test Loss = 53.6246, Test Accuracy = 0.1161\n",
      "Iteration 1362: Loss = 2.2375, Accuracy = 0.4300 Test Loss = 53.6215, Test Accuracy = 0.1161\n",
      "Iteration 1363: Loss = 2.2346, Accuracy = 0.4300 Test Loss = 53.6184, Test Accuracy = 0.1161\n",
      "Iteration 1364: Loss = 2.2317, Accuracy = 0.4300 Test Loss = 53.6153, Test Accuracy = 0.1161\n",
      "Iteration 1365: Loss = 2.2289, Accuracy = 0.4300 Test Loss = 53.6122, Test Accuracy = 0.1162\n",
      "Iteration 1366: Loss = 2.2260, Accuracy = 0.4300 Test Loss = 53.6091, Test Accuracy = 0.1163\n",
      "Iteration 1367: Loss = 2.2231, Accuracy = 0.4300 Test Loss = 53.6060, Test Accuracy = 0.1163\n",
      "Iteration 1368: Loss = 2.2202, Accuracy = 0.4300 Test Loss = 53.6030, Test Accuracy = 0.1163\n",
      "Iteration 1369: Loss = 2.2173, Accuracy = 0.4400 Test Loss = 53.5999, Test Accuracy = 0.1163\n",
      "Iteration 1370: Loss = 2.2145, Accuracy = 0.4400 Test Loss = 53.5968, Test Accuracy = 0.1163\n",
      "Iteration 1371: Loss = 2.2116, Accuracy = 0.4400 Test Loss = 53.5938, Test Accuracy = 0.1164\n",
      "Iteration 1372: Loss = 2.2088, Accuracy = 0.4400 Test Loss = 53.5907, Test Accuracy = 0.1165\n",
      "Iteration 1373: Loss = 2.2059, Accuracy = 0.4400 Test Loss = 53.5877, Test Accuracy = 0.1165\n",
      "Iteration 1374: Loss = 2.2031, Accuracy = 0.4400 Test Loss = 53.5846, Test Accuracy = 0.1165\n",
      "Iteration 1375: Loss = 2.2002, Accuracy = 0.4400 Test Loss = 53.5816, Test Accuracy = 0.1165\n",
      "Iteration 1376: Loss = 2.1974, Accuracy = 0.4400 Test Loss = 53.5786, Test Accuracy = 0.1164\n",
      "Iteration 1377: Loss = 2.1946, Accuracy = 0.4400 Test Loss = 53.5755, Test Accuracy = 0.1163\n",
      "Iteration 1378: Loss = 2.1917, Accuracy = 0.4400 Test Loss = 53.5725, Test Accuracy = 0.1163\n",
      "Iteration 1379: Loss = 2.1889, Accuracy = 0.4400 Test Loss = 53.5695, Test Accuracy = 0.1163\n",
      "Iteration 1380: Loss = 2.1861, Accuracy = 0.4400 Test Loss = 53.5665, Test Accuracy = 0.1162\n",
      "Iteration 1381: Loss = 2.1833, Accuracy = 0.4400 Test Loss = 53.5635, Test Accuracy = 0.1162\n",
      "Iteration 1382: Loss = 2.1805, Accuracy = 0.4400 Test Loss = 53.5605, Test Accuracy = 0.1162\n",
      "Iteration 1383: Loss = 2.1777, Accuracy = 0.4400 Test Loss = 53.5575, Test Accuracy = 0.1161\n",
      "Iteration 1384: Loss = 2.1749, Accuracy = 0.4400 Test Loss = 53.5545, Test Accuracy = 0.1161\n",
      "Iteration 1385: Loss = 2.1721, Accuracy = 0.4400 Test Loss = 53.5515, Test Accuracy = 0.1161\n",
      "Iteration 1386: Loss = 2.1693, Accuracy = 0.4400 Test Loss = 53.5485, Test Accuracy = 0.1161\n",
      "Iteration 1387: Loss = 2.1665, Accuracy = 0.4400 Test Loss = 53.5455, Test Accuracy = 0.1161\n",
      "Iteration 1388: Loss = 2.1638, Accuracy = 0.4400 Test Loss = 53.5426, Test Accuracy = 0.1161\n",
      "Iteration 1389: Loss = 2.1610, Accuracy = 0.4400 Test Loss = 53.5396, Test Accuracy = 0.1161\n",
      "Iteration 1390: Loss = 2.1582, Accuracy = 0.4400 Test Loss = 53.5366, Test Accuracy = 0.1161\n",
      "Iteration 1391: Loss = 2.1555, Accuracy = 0.4500 Test Loss = 53.5337, Test Accuracy = 0.1161\n",
      "Iteration 1392: Loss = 2.1527, Accuracy = 0.4500 Test Loss = 53.5307, Test Accuracy = 0.1161\n",
      "Iteration 1393: Loss = 2.1499, Accuracy = 0.4500 Test Loss = 53.5278, Test Accuracy = 0.1161\n",
      "Iteration 1394: Loss = 2.1472, Accuracy = 0.4500 Test Loss = 53.5249, Test Accuracy = 0.1161\n",
      "Iteration 1395: Loss = 2.1444, Accuracy = 0.4500 Test Loss = 53.5219, Test Accuracy = 0.1162\n",
      "Iteration 1396: Loss = 2.1417, Accuracy = 0.4500 Test Loss = 53.5190, Test Accuracy = 0.1162\n",
      "Iteration 1397: Loss = 2.1390, Accuracy = 0.4500 Test Loss = 53.5161, Test Accuracy = 0.1162\n",
      "Iteration 1398: Loss = 2.1362, Accuracy = 0.4500 Test Loss = 53.5131, Test Accuracy = 0.1162\n",
      "Iteration 1399: Loss = 2.1335, Accuracy = 0.4500 Test Loss = 53.5102, Test Accuracy = 0.1162\n",
      "Iteration 1400: Loss = 2.1308, Accuracy = 0.4500 Test Loss = 53.5073, Test Accuracy = 0.1162\n",
      "Iteration 1401: Loss = 2.1281, Accuracy = 0.4600 Test Loss = 53.5044, Test Accuracy = 0.1163\n",
      "Iteration 1402: Loss = 2.1254, Accuracy = 0.4600 Test Loss = 53.5015, Test Accuracy = 0.1163\n",
      "Iteration 1403: Loss = 2.1227, Accuracy = 0.4600 Test Loss = 53.4986, Test Accuracy = 0.1163\n",
      "Iteration 1404: Loss = 2.1200, Accuracy = 0.4600 Test Loss = 53.4957, Test Accuracy = 0.1163\n",
      "Iteration 1405: Loss = 2.1173, Accuracy = 0.4600 Test Loss = 53.4929, Test Accuracy = 0.1164\n",
      "Iteration 1406: Loss = 2.1146, Accuracy = 0.4600 Test Loss = 53.4900, Test Accuracy = 0.1164\n",
      "Iteration 1407: Loss = 2.1119, Accuracy = 0.4600 Test Loss = 53.4871, Test Accuracy = 0.1164\n",
      "Iteration 1408: Loss = 2.1092, Accuracy = 0.4600 Test Loss = 53.4842, Test Accuracy = 0.1164\n",
      "Iteration 1409: Loss = 2.1065, Accuracy = 0.4600 Test Loss = 53.4814, Test Accuracy = 0.1164\n",
      "Iteration 1410: Loss = 2.1038, Accuracy = 0.4700 Test Loss = 53.4785, Test Accuracy = 0.1163\n",
      "Iteration 1411: Loss = 2.1012, Accuracy = 0.4700 Test Loss = 53.4757, Test Accuracy = 0.1163\n",
      "Iteration 1412: Loss = 2.0985, Accuracy = 0.4700 Test Loss = 53.4728, Test Accuracy = 0.1163\n",
      "Iteration 1413: Loss = 2.0958, Accuracy = 0.4700 Test Loss = 53.4700, Test Accuracy = 0.1163\n",
      "Iteration 1414: Loss = 2.0932, Accuracy = 0.4800 Test Loss = 53.4671, Test Accuracy = 0.1163\n",
      "Iteration 1415: Loss = 2.0905, Accuracy = 0.4800 Test Loss = 53.4643, Test Accuracy = 0.1163\n",
      "Iteration 1416: Loss = 2.0879, Accuracy = 0.4800 Test Loss = 53.4614, Test Accuracy = 0.1163\n",
      "Iteration 1417: Loss = 2.0852, Accuracy = 0.4800 Test Loss = 53.4586, Test Accuracy = 0.1163\n",
      "Iteration 1418: Loss = 2.0826, Accuracy = 0.4800 Test Loss = 53.4558, Test Accuracy = 0.1163\n",
      "Iteration 1419: Loss = 2.0799, Accuracy = 0.4800 Test Loss = 53.4530, Test Accuracy = 0.1163\n",
      "Iteration 1420: Loss = 2.0773, Accuracy = 0.4800 Test Loss = 53.4502, Test Accuracy = 0.1163\n",
      "Iteration 1421: Loss = 2.0747, Accuracy = 0.4800 Test Loss = 53.4474, Test Accuracy = 0.1163\n",
      "Iteration 1422: Loss = 2.0721, Accuracy = 0.4800 Test Loss = 53.4446, Test Accuracy = 0.1163\n",
      "Iteration 1423: Loss = 2.0694, Accuracy = 0.4800 Test Loss = 53.4418, Test Accuracy = 0.1162\n",
      "Iteration 1424: Loss = 2.0668, Accuracy = 0.4800 Test Loss = 53.4390, Test Accuracy = 0.1160\n",
      "Iteration 1425: Loss = 2.0642, Accuracy = 0.4800 Test Loss = 53.4362, Test Accuracy = 0.1160\n",
      "Iteration 1426: Loss = 2.0616, Accuracy = 0.4800 Test Loss = 53.4334, Test Accuracy = 0.1160\n",
      "Iteration 1427: Loss = 2.0590, Accuracy = 0.4800 Test Loss = 53.4306, Test Accuracy = 0.1159\n",
      "Iteration 1428: Loss = 2.0564, Accuracy = 0.4800 Test Loss = 53.4278, Test Accuracy = 0.1159\n",
      "Iteration 1429: Loss = 2.0538, Accuracy = 0.4800 Test Loss = 53.4251, Test Accuracy = 0.1159\n",
      "Iteration 1430: Loss = 2.0512, Accuracy = 0.4800 Test Loss = 53.4223, Test Accuracy = 0.1160\n",
      "Iteration 1431: Loss = 2.0487, Accuracy = 0.4800 Test Loss = 53.4196, Test Accuracy = 0.1160\n",
      "Iteration 1432: Loss = 2.0461, Accuracy = 0.4800 Test Loss = 53.4168, Test Accuracy = 0.1160\n",
      "Iteration 1433: Loss = 2.0435, Accuracy = 0.4800 Test Loss = 53.4141, Test Accuracy = 0.1160\n",
      "Iteration 1434: Loss = 2.0409, Accuracy = 0.4800 Test Loss = 53.4113, Test Accuracy = 0.1159\n",
      "Iteration 1435: Loss = 2.0384, Accuracy = 0.4800 Test Loss = 53.4086, Test Accuracy = 0.1160\n",
      "Iteration 1436: Loss = 2.0358, Accuracy = 0.4800 Test Loss = 53.4058, Test Accuracy = 0.1161\n",
      "Iteration 1437: Loss = 2.0332, Accuracy = 0.4800 Test Loss = 53.4031, Test Accuracy = 0.1161\n",
      "Iteration 1438: Loss = 2.0307, Accuracy = 0.4800 Test Loss = 53.4004, Test Accuracy = 0.1161\n",
      "Iteration 1439: Loss = 2.0281, Accuracy = 0.4800 Test Loss = 53.3977, Test Accuracy = 0.1160\n",
      "Iteration 1440: Loss = 2.0256, Accuracy = 0.4800 Test Loss = 53.3949, Test Accuracy = 0.1160\n",
      "Iteration 1441: Loss = 2.0230, Accuracy = 0.4800 Test Loss = 53.3922, Test Accuracy = 0.1160\n",
      "Iteration 1442: Loss = 2.0205, Accuracy = 0.4800 Test Loss = 53.3895, Test Accuracy = 0.1160\n",
      "Iteration 1443: Loss = 2.0180, Accuracy = 0.4800 Test Loss = 53.3868, Test Accuracy = 0.1160\n",
      "Iteration 1444: Loss = 2.0154, Accuracy = 0.4800 Test Loss = 53.3841, Test Accuracy = 0.1161\n",
      "Iteration 1445: Loss = 2.0129, Accuracy = 0.4800 Test Loss = 53.3814, Test Accuracy = 0.1160\n",
      "Iteration 1446: Loss = 2.0104, Accuracy = 0.4800 Test Loss = 53.3787, Test Accuracy = 0.1160\n",
      "Iteration 1447: Loss = 2.0079, Accuracy = 0.4800 Test Loss = 53.3760, Test Accuracy = 0.1160\n",
      "Iteration 1448: Loss = 2.0054, Accuracy = 0.4800 Test Loss = 53.3734, Test Accuracy = 0.1160\n",
      "Iteration 1449: Loss = 2.0029, Accuracy = 0.4800 Test Loss = 53.3707, Test Accuracy = 0.1158\n",
      "Iteration 1450: Loss = 2.0004, Accuracy = 0.4800 Test Loss = 53.3680, Test Accuracy = 0.1158\n",
      "Iteration 1451: Loss = 1.9979, Accuracy = 0.4800 Test Loss = 53.3653, Test Accuracy = 0.1158\n",
      "Iteration 1452: Loss = 1.9954, Accuracy = 0.4800 Test Loss = 53.3627, Test Accuracy = 0.1158\n",
      "Iteration 1453: Loss = 1.9929, Accuracy = 0.4800 Test Loss = 53.3600, Test Accuracy = 0.1158\n",
      "Iteration 1454: Loss = 1.9904, Accuracy = 0.4800 Test Loss = 53.3574, Test Accuracy = 0.1159\n",
      "Iteration 1455: Loss = 1.9879, Accuracy = 0.4800 Test Loss = 53.3547, Test Accuracy = 0.1159\n",
      "Iteration 1456: Loss = 1.9854, Accuracy = 0.4800 Test Loss = 53.3521, Test Accuracy = 0.1159\n",
      "Iteration 1457: Loss = 1.9830, Accuracy = 0.4800 Test Loss = 53.3494, Test Accuracy = 0.1159\n",
      "Iteration 1458: Loss = 1.9805, Accuracy = 0.4800 Test Loss = 53.3468, Test Accuracy = 0.1159\n",
      "Iteration 1459: Loss = 1.9780, Accuracy = 0.4800 Test Loss = 53.3442, Test Accuracy = 0.1159\n",
      "Iteration 1460: Loss = 1.9756, Accuracy = 0.4800 Test Loss = 53.3415, Test Accuracy = 0.1159\n",
      "Iteration 1461: Loss = 1.9731, Accuracy = 0.4800 Test Loss = 53.3389, Test Accuracy = 0.1157\n",
      "Iteration 1462: Loss = 1.9706, Accuracy = 0.4800 Test Loss = 53.3363, Test Accuracy = 0.1156\n",
      "Iteration 1463: Loss = 1.9682, Accuracy = 0.4800 Test Loss = 53.3337, Test Accuracy = 0.1156\n",
      "Iteration 1464: Loss = 1.9657, Accuracy = 0.4800 Test Loss = 53.3311, Test Accuracy = 0.1156\n",
      "Iteration 1465: Loss = 1.9633, Accuracy = 0.4800 Test Loss = 53.3285, Test Accuracy = 0.1156\n",
      "Iteration 1466: Loss = 1.9609, Accuracy = 0.4800 Test Loss = 53.3259, Test Accuracy = 0.1156\n",
      "Iteration 1467: Loss = 1.9584, Accuracy = 0.4800 Test Loss = 53.3233, Test Accuracy = 0.1157\n",
      "Iteration 1468: Loss = 1.9560, Accuracy = 0.4800 Test Loss = 53.3207, Test Accuracy = 0.1157\n",
      "Iteration 1469: Loss = 1.9536, Accuracy = 0.4800 Test Loss = 53.3181, Test Accuracy = 0.1157\n",
      "Iteration 1470: Loss = 1.9511, Accuracy = 0.4800 Test Loss = 53.3155, Test Accuracy = 0.1157\n",
      "Iteration 1471: Loss = 1.9487, Accuracy = 0.4800 Test Loss = 53.3129, Test Accuracy = 0.1157\n",
      "Iteration 1472: Loss = 1.9463, Accuracy = 0.4800 Test Loss = 53.3103, Test Accuracy = 0.1157\n",
      "Iteration 1473: Loss = 1.9439, Accuracy = 0.4800 Test Loss = 53.3078, Test Accuracy = 0.1157\n",
      "Iteration 1474: Loss = 1.9415, Accuracy = 0.4800 Test Loss = 53.3052, Test Accuracy = 0.1157\n",
      "Iteration 1475: Loss = 1.9391, Accuracy = 0.4800 Test Loss = 53.3027, Test Accuracy = 0.1157\n",
      "Iteration 1476: Loss = 1.9367, Accuracy = 0.4800 Test Loss = 53.3001, Test Accuracy = 0.1157\n",
      "Iteration 1477: Loss = 1.9343, Accuracy = 0.4800 Test Loss = 53.2975, Test Accuracy = 0.1157\n",
      "Iteration 1478: Loss = 1.9319, Accuracy = 0.4800 Test Loss = 53.2950, Test Accuracy = 0.1157\n",
      "Iteration 1479: Loss = 1.9295, Accuracy = 0.4800 Test Loss = 53.2924, Test Accuracy = 0.1157\n",
      "Iteration 1480: Loss = 1.9271, Accuracy = 0.4800 Test Loss = 53.2899, Test Accuracy = 0.1157\n",
      "Iteration 1481: Loss = 1.9247, Accuracy = 0.4800 Test Loss = 53.2874, Test Accuracy = 0.1157\n",
      "Iteration 1482: Loss = 1.9224, Accuracy = 0.4800 Test Loss = 53.2848, Test Accuracy = 0.1157\n",
      "Iteration 1483: Loss = 1.9200, Accuracy = 0.4800 Test Loss = 53.2823, Test Accuracy = 0.1157\n",
      "Iteration 1484: Loss = 1.9176, Accuracy = 0.4800 Test Loss = 53.2798, Test Accuracy = 0.1157\n",
      "Iteration 1485: Loss = 1.9153, Accuracy = 0.4800 Test Loss = 53.2773, Test Accuracy = 0.1157\n",
      "Iteration 1486: Loss = 1.9129, Accuracy = 0.4800 Test Loss = 53.2747, Test Accuracy = 0.1158\n",
      "Iteration 1487: Loss = 1.9106, Accuracy = 0.4800 Test Loss = 53.2722, Test Accuracy = 0.1158\n",
      "Iteration 1488: Loss = 1.9082, Accuracy = 0.4800 Test Loss = 53.2697, Test Accuracy = 0.1158\n",
      "Iteration 1489: Loss = 1.9058, Accuracy = 0.4800 Test Loss = 53.2672, Test Accuracy = 0.1158\n",
      "Iteration 1490: Loss = 1.9035, Accuracy = 0.4800 Test Loss = 53.2647, Test Accuracy = 0.1158\n",
      "Iteration 1491: Loss = 1.9012, Accuracy = 0.4800 Test Loss = 53.2622, Test Accuracy = 0.1159\n",
      "Iteration 1492: Loss = 1.8988, Accuracy = 0.4800 Test Loss = 53.2597, Test Accuracy = 0.1159\n",
      "Iteration 1493: Loss = 1.8965, Accuracy = 0.4800 Test Loss = 53.2573, Test Accuracy = 0.1159\n",
      "Iteration 1494: Loss = 1.8942, Accuracy = 0.4800 Test Loss = 53.2548, Test Accuracy = 0.1159\n",
      "Iteration 1495: Loss = 1.8918, Accuracy = 0.4800 Test Loss = 53.2523, Test Accuracy = 0.1160\n",
      "Iteration 1496: Loss = 1.8895, Accuracy = 0.4800 Test Loss = 53.2498, Test Accuracy = 0.1160\n",
      "Iteration 1497: Loss = 1.8872, Accuracy = 0.4800 Test Loss = 53.2473, Test Accuracy = 0.1159\n",
      "Iteration 1498: Loss = 1.8849, Accuracy = 0.4900 Test Loss = 53.2449, Test Accuracy = 0.1159\n",
      "Iteration 1499: Loss = 1.8826, Accuracy = 0.4900 Test Loss = 53.2424, Test Accuracy = 0.1159\n",
      "Iteration 1500: Loss = 1.8803, Accuracy = 0.4900 Test Loss = 53.2400, Test Accuracy = 0.1160\n",
      "Iteration 1501: Loss = 1.8780, Accuracy = 0.4900 Test Loss = 53.2375, Test Accuracy = 0.1160\n",
      "Iteration 1502: Loss = 1.8757, Accuracy = 0.4900 Test Loss = 53.2351, Test Accuracy = 0.1160\n",
      "Iteration 1503: Loss = 1.8734, Accuracy = 0.4900 Test Loss = 53.2326, Test Accuracy = 0.1159\n",
      "Iteration 1504: Loss = 1.8711, Accuracy = 0.4900 Test Loss = 53.2302, Test Accuracy = 0.1158\n",
      "Iteration 1505: Loss = 1.8688, Accuracy = 0.4900 Test Loss = 53.2277, Test Accuracy = 0.1158\n",
      "Iteration 1506: Loss = 1.8665, Accuracy = 0.4900 Test Loss = 53.2253, Test Accuracy = 0.1158\n",
      "Iteration 1507: Loss = 1.8642, Accuracy = 0.4900 Test Loss = 53.2229, Test Accuracy = 0.1158\n",
      "Iteration 1508: Loss = 1.8619, Accuracy = 0.4900 Test Loss = 53.2205, Test Accuracy = 0.1159\n",
      "Iteration 1509: Loss = 1.8597, Accuracy = 0.4900 Test Loss = 53.2180, Test Accuracy = 0.1159\n",
      "Iteration 1510: Loss = 1.8574, Accuracy = 0.4900 Test Loss = 53.2156, Test Accuracy = 0.1159\n",
      "Iteration 1511: Loss = 1.8551, Accuracy = 0.4900 Test Loss = 53.2132, Test Accuracy = 0.1159\n",
      "Iteration 1512: Loss = 1.8528, Accuracy = 0.4900 Test Loss = 53.2108, Test Accuracy = 0.1159\n",
      "Iteration 1513: Loss = 1.8506, Accuracy = 0.4900 Test Loss = 53.2084, Test Accuracy = 0.1159\n",
      "Iteration 1514: Loss = 1.8483, Accuracy = 0.4900 Test Loss = 53.2060, Test Accuracy = 0.1160\n",
      "Iteration 1515: Loss = 1.8461, Accuracy = 0.4900 Test Loss = 53.2036, Test Accuracy = 0.1160\n",
      "Iteration 1516: Loss = 1.8438, Accuracy = 0.4900 Test Loss = 53.2012, Test Accuracy = 0.1160\n",
      "Iteration 1517: Loss = 1.8416, Accuracy = 0.4900 Test Loss = 53.1988, Test Accuracy = 0.1160\n",
      "Iteration 1518: Loss = 1.8393, Accuracy = 0.4900 Test Loss = 53.1964, Test Accuracy = 0.1160\n",
      "Iteration 1519: Loss = 1.8371, Accuracy = 0.4900 Test Loss = 53.1940, Test Accuracy = 0.1160\n",
      "Iteration 1520: Loss = 1.8349, Accuracy = 0.4900 Test Loss = 53.1917, Test Accuracy = 0.1160\n",
      "Iteration 1521: Loss = 1.8326, Accuracy = 0.4900 Test Loss = 53.1893, Test Accuracy = 0.1160\n",
      "Iteration 1522: Loss = 1.8304, Accuracy = 0.4900 Test Loss = 53.1869, Test Accuracy = 0.1160\n",
      "Iteration 1523: Loss = 1.8282, Accuracy = 0.4900 Test Loss = 53.1845, Test Accuracy = 0.1160\n",
      "Iteration 1524: Loss = 1.8260, Accuracy = 0.4900 Test Loss = 53.1822, Test Accuracy = 0.1161\n",
      "Iteration 1525: Loss = 1.8237, Accuracy = 0.4900 Test Loss = 53.1798, Test Accuracy = 0.1161\n",
      "Iteration 1526: Loss = 1.8215, Accuracy = 0.4900 Test Loss = 53.1775, Test Accuracy = 0.1161\n",
      "Iteration 1527: Loss = 1.8193, Accuracy = 0.4900 Test Loss = 53.1751, Test Accuracy = 0.1161\n",
      "Iteration 1528: Loss = 1.8171, Accuracy = 0.4900 Test Loss = 53.1728, Test Accuracy = 0.1161\n",
      "Iteration 1529: Loss = 1.8149, Accuracy = 0.4900 Test Loss = 53.1704, Test Accuracy = 0.1159\n",
      "Iteration 1530: Loss = 1.8127, Accuracy = 0.4900 Test Loss = 53.1681, Test Accuracy = 0.1159\n",
      "Iteration 1531: Loss = 1.8105, Accuracy = 0.4900 Test Loss = 53.1657, Test Accuracy = 0.1159\n",
      "Iteration 1532: Loss = 1.8083, Accuracy = 0.4900 Test Loss = 53.1634, Test Accuracy = 0.1157\n",
      "Iteration 1533: Loss = 1.8061, Accuracy = 0.4900 Test Loss = 53.1611, Test Accuracy = 0.1159\n",
      "Iteration 1534: Loss = 1.8039, Accuracy = 0.4900 Test Loss = 53.1588, Test Accuracy = 0.1159\n",
      "Iteration 1535: Loss = 1.8018, Accuracy = 0.4900 Test Loss = 53.1564, Test Accuracy = 0.1159\n",
      "Iteration 1536: Loss = 1.7996, Accuracy = 0.4900 Test Loss = 53.1541, Test Accuracy = 0.1159\n",
      "Iteration 1537: Loss = 1.7974, Accuracy = 0.5000 Test Loss = 53.1518, Test Accuracy = 0.1158\n",
      "Iteration 1538: Loss = 1.7952, Accuracy = 0.5000 Test Loss = 53.1495, Test Accuracy = 0.1158\n",
      "Iteration 1539: Loss = 1.7931, Accuracy = 0.5000 Test Loss = 53.1472, Test Accuracy = 0.1158\n",
      "Iteration 1540: Loss = 1.7909, Accuracy = 0.5000 Test Loss = 53.1449, Test Accuracy = 0.1158\n",
      "Iteration 1541: Loss = 1.7887, Accuracy = 0.5000 Test Loss = 53.1426, Test Accuracy = 0.1158\n",
      "Iteration 1542: Loss = 1.7866, Accuracy = 0.5000 Test Loss = 53.1403, Test Accuracy = 0.1158\n",
      "Iteration 1543: Loss = 1.7844, Accuracy = 0.5000 Test Loss = 53.1380, Test Accuracy = 0.1158\n",
      "Iteration 1544: Loss = 1.7823, Accuracy = 0.5000 Test Loss = 53.1357, Test Accuracy = 0.1158\n",
      "Iteration 1545: Loss = 1.7801, Accuracy = 0.5000 Test Loss = 53.1334, Test Accuracy = 0.1157\n",
      "Iteration 1546: Loss = 1.7780, Accuracy = 0.5000 Test Loss = 53.1312, Test Accuracy = 0.1157\n",
      "Iteration 1547: Loss = 1.7758, Accuracy = 0.5100 Test Loss = 53.1289, Test Accuracy = 0.1156\n",
      "Iteration 1548: Loss = 1.7737, Accuracy = 0.5100 Test Loss = 53.1266, Test Accuracy = 0.1156\n",
      "Iteration 1549: Loss = 1.7716, Accuracy = 0.5200 Test Loss = 53.1244, Test Accuracy = 0.1155\n",
      "Iteration 1550: Loss = 1.7694, Accuracy = 0.5200 Test Loss = 53.1221, Test Accuracy = 0.1156\n",
      "Iteration 1551: Loss = 1.7673, Accuracy = 0.5200 Test Loss = 53.1198, Test Accuracy = 0.1156\n",
      "Iteration 1552: Loss = 1.7652, Accuracy = 0.5200 Test Loss = 53.1176, Test Accuracy = 0.1156\n",
      "Iteration 1553: Loss = 1.7631, Accuracy = 0.5200 Test Loss = 53.1153, Test Accuracy = 0.1157\n",
      "Iteration 1554: Loss = 1.7609, Accuracy = 0.5200 Test Loss = 53.1131, Test Accuracy = 0.1157\n",
      "Iteration 1555: Loss = 1.7588, Accuracy = 0.5200 Test Loss = 53.1108, Test Accuracy = 0.1156\n",
      "Iteration 1556: Loss = 1.7567, Accuracy = 0.5200 Test Loss = 53.1086, Test Accuracy = 0.1156\n",
      "Iteration 1557: Loss = 1.7546, Accuracy = 0.5200 Test Loss = 53.1063, Test Accuracy = 0.1156\n",
      "Iteration 1558: Loss = 1.7525, Accuracy = 0.5200 Test Loss = 53.1041, Test Accuracy = 0.1156\n",
      "Iteration 1559: Loss = 1.7504, Accuracy = 0.5200 Test Loss = 53.1019, Test Accuracy = 0.1156\n",
      "Iteration 1560: Loss = 1.7483, Accuracy = 0.5200 Test Loss = 53.0997, Test Accuracy = 0.1156\n",
      "Iteration 1561: Loss = 1.7462, Accuracy = 0.5200 Test Loss = 53.0974, Test Accuracy = 0.1156\n",
      "Iteration 1562: Loss = 1.7441, Accuracy = 0.5200 Test Loss = 53.0952, Test Accuracy = 0.1156\n",
      "Iteration 1563: Loss = 1.7420, Accuracy = 0.5200 Test Loss = 53.0930, Test Accuracy = 0.1156\n",
      "Iteration 1564: Loss = 1.7399, Accuracy = 0.5200 Test Loss = 53.0908, Test Accuracy = 0.1156\n",
      "Iteration 1565: Loss = 1.7379, Accuracy = 0.5200 Test Loss = 53.0886, Test Accuracy = 0.1156\n",
      "Iteration 1566: Loss = 1.7358, Accuracy = 0.5200 Test Loss = 53.0864, Test Accuracy = 0.1156\n",
      "Iteration 1567: Loss = 1.7337, Accuracy = 0.5200 Test Loss = 53.0842, Test Accuracy = 0.1156\n",
      "Iteration 1568: Loss = 1.7316, Accuracy = 0.5200 Test Loss = 53.0820, Test Accuracy = 0.1156\n",
      "Iteration 1569: Loss = 1.7296, Accuracy = 0.5200 Test Loss = 53.0798, Test Accuracy = 0.1157\n",
      "Iteration 1570: Loss = 1.7275, Accuracy = 0.5200 Test Loss = 53.0776, Test Accuracy = 0.1157\n",
      "Iteration 1571: Loss = 1.7254, Accuracy = 0.5200 Test Loss = 53.0754, Test Accuracy = 0.1157\n",
      "Iteration 1572: Loss = 1.7234, Accuracy = 0.5200 Test Loss = 53.0732, Test Accuracy = 0.1157\n",
      "Iteration 1573: Loss = 1.7213, Accuracy = 0.5200 Test Loss = 53.0710, Test Accuracy = 0.1157\n",
      "Iteration 1574: Loss = 1.7193, Accuracy = 0.5200 Test Loss = 53.0688, Test Accuracy = 0.1157\n",
      "Iteration 1575: Loss = 1.7172, Accuracy = 0.5200 Test Loss = 53.0667, Test Accuracy = 0.1157\n",
      "Iteration 1576: Loss = 1.7152, Accuracy = 0.5200 Test Loss = 53.0645, Test Accuracy = 0.1156\n",
      "Iteration 1577: Loss = 1.7131, Accuracy = 0.5200 Test Loss = 53.0623, Test Accuracy = 0.1156\n",
      "Iteration 1578: Loss = 1.7111, Accuracy = 0.5200 Test Loss = 53.0602, Test Accuracy = 0.1156\n",
      "Iteration 1579: Loss = 1.7091, Accuracy = 0.5200 Test Loss = 53.0580, Test Accuracy = 0.1156\n",
      "Iteration 1580: Loss = 1.7070, Accuracy = 0.5200 Test Loss = 53.0559, Test Accuracy = 0.1156\n",
      "Iteration 1581: Loss = 1.7050, Accuracy = 0.5200 Test Loss = 53.0537, Test Accuracy = 0.1156\n",
      "Iteration 1582: Loss = 1.7030, Accuracy = 0.5200 Test Loss = 53.0516, Test Accuracy = 0.1156\n",
      "Iteration 1583: Loss = 1.7009, Accuracy = 0.5200 Test Loss = 53.0494, Test Accuracy = 0.1156\n",
      "Iteration 1584: Loss = 1.6989, Accuracy = 0.5200 Test Loss = 53.0472, Test Accuracy = 0.1156\n",
      "Iteration 1585: Loss = 1.6969, Accuracy = 0.5200 Test Loss = 53.0451, Test Accuracy = 0.1156\n",
      "Iteration 1586: Loss = 1.6949, Accuracy = 0.5200 Test Loss = 53.0430, Test Accuracy = 0.1155\n",
      "Iteration 1587: Loss = 1.6929, Accuracy = 0.5200 Test Loss = 53.0409, Test Accuracy = 0.1155\n",
      "Iteration 1588: Loss = 1.6909, Accuracy = 0.5200 Test Loss = 53.0387, Test Accuracy = 0.1155\n",
      "Iteration 1589: Loss = 1.6889, Accuracy = 0.5200 Test Loss = 53.0366, Test Accuracy = 0.1155\n",
      "Iteration 1590: Loss = 1.6869, Accuracy = 0.5200 Test Loss = 53.0345, Test Accuracy = 0.1155\n",
      "Iteration 1591: Loss = 1.6849, Accuracy = 0.5200 Test Loss = 53.0324, Test Accuracy = 0.1155\n",
      "Iteration 1592: Loss = 1.6829, Accuracy = 0.5200 Test Loss = 53.0302, Test Accuracy = 0.1155\n",
      "Iteration 1593: Loss = 1.6809, Accuracy = 0.5200 Test Loss = 53.0281, Test Accuracy = 0.1155\n",
      "Iteration 1594: Loss = 1.6789, Accuracy = 0.5200 Test Loss = 53.0260, Test Accuracy = 0.1155\n",
      "Iteration 1595: Loss = 1.6769, Accuracy = 0.5200 Test Loss = 53.0239, Test Accuracy = 0.1154\n",
      "Iteration 1596: Loss = 1.6749, Accuracy = 0.5200 Test Loss = 53.0218, Test Accuracy = 0.1154\n",
      "Iteration 1597: Loss = 1.6729, Accuracy = 0.5200 Test Loss = 53.0197, Test Accuracy = 0.1154\n",
      "Iteration 1598: Loss = 1.6710, Accuracy = 0.5200 Test Loss = 53.0176, Test Accuracy = 0.1155\n",
      "Iteration 1599: Loss = 1.6690, Accuracy = 0.5200 Test Loss = 53.0155, Test Accuracy = 0.1155\n",
      "Iteration 1600: Loss = 1.6670, Accuracy = 0.5200 Test Loss = 53.0134, Test Accuracy = 0.1155\n",
      "Iteration 1601: Loss = 1.6650, Accuracy = 0.5200 Test Loss = 53.0113, Test Accuracy = 0.1155\n",
      "Iteration 1602: Loss = 1.6631, Accuracy = 0.5200 Test Loss = 53.0093, Test Accuracy = 0.1155\n",
      "Iteration 1603: Loss = 1.6611, Accuracy = 0.5200 Test Loss = 53.0072, Test Accuracy = 0.1155\n",
      "Iteration 1604: Loss = 1.6592, Accuracy = 0.5200 Test Loss = 53.0051, Test Accuracy = 0.1155\n",
      "Iteration 1605: Loss = 1.6572, Accuracy = 0.5200 Test Loss = 53.0030, Test Accuracy = 0.1155\n",
      "Iteration 1606: Loss = 1.6552, Accuracy = 0.5200 Test Loss = 53.0010, Test Accuracy = 0.1155\n",
      "Iteration 1607: Loss = 1.6533, Accuracy = 0.5200 Test Loss = 52.9989, Test Accuracy = 0.1155\n",
      "Iteration 1608: Loss = 1.6514, Accuracy = 0.5200 Test Loss = 52.9968, Test Accuracy = 0.1155\n",
      "Iteration 1609: Loss = 1.6494, Accuracy = 0.5200 Test Loss = 52.9948, Test Accuracy = 0.1155\n",
      "Iteration 1610: Loss = 1.6475, Accuracy = 0.5200 Test Loss = 52.9927, Test Accuracy = 0.1155\n",
      "Iteration 1611: Loss = 1.6455, Accuracy = 0.5200 Test Loss = 52.9907, Test Accuracy = 0.1155\n",
      "Iteration 1612: Loss = 1.6436, Accuracy = 0.5200 Test Loss = 52.9886, Test Accuracy = 0.1155\n",
      "Iteration 1613: Loss = 1.6417, Accuracy = 0.5200 Test Loss = 52.9866, Test Accuracy = 0.1155\n",
      "Iteration 1614: Loss = 1.6397, Accuracy = 0.5200 Test Loss = 52.9845, Test Accuracy = 0.1155\n",
      "Iteration 1615: Loss = 1.6378, Accuracy = 0.5200 Test Loss = 52.9825, Test Accuracy = 0.1155\n",
      "Iteration 1616: Loss = 1.6359, Accuracy = 0.5200 Test Loss = 52.9805, Test Accuracy = 0.1154\n",
      "Iteration 1617: Loss = 1.6340, Accuracy = 0.5200 Test Loss = 52.9784, Test Accuracy = 0.1154\n",
      "Iteration 1618: Loss = 1.6320, Accuracy = 0.5200 Test Loss = 52.9764, Test Accuracy = 0.1154\n",
      "Iteration 1619: Loss = 1.6301, Accuracy = 0.5200 Test Loss = 52.9744, Test Accuracy = 0.1154\n",
      "Iteration 1620: Loss = 1.6282, Accuracy = 0.5200 Test Loss = 52.9724, Test Accuracy = 0.1154\n",
      "Iteration 1621: Loss = 1.6263, Accuracy = 0.5300 Test Loss = 52.9703, Test Accuracy = 0.1154\n",
      "Iteration 1622: Loss = 1.6244, Accuracy = 0.5300 Test Loss = 52.9683, Test Accuracy = 0.1155\n",
      "Iteration 1623: Loss = 1.6225, Accuracy = 0.5300 Test Loss = 52.9663, Test Accuracy = 0.1155\n",
      "Iteration 1624: Loss = 1.6206, Accuracy = 0.5300 Test Loss = 52.9643, Test Accuracy = 0.1155\n",
      "Iteration 1625: Loss = 1.6187, Accuracy = 0.5300 Test Loss = 52.9623, Test Accuracy = 0.1155\n",
      "Iteration 1626: Loss = 1.6168, Accuracy = 0.5300 Test Loss = 52.9603, Test Accuracy = 0.1155\n",
      "Iteration 1627: Loss = 1.6149, Accuracy = 0.5300 Test Loss = 52.9583, Test Accuracy = 0.1155\n",
      "Iteration 1628: Loss = 1.6130, Accuracy = 0.5300 Test Loss = 52.9563, Test Accuracy = 0.1155\n",
      "Iteration 1629: Loss = 1.6111, Accuracy = 0.5300 Test Loss = 52.9543, Test Accuracy = 0.1155\n",
      "Iteration 1630: Loss = 1.6093, Accuracy = 0.5300 Test Loss = 52.9523, Test Accuracy = 0.1155\n",
      "Iteration 1631: Loss = 1.6074, Accuracy = 0.5300 Test Loss = 52.9503, Test Accuracy = 0.1155\n",
      "Iteration 1632: Loss = 1.6055, Accuracy = 0.5300 Test Loss = 52.9483, Test Accuracy = 0.1155\n",
      "Iteration 1633: Loss = 1.6036, Accuracy = 0.5300 Test Loss = 52.9463, Test Accuracy = 0.1155\n",
      "Iteration 1634: Loss = 1.6018, Accuracy = 0.5300 Test Loss = 52.9444, Test Accuracy = 0.1155\n",
      "Iteration 1635: Loss = 1.5999, Accuracy = 0.5300 Test Loss = 52.9424, Test Accuracy = 0.1155\n",
      "Iteration 1636: Loss = 1.5980, Accuracy = 0.5300 Test Loss = 52.9404, Test Accuracy = 0.1155\n",
      "Iteration 1637: Loss = 1.5962, Accuracy = 0.5300 Test Loss = 52.9384, Test Accuracy = 0.1155\n",
      "Iteration 1638: Loss = 1.5943, Accuracy = 0.5300 Test Loss = 52.9365, Test Accuracy = 0.1155\n",
      "Iteration 1639: Loss = 1.5924, Accuracy = 0.5300 Test Loss = 52.9345, Test Accuracy = 0.1155\n",
      "Iteration 1640: Loss = 1.5906, Accuracy = 0.5300 Test Loss = 52.9326, Test Accuracy = 0.1155\n",
      "Iteration 1641: Loss = 1.5887, Accuracy = 0.5300 Test Loss = 52.9306, Test Accuracy = 0.1156\n",
      "Iteration 1642: Loss = 1.5869, Accuracy = 0.5400 Test Loss = 52.9286, Test Accuracy = 0.1156\n",
      "Iteration 1643: Loss = 1.5850, Accuracy = 0.5400 Test Loss = 52.9267, Test Accuracy = 0.1156\n",
      "Iteration 1644: Loss = 1.5832, Accuracy = 0.5400 Test Loss = 52.9248, Test Accuracy = 0.1156\n",
      "Iteration 1645: Loss = 1.5814, Accuracy = 0.5400 Test Loss = 52.9228, Test Accuracy = 0.1156\n",
      "Iteration 1646: Loss = 1.5795, Accuracy = 0.5400 Test Loss = 52.9209, Test Accuracy = 0.1156\n",
      "Iteration 1647: Loss = 1.5777, Accuracy = 0.5400 Test Loss = 52.9189, Test Accuracy = 0.1156\n",
      "Iteration 1648: Loss = 1.5758, Accuracy = 0.5400 Test Loss = 52.9170, Test Accuracy = 0.1156\n",
      "Iteration 1649: Loss = 1.5740, Accuracy = 0.5400 Test Loss = 52.9151, Test Accuracy = 0.1156\n",
      "Iteration 1650: Loss = 1.5722, Accuracy = 0.5400 Test Loss = 52.9131, Test Accuracy = 0.1156\n",
      "Iteration 1651: Loss = 1.5704, Accuracy = 0.5400 Test Loss = 52.9112, Test Accuracy = 0.1156\n",
      "Iteration 1652: Loss = 1.5685, Accuracy = 0.5400 Test Loss = 52.9093, Test Accuracy = 0.1156\n",
      "Iteration 1653: Loss = 1.5667, Accuracy = 0.5400 Test Loss = 52.9074, Test Accuracy = 0.1156\n",
      "Iteration 1654: Loss = 1.5649, Accuracy = 0.5400 Test Loss = 52.9054, Test Accuracy = 0.1156\n",
      "Iteration 1655: Loss = 1.5631, Accuracy = 0.5400 Test Loss = 52.9035, Test Accuracy = 0.1156\n",
      "Iteration 1656: Loss = 1.5613, Accuracy = 0.5500 Test Loss = 52.9016, Test Accuracy = 0.1157\n",
      "Iteration 1657: Loss = 1.5595, Accuracy = 0.5500 Test Loss = 52.8997, Test Accuracy = 0.1155\n",
      "Iteration 1658: Loss = 1.5577, Accuracy = 0.5500 Test Loss = 52.8978, Test Accuracy = 0.1155\n",
      "Iteration 1659: Loss = 1.5559, Accuracy = 0.5500 Test Loss = 52.8959, Test Accuracy = 0.1155\n",
      "Iteration 1660: Loss = 1.5541, Accuracy = 0.5500 Test Loss = 52.8940, Test Accuracy = 0.1155\n",
      "Iteration 1661: Loss = 1.5523, Accuracy = 0.5500 Test Loss = 52.8921, Test Accuracy = 0.1156\n",
      "Iteration 1662: Loss = 1.5505, Accuracy = 0.5500 Test Loss = 52.8902, Test Accuracy = 0.1156\n",
      "Iteration 1663: Loss = 1.5487, Accuracy = 0.5500 Test Loss = 52.8883, Test Accuracy = 0.1155\n",
      "Iteration 1664: Loss = 1.5469, Accuracy = 0.5500 Test Loss = 52.8864, Test Accuracy = 0.1155\n",
      "Iteration 1665: Loss = 1.5451, Accuracy = 0.5500 Test Loss = 52.8846, Test Accuracy = 0.1158\n",
      "Iteration 1666: Loss = 1.5433, Accuracy = 0.5500 Test Loss = 52.8827, Test Accuracy = 0.1158\n",
      "Iteration 1667: Loss = 1.5416, Accuracy = 0.5500 Test Loss = 52.8808, Test Accuracy = 0.1158\n",
      "Iteration 1668: Loss = 1.5398, Accuracy = 0.5500 Test Loss = 52.8789, Test Accuracy = 0.1158\n",
      "Iteration 1669: Loss = 1.5380, Accuracy = 0.5500 Test Loss = 52.8770, Test Accuracy = 0.1160\n",
      "Iteration 1670: Loss = 1.5362, Accuracy = 0.5500 Test Loss = 52.8752, Test Accuracy = 0.1160\n",
      "Iteration 1671: Loss = 1.5345, Accuracy = 0.5500 Test Loss = 52.8733, Test Accuracy = 0.1160\n",
      "Iteration 1672: Loss = 1.5327, Accuracy = 0.5500 Test Loss = 52.8714, Test Accuracy = 0.1161\n",
      "Iteration 1673: Loss = 1.5309, Accuracy = 0.5500 Test Loss = 52.8696, Test Accuracy = 0.1161\n",
      "Iteration 1674: Loss = 1.5292, Accuracy = 0.5500 Test Loss = 52.8677, Test Accuracy = 0.1161\n",
      "Iteration 1675: Loss = 1.5274, Accuracy = 0.5500 Test Loss = 52.8659, Test Accuracy = 0.1161\n",
      "Iteration 1676: Loss = 1.5256, Accuracy = 0.5500 Test Loss = 52.8640, Test Accuracy = 0.1161\n",
      "Iteration 1677: Loss = 1.5239, Accuracy = 0.5500 Test Loss = 52.8622, Test Accuracy = 0.1161\n",
      "Iteration 1678: Loss = 1.5221, Accuracy = 0.5500 Test Loss = 52.8603, Test Accuracy = 0.1161\n",
      "Iteration 1679: Loss = 1.5204, Accuracy = 0.5500 Test Loss = 52.8585, Test Accuracy = 0.1160\n",
      "Iteration 1680: Loss = 1.5186, Accuracy = 0.5500 Test Loss = 52.8566, Test Accuracy = 0.1160\n",
      "Iteration 1681: Loss = 1.5169, Accuracy = 0.5500 Test Loss = 52.8548, Test Accuracy = 0.1160\n",
      "Iteration 1682: Loss = 1.5152, Accuracy = 0.5500 Test Loss = 52.8530, Test Accuracy = 0.1160\n",
      "Iteration 1683: Loss = 1.5134, Accuracy = 0.5500 Test Loss = 52.8511, Test Accuracy = 0.1159\n",
      "Iteration 1684: Loss = 1.5117, Accuracy = 0.5500 Test Loss = 52.8493, Test Accuracy = 0.1159\n",
      "Iteration 1685: Loss = 1.5100, Accuracy = 0.5500 Test Loss = 52.8475, Test Accuracy = 0.1159\n",
      "Iteration 1686: Loss = 1.5082, Accuracy = 0.5500 Test Loss = 52.8457, Test Accuracy = 0.1160\n",
      "Iteration 1687: Loss = 1.5065, Accuracy = 0.5500 Test Loss = 52.8438, Test Accuracy = 0.1160\n",
      "Iteration 1688: Loss = 1.5048, Accuracy = 0.5500 Test Loss = 52.8420, Test Accuracy = 0.1160\n",
      "Iteration 1689: Loss = 1.5030, Accuracy = 0.5500 Test Loss = 52.8402, Test Accuracy = 0.1160\n",
      "Iteration 1690: Loss = 1.5013, Accuracy = 0.5500 Test Loss = 52.8384, Test Accuracy = 0.1160\n",
      "Iteration 1691: Loss = 1.4996, Accuracy = 0.5500 Test Loss = 52.8366, Test Accuracy = 0.1160\n",
      "Iteration 1692: Loss = 1.4979, Accuracy = 0.5500 Test Loss = 52.8348, Test Accuracy = 0.1159\n",
      "Iteration 1693: Loss = 1.4962, Accuracy = 0.5500 Test Loss = 52.8330, Test Accuracy = 0.1159\n",
      "Iteration 1694: Loss = 1.4945, Accuracy = 0.5500 Test Loss = 52.8312, Test Accuracy = 0.1160\n",
      "Iteration 1695: Loss = 1.4928, Accuracy = 0.5500 Test Loss = 52.8294, Test Accuracy = 0.1160\n",
      "Iteration 1696: Loss = 1.4911, Accuracy = 0.5500 Test Loss = 52.8276, Test Accuracy = 0.1160\n",
      "Iteration 1697: Loss = 1.4894, Accuracy = 0.5500 Test Loss = 52.8258, Test Accuracy = 0.1160\n",
      "Iteration 1698: Loss = 1.4877, Accuracy = 0.5500 Test Loss = 52.8240, Test Accuracy = 0.1161\n",
      "Iteration 1699: Loss = 1.4860, Accuracy = 0.5500 Test Loss = 52.8222, Test Accuracy = 0.1161\n",
      "Iteration 1700: Loss = 1.4843, Accuracy = 0.5500 Test Loss = 52.8204, Test Accuracy = 0.1161\n",
      "Iteration 1701: Loss = 1.4826, Accuracy = 0.5500 Test Loss = 52.8187, Test Accuracy = 0.1161\n",
      "Iteration 1702: Loss = 1.4809, Accuracy = 0.5500 Test Loss = 52.8169, Test Accuracy = 0.1161\n",
      "Iteration 1703: Loss = 1.4792, Accuracy = 0.5500 Test Loss = 52.8151, Test Accuracy = 0.1161\n",
      "Iteration 1704: Loss = 1.4775, Accuracy = 0.5500 Test Loss = 52.8133, Test Accuracy = 0.1161\n",
      "Iteration 1705: Loss = 1.4758, Accuracy = 0.5500 Test Loss = 52.8116, Test Accuracy = 0.1161\n",
      "Iteration 1706: Loss = 1.4741, Accuracy = 0.5500 Test Loss = 52.8098, Test Accuracy = 0.1162\n",
      "Iteration 1707: Loss = 1.4725, Accuracy = 0.5500 Test Loss = 52.8080, Test Accuracy = 0.1162\n",
      "Iteration 1708: Loss = 1.4708, Accuracy = 0.5500 Test Loss = 52.8063, Test Accuracy = 0.1163\n",
      "Iteration 1709: Loss = 1.4691, Accuracy = 0.5500 Test Loss = 52.8045, Test Accuracy = 0.1163\n",
      "Iteration 1710: Loss = 1.4674, Accuracy = 0.5500 Test Loss = 52.8027, Test Accuracy = 0.1163\n",
      "Iteration 1711: Loss = 1.4658, Accuracy = 0.5500 Test Loss = 52.8010, Test Accuracy = 0.1162\n",
      "Iteration 1712: Loss = 1.4641, Accuracy = 0.5500 Test Loss = 52.7992, Test Accuracy = 0.1163\n",
      "Iteration 1713: Loss = 1.4625, Accuracy = 0.5500 Test Loss = 52.7975, Test Accuracy = 0.1163\n",
      "Iteration 1714: Loss = 1.4608, Accuracy = 0.5500 Test Loss = 52.7957, Test Accuracy = 0.1163\n",
      "Iteration 1715: Loss = 1.4591, Accuracy = 0.5500 Test Loss = 52.7940, Test Accuracy = 0.1163\n",
      "Iteration 1716: Loss = 1.4575, Accuracy = 0.5500 Test Loss = 52.7923, Test Accuracy = 0.1163\n",
      "Iteration 1717: Loss = 1.4558, Accuracy = 0.5500 Test Loss = 52.7905, Test Accuracy = 0.1163\n",
      "Iteration 1718: Loss = 1.4542, Accuracy = 0.5500 Test Loss = 52.7888, Test Accuracy = 0.1163\n",
      "Iteration 1719: Loss = 1.4525, Accuracy = 0.5500 Test Loss = 52.7871, Test Accuracy = 0.1163\n",
      "Iteration 1720: Loss = 1.4509, Accuracy = 0.5500 Test Loss = 52.7853, Test Accuracy = 0.1163\n",
      "Iteration 1721: Loss = 1.4492, Accuracy = 0.5500 Test Loss = 52.7836, Test Accuracy = 0.1163\n",
      "Iteration 1722: Loss = 1.4476, Accuracy = 0.5500 Test Loss = 52.7819, Test Accuracy = 0.1163\n",
      "Iteration 1723: Loss = 1.4460, Accuracy = 0.5500 Test Loss = 52.7802, Test Accuracy = 0.1163\n",
      "Iteration 1724: Loss = 1.4443, Accuracy = 0.5500 Test Loss = 52.7784, Test Accuracy = 0.1162\n",
      "Iteration 1725: Loss = 1.4427, Accuracy = 0.5500 Test Loss = 52.7767, Test Accuracy = 0.1161\n",
      "Iteration 1726: Loss = 1.4411, Accuracy = 0.5500 Test Loss = 52.7750, Test Accuracy = 0.1161\n",
      "Iteration 1727: Loss = 1.4394, Accuracy = 0.5500 Test Loss = 52.7733, Test Accuracy = 0.1162\n",
      "Iteration 1728: Loss = 1.4378, Accuracy = 0.5500 Test Loss = 52.7716, Test Accuracy = 0.1162\n",
      "Iteration 1729: Loss = 1.4362, Accuracy = 0.5500 Test Loss = 52.7699, Test Accuracy = 0.1162\n",
      "Iteration 1730: Loss = 1.4346, Accuracy = 0.5500 Test Loss = 52.7682, Test Accuracy = 0.1161\n",
      "Iteration 1731: Loss = 1.4329, Accuracy = 0.5500 Test Loss = 52.7665, Test Accuracy = 0.1161\n",
      "Iteration 1732: Loss = 1.4313, Accuracy = 0.5500 Test Loss = 52.7648, Test Accuracy = 0.1161\n",
      "Iteration 1733: Loss = 1.4297, Accuracy = 0.5500 Test Loss = 52.7631, Test Accuracy = 0.1161\n",
      "Iteration 1734: Loss = 1.4281, Accuracy = 0.5500 Test Loss = 52.7614, Test Accuracy = 0.1161\n",
      "Iteration 1735: Loss = 1.4265, Accuracy = 0.5500 Test Loss = 52.7597, Test Accuracy = 0.1161\n",
      "Iteration 1736: Loss = 1.4249, Accuracy = 0.5500 Test Loss = 52.7580, Test Accuracy = 0.1161\n",
      "Iteration 1737: Loss = 1.4233, Accuracy = 0.5500 Test Loss = 52.7563, Test Accuracy = 0.1161\n",
      "Iteration 1738: Loss = 1.4217, Accuracy = 0.5500 Test Loss = 52.7547, Test Accuracy = 0.1161\n",
      "Iteration 1739: Loss = 1.4201, Accuracy = 0.5500 Test Loss = 52.7530, Test Accuracy = 0.1162\n",
      "Iteration 1740: Loss = 1.4185, Accuracy = 0.5500 Test Loss = 52.7513, Test Accuracy = 0.1162\n",
      "Iteration 1741: Loss = 1.4169, Accuracy = 0.5500 Test Loss = 52.7496, Test Accuracy = 0.1161\n",
      "Iteration 1742: Loss = 1.4153, Accuracy = 0.5500 Test Loss = 52.7480, Test Accuracy = 0.1161\n",
      "Iteration 1743: Loss = 1.4137, Accuracy = 0.5500 Test Loss = 52.7463, Test Accuracy = 0.1160\n",
      "Iteration 1744: Loss = 1.4121, Accuracy = 0.5500 Test Loss = 52.7446, Test Accuracy = 0.1160\n",
      "Iteration 1745: Loss = 1.4105, Accuracy = 0.5500 Test Loss = 52.7430, Test Accuracy = 0.1160\n",
      "Iteration 1746: Loss = 1.4089, Accuracy = 0.5500 Test Loss = 52.7413, Test Accuracy = 0.1160\n",
      "Iteration 1747: Loss = 1.4073, Accuracy = 0.5500 Test Loss = 52.7396, Test Accuracy = 0.1160\n",
      "Iteration 1748: Loss = 1.4058, Accuracy = 0.5500 Test Loss = 52.7380, Test Accuracy = 0.1161\n",
      "Iteration 1749: Loss = 1.4042, Accuracy = 0.5500 Test Loss = 52.7363, Test Accuracy = 0.1161\n",
      "Iteration 1750: Loss = 1.4026, Accuracy = 0.5500 Test Loss = 52.7347, Test Accuracy = 0.1161\n",
      "Iteration 1751: Loss = 1.4010, Accuracy = 0.5500 Test Loss = 52.7330, Test Accuracy = 0.1161\n",
      "Iteration 1752: Loss = 1.3995, Accuracy = 0.5500 Test Loss = 52.7314, Test Accuracy = 0.1161\n",
      "Iteration 1753: Loss = 1.3979, Accuracy = 0.5500 Test Loss = 52.7297, Test Accuracy = 0.1161\n",
      "Iteration 1754: Loss = 1.3963, Accuracy = 0.5500 Test Loss = 52.7281, Test Accuracy = 0.1162\n",
      "Iteration 1755: Loss = 1.3948, Accuracy = 0.5500 Test Loss = 52.7265, Test Accuracy = 0.1162\n",
      "Iteration 1756: Loss = 1.3932, Accuracy = 0.5500 Test Loss = 52.7248, Test Accuracy = 0.1162\n",
      "Iteration 1757: Loss = 1.3916, Accuracy = 0.5500 Test Loss = 52.7232, Test Accuracy = 0.1162\n",
      "Iteration 1758: Loss = 1.3901, Accuracy = 0.5500 Test Loss = 52.7215, Test Accuracy = 0.1162\n",
      "Iteration 1759: Loss = 1.3885, Accuracy = 0.5500 Test Loss = 52.7199, Test Accuracy = 0.1163\n",
      "Iteration 1760: Loss = 1.3870, Accuracy = 0.5500 Test Loss = 52.7183, Test Accuracy = 0.1163\n",
      "Iteration 1761: Loss = 1.3854, Accuracy = 0.5500 Test Loss = 52.7167, Test Accuracy = 0.1163\n",
      "Iteration 1762: Loss = 1.3839, Accuracy = 0.5500 Test Loss = 52.7150, Test Accuracy = 0.1163\n",
      "Iteration 1763: Loss = 1.3823, Accuracy = 0.5500 Test Loss = 52.7134, Test Accuracy = 0.1162\n",
      "Iteration 1764: Loss = 1.3808, Accuracy = 0.5500 Test Loss = 52.7118, Test Accuracy = 0.1162\n",
      "Iteration 1765: Loss = 1.3793, Accuracy = 0.5500 Test Loss = 52.7102, Test Accuracy = 0.1162\n",
      "Iteration 1766: Loss = 1.3777, Accuracy = 0.5500 Test Loss = 52.7086, Test Accuracy = 0.1161\n",
      "Iteration 1767: Loss = 1.3762, Accuracy = 0.5500 Test Loss = 52.7070, Test Accuracy = 0.1160\n",
      "Iteration 1768: Loss = 1.3746, Accuracy = 0.5500 Test Loss = 52.7054, Test Accuracy = 0.1160\n",
      "Iteration 1769: Loss = 1.3731, Accuracy = 0.5500 Test Loss = 52.7038, Test Accuracy = 0.1160\n",
      "Iteration 1770: Loss = 1.3716, Accuracy = 0.5500 Test Loss = 52.7022, Test Accuracy = 0.1161\n",
      "Iteration 1771: Loss = 1.3701, Accuracy = 0.5500 Test Loss = 52.7006, Test Accuracy = 0.1161\n",
      "Iteration 1772: Loss = 1.3685, Accuracy = 0.5500 Test Loss = 52.6990, Test Accuracy = 0.1161\n",
      "Iteration 1773: Loss = 1.3670, Accuracy = 0.5500 Test Loss = 52.6974, Test Accuracy = 0.1161\n",
      "Iteration 1774: Loss = 1.3655, Accuracy = 0.5500 Test Loss = 52.6958, Test Accuracy = 0.1161\n",
      "Iteration 1775: Loss = 1.3640, Accuracy = 0.5500 Test Loss = 52.6942, Test Accuracy = 0.1161\n",
      "Iteration 1776: Loss = 1.3624, Accuracy = 0.5500 Test Loss = 52.6926, Test Accuracy = 0.1160\n",
      "Iteration 1777: Loss = 1.3609, Accuracy = 0.5500 Test Loss = 52.6910, Test Accuracy = 0.1160\n",
      "Iteration 1778: Loss = 1.3594, Accuracy = 0.5500 Test Loss = 52.6894, Test Accuracy = 0.1161\n",
      "Iteration 1779: Loss = 1.3579, Accuracy = 0.5500 Test Loss = 52.6879, Test Accuracy = 0.1161\n",
      "Iteration 1780: Loss = 1.3564, Accuracy = 0.5500 Test Loss = 52.6863, Test Accuracy = 0.1161\n",
      "Iteration 1781: Loss = 1.3549, Accuracy = 0.5500 Test Loss = 52.6847, Test Accuracy = 0.1162\n",
      "Iteration 1782: Loss = 1.3534, Accuracy = 0.5600 Test Loss = 52.6831, Test Accuracy = 0.1162\n",
      "Iteration 1783: Loss = 1.3519, Accuracy = 0.5600 Test Loss = 52.6816, Test Accuracy = 0.1162\n",
      "Iteration 1784: Loss = 1.3504, Accuracy = 0.5600 Test Loss = 52.6800, Test Accuracy = 0.1162\n",
      "Iteration 1785: Loss = 1.3489, Accuracy = 0.5600 Test Loss = 52.6784, Test Accuracy = 0.1163\n",
      "Iteration 1786: Loss = 1.3474, Accuracy = 0.5600 Test Loss = 52.6769, Test Accuracy = 0.1163\n",
      "Iteration 1787: Loss = 1.3459, Accuracy = 0.5600 Test Loss = 52.6753, Test Accuracy = 0.1163\n",
      "Iteration 1788: Loss = 1.3444, Accuracy = 0.5600 Test Loss = 52.6738, Test Accuracy = 0.1164\n",
      "Iteration 1789: Loss = 1.3429, Accuracy = 0.5600 Test Loss = 52.6722, Test Accuracy = 0.1164\n",
      "Iteration 1790: Loss = 1.3414, Accuracy = 0.5600 Test Loss = 52.6706, Test Accuracy = 0.1164\n",
      "Iteration 1791: Loss = 1.3399, Accuracy = 0.5700 Test Loss = 52.6691, Test Accuracy = 0.1164\n",
      "Iteration 1792: Loss = 1.3385, Accuracy = 0.5800 Test Loss = 52.6675, Test Accuracy = 0.1164\n",
      "Iteration 1793: Loss = 1.3370, Accuracy = 0.5800 Test Loss = 52.6660, Test Accuracy = 0.1164\n",
      "Iteration 1794: Loss = 1.3355, Accuracy = 0.5800 Test Loss = 52.6645, Test Accuracy = 0.1164\n",
      "Iteration 1795: Loss = 1.3340, Accuracy = 0.5800 Test Loss = 52.6629, Test Accuracy = 0.1164\n",
      "Iteration 1796: Loss = 1.3326, Accuracy = 0.5800 Test Loss = 52.6614, Test Accuracy = 0.1164\n",
      "Iteration 1797: Loss = 1.3311, Accuracy = 0.5800 Test Loss = 52.6598, Test Accuracy = 0.1163\n",
      "Iteration 1798: Loss = 1.3296, Accuracy = 0.5800 Test Loss = 52.6583, Test Accuracy = 0.1162\n",
      "Iteration 1799: Loss = 1.3281, Accuracy = 0.5800 Test Loss = 52.6568, Test Accuracy = 0.1162\n",
      "Iteration 1800: Loss = 1.3267, Accuracy = 0.5800 Test Loss = 52.6552, Test Accuracy = 0.1162\n",
      "Iteration 1801: Loss = 1.3252, Accuracy = 0.5800 Test Loss = 52.6537, Test Accuracy = 0.1162\n",
      "Iteration 1802: Loss = 1.3238, Accuracy = 0.5900 Test Loss = 52.6522, Test Accuracy = 0.1162\n",
      "Iteration 1803: Loss = 1.3223, Accuracy = 0.5900 Test Loss = 52.6507, Test Accuracy = 0.1162\n",
      "Iteration 1804: Loss = 1.3208, Accuracy = 0.5900 Test Loss = 52.6491, Test Accuracy = 0.1162\n",
      "Iteration 1805: Loss = 1.3194, Accuracy = 0.5900 Test Loss = 52.6476, Test Accuracy = 0.1162\n",
      "Iteration 1806: Loss = 1.3179, Accuracy = 0.5900 Test Loss = 52.6461, Test Accuracy = 0.1162\n",
      "Iteration 1807: Loss = 1.3165, Accuracy = 0.5900 Test Loss = 52.6446, Test Accuracy = 0.1161\n",
      "Iteration 1808: Loss = 1.3150, Accuracy = 0.5900 Test Loss = 52.6431, Test Accuracy = 0.1162\n",
      "Iteration 1809: Loss = 1.3136, Accuracy = 0.5900 Test Loss = 52.6416, Test Accuracy = 0.1162\n",
      "Iteration 1810: Loss = 1.3121, Accuracy = 0.5900 Test Loss = 52.6401, Test Accuracy = 0.1162\n",
      "Iteration 1811: Loss = 1.3107, Accuracy = 0.5900 Test Loss = 52.6386, Test Accuracy = 0.1163\n",
      "Iteration 1812: Loss = 1.3092, Accuracy = 0.5900 Test Loss = 52.6371, Test Accuracy = 0.1163\n",
      "Iteration 1813: Loss = 1.3078, Accuracy = 0.5900 Test Loss = 52.6356, Test Accuracy = 0.1163\n",
      "Iteration 1814: Loss = 1.3064, Accuracy = 0.5900 Test Loss = 52.6341, Test Accuracy = 0.1163\n",
      "Iteration 1815: Loss = 1.3049, Accuracy = 0.5900 Test Loss = 52.6326, Test Accuracy = 0.1163\n",
      "Iteration 1816: Loss = 1.3035, Accuracy = 0.5900 Test Loss = 52.6311, Test Accuracy = 0.1163\n",
      "Iteration 1817: Loss = 1.3021, Accuracy = 0.5900 Test Loss = 52.6296, Test Accuracy = 0.1163\n",
      "Iteration 1818: Loss = 1.3006, Accuracy = 0.5900 Test Loss = 52.6281, Test Accuracy = 0.1163\n",
      "Iteration 1819: Loss = 1.2992, Accuracy = 0.5900 Test Loss = 52.6266, Test Accuracy = 0.1162\n",
      "Iteration 1820: Loss = 1.2978, Accuracy = 0.5900 Test Loss = 52.6251, Test Accuracy = 0.1162\n",
      "Iteration 1821: Loss = 1.2964, Accuracy = 0.5900 Test Loss = 52.6236, Test Accuracy = 0.1161\n",
      "Iteration 1822: Loss = 1.2950, Accuracy = 0.5900 Test Loss = 52.6222, Test Accuracy = 0.1162\n",
      "Iteration 1823: Loss = 1.2935, Accuracy = 0.5900 Test Loss = 52.6207, Test Accuracy = 0.1162\n",
      "Iteration 1824: Loss = 1.2921, Accuracy = 0.5900 Test Loss = 52.6192, Test Accuracy = 0.1162\n",
      "Iteration 1825: Loss = 1.2907, Accuracy = 0.5900 Test Loss = 52.6177, Test Accuracy = 0.1162\n",
      "Iteration 1826: Loss = 1.2893, Accuracy = 0.6000 Test Loss = 52.6163, Test Accuracy = 0.1162\n",
      "Iteration 1827: Loss = 1.2879, Accuracy = 0.6000 Test Loss = 52.6148, Test Accuracy = 0.1162\n",
      "Iteration 1828: Loss = 1.2865, Accuracy = 0.6000 Test Loss = 52.6133, Test Accuracy = 0.1163\n",
      "Iteration 1829: Loss = 1.2851, Accuracy = 0.6000 Test Loss = 52.6119, Test Accuracy = 0.1164\n",
      "Iteration 1830: Loss = 1.2837, Accuracy = 0.6000 Test Loss = 52.6104, Test Accuracy = 0.1164\n",
      "Iteration 1831: Loss = 1.2823, Accuracy = 0.6100 Test Loss = 52.6089, Test Accuracy = 0.1164\n",
      "Iteration 1832: Loss = 1.2809, Accuracy = 0.6100 Test Loss = 52.6075, Test Accuracy = 0.1164\n",
      "Iteration 1833: Loss = 1.2795, Accuracy = 0.6100 Test Loss = 52.6060, Test Accuracy = 0.1164\n",
      "Iteration 1834: Loss = 1.2781, Accuracy = 0.6100 Test Loss = 52.6046, Test Accuracy = 0.1163\n",
      "Iteration 1835: Loss = 1.2767, Accuracy = 0.6100 Test Loss = 52.6031, Test Accuracy = 0.1163\n",
      "Iteration 1836: Loss = 1.2753, Accuracy = 0.6100 Test Loss = 52.6017, Test Accuracy = 0.1164\n",
      "Iteration 1837: Loss = 1.2739, Accuracy = 0.6100 Test Loss = 52.6002, Test Accuracy = 0.1164\n",
      "Iteration 1838: Loss = 1.2725, Accuracy = 0.6100 Test Loss = 52.5988, Test Accuracy = 0.1165\n",
      "Iteration 1839: Loss = 1.2711, Accuracy = 0.6100 Test Loss = 52.5973, Test Accuracy = 0.1165\n",
      "Iteration 1840: Loss = 1.2697, Accuracy = 0.6100 Test Loss = 52.5959, Test Accuracy = 0.1165\n",
      "Iteration 1841: Loss = 1.2683, Accuracy = 0.6100 Test Loss = 52.5945, Test Accuracy = 0.1165\n",
      "Iteration 1842: Loss = 1.2670, Accuracy = 0.6100 Test Loss = 52.5930, Test Accuracy = 0.1165\n",
      "Iteration 1843: Loss = 1.2656, Accuracy = 0.6100 Test Loss = 52.5916, Test Accuracy = 0.1165\n",
      "Iteration 1844: Loss = 1.2642, Accuracy = 0.6100 Test Loss = 52.5901, Test Accuracy = 0.1165\n",
      "Iteration 1845: Loss = 1.2628, Accuracy = 0.6100 Test Loss = 52.5887, Test Accuracy = 0.1165\n",
      "Iteration 1846: Loss = 1.2614, Accuracy = 0.6100 Test Loss = 52.5873, Test Accuracy = 0.1165\n",
      "Iteration 1847: Loss = 1.2601, Accuracy = 0.6100 Test Loss = 52.5859, Test Accuracy = 0.1165\n",
      "Iteration 1848: Loss = 1.2587, Accuracy = 0.6100 Test Loss = 52.5844, Test Accuracy = 0.1165\n",
      "Iteration 1849: Loss = 1.2573, Accuracy = 0.6100 Test Loss = 52.5830, Test Accuracy = 0.1165\n",
      "Iteration 1850: Loss = 1.2560, Accuracy = 0.6100 Test Loss = 52.5816, Test Accuracy = 0.1165\n",
      "Iteration 1851: Loss = 1.2546, Accuracy = 0.6100 Test Loss = 52.5802, Test Accuracy = 0.1165\n",
      "Iteration 1852: Loss = 1.2532, Accuracy = 0.6100 Test Loss = 52.5788, Test Accuracy = 0.1165\n",
      "Iteration 1853: Loss = 1.2519, Accuracy = 0.6100 Test Loss = 52.5774, Test Accuracy = 0.1165\n",
      "Iteration 1854: Loss = 1.2505, Accuracy = 0.6100 Test Loss = 52.5760, Test Accuracy = 0.1165\n",
      "Iteration 1855: Loss = 1.2492, Accuracy = 0.6100 Test Loss = 52.5745, Test Accuracy = 0.1164\n",
      "Iteration 1856: Loss = 1.2478, Accuracy = 0.6100 Test Loss = 52.5731, Test Accuracy = 0.1164\n",
      "Iteration 1857: Loss = 1.2465, Accuracy = 0.6100 Test Loss = 52.5717, Test Accuracy = 0.1164\n",
      "Iteration 1858: Loss = 1.2451, Accuracy = 0.6100 Test Loss = 52.5703, Test Accuracy = 0.1164\n",
      "Iteration 1859: Loss = 1.2438, Accuracy = 0.6100 Test Loss = 52.5689, Test Accuracy = 0.1164\n",
      "Iteration 1860: Loss = 1.2424, Accuracy = 0.6100 Test Loss = 52.5675, Test Accuracy = 0.1164\n",
      "Iteration 1861: Loss = 1.2411, Accuracy = 0.6100 Test Loss = 52.5661, Test Accuracy = 0.1164\n",
      "Iteration 1862: Loss = 1.2397, Accuracy = 0.6100 Test Loss = 52.5647, Test Accuracy = 0.1164\n",
      "Iteration 1863: Loss = 1.2384, Accuracy = 0.6100 Test Loss = 52.5634, Test Accuracy = 0.1164\n",
      "Iteration 1864: Loss = 1.2370, Accuracy = 0.6100 Test Loss = 52.5620, Test Accuracy = 0.1164\n",
      "Iteration 1865: Loss = 1.2357, Accuracy = 0.6100 Test Loss = 52.5606, Test Accuracy = 0.1164\n",
      "Iteration 1866: Loss = 1.2344, Accuracy = 0.6100 Test Loss = 52.5592, Test Accuracy = 0.1164\n",
      "Iteration 1867: Loss = 1.2330, Accuracy = 0.6100 Test Loss = 52.5578, Test Accuracy = 0.1164\n",
      "Iteration 1868: Loss = 1.2317, Accuracy = 0.6100 Test Loss = 52.5564, Test Accuracy = 0.1165\n",
      "Iteration 1869: Loss = 1.2304, Accuracy = 0.6200 Test Loss = 52.5550, Test Accuracy = 0.1164\n",
      "Iteration 1870: Loss = 1.2291, Accuracy = 0.6200 Test Loss = 52.5537, Test Accuracy = 0.1164\n",
      "Iteration 1871: Loss = 1.2277, Accuracy = 0.6200 Test Loss = 52.5523, Test Accuracy = 0.1164\n",
      "Iteration 1872: Loss = 1.2264, Accuracy = 0.6200 Test Loss = 52.5509, Test Accuracy = 0.1165\n",
      "Iteration 1873: Loss = 1.2251, Accuracy = 0.6300 Test Loss = 52.5495, Test Accuracy = 0.1165\n",
      "Iteration 1874: Loss = 1.2238, Accuracy = 0.6400 Test Loss = 52.5482, Test Accuracy = 0.1166\n",
      "Iteration 1875: Loss = 1.2224, Accuracy = 0.6400 Test Loss = 52.5468, Test Accuracy = 0.1165\n",
      "Iteration 1876: Loss = 1.2211, Accuracy = 0.6400 Test Loss = 52.5454, Test Accuracy = 0.1165\n",
      "Iteration 1877: Loss = 1.2198, Accuracy = 0.6400 Test Loss = 52.5441, Test Accuracy = 0.1165\n",
      "Iteration 1878: Loss = 1.2185, Accuracy = 0.6400 Test Loss = 52.5427, Test Accuracy = 0.1165\n",
      "Iteration 1879: Loss = 1.2172, Accuracy = 0.6400 Test Loss = 52.5414, Test Accuracy = 0.1165\n",
      "Iteration 1880: Loss = 1.2159, Accuracy = 0.6400 Test Loss = 52.5400, Test Accuracy = 0.1165\n",
      "Iteration 1881: Loss = 1.2146, Accuracy = 0.6400 Test Loss = 52.5387, Test Accuracy = 0.1165\n",
      "Iteration 1882: Loss = 1.2133, Accuracy = 0.6400 Test Loss = 52.5373, Test Accuracy = 0.1165\n",
      "Iteration 1883: Loss = 1.2120, Accuracy = 0.6500 Test Loss = 52.5359, Test Accuracy = 0.1166\n",
      "Iteration 1884: Loss = 1.2106, Accuracy = 0.6500 Test Loss = 52.5346, Test Accuracy = 0.1166\n",
      "Iteration 1885: Loss = 1.2093, Accuracy = 0.6500 Test Loss = 52.5332, Test Accuracy = 0.1166\n",
      "Iteration 1886: Loss = 1.2080, Accuracy = 0.6500 Test Loss = 52.5319, Test Accuracy = 0.1166\n",
      "Iteration 1887: Loss = 1.2068, Accuracy = 0.6500 Test Loss = 52.5306, Test Accuracy = 0.1167\n",
      "Iteration 1888: Loss = 1.2055, Accuracy = 0.6500 Test Loss = 52.5292, Test Accuracy = 0.1167\n",
      "Iteration 1889: Loss = 1.2042, Accuracy = 0.6500 Test Loss = 52.5279, Test Accuracy = 0.1167\n",
      "Iteration 1890: Loss = 1.2029, Accuracy = 0.6500 Test Loss = 52.5265, Test Accuracy = 0.1167\n",
      "Iteration 1891: Loss = 1.2016, Accuracy = 0.6500 Test Loss = 52.5252, Test Accuracy = 0.1167\n",
      "Iteration 1892: Loss = 1.2003, Accuracy = 0.6500 Test Loss = 52.5239, Test Accuracy = 0.1168\n",
      "Iteration 1893: Loss = 1.1990, Accuracy = 0.6500 Test Loss = 52.5225, Test Accuracy = 0.1168\n",
      "Iteration 1894: Loss = 1.1977, Accuracy = 0.6500 Test Loss = 52.5212, Test Accuracy = 0.1168\n",
      "Iteration 1895: Loss = 1.1964, Accuracy = 0.6500 Test Loss = 52.5199, Test Accuracy = 0.1169\n",
      "Iteration 1896: Loss = 1.1952, Accuracy = 0.6500 Test Loss = 52.5186, Test Accuracy = 0.1169\n",
      "Iteration 1897: Loss = 1.1939, Accuracy = 0.6500 Test Loss = 52.5172, Test Accuracy = 0.1170\n",
      "Iteration 1898: Loss = 1.1926, Accuracy = 0.6500 Test Loss = 52.5159, Test Accuracy = 0.1170\n",
      "Iteration 1899: Loss = 1.1913, Accuracy = 0.6500 Test Loss = 52.5146, Test Accuracy = 0.1170\n",
      "Iteration 1900: Loss = 1.1900, Accuracy = 0.6500 Test Loss = 52.5133, Test Accuracy = 0.1170\n",
      "Iteration 1901: Loss = 1.1888, Accuracy = 0.6500 Test Loss = 52.5120, Test Accuracy = 0.1169\n",
      "Iteration 1902: Loss = 1.1875, Accuracy = 0.6500 Test Loss = 52.5107, Test Accuracy = 0.1169\n",
      "Iteration 1903: Loss = 1.1862, Accuracy = 0.6500 Test Loss = 52.5093, Test Accuracy = 0.1169\n",
      "Iteration 1904: Loss = 1.1850, Accuracy = 0.6500 Test Loss = 52.5080, Test Accuracy = 0.1169\n",
      "Iteration 1905: Loss = 1.1837, Accuracy = 0.6500 Test Loss = 52.5067, Test Accuracy = 0.1169\n",
      "Iteration 1906: Loss = 1.1824, Accuracy = 0.6500 Test Loss = 52.5054, Test Accuracy = 0.1169\n",
      "Iteration 1907: Loss = 1.1812, Accuracy = 0.6500 Test Loss = 52.5041, Test Accuracy = 0.1168\n",
      "Iteration 1908: Loss = 1.1799, Accuracy = 0.6500 Test Loss = 52.5028, Test Accuracy = 0.1168\n",
      "Iteration 1909: Loss = 1.1787, Accuracy = 0.6600 Test Loss = 52.5015, Test Accuracy = 0.1169\n",
      "Iteration 1910: Loss = 1.1774, Accuracy = 0.6600 Test Loss = 52.5002, Test Accuracy = 0.1168\n",
      "Iteration 1911: Loss = 1.1761, Accuracy = 0.6600 Test Loss = 52.4989, Test Accuracy = 0.1168\n",
      "Iteration 1912: Loss = 1.1749, Accuracy = 0.6600 Test Loss = 52.4976, Test Accuracy = 0.1168\n",
      "Iteration 1913: Loss = 1.1736, Accuracy = 0.6600 Test Loss = 52.4963, Test Accuracy = 0.1168\n",
      "Iteration 1914: Loss = 1.1724, Accuracy = 0.6600 Test Loss = 52.4950, Test Accuracy = 0.1168\n",
      "Iteration 1915: Loss = 1.1711, Accuracy = 0.6600 Test Loss = 52.4938, Test Accuracy = 0.1168\n",
      "Iteration 1916: Loss = 1.1699, Accuracy = 0.6600 Test Loss = 52.4925, Test Accuracy = 0.1169\n",
      "Iteration 1917: Loss = 1.1687, Accuracy = 0.6600 Test Loss = 52.4912, Test Accuracy = 0.1169\n",
      "Iteration 1918: Loss = 1.1674, Accuracy = 0.6600 Test Loss = 52.4899, Test Accuracy = 0.1168\n",
      "Iteration 1919: Loss = 1.1662, Accuracy = 0.6600 Test Loss = 52.4886, Test Accuracy = 0.1168\n",
      "Iteration 1920: Loss = 1.1649, Accuracy = 0.6600 Test Loss = 52.4874, Test Accuracy = 0.1168\n",
      "Iteration 1921: Loss = 1.1637, Accuracy = 0.6600 Test Loss = 52.4861, Test Accuracy = 0.1168\n",
      "Iteration 1922: Loss = 1.1625, Accuracy = 0.6600 Test Loss = 52.4848, Test Accuracy = 0.1169\n",
      "Iteration 1923: Loss = 1.1612, Accuracy = 0.6600 Test Loss = 52.4835, Test Accuracy = 0.1168\n",
      "Iteration 1924: Loss = 1.1600, Accuracy = 0.6600 Test Loss = 52.4823, Test Accuracy = 0.1168\n",
      "Iteration 1925: Loss = 1.1588, Accuracy = 0.6600 Test Loss = 52.4810, Test Accuracy = 0.1168\n",
      "Iteration 1926: Loss = 1.1575, Accuracy = 0.6600 Test Loss = 52.4797, Test Accuracy = 0.1168\n",
      "Iteration 1927: Loss = 1.1563, Accuracy = 0.6600 Test Loss = 52.4784, Test Accuracy = 0.1168\n",
      "Iteration 1928: Loss = 1.1551, Accuracy = 0.6600 Test Loss = 52.4772, Test Accuracy = 0.1168\n",
      "Iteration 1929: Loss = 1.1538, Accuracy = 0.6600 Test Loss = 52.4759, Test Accuracy = 0.1167\n",
      "Iteration 1930: Loss = 1.1526, Accuracy = 0.6600 Test Loss = 52.4747, Test Accuracy = 0.1167\n",
      "Iteration 1931: Loss = 1.1514, Accuracy = 0.6600 Test Loss = 52.4734, Test Accuracy = 0.1167\n",
      "Iteration 1932: Loss = 1.1502, Accuracy = 0.6600 Test Loss = 52.4721, Test Accuracy = 0.1167\n",
      "Iteration 1933: Loss = 1.1490, Accuracy = 0.6600 Test Loss = 52.4709, Test Accuracy = 0.1167\n",
      "Iteration 1934: Loss = 1.1477, Accuracy = 0.6600 Test Loss = 52.4696, Test Accuracy = 0.1167\n",
      "Iteration 1935: Loss = 1.1465, Accuracy = 0.6600 Test Loss = 52.4684, Test Accuracy = 0.1167\n",
      "Iteration 1936: Loss = 1.1453, Accuracy = 0.6600 Test Loss = 52.4671, Test Accuracy = 0.1167\n",
      "Iteration 1937: Loss = 1.1441, Accuracy = 0.6600 Test Loss = 52.4659, Test Accuracy = 0.1167\n",
      "Iteration 1938: Loss = 1.1429, Accuracy = 0.6600 Test Loss = 52.4646, Test Accuracy = 0.1167\n",
      "Iteration 1939: Loss = 1.1417, Accuracy = 0.6600 Test Loss = 52.4634, Test Accuracy = 0.1167\n",
      "Iteration 1940: Loss = 1.1405, Accuracy = 0.6600 Test Loss = 52.4622, Test Accuracy = 0.1167\n",
      "Iteration 1941: Loss = 1.1393, Accuracy = 0.6600 Test Loss = 52.4609, Test Accuracy = 0.1167\n",
      "Iteration 1942: Loss = 1.1381, Accuracy = 0.6600 Test Loss = 52.4597, Test Accuracy = 0.1167\n",
      "Iteration 1943: Loss = 1.1369, Accuracy = 0.6600 Test Loss = 52.4585, Test Accuracy = 0.1167\n",
      "Iteration 1944: Loss = 1.1357, Accuracy = 0.6600 Test Loss = 52.4572, Test Accuracy = 0.1167\n",
      "Iteration 1945: Loss = 1.1345, Accuracy = 0.6600 Test Loss = 52.4560, Test Accuracy = 0.1167\n",
      "Iteration 1946: Loss = 1.1333, Accuracy = 0.6600 Test Loss = 52.4548, Test Accuracy = 0.1167\n",
      "Iteration 1947: Loss = 1.1321, Accuracy = 0.6600 Test Loss = 52.4535, Test Accuracy = 0.1167\n",
      "Iteration 1948: Loss = 1.1309, Accuracy = 0.6600 Test Loss = 52.4523, Test Accuracy = 0.1167\n",
      "Iteration 1949: Loss = 1.1297, Accuracy = 0.6600 Test Loss = 52.4511, Test Accuracy = 0.1167\n",
      "Iteration 1950: Loss = 1.1285, Accuracy = 0.6600 Test Loss = 52.4498, Test Accuracy = 0.1167\n",
      "Iteration 1951: Loss = 1.1273, Accuracy = 0.6600 Test Loss = 52.4486, Test Accuracy = 0.1167\n",
      "Iteration 1952: Loss = 1.1261, Accuracy = 0.6600 Test Loss = 52.4474, Test Accuracy = 0.1167\n",
      "Iteration 1953: Loss = 1.1249, Accuracy = 0.6600 Test Loss = 52.4462, Test Accuracy = 0.1167\n",
      "Iteration 1954: Loss = 1.1238, Accuracy = 0.6600 Test Loss = 52.4450, Test Accuracy = 0.1167\n",
      "Iteration 1955: Loss = 1.1226, Accuracy = 0.6600 Test Loss = 52.4437, Test Accuracy = 0.1167\n",
      "Iteration 1956: Loss = 1.1214, Accuracy = 0.6600 Test Loss = 52.4425, Test Accuracy = 0.1168\n",
      "Iteration 1957: Loss = 1.1202, Accuracy = 0.6600 Test Loss = 52.4413, Test Accuracy = 0.1168\n",
      "Iteration 1958: Loss = 1.1190, Accuracy = 0.6600 Test Loss = 52.4401, Test Accuracy = 0.1168\n",
      "Iteration 1959: Loss = 1.1179, Accuracy = 0.6600 Test Loss = 52.4389, Test Accuracy = 0.1168\n",
      "Iteration 1960: Loss = 1.1167, Accuracy = 0.6600 Test Loss = 52.4377, Test Accuracy = 0.1168\n",
      "Iteration 1961: Loss = 1.1155, Accuracy = 0.6600 Test Loss = 52.4365, Test Accuracy = 0.1168\n",
      "Iteration 1962: Loss = 1.1144, Accuracy = 0.6600 Test Loss = 52.4353, Test Accuracy = 0.1168\n",
      "Iteration 1963: Loss = 1.1132, Accuracy = 0.6600 Test Loss = 52.4341, Test Accuracy = 0.1168\n",
      "Iteration 1964: Loss = 1.1120, Accuracy = 0.6600 Test Loss = 52.4329, Test Accuracy = 0.1168\n",
      "Iteration 1965: Loss = 1.1109, Accuracy = 0.6600 Test Loss = 52.4317, Test Accuracy = 0.1168\n",
      "Iteration 1966: Loss = 1.1097, Accuracy = 0.6600 Test Loss = 52.4305, Test Accuracy = 0.1168\n",
      "Iteration 1967: Loss = 1.1085, Accuracy = 0.6600 Test Loss = 52.4293, Test Accuracy = 0.1168\n",
      "Iteration 1968: Loss = 1.1074, Accuracy = 0.6600 Test Loss = 52.4281, Test Accuracy = 0.1168\n",
      "Iteration 1969: Loss = 1.1062, Accuracy = 0.6600 Test Loss = 52.4269, Test Accuracy = 0.1168\n",
      "Iteration 1970: Loss = 1.1050, Accuracy = 0.6600 Test Loss = 52.4258, Test Accuracy = 0.1168\n",
      "Iteration 1971: Loss = 1.1039, Accuracy = 0.6600 Test Loss = 52.4246, Test Accuracy = 0.1168\n",
      "Iteration 1972: Loss = 1.1027, Accuracy = 0.6600 Test Loss = 52.4234, Test Accuracy = 0.1168\n",
      "Iteration 1973: Loss = 1.1016, Accuracy = 0.6700 Test Loss = 52.4222, Test Accuracy = 0.1168\n",
      "Iteration 1974: Loss = 1.1004, Accuracy = 0.6700 Test Loss = 52.4210, Test Accuracy = 0.1168\n",
      "Iteration 1975: Loss = 1.0993, Accuracy = 0.6700 Test Loss = 52.4198, Test Accuracy = 0.1168\n",
      "Iteration 1976: Loss = 1.0981, Accuracy = 0.6700 Test Loss = 52.4187, Test Accuracy = 0.1168\n",
      "Iteration 1977: Loss = 1.0970, Accuracy = 0.6700 Test Loss = 52.4175, Test Accuracy = 0.1169\n",
      "Iteration 1978: Loss = 1.0958, Accuracy = 0.6700 Test Loss = 52.4163, Test Accuracy = 0.1169\n",
      "Iteration 1979: Loss = 1.0947, Accuracy = 0.6700 Test Loss = 52.4151, Test Accuracy = 0.1170\n",
      "Iteration 1980: Loss = 1.0935, Accuracy = 0.6700 Test Loss = 52.4140, Test Accuracy = 0.1170\n",
      "Iteration 1981: Loss = 1.0924, Accuracy = 0.6700 Test Loss = 52.4128, Test Accuracy = 0.1170\n",
      "Iteration 1982: Loss = 1.0913, Accuracy = 0.6700 Test Loss = 52.4116, Test Accuracy = 0.1170\n",
      "Iteration 1983: Loss = 1.0901, Accuracy = 0.6700 Test Loss = 52.4105, Test Accuracy = 0.1171\n",
      "Iteration 1984: Loss = 1.0890, Accuracy = 0.6700 Test Loss = 52.4093, Test Accuracy = 0.1171\n",
      "Iteration 1985: Loss = 1.0879, Accuracy = 0.6700 Test Loss = 52.4081, Test Accuracy = 0.1171\n",
      "Iteration 1986: Loss = 1.0867, Accuracy = 0.6700 Test Loss = 52.4070, Test Accuracy = 0.1171\n",
      "Iteration 1987: Loss = 1.0856, Accuracy = 0.6700 Test Loss = 52.4058, Test Accuracy = 0.1171\n",
      "Iteration 1988: Loss = 1.0845, Accuracy = 0.6700 Test Loss = 52.4047, Test Accuracy = 0.1171\n",
      "Iteration 1989: Loss = 1.0833, Accuracy = 0.6700 Test Loss = 52.4035, Test Accuracy = 0.1172\n",
      "Iteration 1990: Loss = 1.0822, Accuracy = 0.6700 Test Loss = 52.4023, Test Accuracy = 0.1173\n",
      "Iteration 1991: Loss = 1.0811, Accuracy = 0.6700 Test Loss = 52.4012, Test Accuracy = 0.1175\n",
      "Iteration 1992: Loss = 1.0799, Accuracy = 0.6700 Test Loss = 52.4000, Test Accuracy = 0.1176\n",
      "Iteration 1993: Loss = 1.0788, Accuracy = 0.6700 Test Loss = 52.3989, Test Accuracy = 0.1176\n",
      "Iteration 1994: Loss = 1.0777, Accuracy = 0.6700 Test Loss = 52.3977, Test Accuracy = 0.1176\n",
      "Iteration 1995: Loss = 1.0766, Accuracy = 0.6700 Test Loss = 52.3966, Test Accuracy = 0.1177\n",
      "Iteration 1996: Loss = 1.0755, Accuracy = 0.6800 Test Loss = 52.3955, Test Accuracy = 0.1178\n",
      "Iteration 1997: Loss = 1.0743, Accuracy = 0.6800 Test Loss = 52.3943, Test Accuracy = 0.1178\n",
      "Iteration 1998: Loss = 1.0732, Accuracy = 0.6800 Test Loss = 52.3932, Test Accuracy = 0.1178\n",
      "Iteration 1999: Loss = 1.0721, Accuracy = 0.6800 Test Loss = 52.3920, Test Accuracy = 0.1178\n",
      "Total training time: 1.06s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = make_train_test_data(train_dataset, test_dataset, n=100)\n",
    "print(X_tr.shape, X_ts.shape)\n",
    "history5 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=2000)\n",
    "plot_history(history5) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training Data = 500`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "torch.Size([500, 28, 28]) torch.Size([10000, 28, 28])\n",
      "Iteration 0: Loss = 263.6085, Accuracy = 0.1300 Test Loss = 235.0645, Test Accuracy = 0.1068\n",
      "Iteration 1: Loss = 220.5105, Accuracy = 0.1400 Test Loss = 203.3869, Test Accuracy = 0.1059\n",
      "Iteration 2: Loss = 166.4272, Accuracy = 0.1000 Test Loss = 181.7765, Test Accuracy = 0.1099\n",
      "Iteration 3: Loss = 161.8938, Accuracy = 0.1300 Test Loss = 164.4771, Test Accuracy = 0.1115\n",
      "Iteration 4: Loss = 159.3849, Accuracy = 0.0800 Test Loss = 151.0813, Test Accuracy = 0.1145\n",
      "Iteration 5: Loss = 148.3352, Accuracy = 0.1600 Test Loss = 140.1876, Test Accuracy = 0.1181\n",
      "Iteration 6: Loss = 121.7409, Accuracy = 0.1300 Test Loss = 131.1083, Test Accuracy = 0.1191\n",
      "Iteration 7: Loss = 123.4297, Accuracy = 0.1900 Test Loss = 123.6000, Test Accuracy = 0.1194\n",
      "Iteration 8: Loss = 113.6706, Accuracy = 0.1300 Test Loss = 116.8933, Test Accuracy = 0.1207\n",
      "Iteration 9: Loss = 108.7630, Accuracy = 0.1600 Test Loss = 111.2071, Test Accuracy = 0.1218\n",
      "Iteration 10: Loss = 108.9095, Accuracy = 0.1900 Test Loss = 106.1075, Test Accuracy = 0.1227\n",
      "Iteration 11: Loss = 95.5947, Accuracy = 0.1700 Test Loss = 102.0468, Test Accuracy = 0.1236\n",
      "Iteration 12: Loss = 89.1348, Accuracy = 0.1700 Test Loss = 98.1623, Test Accuracy = 0.1238\n",
      "Iteration 13: Loss = 92.9085, Accuracy = 0.1100 Test Loss = 94.4839, Test Accuracy = 0.1244\n",
      "Iteration 14: Loss = 91.2378, Accuracy = 0.1800 Test Loss = 91.6402, Test Accuracy = 0.1250\n",
      "Iteration 15: Loss = 73.7123, Accuracy = 0.2000 Test Loss = 88.6516, Test Accuracy = 0.1241\n",
      "Iteration 16: Loss = 88.5570, Accuracy = 0.1700 Test Loss = 85.9957, Test Accuracy = 0.1259\n",
      "Iteration 17: Loss = 76.4637, Accuracy = 0.1800 Test Loss = 83.2032, Test Accuracy = 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor(train_dataset.data, dtype=torch.float32) / 255\n",
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = torch.tensor(test_dataset.data, dtype=torch.float32) / 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18: Loss = 70.0997, Accuracy = 0.1300 Test Loss = 81.0418, Test Accuracy = 0.1238\n",
      "Iteration 19: Loss = 74.9634, Accuracy = 0.1400 Test Loss = 78.7420, Test Accuracy = 0.1263\n",
      "Iteration 20: Loss = 70.5001, Accuracy = 0.2300 Test Loss = 76.7935, Test Accuracy = 0.1268\n",
      "Iteration 21: Loss = 68.4135, Accuracy = 0.0900 Test Loss = 75.0892, Test Accuracy = 0.1252\n",
      "Iteration 22: Loss = 62.9925, Accuracy = 0.1800 Test Loss = 73.1474, Test Accuracy = 0.1256\n",
      "Iteration 23: Loss = 64.5152, Accuracy = 0.1500 Test Loss = 71.4169, Test Accuracy = 0.1264\n",
      "Iteration 24: Loss = 58.8054, Accuracy = 0.1400 Test Loss = 70.0943, Test Accuracy = 0.1250\n",
      "Iteration 25: Loss = 68.3047, Accuracy = 0.1900 Test Loss = 68.4871, Test Accuracy = 0.1258\n",
      "Iteration 26: Loss = 59.6394, Accuracy = 0.1400 Test Loss = 67.1869, Test Accuracy = 0.1254\n",
      "Iteration 27: Loss = 60.2234, Accuracy = 0.1500 Test Loss = 65.9612, Test Accuracy = 0.1255\n",
      "Iteration 28: Loss = 53.7459, Accuracy = 0.1500 Test Loss = 64.5663, Test Accuracy = 0.1261\n",
      "Iteration 29: Loss = 57.2649, Accuracy = 0.1300 Test Loss = 63.3688, Test Accuracy = 0.1261\n",
      "Iteration 30: Loss = 54.5661, Accuracy = 0.1700 Test Loss = 62.3493, Test Accuracy = 0.1252\n",
      "Iteration 31: Loss = 53.9762, Accuracy = 0.1800 Test Loss = 61.1852, Test Accuracy = 0.1270\n",
      "Iteration 32: Loss = 48.4652, Accuracy = 0.0900 Test Loss = 60.1432, Test Accuracy = 0.1263\n",
      "Iteration 33: Loss = 56.4052, Accuracy = 0.1100 Test Loss = 59.1537, Test Accuracy = 0.1271\n",
      "Iteration 34: Loss = 51.7794, Accuracy = 0.1200 Test Loss = 58.1792, Test Accuracy = 0.1265\n",
      "Iteration 35: Loss = 49.8944, Accuracy = 0.1700 Test Loss = 57.2085, Test Accuracy = 0.1271\n",
      "Iteration 36: Loss = 47.2620, Accuracy = 0.1800 Test Loss = 56.4779, Test Accuracy = 0.1279\n",
      "Iteration 37: Loss = 52.6642, Accuracy = 0.1300 Test Loss = 55.5937, Test Accuracy = 0.1259\n",
      "Iteration 38: Loss = 45.8039, Accuracy = 0.1200 Test Loss = 54.8102, Test Accuracy = 0.1282\n",
      "Iteration 39: Loss = 47.4766, Accuracy = 0.1900 Test Loss = 54.0602, Test Accuracy = 0.1277\n",
      "Iteration 40: Loss = 46.9687, Accuracy = 0.1400 Test Loss = 53.2266, Test Accuracy = 0.1271\n",
      "Iteration 41: Loss = 44.8752, Accuracy = 0.1400 Test Loss = 52.5432, Test Accuracy = 0.1309\n",
      "Iteration 42: Loss = 40.4037, Accuracy = 0.1400 Test Loss = 51.9443, Test Accuracy = 0.1301\n",
      "Iteration 43: Loss = 42.6939, Accuracy = 0.1100 Test Loss = 51.2185, Test Accuracy = 0.1303\n",
      "Iteration 44: Loss = 42.8455, Accuracy = 0.1500 Test Loss = 50.6099, Test Accuracy = 0.1304\n",
      "Iteration 45: Loss = 44.3747, Accuracy = 0.1400 Test Loss = 49.9927, Test Accuracy = 0.1296\n",
      "Iteration 46: Loss = 43.8229, Accuracy = 0.1400 Test Loss = 49.4119, Test Accuracy = 0.1309\n",
      "Iteration 47: Loss = 38.2810, Accuracy = 0.1400 Test Loss = 48.8621, Test Accuracy = 0.1312\n",
      "Iteration 48: Loss = 41.5737, Accuracy = 0.1200 Test Loss = 48.2701, Test Accuracy = 0.1311\n",
      "Iteration 49: Loss = 38.7297, Accuracy = 0.1800 Test Loss = 47.7274, Test Accuracy = 0.1318\n",
      "Iteration 50: Loss = 39.9843, Accuracy = 0.2000 Test Loss = 47.2464, Test Accuracy = 0.1322\n",
      "Iteration 51: Loss = 41.0554, Accuracy = 0.1600 Test Loss = 46.7766, Test Accuracy = 0.1330\n",
      "Iteration 52: Loss = 37.7613, Accuracy = 0.1900 Test Loss = 46.3174, Test Accuracy = 0.1333\n",
      "Iteration 53: Loss = 36.3815, Accuracy = 0.1600 Test Loss = 45.7644, Test Accuracy = 0.1324\n",
      "Iteration 54: Loss = 37.9094, Accuracy = 0.1200 Test Loss = 45.2464, Test Accuracy = 0.1325\n",
      "Iteration 55: Loss = 34.1086, Accuracy = 0.1500 Test Loss = 44.8388, Test Accuracy = 0.1332\n",
      "Iteration 56: Loss = 36.6988, Accuracy = 0.0700 Test Loss = 44.4853, Test Accuracy = 0.1319\n",
      "Iteration 57: Loss = 36.5903, Accuracy = 0.1500 Test Loss = 44.0263, Test Accuracy = 0.1323\n",
      "Iteration 58: Loss = 34.6490, Accuracy = 0.1800 Test Loss = 43.7019, Test Accuracy = 0.1341\n",
      "Iteration 59: Loss = 34.9425, Accuracy = 0.0800 Test Loss = 43.2111, Test Accuracy = 0.1338\n",
      "Iteration 60: Loss = 34.3684, Accuracy = 0.1600 Test Loss = 42.8957, Test Accuracy = 0.1331\n",
      "Iteration 61: Loss = 35.4703, Accuracy = 0.1400 Test Loss = 42.4075, Test Accuracy = 0.1335\n",
      "Iteration 62: Loss = 31.4971, Accuracy = 0.1300 Test Loss = 42.1607, Test Accuracy = 0.1326\n",
      "Iteration 63: Loss = 30.9546, Accuracy = 0.1800 Test Loss = 41.7766, Test Accuracy = 0.1328\n",
      "Iteration 64: Loss = 31.6478, Accuracy = 0.1900 Test Loss = 41.3953, Test Accuracy = 0.1330\n",
      "Iteration 65: Loss = 30.7592, Accuracy = 0.2000 Test Loss = 41.0437, Test Accuracy = 0.1339\n",
      "Iteration 66: Loss = 32.8898, Accuracy = 0.1600 Test Loss = 40.7536, Test Accuracy = 0.1340\n",
      "Iteration 67: Loss = 33.7062, Accuracy = 0.1400 Test Loss = 40.4057, Test Accuracy = 0.1346\n",
      "Iteration 68: Loss = 32.2775, Accuracy = 0.1800 Test Loss = 40.1074, Test Accuracy = 0.1345\n",
      "Iteration 69: Loss = 32.8834, Accuracy = 0.1600 Test Loss = 39.8664, Test Accuracy = 0.1352\n",
      "Iteration 70: Loss = 31.4641, Accuracy = 0.1400 Test Loss = 39.5047, Test Accuracy = 0.1371\n",
      "Iteration 71: Loss = 31.2718, Accuracy = 0.1300 Test Loss = 39.2369, Test Accuracy = 0.1359\n",
      "Iteration 72: Loss = 30.7983, Accuracy = 0.1200 Test Loss = 38.8947, Test Accuracy = 0.1352\n",
      "Iteration 73: Loss = 29.7033, Accuracy = 0.1500 Test Loss = 38.6084, Test Accuracy = 0.1355\n",
      "Iteration 74: Loss = 31.1669, Accuracy = 0.1800 Test Loss = 38.3483, Test Accuracy = 0.1379\n",
      "Iteration 75: Loss = 28.7200, Accuracy = 0.1900 Test Loss = 38.1198, Test Accuracy = 0.1380\n",
      "Iteration 76: Loss = 29.8435, Accuracy = 0.1100 Test Loss = 37.8073, Test Accuracy = 0.1362\n",
      "Iteration 77: Loss = 28.8552, Accuracy = 0.1200 Test Loss = 37.5948, Test Accuracy = 0.1367\n",
      "Iteration 78: Loss = 26.0369, Accuracy = 0.1100 Test Loss = 37.3035, Test Accuracy = 0.1372\n",
      "Iteration 79: Loss = 28.3594, Accuracy = 0.1700 Test Loss = 37.1391, Test Accuracy = 0.1366\n",
      "Iteration 80: Loss = 27.5081, Accuracy = 0.1800 Test Loss = 36.8530, Test Accuracy = 0.1370\n",
      "Iteration 81: Loss = 27.4374, Accuracy = 0.1100 Test Loss = 36.6013, Test Accuracy = 0.1373\n",
      "Iteration 82: Loss = 28.7164, Accuracy = 0.1600 Test Loss = 36.3975, Test Accuracy = 0.1370\n",
      "Iteration 83: Loss = 29.4713, Accuracy = 0.1100 Test Loss = 36.1697, Test Accuracy = 0.1385\n",
      "Iteration 84: Loss = 25.7796, Accuracy = 0.1400 Test Loss = 36.0090, Test Accuracy = 0.1392\n",
      "Iteration 85: Loss = 27.3083, Accuracy = 0.1400 Test Loss = 35.6952, Test Accuracy = 0.1379\n",
      "Iteration 86: Loss = 27.1128, Accuracy = 0.1600 Test Loss = 35.4945, Test Accuracy = 0.1390\n",
      "Iteration 87: Loss = 26.2077, Accuracy = 0.2200 Test Loss = 35.2988, Test Accuracy = 0.1375\n",
      "Iteration 88: Loss = 26.3951, Accuracy = 0.1600 Test Loss = 35.0902, Test Accuracy = 0.1389\n",
      "Iteration 89: Loss = 25.5045, Accuracy = 0.1800 Test Loss = 34.9093, Test Accuracy = 0.1376\n",
      "Iteration 90: Loss = 25.9341, Accuracy = 0.1200 Test Loss = 34.7152, Test Accuracy = 0.1381\n",
      "Iteration 91: Loss = 26.0700, Accuracy = 0.1200 Test Loss = 34.4610, Test Accuracy = 0.1385\n",
      "Iteration 92: Loss = 26.1608, Accuracy = 0.1700 Test Loss = 34.2993, Test Accuracy = 0.1390\n",
      "Iteration 93: Loss = 25.5824, Accuracy = 0.1400 Test Loss = 34.1301, Test Accuracy = 0.1384\n",
      "Iteration 94: Loss = 27.0816, Accuracy = 0.1200 Test Loss = 33.9882, Test Accuracy = 0.1377\n",
      "Iteration 95: Loss = 23.7740, Accuracy = 0.1000 Test Loss = 33.7376, Test Accuracy = 0.1370\n",
      "Iteration 96: Loss = 24.1747, Accuracy = 0.2000 Test Loss = 33.5592, Test Accuracy = 0.1371\n",
      "Iteration 97: Loss = 24.1065, Accuracy = 0.1400 Test Loss = 33.4335, Test Accuracy = 0.1377\n",
      "Iteration 98: Loss = 23.5784, Accuracy = 0.1200 Test Loss = 33.2063, Test Accuracy = 0.1394\n",
      "Iteration 99: Loss = 24.7188, Accuracy = 0.1700 Test Loss = 33.0436, Test Accuracy = 0.1394\n",
      "Iteration 100: Loss = 23.0383, Accuracy = 0.0900 Test Loss = 32.8717, Test Accuracy = 0.1381\n",
      "Iteration 101: Loss = 21.7740, Accuracy = 0.1700 Test Loss = 32.7564, Test Accuracy = 0.1389\n",
      "Iteration 102: Loss = 24.2472, Accuracy = 0.1900 Test Loss = 32.5267, Test Accuracy = 0.1396\n",
      "Iteration 103: Loss = 21.7780, Accuracy = 0.1900 Test Loss = 32.4080, Test Accuracy = 0.1397\n",
      "Iteration 104: Loss = 22.7204, Accuracy = 0.1900 Test Loss = 32.2690, Test Accuracy = 0.1404\n",
      "Iteration 105: Loss = 23.1416, Accuracy = 0.1400 Test Loss = 32.1047, Test Accuracy = 0.1388\n",
      "Iteration 106: Loss = 22.3053, Accuracy = 0.2100 Test Loss = 32.0018, Test Accuracy = 0.1410\n",
      "Iteration 107: Loss = 22.1655, Accuracy = 0.1000 Test Loss = 31.8182, Test Accuracy = 0.1400\n",
      "Iteration 108: Loss = 22.2662, Accuracy = 0.1400 Test Loss = 31.7170, Test Accuracy = 0.1387\n",
      "Iteration 109: Loss = 20.4778, Accuracy = 0.1900 Test Loss = 31.5010, Test Accuracy = 0.1413\n",
      "Iteration 110: Loss = 21.7775, Accuracy = 0.1600 Test Loss = 31.4235, Test Accuracy = 0.1413\n",
      "Iteration 111: Loss = 21.3657, Accuracy = 0.1200 Test Loss = 31.2165, Test Accuracy = 0.1396\n",
      "Iteration 112: Loss = 23.9400, Accuracy = 0.1400 Test Loss = 31.1059, Test Accuracy = 0.1411\n",
      "Iteration 113: Loss = 21.7619, Accuracy = 0.1700 Test Loss = 31.0096, Test Accuracy = 0.1408\n",
      "Iteration 114: Loss = 21.8284, Accuracy = 0.1500 Test Loss = 30.8090, Test Accuracy = 0.1406\n",
      "Iteration 115: Loss = 21.0363, Accuracy = 0.1800 Test Loss = 30.7004, Test Accuracy = 0.1414\n",
      "Iteration 116: Loss = 20.3966, Accuracy = 0.1600 Test Loss = 30.5502, Test Accuracy = 0.1406\n",
      "Iteration 117: Loss = 20.7785, Accuracy = 0.1300 Test Loss = 30.4256, Test Accuracy = 0.1422\n",
      "Iteration 118: Loss = 20.6939, Accuracy = 0.1800 Test Loss = 30.3724, Test Accuracy = 0.1412\n",
      "Iteration 119: Loss = 21.6491, Accuracy = 0.1600 Test Loss = 30.2127, Test Accuracy = 0.1419\n",
      "Iteration 120: Loss = 23.7606, Accuracy = 0.1000 Test Loss = 30.0935, Test Accuracy = 0.1417\n",
      "Iteration 121: Loss = 20.5281, Accuracy = 0.2200 Test Loss = 29.9621, Test Accuracy = 0.1408\n",
      "Iteration 122: Loss = 19.2116, Accuracy = 0.1700 Test Loss = 29.8531, Test Accuracy = 0.1433\n",
      "Iteration 123: Loss = 18.8755, Accuracy = 0.2400 Test Loss = 29.7114, Test Accuracy = 0.1413\n",
      "Iteration 124: Loss = 19.3481, Accuracy = 0.1500 Test Loss = 29.6191, Test Accuracy = 0.1419\n",
      "Iteration 125: Loss = 18.6519, Accuracy = 0.2000 Test Loss = 29.4542, Test Accuracy = 0.1430\n",
      "Iteration 126: Loss = 20.1388, Accuracy = 0.1400 Test Loss = 29.3398, Test Accuracy = 0.1428\n",
      "Iteration 127: Loss = 19.8663, Accuracy = 0.1300 Test Loss = 29.2555, Test Accuracy = 0.1424\n",
      "Iteration 128: Loss = 18.9845, Accuracy = 0.2200 Test Loss = 29.1754, Test Accuracy = 0.1433\n",
      "Iteration 129: Loss = 20.9352, Accuracy = 0.1700 Test Loss = 29.0408, Test Accuracy = 0.1434\n",
      "Iteration 130: Loss = 20.4249, Accuracy = 0.1600 Test Loss = 28.9612, Test Accuracy = 0.1422\n",
      "Iteration 131: Loss = 19.9028, Accuracy = 0.1500 Test Loss = 28.8171, Test Accuracy = 0.1439\n",
      "Iteration 132: Loss = 19.0275, Accuracy = 0.1400 Test Loss = 28.7202, Test Accuracy = 0.1444\n",
      "Iteration 133: Loss = 20.5309, Accuracy = 0.1900 Test Loss = 28.6068, Test Accuracy = 0.1452\n",
      "Iteration 134: Loss = 19.6711, Accuracy = 0.1400 Test Loss = 28.5259, Test Accuracy = 0.1426\n",
      "Iteration 135: Loss = 18.1934, Accuracy = 0.1600 Test Loss = 28.3980, Test Accuracy = 0.1453\n",
      "Iteration 136: Loss = 18.9530, Accuracy = 0.1200 Test Loss = 28.3077, Test Accuracy = 0.1443\n",
      "Iteration 137: Loss = 19.1307, Accuracy = 0.1300 Test Loss = 28.1856, Test Accuracy = 0.1444\n",
      "Iteration 138: Loss = 18.5417, Accuracy = 0.1500 Test Loss = 28.1027, Test Accuracy = 0.1456\n",
      "Iteration 139: Loss = 18.5032, Accuracy = 0.1300 Test Loss = 28.0012, Test Accuracy = 0.1450\n",
      "Iteration 140: Loss = 17.2697, Accuracy = 0.1700 Test Loss = 27.9056, Test Accuracy = 0.1452\n",
      "Iteration 141: Loss = 18.7283, Accuracy = 0.1700 Test Loss = 27.8350, Test Accuracy = 0.1458\n",
      "Iteration 142: Loss = 19.0221, Accuracy = 0.1600 Test Loss = 27.7374, Test Accuracy = 0.1461\n",
      "Iteration 143: Loss = 17.0172, Accuracy = 0.2100 Test Loss = 27.6363, Test Accuracy = 0.1469\n",
      "Iteration 144: Loss = 18.3593, Accuracy = 0.1400 Test Loss = 27.5594, Test Accuracy = 0.1456\n",
      "Iteration 145: Loss = 17.2153, Accuracy = 0.2000 Test Loss = 27.4305, Test Accuracy = 0.1451\n",
      "Iteration 146: Loss = 17.8900, Accuracy = 0.1800 Test Loss = 27.3370, Test Accuracy = 0.1458\n",
      "Iteration 147: Loss = 16.8249, Accuracy = 0.1900 Test Loss = 27.2889, Test Accuracy = 0.1459\n",
      "Iteration 148: Loss = 17.5878, Accuracy = 0.1300 Test Loss = 27.2300, Test Accuracy = 0.1454\n",
      "Iteration 149: Loss = 17.4744, Accuracy = 0.0800 Test Loss = 27.0953, Test Accuracy = 0.1458\n",
      "Iteration 150: Loss = 18.4752, Accuracy = 0.2100 Test Loss = 26.9734, Test Accuracy = 0.1462\n",
      "Iteration 151: Loss = 16.2939, Accuracy = 0.2000 Test Loss = 26.9070, Test Accuracy = 0.1470\n",
      "Iteration 152: Loss = 18.0968, Accuracy = 0.1800 Test Loss = 26.8297, Test Accuracy = 0.1471\n",
      "Iteration 153: Loss = 17.7975, Accuracy = 0.1600 Test Loss = 26.7825, Test Accuracy = 0.1465\n",
      "Iteration 154: Loss = 16.3190, Accuracy = 0.1100 Test Loss = 26.6903, Test Accuracy = 0.1461\n",
      "Iteration 155: Loss = 17.8968, Accuracy = 0.1400 Test Loss = 26.5873, Test Accuracy = 0.1475\n",
      "Iteration 156: Loss = 17.5615, Accuracy = 0.2400 Test Loss = 26.5550, Test Accuracy = 0.1463\n",
      "Iteration 157: Loss = 16.9525, Accuracy = 0.1600 Test Loss = 26.4670, Test Accuracy = 0.1461\n",
      "Iteration 158: Loss = 18.4289, Accuracy = 0.1700 Test Loss = 26.3893, Test Accuracy = 0.1472\n",
      "Iteration 159: Loss = 17.1677, Accuracy = 0.2100 Test Loss = 26.3171, Test Accuracy = 0.1465\n",
      "Iteration 160: Loss = 16.3273, Accuracy = 0.1400 Test Loss = 26.2274, Test Accuracy = 0.1466\n",
      "Iteration 161: Loss = 15.1990, Accuracy = 0.1000 Test Loss = 26.1204, Test Accuracy = 0.1472\n",
      "Iteration 162: Loss = 17.1135, Accuracy = 0.1800 Test Loss = 26.0692, Test Accuracy = 0.1485\n",
      "Iteration 163: Loss = 15.8650, Accuracy = 0.1400 Test Loss = 25.9784, Test Accuracy = 0.1469\n",
      "Iteration 164: Loss = 17.1265, Accuracy = 0.1700 Test Loss = 25.9154, Test Accuracy = 0.1470\n",
      "Iteration 165: Loss = 16.8162, Accuracy = 0.1700 Test Loss = 25.8173, Test Accuracy = 0.1475\n",
      "Iteration 166: Loss = 18.3991, Accuracy = 0.1500 Test Loss = 25.7482, Test Accuracy = 0.1492\n",
      "Iteration 167: Loss = 15.2567, Accuracy = 0.1700 Test Loss = 25.6935, Test Accuracy = 0.1462\n",
      "Iteration 168: Loss = 16.8914, Accuracy = 0.1600 Test Loss = 25.6238, Test Accuracy = 0.1478\n",
      "Iteration 169: Loss = 16.7737, Accuracy = 0.1700 Test Loss = 25.5354, Test Accuracy = 0.1488\n",
      "Iteration 170: Loss = 16.0516, Accuracy = 0.2200 Test Loss = 25.4922, Test Accuracy = 0.1483\n",
      "Iteration 171: Loss = 16.5301, Accuracy = 0.1600 Test Loss = 25.4036, Test Accuracy = 0.1487\n",
      "Iteration 172: Loss = 14.9899, Accuracy = 0.2100 Test Loss = 25.3687, Test Accuracy = 0.1507\n",
      "Iteration 173: Loss = 15.9036, Accuracy = 0.1600 Test Loss = 25.2643, Test Accuracy = 0.1494\n",
      "Iteration 174: Loss = 15.0300, Accuracy = 0.1900 Test Loss = 25.1819, Test Accuracy = 0.1487\n",
      "Iteration 175: Loss = 16.2138, Accuracy = 0.1300 Test Loss = 25.1252, Test Accuracy = 0.1512\n",
      "Iteration 176: Loss = 16.2190, Accuracy = 0.1700 Test Loss = 25.0461, Test Accuracy = 0.1493\n",
      "Iteration 177: Loss = 16.2409, Accuracy = 0.1600 Test Loss = 24.9785, Test Accuracy = 0.1501\n",
      "Iteration 178: Loss = 14.2974, Accuracy = 0.1800 Test Loss = 24.9348, Test Accuracy = 0.1501\n",
      "Iteration 179: Loss = 14.1338, Accuracy = 0.2200 Test Loss = 24.8766, Test Accuracy = 0.1499\n",
      "Iteration 180: Loss = 14.9571, Accuracy = 0.1600 Test Loss = 24.8317, Test Accuracy = 0.1509\n",
      "Iteration 181: Loss = 15.2953, Accuracy = 0.1500 Test Loss = 24.7253, Test Accuracy = 0.1490\n",
      "Iteration 182: Loss = 15.3169, Accuracy = 0.2300 Test Loss = 24.6778, Test Accuracy = 0.1504\n",
      "Iteration 183: Loss = 15.0872, Accuracy = 0.1700 Test Loss = 24.5857, Test Accuracy = 0.1495\n",
      "Iteration 184: Loss = 14.7308, Accuracy = 0.1900 Test Loss = 24.5758, Test Accuracy = 0.1515\n",
      "Iteration 185: Loss = 15.2524, Accuracy = 0.2100 Test Loss = 24.4796, Test Accuracy = 0.1516\n",
      "Iteration 186: Loss = 14.0995, Accuracy = 0.1700 Test Loss = 24.4337, Test Accuracy = 0.1515\n",
      "Iteration 187: Loss = 14.4742, Accuracy = 0.1900 Test Loss = 24.3635, Test Accuracy = 0.1494\n",
      "Iteration 188: Loss = 14.7578, Accuracy = 0.1800 Test Loss = 24.3297, Test Accuracy = 0.1497\n",
      "Iteration 189: Loss = 14.8421, Accuracy = 0.1700 Test Loss = 24.2460, Test Accuracy = 0.1504\n",
      "Iteration 190: Loss = 16.1050, Accuracy = 0.1700 Test Loss = 24.2013, Test Accuracy = 0.1517\n",
      "Iteration 191: Loss = 14.5801, Accuracy = 0.2000 Test Loss = 24.1436, Test Accuracy = 0.1515\n",
      "Iteration 192: Loss = 14.1199, Accuracy = 0.1600 Test Loss = 24.0650, Test Accuracy = 0.1517\n",
      "Iteration 193: Loss = 13.6779, Accuracy = 0.2200 Test Loss = 23.9830, Test Accuracy = 0.1502\n",
      "Iteration 194: Loss = 14.6854, Accuracy = 0.1600 Test Loss = 23.9739, Test Accuracy = 0.1543\n",
      "Iteration 195: Loss = 13.8417, Accuracy = 0.1400 Test Loss = 23.8933, Test Accuracy = 0.1532\n",
      "Iteration 196: Loss = 14.1639, Accuracy = 0.2100 Test Loss = 23.8627, Test Accuracy = 0.1521\n",
      "Iteration 197: Loss = 14.4711, Accuracy = 0.1500 Test Loss = 23.8091, Test Accuracy = 0.1515\n",
      "Iteration 198: Loss = 13.7407, Accuracy = 0.1600 Test Loss = 23.7536, Test Accuracy = 0.1523\n",
      "Iteration 199: Loss = 14.6872, Accuracy = 0.1900 Test Loss = 23.6774, Test Accuracy = 0.1503\n",
      "Iteration 200: Loss = 14.1124, Accuracy = 0.1400 Test Loss = 23.6009, Test Accuracy = 0.1523\n",
      "Iteration 201: Loss = 13.2966, Accuracy = 0.1200 Test Loss = 23.5619, Test Accuracy = 0.1514\n",
      "Iteration 202: Loss = 14.5461, Accuracy = 0.1700 Test Loss = 23.5453, Test Accuracy = 0.1526\n",
      "Iteration 203: Loss = 12.9853, Accuracy = 0.2300 Test Loss = 23.4602, Test Accuracy = 0.1527\n",
      "Iteration 204: Loss = 13.4490, Accuracy = 0.1400 Test Loss = 23.3842, Test Accuracy = 0.1534\n",
      "Iteration 205: Loss = 14.2948, Accuracy = 0.1600 Test Loss = 23.3585, Test Accuracy = 0.1530\n",
      "Iteration 206: Loss = 13.8531, Accuracy = 0.1300 Test Loss = 23.3163, Test Accuracy = 0.1535\n",
      "Iteration 207: Loss = 13.3974, Accuracy = 0.1400 Test Loss = 23.2268, Test Accuracy = 0.1513\n",
      "Iteration 208: Loss = 12.9504, Accuracy = 0.2400 Test Loss = 23.2106, Test Accuracy = 0.1541\n",
      "Iteration 209: Loss = 13.9147, Accuracy = 0.1700 Test Loss = 23.1362, Test Accuracy = 0.1529\n",
      "Iteration 210: Loss = 13.7335, Accuracy = 0.1600 Test Loss = 23.1148, Test Accuracy = 0.1526\n",
      "Iteration 211: Loss = 12.7343, Accuracy = 0.1500 Test Loss = 23.0384, Test Accuracy = 0.1545\n",
      "Iteration 212: Loss = 12.9784, Accuracy = 0.1300 Test Loss = 23.0081, Test Accuracy = 0.1537\n",
      "Iteration 213: Loss = 13.5550, Accuracy = 0.1300 Test Loss = 22.9413, Test Accuracy = 0.1544\n",
      "Iteration 214: Loss = 12.4779, Accuracy = 0.2200 Test Loss = 22.9202, Test Accuracy = 0.1557\n",
      "Iteration 215: Loss = 14.1221, Accuracy = 0.1800 Test Loss = 22.8741, Test Accuracy = 0.1549\n",
      "Iteration 216: Loss = 13.2232, Accuracy = 0.1400 Test Loss = 22.8086, Test Accuracy = 0.1552\n",
      "Iteration 217: Loss = 12.9240, Accuracy = 0.1800 Test Loss = 22.7636, Test Accuracy = 0.1552\n",
      "Iteration 218: Loss = 14.1890, Accuracy = 0.1800 Test Loss = 22.7022, Test Accuracy = 0.1544\n",
      "Iteration 219: Loss = 13.1495, Accuracy = 0.1000 Test Loss = 22.6682, Test Accuracy = 0.1551\n",
      "Iteration 220: Loss = 12.8704, Accuracy = 0.1800 Test Loss = 22.6152, Test Accuracy = 0.1559\n",
      "Iteration 221: Loss = 14.1382, Accuracy = 0.1800 Test Loss = 22.5527, Test Accuracy = 0.1533\n",
      "Iteration 222: Loss = 14.2861, Accuracy = 0.1500 Test Loss = 22.5184, Test Accuracy = 0.1547\n",
      "Iteration 223: Loss = 13.3578, Accuracy = 0.1900 Test Loss = 22.4749, Test Accuracy = 0.1563\n",
      "Iteration 224: Loss = 12.4259, Accuracy = 0.1400 Test Loss = 22.4216, Test Accuracy = 0.1558\n",
      "Iteration 225: Loss = 13.6257, Accuracy = 0.1800 Test Loss = 22.4001, Test Accuracy = 0.1548\n",
      "Iteration 226: Loss = 13.3106, Accuracy = 0.1600 Test Loss = 22.3287, Test Accuracy = 0.1569\n",
      "Iteration 227: Loss = 13.2309, Accuracy = 0.1600 Test Loss = 22.2637, Test Accuracy = 0.1537\n",
      "Iteration 228: Loss = 13.0527, Accuracy = 0.1300 Test Loss = 22.2563, Test Accuracy = 0.1540\n",
      "Iteration 229: Loss = 13.3868, Accuracy = 0.1600 Test Loss = 22.1838, Test Accuracy = 0.1555\n",
      "Iteration 230: Loss = 13.1541, Accuracy = 0.1200 Test Loss = 22.1400, Test Accuracy = 0.1566\n",
      "Iteration 231: Loss = 13.3728, Accuracy = 0.1200 Test Loss = 22.0996, Test Accuracy = 0.1561\n",
      "Iteration 232: Loss = 13.0936, Accuracy = 0.1800 Test Loss = 22.0523, Test Accuracy = 0.1563\n",
      "Iteration 233: Loss = 13.1605, Accuracy = 0.1400 Test Loss = 22.0309, Test Accuracy = 0.1560\n",
      "Iteration 234: Loss = 11.7847, Accuracy = 0.1500 Test Loss = 21.9669, Test Accuracy = 0.1544\n",
      "Iteration 235: Loss = 12.6332, Accuracy = 0.1400 Test Loss = 21.9561, Test Accuracy = 0.1561\n",
      "Iteration 236: Loss = 11.7442, Accuracy = 0.1400 Test Loss = 21.9043, Test Accuracy = 0.1576\n",
      "Iteration 237: Loss = 13.2061, Accuracy = 0.2200 Test Loss = 21.8420, Test Accuracy = 0.1567\n",
      "Iteration 238: Loss = 12.8395, Accuracy = 0.1300 Test Loss = 21.8157, Test Accuracy = 0.1547\n",
      "Iteration 239: Loss = 12.0585, Accuracy = 0.1500 Test Loss = 21.7699, Test Accuracy = 0.1559\n",
      "Iteration 240: Loss = 11.3026, Accuracy = 0.2300 Test Loss = 21.7288, Test Accuracy = 0.1572\n",
      "Iteration 241: Loss = 12.0564, Accuracy = 0.2100 Test Loss = 21.6716, Test Accuracy = 0.1557\n",
      "Iteration 242: Loss = 12.5372, Accuracy = 0.0700 Test Loss = 21.6496, Test Accuracy = 0.1567\n",
      "Iteration 243: Loss = 11.4927, Accuracy = 0.1300 Test Loss = 21.6148, Test Accuracy = 0.1556\n",
      "Iteration 244: Loss = 11.9427, Accuracy = 0.1100 Test Loss = 21.5566, Test Accuracy = 0.1570\n",
      "Iteration 245: Loss = 12.4426, Accuracy = 0.1300 Test Loss = 21.5286, Test Accuracy = 0.1559\n",
      "Iteration 246: Loss = 12.6853, Accuracy = 0.1000 Test Loss = 21.4933, Test Accuracy = 0.1564\n",
      "Iteration 247: Loss = 12.3940, Accuracy = 0.1600 Test Loss = 21.4369, Test Accuracy = 0.1565\n",
      "Iteration 248: Loss = 11.8103, Accuracy = 0.2100 Test Loss = 21.4208, Test Accuracy = 0.1574\n",
      "Iteration 249: Loss = 12.0445, Accuracy = 0.1800 Test Loss = 21.3803, Test Accuracy = 0.1573\n",
      "Iteration 250: Loss = 11.5816, Accuracy = 0.1900 Test Loss = 21.3219, Test Accuracy = 0.1568\n",
      "Iteration 251: Loss = 11.7906, Accuracy = 0.1400 Test Loss = 21.2766, Test Accuracy = 0.1564\n",
      "Iteration 252: Loss = 11.7747, Accuracy = 0.1600 Test Loss = 21.2557, Test Accuracy = 0.1581\n",
      "Iteration 253: Loss = 12.4333, Accuracy = 0.1500 Test Loss = 21.2119, Test Accuracy = 0.1578\n",
      "Iteration 254: Loss = 11.1985, Accuracy = 0.1700 Test Loss = 21.1710, Test Accuracy = 0.1579\n",
      "Iteration 255: Loss = 11.2201, Accuracy = 0.1400 Test Loss = 21.1552, Test Accuracy = 0.1578\n",
      "Iteration 256: Loss = 11.4966, Accuracy = 0.2400 Test Loss = 21.1008, Test Accuracy = 0.1565\n",
      "Iteration 257: Loss = 10.8047, Accuracy = 0.1900 Test Loss = 21.0563, Test Accuracy = 0.1578\n",
      "Iteration 258: Loss = 12.0136, Accuracy = 0.1600 Test Loss = 21.0215, Test Accuracy = 0.1574\n",
      "Iteration 259: Loss = 11.8243, Accuracy = 0.1400 Test Loss = 20.9675, Test Accuracy = 0.1578\n",
      "Iteration 260: Loss = 11.6617, Accuracy = 0.1400 Test Loss = 20.9698, Test Accuracy = 0.1581\n",
      "Iteration 261: Loss = 12.2490, Accuracy = 0.1500 Test Loss = 20.8942, Test Accuracy = 0.1580\n",
      "Iteration 262: Loss = 10.6198, Accuracy = 0.2100 Test Loss = 20.8790, Test Accuracy = 0.1584\n",
      "Iteration 263: Loss = 12.0686, Accuracy = 0.2000 Test Loss = 20.8174, Test Accuracy = 0.1577\n",
      "Iteration 264: Loss = 11.3844, Accuracy = 0.1800 Test Loss = 20.8011, Test Accuracy = 0.1579\n",
      "Iteration 265: Loss = 11.5774, Accuracy = 0.1600 Test Loss = 20.7562, Test Accuracy = 0.1588\n",
      "Iteration 266: Loss = 11.8200, Accuracy = 0.1600 Test Loss = 20.7398, Test Accuracy = 0.1583\n",
      "Iteration 267: Loss = 11.6538, Accuracy = 0.1500 Test Loss = 20.6892, Test Accuracy = 0.1587\n",
      "Iteration 268: Loss = 11.5619, Accuracy = 0.1900 Test Loss = 20.6576, Test Accuracy = 0.1591\n",
      "Iteration 269: Loss = 10.5397, Accuracy = 0.2300 Test Loss = 20.6045, Test Accuracy = 0.1594\n",
      "Iteration 270: Loss = 11.1289, Accuracy = 0.1600 Test Loss = 20.6070, Test Accuracy = 0.1583\n",
      "Iteration 271: Loss = 11.1194, Accuracy = 0.1500 Test Loss = 20.5673, Test Accuracy = 0.1600\n",
      "Iteration 272: Loss = 10.7986, Accuracy = 0.1700 Test Loss = 20.5269, Test Accuracy = 0.1594\n",
      "Iteration 273: Loss = 11.0748, Accuracy = 0.2100 Test Loss = 20.4793, Test Accuracy = 0.1599\n",
      "Iteration 274: Loss = 11.4532, Accuracy = 0.1800 Test Loss = 20.4572, Test Accuracy = 0.1591\n",
      "Iteration 275: Loss = 11.2799, Accuracy = 0.2600 Test Loss = 20.4174, Test Accuracy = 0.1605\n",
      "Iteration 276: Loss = 11.1120, Accuracy = 0.0900 Test Loss = 20.3929, Test Accuracy = 0.1590\n",
      "Iteration 277: Loss = 10.6221, Accuracy = 0.1100 Test Loss = 20.3686, Test Accuracy = 0.1577\n",
      "Iteration 278: Loss = 10.2436, Accuracy = 0.1500 Test Loss = 20.3230, Test Accuracy = 0.1596\n",
      "Iteration 279: Loss = 10.9286, Accuracy = 0.1700 Test Loss = 20.2758, Test Accuracy = 0.1604\n",
      "Iteration 280: Loss = 10.5304, Accuracy = 0.1200 Test Loss = 20.2502, Test Accuracy = 0.1584\n",
      "Iteration 281: Loss = 11.2623, Accuracy = 0.1900 Test Loss = 20.2280, Test Accuracy = 0.1600\n",
      "Iteration 282: Loss = 10.9945, Accuracy = 0.1200 Test Loss = 20.2103, Test Accuracy = 0.1591\n",
      "Iteration 283: Loss = 11.1299, Accuracy = 0.1700 Test Loss = 20.1467, Test Accuracy = 0.1596\n",
      "Iteration 284: Loss = 10.9981, Accuracy = 0.1800 Test Loss = 20.1200, Test Accuracy = 0.1604\n",
      "Iteration 285: Loss = 11.4239, Accuracy = 0.1500 Test Loss = 20.0958, Test Accuracy = 0.1611\n",
      "Iteration 286: Loss = 10.3873, Accuracy = 0.1800 Test Loss = 20.0484, Test Accuracy = 0.1615\n",
      "Iteration 287: Loss = 10.7910, Accuracy = 0.1400 Test Loss = 20.0038, Test Accuracy = 0.1599\n",
      "Iteration 288: Loss = 10.5962, Accuracy = 0.1800 Test Loss = 19.9901, Test Accuracy = 0.1608\n",
      "Iteration 289: Loss = 10.6994, Accuracy = 0.1500 Test Loss = 19.9681, Test Accuracy = 0.1620\n",
      "Iteration 290: Loss = 10.7219, Accuracy = 0.1500 Test Loss = 19.9169, Test Accuracy = 0.1606\n",
      "Iteration 291: Loss = 11.3243, Accuracy = 0.1000 Test Loss = 19.8828, Test Accuracy = 0.1605\n",
      "Iteration 292: Loss = 10.4399, Accuracy = 0.1300 Test Loss = 19.8675, Test Accuracy = 0.1585\n",
      "Iteration 293: Loss = 10.0645, Accuracy = 0.2400 Test Loss = 19.8323, Test Accuracy = 0.1598\n",
      "Iteration 294: Loss = 10.7757, Accuracy = 0.1300 Test Loss = 19.8065, Test Accuracy = 0.1596\n",
      "Iteration 295: Loss = 10.0755, Accuracy = 0.1900 Test Loss = 19.7718, Test Accuracy = 0.1613\n",
      "Iteration 296: Loss = 10.4675, Accuracy = 0.1700 Test Loss = 19.7505, Test Accuracy = 0.1598\n",
      "Iteration 297: Loss = 10.3428, Accuracy = 0.1900 Test Loss = 19.7216, Test Accuracy = 0.1627\n",
      "Iteration 298: Loss = 10.3591, Accuracy = 0.1400 Test Loss = 19.7172, Test Accuracy = 0.1627\n",
      "Iteration 299: Loss = 10.6451, Accuracy = 0.1900 Test Loss = 19.6394, Test Accuracy = 0.1609\n",
      "Iteration 300: Loss = 10.3647, Accuracy = 0.1000 Test Loss = 19.6177, Test Accuracy = 0.1605\n",
      "Iteration 301: Loss = 10.0326, Accuracy = 0.1600 Test Loss = 19.5988, Test Accuracy = 0.1606\n",
      "Iteration 302: Loss = 9.8292, Accuracy = 0.1400 Test Loss = 19.5659, Test Accuracy = 0.1614\n",
      "Iteration 303: Loss = 10.3502, Accuracy = 0.2000 Test Loss = 19.5258, Test Accuracy = 0.1611\n",
      "Iteration 304: Loss = 10.0997, Accuracy = 0.1600 Test Loss = 19.5126, Test Accuracy = 0.1609\n",
      "Iteration 305: Loss = 9.5469, Accuracy = 0.2100 Test Loss = 19.4828, Test Accuracy = 0.1609\n",
      "Iteration 306: Loss = 10.2996, Accuracy = 0.1500 Test Loss = 19.4386, Test Accuracy = 0.1609\n",
      "Iteration 307: Loss = 10.2669, Accuracy = 0.2000 Test Loss = 19.4198, Test Accuracy = 0.1628\n",
      "Iteration 308: Loss = 10.2220, Accuracy = 0.2300 Test Loss = 19.3961, Test Accuracy = 0.1614\n",
      "Iteration 309: Loss = 9.6383, Accuracy = 0.1300 Test Loss = 19.3629, Test Accuracy = 0.1611\n",
      "Iteration 310: Loss = 9.5984, Accuracy = 0.0900 Test Loss = 19.3222, Test Accuracy = 0.1628\n",
      "Iteration 311: Loss = 9.3334, Accuracy = 0.1900 Test Loss = 19.3091, Test Accuracy = 0.1627\n",
      "Iteration 312: Loss = 10.2438, Accuracy = 0.1800 Test Loss = 19.2727, Test Accuracy = 0.1614\n",
      "Iteration 313: Loss = 8.9300, Accuracy = 0.1300 Test Loss = 19.2428, Test Accuracy = 0.1616\n",
      "Iteration 314: Loss = 9.6008, Accuracy = 0.2200 Test Loss = 19.2133, Test Accuracy = 0.1610\n",
      "Iteration 315: Loss = 9.5721, Accuracy = 0.1500 Test Loss = 19.2006, Test Accuracy = 0.1620\n",
      "Iteration 316: Loss = 9.3114, Accuracy = 0.1400 Test Loss = 19.1474, Test Accuracy = 0.1624\n",
      "Iteration 317: Loss = 9.9895, Accuracy = 0.0900 Test Loss = 19.1369, Test Accuracy = 0.1625\n",
      "Iteration 318: Loss = 9.8262, Accuracy = 0.1400 Test Loss = 19.1190, Test Accuracy = 0.1626\n",
      "Iteration 319: Loss = 9.9220, Accuracy = 0.1900 Test Loss = 19.0779, Test Accuracy = 0.1618\n",
      "Iteration 320: Loss = 10.0899, Accuracy = 0.0900 Test Loss = 19.0530, Test Accuracy = 0.1625\n",
      "Iteration 321: Loss = 10.7970, Accuracy = 0.1900 Test Loss = 19.0526, Test Accuracy = 0.1628\n",
      "Iteration 322: Loss = 10.1182, Accuracy = 0.1900 Test Loss = 19.0357, Test Accuracy = 0.1646\n",
      "Iteration 323: Loss = 10.1351, Accuracy = 0.2200 Test Loss = 18.9779, Test Accuracy = 0.1638\n",
      "Iteration 324: Loss = 9.1689, Accuracy = 0.2200 Test Loss = 18.9703, Test Accuracy = 0.1626\n",
      "Iteration 325: Loss = 9.7810, Accuracy = 0.1700 Test Loss = 18.9286, Test Accuracy = 0.1618\n",
      "Iteration 326: Loss = 9.7927, Accuracy = 0.1600 Test Loss = 18.8806, Test Accuracy = 0.1619\n",
      "Iteration 327: Loss = 9.2853, Accuracy = 0.1800 Test Loss = 18.8651, Test Accuracy = 0.1616\n",
      "Iteration 328: Loss = 9.4058, Accuracy = 0.2400 Test Loss = 18.8379, Test Accuracy = 0.1619\n",
      "Iteration 329: Loss = 10.9157, Accuracy = 0.2000 Test Loss = 18.7986, Test Accuracy = 0.1623\n",
      "Iteration 330: Loss = 10.6631, Accuracy = 0.1500 Test Loss = 18.7894, Test Accuracy = 0.1623\n",
      "Iteration 331: Loss = 9.2141, Accuracy = 0.2000 Test Loss = 18.7584, Test Accuracy = 0.1630\n",
      "Iteration 332: Loss = 9.1989, Accuracy = 0.1500 Test Loss = 18.7229, Test Accuracy = 0.1625\n",
      "Iteration 333: Loss = 9.3952, Accuracy = 0.1300 Test Loss = 18.7341, Test Accuracy = 0.1642\n",
      "Iteration 334: Loss = 10.1687, Accuracy = 0.2200 Test Loss = 18.6850, Test Accuracy = 0.1637\n",
      "Iteration 335: Loss = 9.1776, Accuracy = 0.2000 Test Loss = 18.6852, Test Accuracy = 0.1641\n",
      "Iteration 336: Loss = 9.3411, Accuracy = 0.1700 Test Loss = 18.6289, Test Accuracy = 0.1629\n",
      "Iteration 337: Loss = 9.2411, Accuracy = 0.1700 Test Loss = 18.6102, Test Accuracy = 0.1633\n",
      "Iteration 338: Loss = 8.5844, Accuracy = 0.1300 Test Loss = 18.5901, Test Accuracy = 0.1628\n",
      "Iteration 339: Loss = 9.6364, Accuracy = 0.1800 Test Loss = 18.5527, Test Accuracy = 0.1633\n",
      "Iteration 340: Loss = 9.3126, Accuracy = 0.2300 Test Loss = 18.5323, Test Accuracy = 0.1633\n",
      "Iteration 341: Loss = 8.9468, Accuracy = 0.2000 Test Loss = 18.5145, Test Accuracy = 0.1637\n",
      "Iteration 342: Loss = 9.2003, Accuracy = 0.2400 Test Loss = 18.4834, Test Accuracy = 0.1649\n",
      "Iteration 343: Loss = 9.4268, Accuracy = 0.1100 Test Loss = 18.4562, Test Accuracy = 0.1630\n",
      "Iteration 344: Loss = 9.1248, Accuracy = 0.1700 Test Loss = 18.4391, Test Accuracy = 0.1629\n",
      "Iteration 345: Loss = 9.3783, Accuracy = 0.1800 Test Loss = 18.4073, Test Accuracy = 0.1638\n",
      "Iteration 346: Loss = 8.8459, Accuracy = 0.2100 Test Loss = 18.3904, Test Accuracy = 0.1641\n",
      "Iteration 347: Loss = 8.7832, Accuracy = 0.2100 Test Loss = 18.3864, Test Accuracy = 0.1631\n",
      "Iteration 348: Loss = 9.3204, Accuracy = 0.1500 Test Loss = 18.3534, Test Accuracy = 0.1643\n",
      "Iteration 349: Loss = 9.7021, Accuracy = 0.2200 Test Loss = 18.3040, Test Accuracy = 0.1632\n",
      "Iteration 350: Loss = 9.0875, Accuracy = 0.1900 Test Loss = 18.2746, Test Accuracy = 0.1633\n",
      "Iteration 351: Loss = 9.2319, Accuracy = 0.1400 Test Loss = 18.2698, Test Accuracy = 0.1642\n",
      "Iteration 352: Loss = 9.2748, Accuracy = 0.1100 Test Loss = 18.2348, Test Accuracy = 0.1634\n",
      "Iteration 353: Loss = 9.3455, Accuracy = 0.2400 Test Loss = 18.2103, Test Accuracy = 0.1639\n",
      "Iteration 354: Loss = 9.1746, Accuracy = 0.1400 Test Loss = 18.1926, Test Accuracy = 0.1639\n",
      "Iteration 355: Loss = 9.1180, Accuracy = 0.1500 Test Loss = 18.1656, Test Accuracy = 0.1632\n",
      "Iteration 356: Loss = 9.5911, Accuracy = 0.1700 Test Loss = 18.1473, Test Accuracy = 0.1645\n",
      "Iteration 357: Loss = 8.9739, Accuracy = 0.1900 Test Loss = 18.1281, Test Accuracy = 0.1636\n",
      "Iteration 358: Loss = 8.4540, Accuracy = 0.1600 Test Loss = 18.0904, Test Accuracy = 0.1643\n",
      "Iteration 359: Loss = 9.1828, Accuracy = 0.1800 Test Loss = 18.0903, Test Accuracy = 0.1648\n",
      "Iteration 360: Loss = 9.0735, Accuracy = 0.1700 Test Loss = 18.0603, Test Accuracy = 0.1650\n",
      "Iteration 361: Loss = 8.9572, Accuracy = 0.2100 Test Loss = 18.0252, Test Accuracy = 0.1638\n",
      "Iteration 362: Loss = 8.6802, Accuracy = 0.2100 Test Loss = 18.0194, Test Accuracy = 0.1646\n",
      "Iteration 363: Loss = 9.3641, Accuracy = 0.1500 Test Loss = 17.9867, Test Accuracy = 0.1637\n",
      "Iteration 364: Loss = 9.2864, Accuracy = 0.1700 Test Loss = 17.9771, Test Accuracy = 0.1652\n",
      "Iteration 365: Loss = 8.6229, Accuracy = 0.1800 Test Loss = 17.9282, Test Accuracy = 0.1639\n",
      "Iteration 366: Loss = 8.3823, Accuracy = 0.1500 Test Loss = 17.9271, Test Accuracy = 0.1651\n",
      "Iteration 367: Loss = 8.2529, Accuracy = 0.1900 Test Loss = 17.8834, Test Accuracy = 0.1647\n",
      "Iteration 368: Loss = 9.3242, Accuracy = 0.1700 Test Loss = 17.8731, Test Accuracy = 0.1642\n",
      "Iteration 369: Loss = 8.9338, Accuracy = 0.2100 Test Loss = 17.8497, Test Accuracy = 0.1656\n",
      "Iteration 370: Loss = 8.7195, Accuracy = 0.1800 Test Loss = 17.8170, Test Accuracy = 0.1643\n",
      "Iteration 371: Loss = 8.9186, Accuracy = 0.1900 Test Loss = 17.8060, Test Accuracy = 0.1665\n",
      "Iteration 372: Loss = 9.0888, Accuracy = 0.1700 Test Loss = 17.8025, Test Accuracy = 0.1667\n",
      "Iteration 373: Loss = 8.7087, Accuracy = 0.2000 Test Loss = 17.7979, Test Accuracy = 0.1651\n",
      "Iteration 374: Loss = 8.5280, Accuracy = 0.2200 Test Loss = 17.7484, Test Accuracy = 0.1664\n",
      "Iteration 375: Loss = 8.6135, Accuracy = 0.1400 Test Loss = 17.7089, Test Accuracy = 0.1646\n",
      "Iteration 376: Loss = 9.3179, Accuracy = 0.1900 Test Loss = 17.6908, Test Accuracy = 0.1652\n",
      "Iteration 377: Loss = 8.7353, Accuracy = 0.1700 Test Loss = 17.6881, Test Accuracy = 0.1660\n",
      "Iteration 378: Loss = 8.5443, Accuracy = 0.1200 Test Loss = 17.6519, Test Accuracy = 0.1650\n",
      "Iteration 379: Loss = 8.8553, Accuracy = 0.2000 Test Loss = 17.6228, Test Accuracy = 0.1657\n",
      "Iteration 380: Loss = 8.8455, Accuracy = 0.1900 Test Loss = 17.6005, Test Accuracy = 0.1656\n",
      "Iteration 381: Loss = 8.3035, Accuracy = 0.1900 Test Loss = 17.5855, Test Accuracy = 0.1655\n",
      "Iteration 382: Loss = 8.2872, Accuracy = 0.1100 Test Loss = 17.5738, Test Accuracy = 0.1655\n",
      "Iteration 383: Loss = 8.2664, Accuracy = 0.1900 Test Loss = 17.5580, Test Accuracy = 0.1657\n",
      "Iteration 384: Loss = 8.9963, Accuracy = 0.1800 Test Loss = 17.5423, Test Accuracy = 0.1651\n",
      "Iteration 385: Loss = 8.2783, Accuracy = 0.1200 Test Loss = 17.4930, Test Accuracy = 0.1651\n",
      "Iteration 386: Loss = 8.6086, Accuracy = 0.1700 Test Loss = 17.4809, Test Accuracy = 0.1662\n",
      "Iteration 387: Loss = 8.3191, Accuracy = 0.1400 Test Loss = 17.4776, Test Accuracy = 0.1670\n",
      "Iteration 388: Loss = 7.8093, Accuracy = 0.1800 Test Loss = 17.4627, Test Accuracy = 0.1659\n",
      "Iteration 389: Loss = 8.6877, Accuracy = 0.2000 Test Loss = 17.4345, Test Accuracy = 0.1658\n",
      "Iteration 390: Loss = 8.2349, Accuracy = 0.1900 Test Loss = 17.4105, Test Accuracy = 0.1658\n",
      "Iteration 391: Loss = 8.6350, Accuracy = 0.1500 Test Loss = 17.3983, Test Accuracy = 0.1651\n",
      "Iteration 392: Loss = 8.5396, Accuracy = 0.1800 Test Loss = 17.3670, Test Accuracy = 0.1680\n",
      "Iteration 393: Loss = 8.0832, Accuracy = 0.1900 Test Loss = 17.3459, Test Accuracy = 0.1659\n",
      "Iteration 394: Loss = 7.8000, Accuracy = 0.2100 Test Loss = 17.3234, Test Accuracy = 0.1665\n",
      "Iteration 395: Loss = 8.4580, Accuracy = 0.1800 Test Loss = 17.3027, Test Accuracy = 0.1658\n",
      "Iteration 396: Loss = 8.1612, Accuracy = 0.1500 Test Loss = 17.2775, Test Accuracy = 0.1665\n",
      "Iteration 397: Loss = 8.1789, Accuracy = 0.1400 Test Loss = 17.2688, Test Accuracy = 0.1664\n",
      "Iteration 398: Loss = 7.9242, Accuracy = 0.1900 Test Loss = 17.2302, Test Accuracy = 0.1661\n",
      "Iteration 399: Loss = 9.2343, Accuracy = 0.1500 Test Loss = 17.2192, Test Accuracy = 0.1672\n",
      "Iteration 400: Loss = 8.0299, Accuracy = 0.1600 Test Loss = 17.1996, Test Accuracy = 0.1670\n",
      "Iteration 401: Loss = 8.1959, Accuracy = 0.1700 Test Loss = 17.1985, Test Accuracy = 0.1692\n",
      "Iteration 402: Loss = 8.5751, Accuracy = 0.1200 Test Loss = 17.1732, Test Accuracy = 0.1661\n",
      "Iteration 403: Loss = 7.9013, Accuracy = 0.2300 Test Loss = 17.1614, Test Accuracy = 0.1684\n",
      "Iteration 404: Loss = 8.4721, Accuracy = 0.2800 Test Loss = 17.1311, Test Accuracy = 0.1670\n",
      "Iteration 405: Loss = 7.6768, Accuracy = 0.2000 Test Loss = 17.1002, Test Accuracy = 0.1669\n",
      "Iteration 406: Loss = 8.1199, Accuracy = 0.1900 Test Loss = 17.1042, Test Accuracy = 0.1681\n",
      "Iteration 407: Loss = 8.7560, Accuracy = 0.2000 Test Loss = 17.0672, Test Accuracy = 0.1671\n",
      "Iteration 408: Loss = 8.3186, Accuracy = 0.1800 Test Loss = 17.0301, Test Accuracy = 0.1673\n",
      "Iteration 409: Loss = 8.0171, Accuracy = 0.1900 Test Loss = 17.0221, Test Accuracy = 0.1671\n",
      "Iteration 410: Loss = 8.0143, Accuracy = 0.1700 Test Loss = 17.0346, Test Accuracy = 0.1687\n",
      "Iteration 411: Loss = 8.6521, Accuracy = 0.1800 Test Loss = 16.9934, Test Accuracy = 0.1673\n",
      "Iteration 412: Loss = 7.4111, Accuracy = 0.1500 Test Loss = 16.9621, Test Accuracy = 0.1683\n",
      "Iteration 413: Loss = 7.6243, Accuracy = 0.1900 Test Loss = 16.9571, Test Accuracy = 0.1681\n",
      "Iteration 414: Loss = 7.9034, Accuracy = 0.1700 Test Loss = 16.9439, Test Accuracy = 0.1690\n",
      "Iteration 415: Loss = 7.9023, Accuracy = 0.2200 Test Loss = 16.9175, Test Accuracy = 0.1677\n",
      "Iteration 416: Loss = 7.9155, Accuracy = 0.2500 Test Loss = 16.9014, Test Accuracy = 0.1689\n",
      "Iteration 417: Loss = 7.9948, Accuracy = 0.1900 Test Loss = 16.8822, Test Accuracy = 0.1696\n",
      "Iteration 418: Loss = 8.7921, Accuracy = 0.2200 Test Loss = 16.8523, Test Accuracy = 0.1696\n",
      "Iteration 419: Loss = 8.1456, Accuracy = 0.1500 Test Loss = 16.8386, Test Accuracy = 0.1682\n",
      "Iteration 420: Loss = 7.8744, Accuracy = 0.1900 Test Loss = 16.8375, Test Accuracy = 0.1715\n",
      "Iteration 421: Loss = 7.8113, Accuracy = 0.2200 Test Loss = 16.8032, Test Accuracy = 0.1683\n",
      "Iteration 422: Loss = 7.1823, Accuracy = 0.2000 Test Loss = 16.7994, Test Accuracy = 0.1691\n",
      "Iteration 423: Loss = 7.8243, Accuracy = 0.1900 Test Loss = 16.7856, Test Accuracy = 0.1690\n",
      "Iteration 424: Loss = 7.5413, Accuracy = 0.2100 Test Loss = 16.7447, Test Accuracy = 0.1694\n",
      "Iteration 425: Loss = 8.3418, Accuracy = 0.1900 Test Loss = 16.7260, Test Accuracy = 0.1690\n",
      "Iteration 426: Loss = 8.1381, Accuracy = 0.1800 Test Loss = 16.7171, Test Accuracy = 0.1701\n",
      "Iteration 427: Loss = 7.7303, Accuracy = 0.1500 Test Loss = 16.6845, Test Accuracy = 0.1696\n",
      "Iteration 428: Loss = 7.8820, Accuracy = 0.1400 Test Loss = 16.6708, Test Accuracy = 0.1690\n",
      "Iteration 429: Loss = 7.6078, Accuracy = 0.2300 Test Loss = 16.6392, Test Accuracy = 0.1687\n",
      "Iteration 430: Loss = 7.8001, Accuracy = 0.1300 Test Loss = 16.6495, Test Accuracy = 0.1697\n",
      "Iteration 431: Loss = 7.2302, Accuracy = 0.2100 Test Loss = 16.6376, Test Accuracy = 0.1692\n",
      "Iteration 432: Loss = 7.6549, Accuracy = 0.2100 Test Loss = 16.6233, Test Accuracy = 0.1696\n",
      "Iteration 433: Loss = 8.2790, Accuracy = 0.1600 Test Loss = 16.5946, Test Accuracy = 0.1698\n",
      "Iteration 434: Loss = 8.4597, Accuracy = 0.2100 Test Loss = 16.5832, Test Accuracy = 0.1703\n",
      "Iteration 435: Loss = 7.2582, Accuracy = 0.1300 Test Loss = 16.5807, Test Accuracy = 0.1710\n",
      "Iteration 436: Loss = 7.7867, Accuracy = 0.2000 Test Loss = 16.5315, Test Accuracy = 0.1703\n",
      "Iteration 437: Loss = 8.1360, Accuracy = 0.2100 Test Loss = 16.5202, Test Accuracy = 0.1699\n",
      "Iteration 438: Loss = 7.1133, Accuracy = 0.1400 Test Loss = 16.4962, Test Accuracy = 0.1703\n",
      "Iteration 439: Loss = 8.0755, Accuracy = 0.1900 Test Loss = 16.4853, Test Accuracy = 0.1717\n",
      "Iteration 440: Loss = 7.7811, Accuracy = 0.2600 Test Loss = 16.4505, Test Accuracy = 0.1708\n",
      "Iteration 441: Loss = 7.6603, Accuracy = 0.2300 Test Loss = 16.4439, Test Accuracy = 0.1716\n",
      "Iteration 442: Loss = 7.1824, Accuracy = 0.2100 Test Loss = 16.4292, Test Accuracy = 0.1694\n",
      "Iteration 443: Loss = 8.0062, Accuracy = 0.1600 Test Loss = 16.4029, Test Accuracy = 0.1702\n",
      "Iteration 444: Loss = 7.3110, Accuracy = 0.1900 Test Loss = 16.3924, Test Accuracy = 0.1719\n",
      "Iteration 445: Loss = 7.3240, Accuracy = 0.1700 Test Loss = 16.3914, Test Accuracy = 0.1706\n",
      "Iteration 446: Loss = 7.5632, Accuracy = 0.1900 Test Loss = 16.3685, Test Accuracy = 0.1700\n",
      "Iteration 447: Loss = 7.9262, Accuracy = 0.2000 Test Loss = 16.3456, Test Accuracy = 0.1707\n",
      "Iteration 448: Loss = 7.8516, Accuracy = 0.2300 Test Loss = 16.3319, Test Accuracy = 0.1710\n",
      "Iteration 449: Loss = 7.6439, Accuracy = 0.2000 Test Loss = 16.3298, Test Accuracy = 0.1714\n",
      "Iteration 450: Loss = 7.4379, Accuracy = 0.1500 Test Loss = 16.3052, Test Accuracy = 0.1711\n",
      "Iteration 451: Loss = 7.8393, Accuracy = 0.2100 Test Loss = 16.2840, Test Accuracy = 0.1726\n",
      "Iteration 452: Loss = 7.3857, Accuracy = 0.2100 Test Loss = 16.2639, Test Accuracy = 0.1706\n",
      "Iteration 453: Loss = 7.7863, Accuracy = 0.1800 Test Loss = 16.2466, Test Accuracy = 0.1716\n",
      "Iteration 454: Loss = 8.0772, Accuracy = 0.1200 Test Loss = 16.2340, Test Accuracy = 0.1714\n",
      "Iteration 455: Loss = 6.8621, Accuracy = 0.1800 Test Loss = 16.2109, Test Accuracy = 0.1722\n",
      "Iteration 456: Loss = 7.7488, Accuracy = 0.1700 Test Loss = 16.1938, Test Accuracy = 0.1710\n",
      "Iteration 457: Loss = 7.1845, Accuracy = 0.2100 Test Loss = 16.1861, Test Accuracy = 0.1713\n",
      "Iteration 458: Loss = 7.5041, Accuracy = 0.2300 Test Loss = 16.1717, Test Accuracy = 0.1740\n",
      "Iteration 459: Loss = 7.9868, Accuracy = 0.2300 Test Loss = 16.1492, Test Accuracy = 0.1731\n",
      "Iteration 460: Loss = 7.1771, Accuracy = 0.1800 Test Loss = 16.1360, Test Accuracy = 0.1725\n",
      "Iteration 461: Loss = 6.9701, Accuracy = 0.1600 Test Loss = 16.1108, Test Accuracy = 0.1727\n",
      "Iteration 462: Loss = 7.1625, Accuracy = 0.1300 Test Loss = 16.1086, Test Accuracy = 0.1712\n",
      "Iteration 463: Loss = 7.3312, Accuracy = 0.1900 Test Loss = 16.0772, Test Accuracy = 0.1724\n",
      "Iteration 464: Loss = 7.0236, Accuracy = 0.2900 Test Loss = 16.0827, Test Accuracy = 0.1729\n",
      "Iteration 465: Loss = 7.0644, Accuracy = 0.2200 Test Loss = 16.0656, Test Accuracy = 0.1727\n",
      "Iteration 466: Loss = 7.4107, Accuracy = 0.1400 Test Loss = 16.0432, Test Accuracy = 0.1728\n",
      "Iteration 467: Loss = 7.0301, Accuracy = 0.2500 Test Loss = 16.0620, Test Accuracy = 0.1729\n",
      "Iteration 468: Loss = 7.2772, Accuracy = 0.1900 Test Loss = 16.0087, Test Accuracy = 0.1718\n",
      "Iteration 469: Loss = 7.1229, Accuracy = 0.1200 Test Loss = 15.9767, Test Accuracy = 0.1715\n",
      "Iteration 470: Loss = 7.5342, Accuracy = 0.1900 Test Loss = 15.9602, Test Accuracy = 0.1726\n",
      "Iteration 471: Loss = 7.8545, Accuracy = 0.1600 Test Loss = 15.9665, Test Accuracy = 0.1720\n",
      "Iteration 472: Loss = 6.9846, Accuracy = 0.2300 Test Loss = 15.9500, Test Accuracy = 0.1729\n",
      "Iteration 473: Loss = 6.8776, Accuracy = 0.2100 Test Loss = 15.9247, Test Accuracy = 0.1721\n",
      "Iteration 474: Loss = 7.5359, Accuracy = 0.1700 Test Loss = 15.9098, Test Accuracy = 0.1730\n",
      "Iteration 475: Loss = 6.7288, Accuracy = 0.1600 Test Loss = 15.9017, Test Accuracy = 0.1730\n",
      "Iteration 476: Loss = 7.7318, Accuracy = 0.2500 Test Loss = 15.8750, Test Accuracy = 0.1731\n",
      "Iteration 477: Loss = 6.5327, Accuracy = 0.2100 Test Loss = 15.8676, Test Accuracy = 0.1729\n",
      "Iteration 478: Loss = 7.3988, Accuracy = 0.1600 Test Loss = 15.8599, Test Accuracy = 0.1730\n",
      "Iteration 479: Loss = 6.8049, Accuracy = 0.2300 Test Loss = 15.8522, Test Accuracy = 0.1728\n",
      "Iteration 480: Loss = 7.4598, Accuracy = 0.2100 Test Loss = 15.8243, Test Accuracy = 0.1723\n",
      "Iteration 481: Loss = 7.0437, Accuracy = 0.1700 Test Loss = 15.7893, Test Accuracy = 0.1737\n",
      "Iteration 482: Loss = 6.9720, Accuracy = 0.2100 Test Loss = 15.7882, Test Accuracy = 0.1732\n",
      "Iteration 483: Loss = 7.6540, Accuracy = 0.2200 Test Loss = 15.7700, Test Accuracy = 0.1731\n",
      "Iteration 484: Loss = 7.4147, Accuracy = 0.2000 Test Loss = 15.7734, Test Accuracy = 0.1743\n",
      "Iteration 485: Loss = 6.4945, Accuracy = 0.2000 Test Loss = 15.7482, Test Accuracy = 0.1736\n",
      "Iteration 486: Loss = 7.1966, Accuracy = 0.2000 Test Loss = 15.7236, Test Accuracy = 0.1742\n",
      "Iteration 487: Loss = 6.3140, Accuracy = 0.2500 Test Loss = 15.7129, Test Accuracy = 0.1732\n",
      "Iteration 488: Loss = 7.2754, Accuracy = 0.2000 Test Loss = 15.6939, Test Accuracy = 0.1730\n",
      "Iteration 489: Loss = 6.7727, Accuracy = 0.2200 Test Loss = 15.6679, Test Accuracy = 0.1726\n",
      "Iteration 490: Loss = 6.8657, Accuracy = 0.2400 Test Loss = 15.6638, Test Accuracy = 0.1742\n",
      "Iteration 491: Loss = 7.0008, Accuracy = 0.2000 Test Loss = 15.6446, Test Accuracy = 0.1739\n",
      "Iteration 492: Loss = 6.5075, Accuracy = 0.1800 Test Loss = 15.6397, Test Accuracy = 0.1732\n",
      "Iteration 493: Loss = 6.9293, Accuracy = 0.1500 Test Loss = 15.6344, Test Accuracy = 0.1743\n",
      "Iteration 494: Loss = 6.5883, Accuracy = 0.1600 Test Loss = 15.6230, Test Accuracy = 0.1733\n",
      "Iteration 495: Loss = 6.2530, Accuracy = 0.2200 Test Loss = 15.6046, Test Accuracy = 0.1742\n",
      "Iteration 496: Loss = 7.1336, Accuracy = 0.1900 Test Loss = 15.5989, Test Accuracy = 0.1744\n",
      "Iteration 497: Loss = 7.0041, Accuracy = 0.1800 Test Loss = 15.5860, Test Accuracy = 0.1743\n",
      "Iteration 498: Loss = 6.4413, Accuracy = 0.2000 Test Loss = 15.5589, Test Accuracy = 0.1745\n",
      "Iteration 499: Loss = 7.1276, Accuracy = 0.2200 Test Loss = 15.5321, Test Accuracy = 0.1746\n",
      "Iteration 500: Loss = 7.3340, Accuracy = 0.1900 Test Loss = 15.5232, Test Accuracy = 0.1745\n",
      "Iteration 501: Loss = 7.2506, Accuracy = 0.2000 Test Loss = 15.5272, Test Accuracy = 0.1738\n",
      "Iteration 502: Loss = 7.9505, Accuracy = 0.2300 Test Loss = 15.4882, Test Accuracy = 0.1746\n",
      "Iteration 503: Loss = 6.5980, Accuracy = 0.2200 Test Loss = 15.4855, Test Accuracy = 0.1750\n",
      "Iteration 504: Loss = 6.9528, Accuracy = 0.1500 Test Loss = 15.4555, Test Accuracy = 0.1746\n",
      "Iteration 505: Loss = 6.6994, Accuracy = 0.2900 Test Loss = 15.4629, Test Accuracy = 0.1757\n",
      "Iteration 506: Loss = 6.9169, Accuracy = 0.2100 Test Loss = 15.4411, Test Accuracy = 0.1756\n",
      "Iteration 507: Loss = 6.9271, Accuracy = 0.1500 Test Loss = 15.4231, Test Accuracy = 0.1746\n",
      "Iteration 508: Loss = 6.5245, Accuracy = 0.2600 Test Loss = 15.4184, Test Accuracy = 0.1749\n",
      "Iteration 509: Loss = 6.3999, Accuracy = 0.1500 Test Loss = 15.3920, Test Accuracy = 0.1741\n",
      "Iteration 510: Loss = 6.3999, Accuracy = 0.2300 Test Loss = 15.3844, Test Accuracy = 0.1753\n",
      "Iteration 511: Loss = 6.8703, Accuracy = 0.1900 Test Loss = 15.3655, Test Accuracy = 0.1742\n",
      "Iteration 512: Loss = 6.4103, Accuracy = 0.2000 Test Loss = 15.3531, Test Accuracy = 0.1752\n",
      "Iteration 513: Loss = 6.4632, Accuracy = 0.1900 Test Loss = 15.3392, Test Accuracy = 0.1753\n",
      "Iteration 514: Loss = 6.6166, Accuracy = 0.1900 Test Loss = 15.3270, Test Accuracy = 0.1753\n",
      "Iteration 515: Loss = 6.6021, Accuracy = 0.1500 Test Loss = 15.3030, Test Accuracy = 0.1762\n",
      "Iteration 516: Loss = 6.2558, Accuracy = 0.2100 Test Loss = 15.2938, Test Accuracy = 0.1759\n",
      "Iteration 517: Loss = 6.7372, Accuracy = 0.1800 Test Loss = 15.2908, Test Accuracy = 0.1759\n",
      "Iteration 518: Loss = 6.2558, Accuracy = 0.2100 Test Loss = 15.2943, Test Accuracy = 0.1758\n",
      "Iteration 519: Loss = 6.4906, Accuracy = 0.1900 Test Loss = 15.2618, Test Accuracy = 0.1757\n",
      "Iteration 520: Loss = 6.5774, Accuracy = 0.1700 Test Loss = 15.2559, Test Accuracy = 0.1752\n",
      "Iteration 521: Loss = 6.2377, Accuracy = 0.1500 Test Loss = 15.2326, Test Accuracy = 0.1744\n",
      "Iteration 522: Loss = 6.6790, Accuracy = 0.2600 Test Loss = 15.2235, Test Accuracy = 0.1751\n",
      "Iteration 523: Loss = 7.1728, Accuracy = 0.1800 Test Loss = 15.2182, Test Accuracy = 0.1755\n",
      "Iteration 524: Loss = 6.1232, Accuracy = 0.2100 Test Loss = 15.1853, Test Accuracy = 0.1755\n",
      "Iteration 525: Loss = 6.3692, Accuracy = 0.2000 Test Loss = 15.1882, Test Accuracy = 0.1765\n",
      "Iteration 526: Loss = 6.0660, Accuracy = 0.1700 Test Loss = 15.1724, Test Accuracy = 0.1755\n",
      "Iteration 527: Loss = 7.2597, Accuracy = 0.1600 Test Loss = 15.1433, Test Accuracy = 0.1758\n",
      "Iteration 528: Loss = 6.7066, Accuracy = 0.1800 Test Loss = 15.1560, Test Accuracy = 0.1765\n",
      "Iteration 529: Loss = 6.9081, Accuracy = 0.1900 Test Loss = 15.1387, Test Accuracy = 0.1755\n",
      "Iteration 530: Loss = 6.5731, Accuracy = 0.2000 Test Loss = 15.1048, Test Accuracy = 0.1755\n",
      "Iteration 531: Loss = 6.1083, Accuracy = 0.2200 Test Loss = 15.1059, Test Accuracy = 0.1752\n",
      "Iteration 532: Loss = 6.0428, Accuracy = 0.2400 Test Loss = 15.0872, Test Accuracy = 0.1757\n",
      "Iteration 533: Loss = 6.8709, Accuracy = 0.2300 Test Loss = 15.0577, Test Accuracy = 0.1763\n",
      "Iteration 534: Loss = 6.6884, Accuracy = 0.2500 Test Loss = 15.0575, Test Accuracy = 0.1762\n",
      "Iteration 535: Loss = 7.0134, Accuracy = 0.2300 Test Loss = 15.0341, Test Accuracy = 0.1764\n",
      "Iteration 536: Loss = 6.2769, Accuracy = 0.2100 Test Loss = 15.0299, Test Accuracy = 0.1755\n",
      "Iteration 537: Loss = 6.3911, Accuracy = 0.1700 Test Loss = 15.0176, Test Accuracy = 0.1758\n",
      "Iteration 538: Loss = 6.4118, Accuracy = 0.2500 Test Loss = 14.9989, Test Accuracy = 0.1760\n",
      "Iteration 539: Loss = 6.8903, Accuracy = 0.2000 Test Loss = 14.9893, Test Accuracy = 0.1759\n",
      "Iteration 540: Loss = 6.8866, Accuracy = 0.1600 Test Loss = 14.9785, Test Accuracy = 0.1763\n",
      "Iteration 541: Loss = 6.1889, Accuracy = 0.2300 Test Loss = 14.9708, Test Accuracy = 0.1760\n",
      "Iteration 542: Loss = 6.2597, Accuracy = 0.2600 Test Loss = 14.9787, Test Accuracy = 0.1762\n",
      "Iteration 543: Loss = 6.4533, Accuracy = 0.1900 Test Loss = 14.9376, Test Accuracy = 0.1758\n",
      "Iteration 544: Loss = 6.4789, Accuracy = 0.2200 Test Loss = 14.9319, Test Accuracy = 0.1764\n",
      "Iteration 545: Loss = 5.8724, Accuracy = 0.3100 Test Loss = 14.9197, Test Accuracy = 0.1756\n",
      "Iteration 546: Loss = 6.3649, Accuracy = 0.1800 Test Loss = 14.9187, Test Accuracy = 0.1764\n",
      "Iteration 547: Loss = 6.2503, Accuracy = 0.1600 Test Loss = 14.8958, Test Accuracy = 0.1759\n",
      "Iteration 548: Loss = 6.6784, Accuracy = 0.1500 Test Loss = 14.8799, Test Accuracy = 0.1766\n",
      "Iteration 549: Loss = 6.7449, Accuracy = 0.1200 Test Loss = 14.8675, Test Accuracy = 0.1756\n",
      "Iteration 550: Loss = 5.9957, Accuracy = 0.2300 Test Loss = 14.8617, Test Accuracy = 0.1760\n",
      "Iteration 551: Loss = 6.0509, Accuracy = 0.2900 Test Loss = 14.8389, Test Accuracy = 0.1753\n",
      "Iteration 552: Loss = 6.2462, Accuracy = 0.2000 Test Loss = 14.8237, Test Accuracy = 0.1754\n",
      "Iteration 553: Loss = 6.0971, Accuracy = 0.2000 Test Loss = 14.8131, Test Accuracy = 0.1759\n",
      "Iteration 554: Loss = 5.6137, Accuracy = 0.2400 Test Loss = 14.8022, Test Accuracy = 0.1765\n",
      "Iteration 555: Loss = 6.6535, Accuracy = 0.2100 Test Loss = 14.7967, Test Accuracy = 0.1760\n",
      "Iteration 556: Loss = 6.0930, Accuracy = 0.1900 Test Loss = 14.7698, Test Accuracy = 0.1754\n",
      "Iteration 557: Loss = 6.5714, Accuracy = 0.2100 Test Loss = 14.7703, Test Accuracy = 0.1772\n",
      "Iteration 558: Loss = 6.4616, Accuracy = 0.2000 Test Loss = 14.7476, Test Accuracy = 0.1756\n",
      "Iteration 559: Loss = 6.3997, Accuracy = 0.1900 Test Loss = 14.7399, Test Accuracy = 0.1762\n",
      "Iteration 560: Loss = 6.0112, Accuracy = 0.2900 Test Loss = 14.7333, Test Accuracy = 0.1765\n",
      "Iteration 561: Loss = 6.0142, Accuracy = 0.2500 Test Loss = 14.7182, Test Accuracy = 0.1776\n",
      "Iteration 562: Loss = 6.1331, Accuracy = 0.2300 Test Loss = 14.7100, Test Accuracy = 0.1776\n",
      "Iteration 563: Loss = 6.1628, Accuracy = 0.2500 Test Loss = 14.6953, Test Accuracy = 0.1764\n",
      "Iteration 564: Loss = 6.1389, Accuracy = 0.2000 Test Loss = 14.6919, Test Accuracy = 0.1775\n",
      "Iteration 565: Loss = 6.0172, Accuracy = 0.2300 Test Loss = 14.6770, Test Accuracy = 0.1771\n",
      "Iteration 566: Loss = 5.9618, Accuracy = 0.2400 Test Loss = 14.6573, Test Accuracy = 0.1773\n",
      "Iteration 567: Loss = 6.3157, Accuracy = 0.1900 Test Loss = 14.6506, Test Accuracy = 0.1773\n",
      "Iteration 568: Loss = 5.8239, Accuracy = 0.2300 Test Loss = 14.6442, Test Accuracy = 0.1775\n",
      "Iteration 569: Loss = 6.2575, Accuracy = 0.2400 Test Loss = 14.6261, Test Accuracy = 0.1780\n",
      "Iteration 570: Loss = 5.9320, Accuracy = 0.2300 Test Loss = 14.6079, Test Accuracy = 0.1770\n",
      "Iteration 571: Loss = 5.8933, Accuracy = 0.2900 Test Loss = 14.6038, Test Accuracy = 0.1772\n",
      "Iteration 572: Loss = 6.3140, Accuracy = 0.2600 Test Loss = 14.6061, Test Accuracy = 0.1785\n",
      "Iteration 573: Loss = 5.5718, Accuracy = 0.2300 Test Loss = 14.5739, Test Accuracy = 0.1770\n",
      "Iteration 574: Loss = 5.9613, Accuracy = 0.1800 Test Loss = 14.5592, Test Accuracy = 0.1768\n",
      "Iteration 575: Loss = 6.3051, Accuracy = 0.2100 Test Loss = 14.5614, Test Accuracy = 0.1773\n",
      "Iteration 576: Loss = 6.1424, Accuracy = 0.2000 Test Loss = 14.5380, Test Accuracy = 0.1764\n",
      "Iteration 577: Loss = 5.7907, Accuracy = 0.2400 Test Loss = 14.5174, Test Accuracy = 0.1770\n",
      "Iteration 578: Loss = 6.1643, Accuracy = 0.2100 Test Loss = 14.5039, Test Accuracy = 0.1759\n",
      "Iteration 579: Loss = 5.7905, Accuracy = 0.2400 Test Loss = 14.5047, Test Accuracy = 0.1768\n",
      "Iteration 580: Loss = 5.7030, Accuracy = 0.2200 Test Loss = 14.5038, Test Accuracy = 0.1778\n",
      "Iteration 581: Loss = 5.9672, Accuracy = 0.2000 Test Loss = 14.4896, Test Accuracy = 0.1771\n",
      "Iteration 582: Loss = 6.1647, Accuracy = 0.2200 Test Loss = 14.4730, Test Accuracy = 0.1788\n",
      "Iteration 583: Loss = 5.7059, Accuracy = 0.3000 Test Loss = 14.4569, Test Accuracy = 0.1771\n",
      "Iteration 584: Loss = 5.6193, Accuracy = 0.1900 Test Loss = 14.4459, Test Accuracy = 0.1770\n",
      "Iteration 585: Loss = 5.7385, Accuracy = 0.1800 Test Loss = 14.4359, Test Accuracy = 0.1773\n",
      "Iteration 586: Loss = 5.7915, Accuracy = 0.1800 Test Loss = 14.4155, Test Accuracy = 0.1771\n",
      "Iteration 587: Loss = 5.7467, Accuracy = 0.1900 Test Loss = 14.4129, Test Accuracy = 0.1780\n",
      "Iteration 588: Loss = 6.1755, Accuracy = 0.1700 Test Loss = 14.4114, Test Accuracy = 0.1783\n",
      "Iteration 589: Loss = 6.0911, Accuracy = 0.2300 Test Loss = 14.3824, Test Accuracy = 0.1776\n",
      "Iteration 590: Loss = 5.8397, Accuracy = 0.2500 Test Loss = 14.3841, Test Accuracy = 0.1790\n",
      "Iteration 591: Loss = 6.3656, Accuracy = 0.2000 Test Loss = 14.3758, Test Accuracy = 0.1772\n",
      "Iteration 592: Loss = 5.8787, Accuracy = 0.2100 Test Loss = 14.3665, Test Accuracy = 0.1771\n",
      "Iteration 593: Loss = 6.1851, Accuracy = 0.2000 Test Loss = 14.3528, Test Accuracy = 0.1780\n",
      "Iteration 594: Loss = 5.8708, Accuracy = 0.2400 Test Loss = 14.3283, Test Accuracy = 0.1765\n",
      "Iteration 595: Loss = 5.4486, Accuracy = 0.2300 Test Loss = 14.3161, Test Accuracy = 0.1786\n",
      "Iteration 596: Loss = 5.6825, Accuracy = 0.2100 Test Loss = 14.3112, Test Accuracy = 0.1776\n",
      "Iteration 597: Loss = 6.0148, Accuracy = 0.1700 Test Loss = 14.3063, Test Accuracy = 0.1775\n",
      "Iteration 598: Loss = 5.9043, Accuracy = 0.2100 Test Loss = 14.2765, Test Accuracy = 0.1764\n",
      "Iteration 599: Loss = 5.4265, Accuracy = 0.2300 Test Loss = 14.2693, Test Accuracy = 0.1782\n",
      "Iteration 600: Loss = 6.0174, Accuracy = 0.1800 Test Loss = 14.2682, Test Accuracy = 0.1786\n",
      "Iteration 601: Loss = 5.5192, Accuracy = 0.2000 Test Loss = 14.2699, Test Accuracy = 0.1788\n",
      "Iteration 602: Loss = 5.2637, Accuracy = 0.2300 Test Loss = 14.2505, Test Accuracy = 0.1794\n",
      "Iteration 603: Loss = 5.7514, Accuracy = 0.2700 Test Loss = 14.2231, Test Accuracy = 0.1780\n",
      "Iteration 604: Loss = 5.7137, Accuracy = 0.2400 Test Loss = 14.2155, Test Accuracy = 0.1778\n",
      "Iteration 605: Loss = 6.3618, Accuracy = 0.2300 Test Loss = 14.2232, Test Accuracy = 0.1785\n",
      "Iteration 606: Loss = 5.8846, Accuracy = 0.2000 Test Loss = 14.2059, Test Accuracy = 0.1778\n",
      "Iteration 607: Loss = 5.9570, Accuracy = 0.1600 Test Loss = 14.1994, Test Accuracy = 0.1784\n",
      "Iteration 608: Loss = 5.3478, Accuracy = 0.2700 Test Loss = 14.1834, Test Accuracy = 0.1779\n",
      "Iteration 609: Loss = 5.3890, Accuracy = 0.2500 Test Loss = 14.1619, Test Accuracy = 0.1782\n",
      "Iteration 610: Loss = 5.7446, Accuracy = 0.1600 Test Loss = 14.1474, Test Accuracy = 0.1787\n",
      "Iteration 611: Loss = 6.1681, Accuracy = 0.2000 Test Loss = 14.1428, Test Accuracy = 0.1784\n",
      "Iteration 612: Loss = 5.6486, Accuracy = 0.1800 Test Loss = 14.1450, Test Accuracy = 0.1789\n",
      "Iteration 613: Loss = 5.6471, Accuracy = 0.2000 Test Loss = 14.1185, Test Accuracy = 0.1788\n",
      "Iteration 614: Loss = 5.6439, Accuracy = 0.2400 Test Loss = 14.1082, Test Accuracy = 0.1782\n",
      "Iteration 615: Loss = 5.3648, Accuracy = 0.1900 Test Loss = 14.1013, Test Accuracy = 0.1781\n",
      "Iteration 616: Loss = 5.2907, Accuracy = 0.2600 Test Loss = 14.1072, Test Accuracy = 0.1792\n",
      "Iteration 617: Loss = 5.2906, Accuracy = 0.2200 Test Loss = 14.0730, Test Accuracy = 0.1779\n",
      "Iteration 618: Loss = 5.1849, Accuracy = 0.2300 Test Loss = 14.0785, Test Accuracy = 0.1780\n",
      "Iteration 619: Loss = 5.7284, Accuracy = 0.2100 Test Loss = 14.0657, Test Accuracy = 0.1787\n",
      "Iteration 620: Loss = 5.6572, Accuracy = 0.1800 Test Loss = 14.0631, Test Accuracy = 0.1792\n",
      "Iteration 621: Loss = 5.3761, Accuracy = 0.2000 Test Loss = 14.0290, Test Accuracy = 0.1791\n",
      "Iteration 622: Loss = 5.3506, Accuracy = 0.2500 Test Loss = 14.0233, Test Accuracy = 0.1786\n",
      "Iteration 623: Loss = 5.5074, Accuracy = 0.1800 Test Loss = 14.0132, Test Accuracy = 0.1797\n",
      "Iteration 624: Loss = 5.6044, Accuracy = 0.2200 Test Loss = 14.0053, Test Accuracy = 0.1799\n",
      "Iteration 625: Loss = 5.2788, Accuracy = 0.2200 Test Loss = 13.9868, Test Accuracy = 0.1785\n",
      "Iteration 626: Loss = 5.2511, Accuracy = 0.2200 Test Loss = 13.9885, Test Accuracy = 0.1796\n",
      "Iteration 627: Loss = 5.7033, Accuracy = 0.2100 Test Loss = 13.9856, Test Accuracy = 0.1803\n",
      "Iteration 628: Loss = 5.5691, Accuracy = 0.2500 Test Loss = 13.9523, Test Accuracy = 0.1785\n",
      "Iteration 629: Loss = 5.4418, Accuracy = 0.2100 Test Loss = 13.9497, Test Accuracy = 0.1791\n",
      "Iteration 630: Loss = 5.4498, Accuracy = 0.2500 Test Loss = 13.9468, Test Accuracy = 0.1806\n",
      "Iteration 631: Loss = 6.0554, Accuracy = 0.2400 Test Loss = 13.9340, Test Accuracy = 0.1797\n",
      "Iteration 632: Loss = 5.8774, Accuracy = 0.2000 Test Loss = 13.9231, Test Accuracy = 0.1799\n",
      "Iteration 633: Loss = 5.5190, Accuracy = 0.2700 Test Loss = 13.9124, Test Accuracy = 0.1791\n",
      "Iteration 634: Loss = 5.5758, Accuracy = 0.2500 Test Loss = 13.9110, Test Accuracy = 0.1797\n",
      "Iteration 635: Loss = 5.5576, Accuracy = 0.2800 Test Loss = 13.8922, Test Accuracy = 0.1793\n",
      "Iteration 636: Loss = 5.4528, Accuracy = 0.2400 Test Loss = 13.8785, Test Accuracy = 0.1803\n",
      "Iteration 637: Loss = 5.2806, Accuracy = 0.2100 Test Loss = 13.8855, Test Accuracy = 0.1805\n",
      "Iteration 638: Loss = 5.4797, Accuracy = 0.2400 Test Loss = 13.8534, Test Accuracy = 0.1793\n",
      "Iteration 639: Loss = 5.4088, Accuracy = 0.2400 Test Loss = 13.8576, Test Accuracy = 0.1798\n",
      "Iteration 640: Loss = 5.1359, Accuracy = 0.2500 Test Loss = 13.8536, Test Accuracy = 0.1779\n",
      "Iteration 641: Loss = 5.3461, Accuracy = 0.2300 Test Loss = 13.8426, Test Accuracy = 0.1794\n",
      "Iteration 642: Loss = 5.6994, Accuracy = 0.2600 Test Loss = 13.8414, Test Accuracy = 0.1815\n",
      "Iteration 643: Loss = 5.1028, Accuracy = 0.2100 Test Loss = 13.8238, Test Accuracy = 0.1810\n",
      "Iteration 644: Loss = 5.8203, Accuracy = 0.2900 Test Loss = 13.7914, Test Accuracy = 0.1794\n",
      "Iteration 645: Loss = 5.1098, Accuracy = 0.2100 Test Loss = 13.7953, Test Accuracy = 0.1801\n",
      "Iteration 646: Loss = 5.3267, Accuracy = 0.1600 Test Loss = 13.7809, Test Accuracy = 0.1793\n",
      "Iteration 647: Loss = 5.6385, Accuracy = 0.2200 Test Loss = 13.7740, Test Accuracy = 0.1800\n",
      "Iteration 648: Loss = 5.5978, Accuracy = 0.1900 Test Loss = 13.7607, Test Accuracy = 0.1792\n",
      "Iteration 649: Loss = 5.4754, Accuracy = 0.2100 Test Loss = 13.7565, Test Accuracy = 0.1804\n",
      "Iteration 650: Loss = 5.4268, Accuracy = 0.2300 Test Loss = 13.7330, Test Accuracy = 0.1794\n",
      "Iteration 651: Loss = 5.0899, Accuracy = 0.2500 Test Loss = 13.7241, Test Accuracy = 0.1792\n",
      "Iteration 652: Loss = 5.5086, Accuracy = 0.2300 Test Loss = 13.7230, Test Accuracy = 0.1797\n",
      "Iteration 653: Loss = 5.5859, Accuracy = 0.2700 Test Loss = 13.7156, Test Accuracy = 0.1793\n",
      "Iteration 654: Loss = 5.3422, Accuracy = 0.2100 Test Loss = 13.6982, Test Accuracy = 0.1791\n",
      "Iteration 655: Loss = 5.7287, Accuracy = 0.2400 Test Loss = 13.7010, Test Accuracy = 0.1803\n",
      "Iteration 656: Loss = 5.3354, Accuracy = 0.2500 Test Loss = 13.6854, Test Accuracy = 0.1801\n",
      "Iteration 657: Loss = 5.1785, Accuracy = 0.1800 Test Loss = 13.6698, Test Accuracy = 0.1795\n",
      "Iteration 658: Loss = 5.7693, Accuracy = 0.2300 Test Loss = 13.6632, Test Accuracy = 0.1795\n",
      "Iteration 659: Loss = 5.3372, Accuracy = 0.2800 Test Loss = 13.6562, Test Accuracy = 0.1802\n",
      "Iteration 660: Loss = 5.3420, Accuracy = 0.2600 Test Loss = 13.6508, Test Accuracy = 0.1802\n",
      "Iteration 661: Loss = 5.0583, Accuracy = 0.2200 Test Loss = 13.6420, Test Accuracy = 0.1809\n",
      "Iteration 662: Loss = 5.3020, Accuracy = 0.2700 Test Loss = 13.6229, Test Accuracy = 0.1801\n",
      "Iteration 663: Loss = 5.4602, Accuracy = 0.2700 Test Loss = 13.6153, Test Accuracy = 0.1813\n",
      "Iteration 664: Loss = 4.9595, Accuracy = 0.2200 Test Loss = 13.6108, Test Accuracy = 0.1796\n",
      "Iteration 665: Loss = 5.6498, Accuracy = 0.2000 Test Loss = 13.6068, Test Accuracy = 0.1807\n",
      "Iteration 666: Loss = 5.1323, Accuracy = 0.2600 Test Loss = 13.5892, Test Accuracy = 0.1798\n",
      "Iteration 667: Loss = 5.1812, Accuracy = 0.2400 Test Loss = 13.5810, Test Accuracy = 0.1799\n",
      "Iteration 668: Loss = 5.4187, Accuracy = 0.2500 Test Loss = 13.5785, Test Accuracy = 0.1805\n",
      "Iteration 669: Loss = 5.0467, Accuracy = 0.2100 Test Loss = 13.5590, Test Accuracy = 0.1800\n",
      "Iteration 670: Loss = 5.1680, Accuracy = 0.2200 Test Loss = 13.5469, Test Accuracy = 0.1800\n",
      "Iteration 671: Loss = 4.8410, Accuracy = 0.2300 Test Loss = 13.5346, Test Accuracy = 0.1805\n",
      "Iteration 672: Loss = 5.2663, Accuracy = 0.2400 Test Loss = 13.5408, Test Accuracy = 0.1801\n",
      "Iteration 673: Loss = 5.1146, Accuracy = 0.2900 Test Loss = 13.5288, Test Accuracy = 0.1807\n",
      "Iteration 674: Loss = 5.1686, Accuracy = 0.2400 Test Loss = 13.5000, Test Accuracy = 0.1805\n",
      "Iteration 675: Loss = 4.9582, Accuracy = 0.3100 Test Loss = 13.4994, Test Accuracy = 0.1816\n",
      "Iteration 676: Loss = 4.9969, Accuracy = 0.2700 Test Loss = 13.4922, Test Accuracy = 0.1810\n",
      "Iteration 677: Loss = 5.6385, Accuracy = 0.2400 Test Loss = 13.4808, Test Accuracy = 0.1805\n",
      "Iteration 678: Loss = 5.0920, Accuracy = 0.2200 Test Loss = 13.4778, Test Accuracy = 0.1809\n",
      "Iteration 679: Loss = 4.7400, Accuracy = 0.2800 Test Loss = 13.4649, Test Accuracy = 0.1809\n",
      "Iteration 680: Loss = 5.3740, Accuracy = 0.2500 Test Loss = 13.4496, Test Accuracy = 0.1808\n",
      "Iteration 681: Loss = 5.3666, Accuracy = 0.2700 Test Loss = 13.4500, Test Accuracy = 0.1806\n",
      "Iteration 682: Loss = 5.3594, Accuracy = 0.2300 Test Loss = 13.4373, Test Accuracy = 0.1813\n",
      "Iteration 683: Loss = 5.1046, Accuracy = 0.3000 Test Loss = 13.4284, Test Accuracy = 0.1800\n",
      "Iteration 684: Loss = 4.9822, Accuracy = 0.3000 Test Loss = 13.4194, Test Accuracy = 0.1803\n",
      "Iteration 685: Loss = 5.3480, Accuracy = 0.2900 Test Loss = 13.4223, Test Accuracy = 0.1808\n",
      "Iteration 686: Loss = 5.1554, Accuracy = 0.2400 Test Loss = 13.3975, Test Accuracy = 0.1815\n",
      "Iteration 687: Loss = 5.1909, Accuracy = 0.2400 Test Loss = 13.3885, Test Accuracy = 0.1818\n",
      "Iteration 688: Loss = 5.3228, Accuracy = 0.2400 Test Loss = 13.3846, Test Accuracy = 0.1814\n",
      "Iteration 689: Loss = 5.1224, Accuracy = 0.2100 Test Loss = 13.3729, Test Accuracy = 0.1815\n",
      "Iteration 690: Loss = 5.1408, Accuracy = 0.2200 Test Loss = 13.3853, Test Accuracy = 0.1825\n",
      "Iteration 691: Loss = 4.7741, Accuracy = 0.3000 Test Loss = 13.3468, Test Accuracy = 0.1811\n",
      "Iteration 692: Loss = 5.3241, Accuracy = 0.2400 Test Loss = 13.3430, Test Accuracy = 0.1806\n",
      "Iteration 693: Loss = 5.3004, Accuracy = 0.3100 Test Loss = 13.3392, Test Accuracy = 0.1812\n",
      "Iteration 694: Loss = 5.0183, Accuracy = 0.2200 Test Loss = 13.3233, Test Accuracy = 0.1812\n",
      "Iteration 695: Loss = 5.0368, Accuracy = 0.3200 Test Loss = 13.3087, Test Accuracy = 0.1808\n",
      "Iteration 696: Loss = 4.9748, Accuracy = 0.2300 Test Loss = 13.3046, Test Accuracy = 0.1817\n",
      "Iteration 697: Loss = 5.1047, Accuracy = 0.2400 Test Loss = 13.2987, Test Accuracy = 0.1807\n",
      "Iteration 698: Loss = 5.1839, Accuracy = 0.2300 Test Loss = 13.2922, Test Accuracy = 0.1819\n",
      "Iteration 699: Loss = 4.8417, Accuracy = 0.3100 Test Loss = 13.2864, Test Accuracy = 0.1809\n",
      "Iteration 700: Loss = 4.6583, Accuracy = 0.2100 Test Loss = 13.2731, Test Accuracy = 0.1810\n",
      "Iteration 701: Loss = 4.9735, Accuracy = 0.1700 Test Loss = 13.2722, Test Accuracy = 0.1820\n",
      "Iteration 702: Loss = 5.1933, Accuracy = 0.2400 Test Loss = 13.2652, Test Accuracy = 0.1813\n",
      "Iteration 703: Loss = 5.1873, Accuracy = 0.3000 Test Loss = 13.2514, Test Accuracy = 0.1813\n",
      "Iteration 704: Loss = 4.7677, Accuracy = 0.2600 Test Loss = 13.2432, Test Accuracy = 0.1823\n",
      "Iteration 705: Loss = 5.2716, Accuracy = 0.1900 Test Loss = 13.2278, Test Accuracy = 0.1813\n",
      "Iteration 706: Loss = 5.0008, Accuracy = 0.2000 Test Loss = 13.2258, Test Accuracy = 0.1817\n",
      "Iteration 707: Loss = 4.8577, Accuracy = 0.2500 Test Loss = 13.2060, Test Accuracy = 0.1818\n",
      "Iteration 708: Loss = 4.9162, Accuracy = 0.2800 Test Loss = 13.2055, Test Accuracy = 0.1828\n",
      "Iteration 709: Loss = 4.9658, Accuracy = 0.1500 Test Loss = 13.1992, Test Accuracy = 0.1809\n",
      "Iteration 710: Loss = 4.9814, Accuracy = 0.3000 Test Loss = 13.1833, Test Accuracy = 0.1815\n",
      "Iteration 711: Loss = 5.2963, Accuracy = 0.2200 Test Loss = 13.1999, Test Accuracy = 0.1826\n",
      "Iteration 712: Loss = 4.5986, Accuracy = 0.2700 Test Loss = 13.1756, Test Accuracy = 0.1826\n",
      "Iteration 713: Loss = 4.5189, Accuracy = 0.3200 Test Loss = 13.1598, Test Accuracy = 0.1825\n",
      "Iteration 714: Loss = 4.9869, Accuracy = 0.2200 Test Loss = 13.1523, Test Accuracy = 0.1805\n",
      "Iteration 715: Loss = 4.6191, Accuracy = 0.2800 Test Loss = 13.1394, Test Accuracy = 0.1815\n",
      "Iteration 716: Loss = 5.1940, Accuracy = 0.2100 Test Loss = 13.1267, Test Accuracy = 0.1820\n",
      "Iteration 717: Loss = 5.2054, Accuracy = 0.3000 Test Loss = 13.1291, Test Accuracy = 0.1824\n",
      "Iteration 718: Loss = 4.8169, Accuracy = 0.2100 Test Loss = 13.1156, Test Accuracy = 0.1817\n",
      "Iteration 719: Loss = 4.7400, Accuracy = 0.2600 Test Loss = 13.1117, Test Accuracy = 0.1828\n",
      "Iteration 720: Loss = 4.4385, Accuracy = 0.2100 Test Loss = 13.1121, Test Accuracy = 0.1830\n",
      "Iteration 721: Loss = 4.8786, Accuracy = 0.3000 Test Loss = 13.1006, Test Accuracy = 0.1832\n",
      "Iteration 722: Loss = 4.4321, Accuracy = 0.2500 Test Loss = 13.0897, Test Accuracy = 0.1830\n",
      "Iteration 723: Loss = 4.4319, Accuracy = 0.2300 Test Loss = 13.0787, Test Accuracy = 0.1823\n",
      "Iteration 724: Loss = 4.7923, Accuracy = 0.2200 Test Loss = 13.0704, Test Accuracy = 0.1824\n",
      "Iteration 725: Loss = 5.2367, Accuracy = 0.1900 Test Loss = 13.0547, Test Accuracy = 0.1818\n",
      "Iteration 726: Loss = 4.6648, Accuracy = 0.2500 Test Loss = 13.0417, Test Accuracy = 0.1825\n",
      "Iteration 727: Loss = 5.0404, Accuracy = 0.2100 Test Loss = 13.0317, Test Accuracy = 0.1830\n",
      "Iteration 728: Loss = 4.8349, Accuracy = 0.3200 Test Loss = 13.0308, Test Accuracy = 0.1825\n",
      "Iteration 729: Loss = 4.6677, Accuracy = 0.1800 Test Loss = 13.0156, Test Accuracy = 0.1823\n",
      "Iteration 730: Loss = 4.6097, Accuracy = 0.2800 Test Loss = 13.0327, Test Accuracy = 0.1835\n",
      "Iteration 731: Loss = 4.7585, Accuracy = 0.2200 Test Loss = 13.0032, Test Accuracy = 0.1828\n",
      "Iteration 732: Loss = 5.2916, Accuracy = 0.2600 Test Loss = 12.9992, Test Accuracy = 0.1833\n",
      "Iteration 733: Loss = 5.1920, Accuracy = 0.2400 Test Loss = 12.9944, Test Accuracy = 0.1816\n",
      "Iteration 734: Loss = 4.7512, Accuracy = 0.1900 Test Loss = 12.9725, Test Accuracy = 0.1819\n",
      "Iteration 735: Loss = 4.8367, Accuracy = 0.2300 Test Loss = 12.9722, Test Accuracy = 0.1828\n",
      "Iteration 736: Loss = 4.6022, Accuracy = 0.2600 Test Loss = 12.9717, Test Accuracy = 0.1830\n",
      "Iteration 737: Loss = 4.5903, Accuracy = 0.2200 Test Loss = 12.9620, Test Accuracy = 0.1831\n",
      "Iteration 738: Loss = 5.0209, Accuracy = 0.2200 Test Loss = 12.9551, Test Accuracy = 0.1834\n",
      "Iteration 739: Loss = 4.9341, Accuracy = 0.2400 Test Loss = 12.9506, Test Accuracy = 0.1835\n",
      "Iteration 740: Loss = 4.7992, Accuracy = 0.2300 Test Loss = 12.9338, Test Accuracy = 0.1822\n",
      "Iteration 741: Loss = 4.6393, Accuracy = 0.2300 Test Loss = 12.9223, Test Accuracy = 0.1829\n",
      "Iteration 742: Loss = 5.0548, Accuracy = 0.2700 Test Loss = 12.9196, Test Accuracy = 0.1827\n",
      "Iteration 743: Loss = 4.6847, Accuracy = 0.3200 Test Loss = 12.9068, Test Accuracy = 0.1840\n",
      "Iteration 744: Loss = 4.4903, Accuracy = 0.2500 Test Loss = 12.8961, Test Accuracy = 0.1831\n",
      "Iteration 745: Loss = 4.6591, Accuracy = 0.2700 Test Loss = 12.8877, Test Accuracy = 0.1824\n",
      "Iteration 746: Loss = 4.6763, Accuracy = 0.2400 Test Loss = 12.9008, Test Accuracy = 0.1825\n",
      "Iteration 747: Loss = 4.7851, Accuracy = 0.2200 Test Loss = 12.8726, Test Accuracy = 0.1835\n",
      "Iteration 748: Loss = 4.5510, Accuracy = 0.2400 Test Loss = 12.8747, Test Accuracy = 0.1838\n",
      "Iteration 749: Loss = 4.5881, Accuracy = 0.2800 Test Loss = 12.8546, Test Accuracy = 0.1831\n",
      "Iteration 750: Loss = 4.4181, Accuracy = 0.3100 Test Loss = 12.8564, Test Accuracy = 0.1829\n",
      "Iteration 751: Loss = 4.7723, Accuracy = 0.2300 Test Loss = 12.8480, Test Accuracy = 0.1836\n",
      "Iteration 752: Loss = 4.9179, Accuracy = 0.2700 Test Loss = 12.8517, Test Accuracy = 0.1838\n",
      "Iteration 753: Loss = 4.9184, Accuracy = 0.2100 Test Loss = 12.8183, Test Accuracy = 0.1824\n",
      "Iteration 754: Loss = 4.3561, Accuracy = 0.2200 Test Loss = 12.8276, Test Accuracy = 0.1832\n",
      "Iteration 755: Loss = 4.6019, Accuracy = 0.2700 Test Loss = 12.8212, Test Accuracy = 0.1839\n",
      "Iteration 756: Loss = 4.8993, Accuracy = 0.2200 Test Loss = 12.8081, Test Accuracy = 0.1839\n",
      "Iteration 757: Loss = 4.9226, Accuracy = 0.2400 Test Loss = 12.7910, Test Accuracy = 0.1838\n",
      "Iteration 758: Loss = 4.6097, Accuracy = 0.2100 Test Loss = 12.8136, Test Accuracy = 0.1851\n",
      "Iteration 759: Loss = 4.3714, Accuracy = 0.2800 Test Loss = 12.7927, Test Accuracy = 0.1844\n",
      "Iteration 760: Loss = 4.4050, Accuracy = 0.2400 Test Loss = 12.7710, Test Accuracy = 0.1846\n",
      "Iteration 761: Loss = 4.5952, Accuracy = 0.2400 Test Loss = 12.7593, Test Accuracy = 0.1836\n",
      "Iteration 762: Loss = 4.2143, Accuracy = 0.2600 Test Loss = 12.7637, Test Accuracy = 0.1838\n",
      "Iteration 763: Loss = 4.6309, Accuracy = 0.2800 Test Loss = 12.7441, Test Accuracy = 0.1837\n",
      "Iteration 764: Loss = 4.4166, Accuracy = 0.2500 Test Loss = 12.7452, Test Accuracy = 0.1842\n",
      "Iteration 765: Loss = 4.2947, Accuracy = 0.2300 Test Loss = 12.7404, Test Accuracy = 0.1842\n",
      "Iteration 766: Loss = 4.3693, Accuracy = 0.2700 Test Loss = 12.7266, Test Accuracy = 0.1839\n",
      "Iteration 767: Loss = 4.4315, Accuracy = 0.1800 Test Loss = 12.7308, Test Accuracy = 0.1842\n",
      "Iteration 768: Loss = 4.7216, Accuracy = 0.2100 Test Loss = 12.7129, Test Accuracy = 0.1836\n",
      "Iteration 769: Loss = 4.6844, Accuracy = 0.2200 Test Loss = 12.6949, Test Accuracy = 0.1826\n",
      "Iteration 770: Loss = 4.4253, Accuracy = 0.2700 Test Loss = 12.6850, Test Accuracy = 0.1837\n",
      "Iteration 771: Loss = 4.8260, Accuracy = 0.2000 Test Loss = 12.6869, Test Accuracy = 0.1849\n",
      "Iteration 772: Loss = 4.5682, Accuracy = 0.2400 Test Loss = 12.6847, Test Accuracy = 0.1853\n",
      "Iteration 773: Loss = 4.5653, Accuracy = 0.2300 Test Loss = 12.6767, Test Accuracy = 0.1849\n",
      "Iteration 774: Loss = 4.8906, Accuracy = 0.2300 Test Loss = 12.6620, Test Accuracy = 0.1853\n",
      "Iteration 775: Loss = 4.4979, Accuracy = 0.3000 Test Loss = 12.6551, Test Accuracy = 0.1843\n",
      "Iteration 776: Loss = 4.6558, Accuracy = 0.2900 Test Loss = 12.6601, Test Accuracy = 0.1854\n",
      "Iteration 777: Loss = 4.4978, Accuracy = 0.2800 Test Loss = 12.6346, Test Accuracy = 0.1851\n",
      "Iteration 778: Loss = 4.4266, Accuracy = 0.2400 Test Loss = 12.6330, Test Accuracy = 0.1839\n",
      "Iteration 779: Loss = 4.6266, Accuracy = 0.1800 Test Loss = 12.6230, Test Accuracy = 0.1849\n",
      "Iteration 780: Loss = 4.4742, Accuracy = 0.2800 Test Loss = 12.6244, Test Accuracy = 0.1850\n",
      "Iteration 781: Loss = 4.6315, Accuracy = 0.2200 Test Loss = 12.6212, Test Accuracy = 0.1838\n",
      "Iteration 782: Loss = 4.7399, Accuracy = 0.2600 Test Loss = 12.6075, Test Accuracy = 0.1857\n",
      "Iteration 783: Loss = 4.3095, Accuracy = 0.2000 Test Loss = 12.5914, Test Accuracy = 0.1849\n",
      "Iteration 784: Loss = 4.2596, Accuracy = 0.3100 Test Loss = 12.5979, Test Accuracy = 0.1850\n",
      "Iteration 785: Loss = 4.4353, Accuracy = 0.2500 Test Loss = 12.5805, Test Accuracy = 0.1848\n",
      "Iteration 786: Loss = 4.3360, Accuracy = 0.2400 Test Loss = 12.5759, Test Accuracy = 0.1857\n",
      "Iteration 787: Loss = 4.4234, Accuracy = 0.2200 Test Loss = 12.5642, Test Accuracy = 0.1839\n",
      "Iteration 788: Loss = 4.3325, Accuracy = 0.2400 Test Loss = 12.5620, Test Accuracy = 0.1847\n",
      "Iteration 789: Loss = 4.6388, Accuracy = 0.2800 Test Loss = 12.5432, Test Accuracy = 0.1848\n",
      "Iteration 790: Loss = 4.4230, Accuracy = 0.2200 Test Loss = 12.5467, Test Accuracy = 0.1855\n",
      "Iteration 791: Loss = 4.4593, Accuracy = 0.3000 Test Loss = 12.5360, Test Accuracy = 0.1849\n",
      "Iteration 792: Loss = 4.5454, Accuracy = 0.2900 Test Loss = 12.5291, Test Accuracy = 0.1849\n",
      "Iteration 793: Loss = 4.8186, Accuracy = 0.2300 Test Loss = 12.5198, Test Accuracy = 0.1849\n",
      "Iteration 794: Loss = 4.4097, Accuracy = 0.2500 Test Loss = 12.5102, Test Accuracy = 0.1850\n",
      "Iteration 795: Loss = 4.5956, Accuracy = 0.1800 Test Loss = 12.5086, Test Accuracy = 0.1850\n",
      "Iteration 796: Loss = 4.7770, Accuracy = 0.3200 Test Loss = 12.5063, Test Accuracy = 0.1854\n",
      "Iteration 797: Loss = 4.3551, Accuracy = 0.1700 Test Loss = 12.4958, Test Accuracy = 0.1854\n",
      "Iteration 798: Loss = 4.5280, Accuracy = 0.2400 Test Loss = 12.4919, Test Accuracy = 0.1855\n",
      "Iteration 799: Loss = 4.0580, Accuracy = 0.3100 Test Loss = 12.4793, Test Accuracy = 0.1844\n",
      "Iteration 800: Loss = 4.4783, Accuracy = 0.3100 Test Loss = 12.4800, Test Accuracy = 0.1851\n",
      "Iteration 801: Loss = 4.4745, Accuracy = 0.2400 Test Loss = 12.4647, Test Accuracy = 0.1852\n",
      "Iteration 802: Loss = 4.2152, Accuracy = 0.3300 Test Loss = 12.4548, Test Accuracy = 0.1847\n",
      "Iteration 803: Loss = 4.7037, Accuracy = 0.2600 Test Loss = 12.4499, Test Accuracy = 0.1851\n",
      "Iteration 804: Loss = 4.3486, Accuracy = 0.2900 Test Loss = 12.4420, Test Accuracy = 0.1853\n",
      "Iteration 805: Loss = 4.4728, Accuracy = 0.2200 Test Loss = 12.4419, Test Accuracy = 0.1850\n",
      "Iteration 806: Loss = 4.1330, Accuracy = 0.2800 Test Loss = 12.4259, Test Accuracy = 0.1842\n",
      "Iteration 807: Loss = 4.2263, Accuracy = 0.2500 Test Loss = 12.4178, Test Accuracy = 0.1852\n",
      "Iteration 808: Loss = 4.4209, Accuracy = 0.2200 Test Loss = 12.4140, Test Accuracy = 0.1852\n",
      "Iteration 809: Loss = 4.6026, Accuracy = 0.2700 Test Loss = 12.4011, Test Accuracy = 0.1851\n",
      "Iteration 810: Loss = 4.1195, Accuracy = 0.2200 Test Loss = 12.3955, Test Accuracy = 0.1854\n",
      "Iteration 811: Loss = 4.5567, Accuracy = 0.1600 Test Loss = 12.4051, Test Accuracy = 0.1870\n",
      "Iteration 812: Loss = 4.0007, Accuracy = 0.3200 Test Loss = 12.3897, Test Accuracy = 0.1862\n",
      "Iteration 813: Loss = 4.1816, Accuracy = 0.3400 Test Loss = 12.3833, Test Accuracy = 0.1867\n",
      "Iteration 814: Loss = 4.0268, Accuracy = 0.2000 Test Loss = 12.3649, Test Accuracy = 0.1853\n",
      "Iteration 815: Loss = 4.0912, Accuracy = 0.2200 Test Loss = 12.3724, Test Accuracy = 0.1872\n",
      "Iteration 816: Loss = 4.3467, Accuracy = 0.2500 Test Loss = 12.3565, Test Accuracy = 0.1853\n",
      "Iteration 817: Loss = 4.4359, Accuracy = 0.2900 Test Loss = 12.3482, Test Accuracy = 0.1869\n",
      "Iteration 818: Loss = 4.2581, Accuracy = 0.3000 Test Loss = 12.3451, Test Accuracy = 0.1860\n",
      "Iteration 819: Loss = 4.4959, Accuracy = 0.2600 Test Loss = 12.3232, Test Accuracy = 0.1852\n",
      "Iteration 820: Loss = 4.2356, Accuracy = 0.2300 Test Loss = 12.3273, Test Accuracy = 0.1856\n",
      "Iteration 821: Loss = 4.4290, Accuracy = 0.2800 Test Loss = 12.3334, Test Accuracy = 0.1863\n",
      "Iteration 822: Loss = 4.1882, Accuracy = 0.2600 Test Loss = 12.3127, Test Accuracy = 0.1863\n",
      "Iteration 823: Loss = 4.1023, Accuracy = 0.2700 Test Loss = 12.3115, Test Accuracy = 0.1870\n",
      "Iteration 824: Loss = 4.0393, Accuracy = 0.2700 Test Loss = 12.2897, Test Accuracy = 0.1849\n",
      "Iteration 825: Loss = 4.4767, Accuracy = 0.2200 Test Loss = 12.2991, Test Accuracy = 0.1866\n",
      "Iteration 826: Loss = 4.3387, Accuracy = 0.2600 Test Loss = 12.2850, Test Accuracy = 0.1863\n",
      "Iteration 827: Loss = 3.8936, Accuracy = 0.2700 Test Loss = 12.2756, Test Accuracy = 0.1864\n",
      "Iteration 828: Loss = 4.1373, Accuracy = 0.3000 Test Loss = 12.2665, Test Accuracy = 0.1848\n",
      "Iteration 829: Loss = 4.1651, Accuracy = 0.2800 Test Loss = 12.2674, Test Accuracy = 0.1855\n",
      "Iteration 830: Loss = 4.3844, Accuracy = 0.2600 Test Loss = 12.2596, Test Accuracy = 0.1861\n",
      "Iteration 831: Loss = 3.9602, Accuracy = 0.2200 Test Loss = 12.2455, Test Accuracy = 0.1860\n",
      "Iteration 832: Loss = 4.1519, Accuracy = 0.2500 Test Loss = 12.2426, Test Accuracy = 0.1868\n",
      "Iteration 833: Loss = 4.4175, Accuracy = 0.2300 Test Loss = 12.2265, Test Accuracy = 0.1856\n",
      "Iteration 834: Loss = 4.4962, Accuracy = 0.2400 Test Loss = 12.2214, Test Accuracy = 0.1852\n",
      "Iteration 835: Loss = 4.1264, Accuracy = 0.2400 Test Loss = 12.2254, Test Accuracy = 0.1864\n",
      "Iteration 836: Loss = 4.0768, Accuracy = 0.3600 Test Loss = 12.2151, Test Accuracy = 0.1858\n",
      "Iteration 837: Loss = 3.9793, Accuracy = 0.2700 Test Loss = 12.2227, Test Accuracy = 0.1869\n",
      "Iteration 838: Loss = 4.1445, Accuracy = 0.3000 Test Loss = 12.1886, Test Accuracy = 0.1858\n",
      "Iteration 839: Loss = 4.5134, Accuracy = 0.2900 Test Loss = 12.1960, Test Accuracy = 0.1864\n",
      "Iteration 840: Loss = 3.9680, Accuracy = 0.2700 Test Loss = 12.1903, Test Accuracy = 0.1870\n",
      "Iteration 841: Loss = 4.3353, Accuracy = 0.2000 Test Loss = 12.1866, Test Accuracy = 0.1859\n",
      "Iteration 842: Loss = 4.2084, Accuracy = 0.2500 Test Loss = 12.1866, Test Accuracy = 0.1859\n",
      "Iteration 843: Loss = 4.1259, Accuracy = 0.2500 Test Loss = 12.1662, Test Accuracy = 0.1861\n",
      "Iteration 844: Loss = 4.3378, Accuracy = 0.1900 Test Loss = 12.1647, Test Accuracy = 0.1871\n",
      "Iteration 845: Loss = 4.0721, Accuracy = 0.2500 Test Loss = 12.1618, Test Accuracy = 0.1862\n",
      "Iteration 846: Loss = 3.8712, Accuracy = 0.2600 Test Loss = 12.1533, Test Accuracy = 0.1859\n",
      "Iteration 847: Loss = 4.0393, Accuracy = 0.2300 Test Loss = 12.1571, Test Accuracy = 0.1867\n",
      "Iteration 848: Loss = 4.3697, Accuracy = 0.2900 Test Loss = 12.1385, Test Accuracy = 0.1872\n",
      "Iteration 849: Loss = 4.3086, Accuracy = 0.2200 Test Loss = 12.1216, Test Accuracy = 0.1864\n",
      "Iteration 850: Loss = 4.2474, Accuracy = 0.2200 Test Loss = 12.1209, Test Accuracy = 0.1864\n",
      "Iteration 851: Loss = 3.9208, Accuracy = 0.2600 Test Loss = 12.1176, Test Accuracy = 0.1863\n",
      "Iteration 852: Loss = 4.3085, Accuracy = 0.2700 Test Loss = 12.1073, Test Accuracy = 0.1868\n",
      "Iteration 853: Loss = 4.0099, Accuracy = 0.3200 Test Loss = 12.0961, Test Accuracy = 0.1875\n",
      "Iteration 854: Loss = 4.0267, Accuracy = 0.2900 Test Loss = 12.1002, Test Accuracy = 0.1865\n",
      "Iteration 855: Loss = 4.3432, Accuracy = 0.2600 Test Loss = 12.0987, Test Accuracy = 0.1857\n",
      "Iteration 856: Loss = 4.1365, Accuracy = 0.2900 Test Loss = 12.0750, Test Accuracy = 0.1870\n",
      "Iteration 857: Loss = 4.4228, Accuracy = 0.2600 Test Loss = 12.0799, Test Accuracy = 0.1862\n",
      "Iteration 858: Loss = 4.1246, Accuracy = 0.2400 Test Loss = 12.0669, Test Accuracy = 0.1880\n",
      "Iteration 859: Loss = 4.0435, Accuracy = 0.2400 Test Loss = 12.0674, Test Accuracy = 0.1869\n",
      "Iteration 860: Loss = 4.2400, Accuracy = 0.2600 Test Loss = 12.0526, Test Accuracy = 0.1865\n",
      "Iteration 861: Loss = 4.0699, Accuracy = 0.1900 Test Loss = 12.0513, Test Accuracy = 0.1869\n",
      "Iteration 862: Loss = 3.9291, Accuracy = 0.2200 Test Loss = 12.0444, Test Accuracy = 0.1871\n",
      "Iteration 863: Loss = 4.5556, Accuracy = 0.2700 Test Loss = 12.0410, Test Accuracy = 0.1874\n",
      "Iteration 864: Loss = 4.1772, Accuracy = 0.2100 Test Loss = 12.0405, Test Accuracy = 0.1876\n",
      "Iteration 865: Loss = 3.9878, Accuracy = 0.2800 Test Loss = 12.0208, Test Accuracy = 0.1879\n",
      "Iteration 866: Loss = 3.9467, Accuracy = 0.3000 Test Loss = 12.0094, Test Accuracy = 0.1869\n",
      "Iteration 867: Loss = 4.2285, Accuracy = 0.3000 Test Loss = 12.0105, Test Accuracy = 0.1868\n",
      "Iteration 868: Loss = 4.0829, Accuracy = 0.2400 Test Loss = 12.0045, Test Accuracy = 0.1882\n",
      "Iteration 869: Loss = 4.1829, Accuracy = 0.2600 Test Loss = 11.9993, Test Accuracy = 0.1883\n",
      "Iteration 870: Loss = 4.0479, Accuracy = 0.3100 Test Loss = 11.9797, Test Accuracy = 0.1875\n",
      "Iteration 871: Loss = 3.9606, Accuracy = 0.2400 Test Loss = 11.9915, Test Accuracy = 0.1875\n",
      "Iteration 872: Loss = 3.9587, Accuracy = 0.2600 Test Loss = 11.9833, Test Accuracy = 0.1876\n",
      "Iteration 873: Loss = 4.0032, Accuracy = 0.2200 Test Loss = 11.9767, Test Accuracy = 0.1879\n",
      "Iteration 874: Loss = 4.0859, Accuracy = 0.2600 Test Loss = 11.9669, Test Accuracy = 0.1881\n",
      "Iteration 875: Loss = 3.8963, Accuracy = 0.2100 Test Loss = 11.9560, Test Accuracy = 0.1872\n",
      "Iteration 876: Loss = 4.1950, Accuracy = 0.2500 Test Loss = 11.9423, Test Accuracy = 0.1879\n",
      "Iteration 877: Loss = 3.9097, Accuracy = 0.2800 Test Loss = 11.9539, Test Accuracy = 0.1886\n",
      "Iteration 878: Loss = 4.0505, Accuracy = 0.2800 Test Loss = 11.9357, Test Accuracy = 0.1897\n",
      "Iteration 879: Loss = 4.1431, Accuracy = 0.2500 Test Loss = 11.9258, Test Accuracy = 0.1884\n",
      "Iteration 880: Loss = 3.9250, Accuracy = 0.2600 Test Loss = 11.9350, Test Accuracy = 0.1883\n",
      "Iteration 881: Loss = 4.1977, Accuracy = 0.2800 Test Loss = 11.9192, Test Accuracy = 0.1885\n",
      "Iteration 882: Loss = 4.0629, Accuracy = 0.1700 Test Loss = 11.9183, Test Accuracy = 0.1891\n",
      "Iteration 883: Loss = 3.8683, Accuracy = 0.2500 Test Loss = 11.9092, Test Accuracy = 0.1874\n",
      "Iteration 884: Loss = 3.6762, Accuracy = 0.2500 Test Loss = 11.8957, Test Accuracy = 0.1869\n",
      "Iteration 885: Loss = 4.1400, Accuracy = 0.2500 Test Loss = 11.8895, Test Accuracy = 0.1884\n",
      "Iteration 886: Loss = 3.7847, Accuracy = 0.3200 Test Loss = 11.8907, Test Accuracy = 0.1880\n",
      "Iteration 887: Loss = 3.9035, Accuracy = 0.2600 Test Loss = 11.8797, Test Accuracy = 0.1878\n",
      "Iteration 888: Loss = 3.8940, Accuracy = 0.3600 Test Loss = 11.8713, Test Accuracy = 0.1887\n",
      "Iteration 889: Loss = 3.9720, Accuracy = 0.3200 Test Loss = 11.8732, Test Accuracy = 0.1890\n",
      "Iteration 890: Loss = 3.7192, Accuracy = 0.3400 Test Loss = 11.8520, Test Accuracy = 0.1881\n",
      "Iteration 891: Loss = 3.8633, Accuracy = 0.2900 Test Loss = 11.8598, Test Accuracy = 0.1880\n",
      "Iteration 892: Loss = 3.5651, Accuracy = 0.3100 Test Loss = 11.8399, Test Accuracy = 0.1890\n",
      "Iteration 893: Loss = 3.8416, Accuracy = 0.2300 Test Loss = 11.8396, Test Accuracy = 0.1883\n",
      "Iteration 894: Loss = 4.0574, Accuracy = 0.2700 Test Loss = 11.8458, Test Accuracy = 0.1895\n",
      "Iteration 895: Loss = 3.9468, Accuracy = 0.2500 Test Loss = 11.8460, Test Accuracy = 0.1892\n",
      "Iteration 896: Loss = 4.1007, Accuracy = 0.2200 Test Loss = 11.8338, Test Accuracy = 0.1895\n",
      "Iteration 897: Loss = 3.7942, Accuracy = 0.3000 Test Loss = 11.8185, Test Accuracy = 0.1882\n",
      "Iteration 898: Loss = 3.7998, Accuracy = 0.3000 Test Loss = 11.8159, Test Accuracy = 0.1890\n",
      "Iteration 899: Loss = 3.8582, Accuracy = 0.2100 Test Loss = 11.8019, Test Accuracy = 0.1882\n",
      "Iteration 900: Loss = 3.8033, Accuracy = 0.3300 Test Loss = 11.8041, Test Accuracy = 0.1876\n",
      "Iteration 901: Loss = 4.0729, Accuracy = 0.2300 Test Loss = 11.7894, Test Accuracy = 0.1882\n",
      "Iteration 902: Loss = 3.9218, Accuracy = 0.2900 Test Loss = 11.7829, Test Accuracy = 0.1888\n",
      "Iteration 903: Loss = 3.6719, Accuracy = 0.3100 Test Loss = 11.7792, Test Accuracy = 0.1901\n",
      "Iteration 904: Loss = 3.7352, Accuracy = 0.2700 Test Loss = 11.7839, Test Accuracy = 0.1895\n",
      "Iteration 905: Loss = 4.0789, Accuracy = 0.3400 Test Loss = 11.7750, Test Accuracy = 0.1888\n",
      "Iteration 906: Loss = 3.7706, Accuracy = 0.3100 Test Loss = 11.7666, Test Accuracy = 0.1890\n",
      "Iteration 907: Loss = 3.9950, Accuracy = 0.2800 Test Loss = 11.7633, Test Accuracy = 0.1888\n",
      "Iteration 908: Loss = 4.1446, Accuracy = 0.2300 Test Loss = 11.7502, Test Accuracy = 0.1888\n",
      "Iteration 909: Loss = 3.8929, Accuracy = 0.3100 Test Loss = 11.7447, Test Accuracy = 0.1898\n",
      "Iteration 910: Loss = 3.4891, Accuracy = 0.2900 Test Loss = 11.7418, Test Accuracy = 0.1894\n",
      "Iteration 911: Loss = 3.6788, Accuracy = 0.2400 Test Loss = 11.7338, Test Accuracy = 0.1897\n",
      "Iteration 912: Loss = 3.9824, Accuracy = 0.2700 Test Loss = 11.7239, Test Accuracy = 0.1892\n",
      "Iteration 913: Loss = 3.9505, Accuracy = 0.2300 Test Loss = 11.7234, Test Accuracy = 0.1896\n",
      "Iteration 914: Loss = 3.7314, Accuracy = 0.2500 Test Loss = 11.7174, Test Accuracy = 0.1902\n",
      "Iteration 915: Loss = 3.9089, Accuracy = 0.2700 Test Loss = 11.7193, Test Accuracy = 0.1905\n",
      "Iteration 916: Loss = 3.7324, Accuracy = 0.3300 Test Loss = 11.6988, Test Accuracy = 0.1893\n",
      "Iteration 917: Loss = 3.7883, Accuracy = 0.2700 Test Loss = 11.7020, Test Accuracy = 0.1893\n",
      "Iteration 918: Loss = 3.5519, Accuracy = 0.2300 Test Loss = 11.6903, Test Accuracy = 0.1898\n",
      "Iteration 919: Loss = 3.7029, Accuracy = 0.3700 Test Loss = 11.6836, Test Accuracy = 0.1887\n",
      "Iteration 920: Loss = 3.8987, Accuracy = 0.2600 Test Loss = 11.6893, Test Accuracy = 0.1893\n",
      "Iteration 921: Loss = 3.7953, Accuracy = 0.2300 Test Loss = 11.6728, Test Accuracy = 0.1903\n",
      "Iteration 922: Loss = 3.5096, Accuracy = 0.2800 Test Loss = 11.6725, Test Accuracy = 0.1892\n",
      "Iteration 923: Loss = 3.8914, Accuracy = 0.2100 Test Loss = 11.6631, Test Accuracy = 0.1892\n",
      "Iteration 924: Loss = 3.7962, Accuracy = 0.2300 Test Loss = 11.6561, Test Accuracy = 0.1902\n",
      "Iteration 925: Loss = 4.1146, Accuracy = 0.2400 Test Loss = 11.6598, Test Accuracy = 0.1903\n",
      "Iteration 926: Loss = 3.9387, Accuracy = 0.2500 Test Loss = 11.6407, Test Accuracy = 0.1897\n",
      "Iteration 927: Loss = 3.8197, Accuracy = 0.3100 Test Loss = 11.6320, Test Accuracy = 0.1895\n",
      "Iteration 928: Loss = 3.5587, Accuracy = 0.2400 Test Loss = 11.6317, Test Accuracy = 0.1897\n",
      "Iteration 929: Loss = 3.7416, Accuracy = 0.3100 Test Loss = 11.6238, Test Accuracy = 0.1889\n",
      "Iteration 930: Loss = 3.6941, Accuracy = 0.3500 Test Loss = 11.6183, Test Accuracy = 0.1899\n",
      "Iteration 931: Loss = 4.0360, Accuracy = 0.3400 Test Loss = 11.6123, Test Accuracy = 0.1893\n",
      "Iteration 932: Loss = 3.7457, Accuracy = 0.2400 Test Loss = 11.6073, Test Accuracy = 0.1893\n",
      "Iteration 933: Loss = 3.9872, Accuracy = 0.2200 Test Loss = 11.5959, Test Accuracy = 0.1900\n",
      "Iteration 934: Loss = 3.9228, Accuracy = 0.3100 Test Loss = 11.5844, Test Accuracy = 0.1886\n",
      "Iteration 935: Loss = 3.6183, Accuracy = 0.3300 Test Loss = 11.5997, Test Accuracy = 0.1896\n",
      "Iteration 936: Loss = 3.6464, Accuracy = 0.2700 Test Loss = 11.5799, Test Accuracy = 0.1896\n",
      "Iteration 937: Loss = 3.7733, Accuracy = 0.2600 Test Loss = 11.5856, Test Accuracy = 0.1893\n",
      "Iteration 938: Loss = 3.7923, Accuracy = 0.3000 Test Loss = 11.5672, Test Accuracy = 0.1894\n",
      "Iteration 939: Loss = 3.6732, Accuracy = 0.2800 Test Loss = 11.5643, Test Accuracy = 0.1903\n",
      "Iteration 940: Loss = 3.9430, Accuracy = 0.3600 Test Loss = 11.5628, Test Accuracy = 0.1890\n",
      "Iteration 941: Loss = 3.4517, Accuracy = 0.2800 Test Loss = 11.5584, Test Accuracy = 0.1903\n",
      "Iteration 942: Loss = 3.7846, Accuracy = 0.2600 Test Loss = 11.5473, Test Accuracy = 0.1901\n",
      "Iteration 943: Loss = 3.5736, Accuracy = 0.2500 Test Loss = 11.5478, Test Accuracy = 0.1904\n",
      "Iteration 944: Loss = 3.8361, Accuracy = 0.2600 Test Loss = 11.5582, Test Accuracy = 0.1905\n",
      "Iteration 945: Loss = 3.7444, Accuracy = 0.2800 Test Loss = 11.5354, Test Accuracy = 0.1896\n",
      "Iteration 946: Loss = 3.6910, Accuracy = 0.2900 Test Loss = 11.5263, Test Accuracy = 0.1905\n",
      "Iteration 947: Loss = 3.6968, Accuracy = 0.3200 Test Loss = 11.5136, Test Accuracy = 0.1890\n",
      "Iteration 948: Loss = 3.5745, Accuracy = 0.3100 Test Loss = 11.5141, Test Accuracy = 0.1912\n",
      "Iteration 949: Loss = 3.6495, Accuracy = 0.2200 Test Loss = 11.5179, Test Accuracy = 0.1908\n",
      "Iteration 950: Loss = 3.4673, Accuracy = 0.3100 Test Loss = 11.5053, Test Accuracy = 0.1900\n",
      "Iteration 951: Loss = 3.3996, Accuracy = 0.3200 Test Loss = 11.5067, Test Accuracy = 0.1907\n",
      "Iteration 952: Loss = 3.8605, Accuracy = 0.2700 Test Loss = 11.4961, Test Accuracy = 0.1906\n",
      "Iteration 953: Loss = 3.7597, Accuracy = 0.2600 Test Loss = 11.4911, Test Accuracy = 0.1911\n",
      "Iteration 954: Loss = 3.7272, Accuracy = 0.2500 Test Loss = 11.4820, Test Accuracy = 0.1911\n",
      "Iteration 955: Loss = 3.6305, Accuracy = 0.2700 Test Loss = 11.4793, Test Accuracy = 0.1906\n",
      "Iteration 956: Loss = 3.5766, Accuracy = 0.3000 Test Loss = 11.4747, Test Accuracy = 0.1902\n",
      "Iteration 957: Loss = 3.5377, Accuracy = 0.2500 Test Loss = 11.4687, Test Accuracy = 0.1899\n",
      "Iteration 958: Loss = 3.6534, Accuracy = 0.2700 Test Loss = 11.4736, Test Accuracy = 0.1904\n",
      "Iteration 959: Loss = 3.9402, Accuracy = 0.2500 Test Loss = 11.4544, Test Accuracy = 0.1895\n",
      "Iteration 960: Loss = 3.3278, Accuracy = 0.3300 Test Loss = 11.4564, Test Accuracy = 0.1916\n",
      "Iteration 961: Loss = 3.7556, Accuracy = 0.2300 Test Loss = 11.4383, Test Accuracy = 0.1904\n",
      "Iteration 962: Loss = 3.6509, Accuracy = 0.2900 Test Loss = 11.4402, Test Accuracy = 0.1904\n",
      "Iteration 963: Loss = 3.9895, Accuracy = 0.2800 Test Loss = 11.4371, Test Accuracy = 0.1903\n",
      "Iteration 964: Loss = 3.8520, Accuracy = 0.2000 Test Loss = 11.4289, Test Accuracy = 0.1910\n",
      "Iteration 965: Loss = 3.7360, Accuracy = 0.2100 Test Loss = 11.4387, Test Accuracy = 0.1918\n",
      "Iteration 966: Loss = 3.4474, Accuracy = 0.3100 Test Loss = 11.4165, Test Accuracy = 0.1906\n",
      "Iteration 967: Loss = 3.5139, Accuracy = 0.2400 Test Loss = 11.4090, Test Accuracy = 0.1905\n",
      "Iteration 968: Loss = 3.8263, Accuracy = 0.2500 Test Loss = 11.4193, Test Accuracy = 0.1909\n",
      "Iteration 969: Loss = 3.5384, Accuracy = 0.2700 Test Loss = 11.4064, Test Accuracy = 0.1916\n",
      "Iteration 970: Loss = 3.7095, Accuracy = 0.2600 Test Loss = 11.4023, Test Accuracy = 0.1907\n",
      "Iteration 971: Loss = 4.0054, Accuracy = 0.2700 Test Loss = 11.3845, Test Accuracy = 0.1910\n",
      "Iteration 972: Loss = 3.6120, Accuracy = 0.3000 Test Loss = 11.3786, Test Accuracy = 0.1910\n",
      "Iteration 973: Loss = 3.7990, Accuracy = 0.2500 Test Loss = 11.3757, Test Accuracy = 0.1898\n",
      "Iteration 974: Loss = 3.3684, Accuracy = 0.3100 Test Loss = 11.3699, Test Accuracy = 0.1911\n",
      "Iteration 975: Loss = 3.5911, Accuracy = 0.2900 Test Loss = 11.3633, Test Accuracy = 0.1903\n",
      "Iteration 976: Loss = 3.5014, Accuracy = 0.2400 Test Loss = 11.3615, Test Accuracy = 0.1910\n",
      "Iteration 977: Loss = 3.5860, Accuracy = 0.2800 Test Loss = 11.3499, Test Accuracy = 0.1921\n",
      "Iteration 978: Loss = 3.5975, Accuracy = 0.3100 Test Loss = 11.3475, Test Accuracy = 0.1905\n",
      "Iteration 979: Loss = 3.6918, Accuracy = 0.2500 Test Loss = 11.3511, Test Accuracy = 0.1917\n",
      "Iteration 980: Loss = 4.0399, Accuracy = 0.2500 Test Loss = 11.3340, Test Accuracy = 0.1905\n",
      "Iteration 981: Loss = 3.2898, Accuracy = 0.2800 Test Loss = 11.3313, Test Accuracy = 0.1904\n",
      "Iteration 982: Loss = 3.7817, Accuracy = 0.2400 Test Loss = 11.3256, Test Accuracy = 0.1911\n",
      "Iteration 983: Loss = 3.6406, Accuracy = 0.2600 Test Loss = 11.3192, Test Accuracy = 0.1908\n",
      "Iteration 984: Loss = 3.7698, Accuracy = 0.2700 Test Loss = 11.3049, Test Accuracy = 0.1909\n",
      "Iteration 985: Loss = 3.5755, Accuracy = 0.2800 Test Loss = 11.3145, Test Accuracy = 0.1898\n",
      "Iteration 986: Loss = 3.6248, Accuracy = 0.2800 Test Loss = 11.3029, Test Accuracy = 0.1914\n",
      "Iteration 987: Loss = 3.5621, Accuracy = 0.2600 Test Loss = 11.3024, Test Accuracy = 0.1917\n",
      "Iteration 988: Loss = 3.5888, Accuracy = 0.2600 Test Loss = 11.2972, Test Accuracy = 0.1903\n",
      "Iteration 989: Loss = 3.5218, Accuracy = 0.2700 Test Loss = 11.3052, Test Accuracy = 0.1915\n",
      "Iteration 990: Loss = 3.5624, Accuracy = 0.3600 Test Loss = 11.2873, Test Accuracy = 0.1912\n",
      "Iteration 991: Loss = 3.6379, Accuracy = 0.2900 Test Loss = 11.2827, Test Accuracy = 0.1922\n",
      "Iteration 992: Loss = 3.4659, Accuracy = 0.3400 Test Loss = 11.2833, Test Accuracy = 0.1919\n",
      "Iteration 993: Loss = 3.5748, Accuracy = 0.2500 Test Loss = 11.2714, Test Accuracy = 0.1912\n",
      "Iteration 994: Loss = 3.5789, Accuracy = 0.2600 Test Loss = 11.2664, Test Accuracy = 0.1899\n",
      "Iteration 995: Loss = 3.5529, Accuracy = 0.2600 Test Loss = 11.2587, Test Accuracy = 0.1903\n",
      "Iteration 996: Loss = 3.3150, Accuracy = 0.3000 Test Loss = 11.2484, Test Accuracy = 0.1905\n",
      "Iteration 997: Loss = 3.5651, Accuracy = 0.3100 Test Loss = 11.2505, Test Accuracy = 0.1915\n",
      "Iteration 998: Loss = 3.3937, Accuracy = 0.2700 Test Loss = 11.2361, Test Accuracy = 0.1915\n",
      "Iteration 999: Loss = 3.5798, Accuracy = 0.2900 Test Loss = 11.2346, Test Accuracy = 0.1912\n",
      "Iteration 1000: Loss = 3.5905, Accuracy = 0.2500 Test Loss = 11.2341, Test Accuracy = 0.1906\n",
      "Iteration 1001: Loss = 3.5732, Accuracy = 0.2500 Test Loss = 11.2290, Test Accuracy = 0.1914\n",
      "Iteration 1002: Loss = 3.4345, Accuracy = 0.2500 Test Loss = 11.2172, Test Accuracy = 0.1916\n",
      "Iteration 1003: Loss = 3.5753, Accuracy = 0.2900 Test Loss = 11.2119, Test Accuracy = 0.1910\n",
      "Iteration 1004: Loss = 3.2724, Accuracy = 0.3000 Test Loss = 11.2082, Test Accuracy = 0.1900\n",
      "Iteration 1005: Loss = 3.3511, Accuracy = 0.3500 Test Loss = 11.2045, Test Accuracy = 0.1903\n",
      "Iteration 1006: Loss = 3.3357, Accuracy = 0.2600 Test Loss = 11.2022, Test Accuracy = 0.1928\n",
      "Iteration 1007: Loss = 3.4893, Accuracy = 0.2900 Test Loss = 11.2004, Test Accuracy = 0.1919\n",
      "Iteration 1008: Loss = 3.6878, Accuracy = 0.2700 Test Loss = 11.2021, Test Accuracy = 0.1910\n",
      "Iteration 1009: Loss = 3.4668, Accuracy = 0.3200 Test Loss = 11.1860, Test Accuracy = 0.1918\n",
      "Iteration 1010: Loss = 3.7635, Accuracy = 0.2600 Test Loss = 11.1804, Test Accuracy = 0.1910\n",
      "Iteration 1011: Loss = 3.4122, Accuracy = 0.3100 Test Loss = 11.1740, Test Accuracy = 0.1916\n",
      "Iteration 1012: Loss = 3.2336, Accuracy = 0.2900 Test Loss = 11.1707, Test Accuracy = 0.1923\n",
      "Iteration 1013: Loss = 3.4159, Accuracy = 0.3400 Test Loss = 11.1619, Test Accuracy = 0.1907\n",
      "Iteration 1014: Loss = 3.6410, Accuracy = 0.2700 Test Loss = 11.1635, Test Accuracy = 0.1905\n",
      "Iteration 1015: Loss = 3.6348, Accuracy = 0.2500 Test Loss = 11.1508, Test Accuracy = 0.1908\n",
      "Iteration 1016: Loss = 3.7097, Accuracy = 0.2800 Test Loss = 11.1407, Test Accuracy = 0.1896\n",
      "Iteration 1017: Loss = 3.4008, Accuracy = 0.3200 Test Loss = 11.1522, Test Accuracy = 0.1923\n",
      "Iteration 1018: Loss = 3.5929, Accuracy = 0.2400 Test Loss = 11.1474, Test Accuracy = 0.1914\n",
      "Iteration 1019: Loss = 3.4067, Accuracy = 0.3300 Test Loss = 11.1306, Test Accuracy = 0.1910\n",
      "Iteration 1020: Loss = 3.6308, Accuracy = 0.2700 Test Loss = 11.1333, Test Accuracy = 0.1928\n",
      "Iteration 1021: Loss = 3.3453, Accuracy = 0.2600 Test Loss = 11.1254, Test Accuracy = 0.1915\n",
      "Iteration 1022: Loss = 3.1326, Accuracy = 0.3100 Test Loss = 11.1203, Test Accuracy = 0.1906\n",
      "Iteration 1023: Loss = 3.3626, Accuracy = 0.3300 Test Loss = 11.1184, Test Accuracy = 0.1913\n",
      "Iteration 1024: Loss = 3.2563, Accuracy = 0.2900 Test Loss = 11.1055, Test Accuracy = 0.1915\n",
      "Iteration 1025: Loss = 3.3331, Accuracy = 0.3800 Test Loss = 11.1103, Test Accuracy = 0.1928\n",
      "Iteration 1026: Loss = 3.3521, Accuracy = 0.3200 Test Loss = 11.1069, Test Accuracy = 0.1913\n",
      "Iteration 1027: Loss = 3.3740, Accuracy = 0.2100 Test Loss = 11.0921, Test Accuracy = 0.1911\n",
      "Iteration 1028: Loss = 3.5185, Accuracy = 0.3000 Test Loss = 11.0940, Test Accuracy = 0.1929\n",
      "Iteration 1029: Loss = 3.4542, Accuracy = 0.2900 Test Loss = 11.0810, Test Accuracy = 0.1913\n",
      "Iteration 1030: Loss = 3.3643, Accuracy = 0.3000 Test Loss = 11.0770, Test Accuracy = 0.1920\n",
      "Iteration 1031: Loss = 3.4410, Accuracy = 0.3500 Test Loss = 11.0805, Test Accuracy = 0.1911\n",
      "Iteration 1032: Loss = 3.3042, Accuracy = 0.3700 Test Loss = 11.0684, Test Accuracy = 0.1919\n",
      "Iteration 1033: Loss = 3.2694, Accuracy = 0.2700 Test Loss = 11.0649, Test Accuracy = 0.1911\n",
      "Iteration 1034: Loss = 3.5017, Accuracy = 0.2700 Test Loss = 11.0640, Test Accuracy = 0.1929\n",
      "Iteration 1035: Loss = 3.5099, Accuracy = 0.2900 Test Loss = 11.0509, Test Accuracy = 0.1922\n",
      "Iteration 1036: Loss = 3.4900, Accuracy = 0.2700 Test Loss = 11.0460, Test Accuracy = 0.1919\n",
      "Iteration 1037: Loss = 3.2830, Accuracy = 0.3000 Test Loss = 11.0434, Test Accuracy = 0.1928\n",
      "Iteration 1038: Loss = 3.3692, Accuracy = 0.3300 Test Loss = 11.0464, Test Accuracy = 0.1901\n",
      "Iteration 1039: Loss = 3.2938, Accuracy = 0.2900 Test Loss = 11.0264, Test Accuracy = 0.1930\n",
      "Iteration 1040: Loss = 3.5335, Accuracy = 0.2700 Test Loss = 11.0254, Test Accuracy = 0.1922\n",
      "Iteration 1041: Loss = 3.3689, Accuracy = 0.3300 Test Loss = 11.0245, Test Accuracy = 0.1925\n",
      "Iteration 1042: Loss = 3.2561, Accuracy = 0.3300 Test Loss = 11.0193, Test Accuracy = 0.1934\n",
      "Iteration 1043: Loss = 3.5097, Accuracy = 0.3000 Test Loss = 11.0140, Test Accuracy = 0.1918\n",
      "Iteration 1044: Loss = 3.6093, Accuracy = 0.2800 Test Loss = 11.0050, Test Accuracy = 0.1916\n",
      "Iteration 1045: Loss = 3.2231, Accuracy = 0.3100 Test Loss = 11.0083, Test Accuracy = 0.1924\n",
      "Iteration 1046: Loss = 3.4034, Accuracy = 0.3300 Test Loss = 10.9915, Test Accuracy = 0.1915\n",
      "Iteration 1047: Loss = 3.4244, Accuracy = 0.2400 Test Loss = 10.9980, Test Accuracy = 0.1912\n",
      "Iteration 1048: Loss = 3.1692, Accuracy = 0.3000 Test Loss = 10.9847, Test Accuracy = 0.1917\n",
      "Iteration 1049: Loss = 3.0592, Accuracy = 0.2900 Test Loss = 10.9790, Test Accuracy = 0.1916\n",
      "Iteration 1050: Loss = 3.5404, Accuracy = 0.2700 Test Loss = 10.9822, Test Accuracy = 0.1930\n",
      "Iteration 1051: Loss = 3.3855, Accuracy = 0.2600 Test Loss = 10.9691, Test Accuracy = 0.1915\n",
      "Iteration 1052: Loss = 3.2960, Accuracy = 0.2800 Test Loss = 10.9683, Test Accuracy = 0.1915\n",
      "Iteration 1053: Loss = 3.1103, Accuracy = 0.3000 Test Loss = 10.9661, Test Accuracy = 0.1919\n",
      "Iteration 1054: Loss = 3.3254, Accuracy = 0.2800 Test Loss = 10.9557, Test Accuracy = 0.1912\n",
      "Iteration 1055: Loss = 2.9523, Accuracy = 0.3700 Test Loss = 10.9569, Test Accuracy = 0.1921\n",
      "Iteration 1056: Loss = 3.3281, Accuracy = 0.2400 Test Loss = 10.9564, Test Accuracy = 0.1921\n",
      "Iteration 1057: Loss = 3.4015, Accuracy = 0.3000 Test Loss = 10.9550, Test Accuracy = 0.1917\n",
      "Iteration 1058: Loss = 3.1420, Accuracy = 0.3300 Test Loss = 10.9399, Test Accuracy = 0.1923\n",
      "Iteration 1059: Loss = 3.1009, Accuracy = 0.2800 Test Loss = 10.9380, Test Accuracy = 0.1918\n",
      "Iteration 1060: Loss = 3.0618, Accuracy = 0.3600 Test Loss = 10.9282, Test Accuracy = 0.1927\n",
      "Iteration 1061: Loss = 3.3165, Accuracy = 0.3300 Test Loss = 10.9214, Test Accuracy = 0.1922\n",
      "Iteration 1062: Loss = 3.2226, Accuracy = 0.2800 Test Loss = 10.9134, Test Accuracy = 0.1924\n",
      "Iteration 1063: Loss = 3.4442, Accuracy = 0.2300 Test Loss = 10.9115, Test Accuracy = 0.1921\n",
      "Iteration 1064: Loss = 3.2716, Accuracy = 0.3100 Test Loss = 10.9007, Test Accuracy = 0.1922\n",
      "Iteration 1065: Loss = 3.1888, Accuracy = 0.2600 Test Loss = 10.9189, Test Accuracy = 0.1928\n",
      "Iteration 1066: Loss = 3.4346, Accuracy = 0.3100 Test Loss = 10.8926, Test Accuracy = 0.1925\n",
      "Iteration 1067: Loss = 3.1280, Accuracy = 0.3400 Test Loss = 10.8922, Test Accuracy = 0.1932\n",
      "Iteration 1068: Loss = 3.3518, Accuracy = 0.2800 Test Loss = 10.9008, Test Accuracy = 0.1929\n",
      "Iteration 1069: Loss = 3.3015, Accuracy = 0.3000 Test Loss = 10.8782, Test Accuracy = 0.1929\n",
      "Iteration 1070: Loss = 3.2765, Accuracy = 0.2400 Test Loss = 10.8759, Test Accuracy = 0.1923\n",
      "Iteration 1071: Loss = 3.2470, Accuracy = 0.2600 Test Loss = 10.8795, Test Accuracy = 0.1932\n",
      "Iteration 1072: Loss = 3.3721, Accuracy = 0.2000 Test Loss = 10.8690, Test Accuracy = 0.1925\n",
      "Iteration 1073: Loss = 3.1910, Accuracy = 0.2400 Test Loss = 10.8699, Test Accuracy = 0.1921\n",
      "Iteration 1074: Loss = 3.2113, Accuracy = 0.3800 Test Loss = 10.8634, Test Accuracy = 0.1935\n",
      "Iteration 1075: Loss = 3.1844, Accuracy = 0.3900 Test Loss = 10.8549, Test Accuracy = 0.1935\n",
      "Iteration 1076: Loss = 3.3593, Accuracy = 0.2800 Test Loss = 10.8545, Test Accuracy = 0.1933\n",
      "Iteration 1077: Loss = 2.9820, Accuracy = 0.2600 Test Loss = 10.8509, Test Accuracy = 0.1923\n",
      "Iteration 1078: Loss = 3.4342, Accuracy = 0.3200 Test Loss = 10.8467, Test Accuracy = 0.1925\n",
      "Iteration 1079: Loss = 3.4854, Accuracy = 0.3000 Test Loss = 10.8388, Test Accuracy = 0.1930\n",
      "Iteration 1080: Loss = 3.1487, Accuracy = 0.2600 Test Loss = 10.8399, Test Accuracy = 0.1930\n",
      "Iteration 1081: Loss = 3.2068, Accuracy = 0.3100 Test Loss = 10.8292, Test Accuracy = 0.1932\n",
      "Iteration 1082: Loss = 3.4772, Accuracy = 0.2900 Test Loss = 10.8122, Test Accuracy = 0.1926\n",
      "Iteration 1083: Loss = 3.3764, Accuracy = 0.2800 Test Loss = 10.8125, Test Accuracy = 0.1927\n",
      "Iteration 1084: Loss = 3.2572, Accuracy = 0.3100 Test Loss = 10.8139, Test Accuracy = 0.1931\n",
      "Iteration 1085: Loss = 3.3667, Accuracy = 0.3200 Test Loss = 10.8007, Test Accuracy = 0.1930\n",
      "Iteration 1086: Loss = 3.3357, Accuracy = 0.3200 Test Loss = 10.8130, Test Accuracy = 0.1923\n",
      "Iteration 1087: Loss = 3.1838, Accuracy = 0.2100 Test Loss = 10.8048, Test Accuracy = 0.1942\n",
      "Iteration 1088: Loss = 3.2807, Accuracy = 0.2600 Test Loss = 10.8019, Test Accuracy = 0.1945\n",
      "Iteration 1089: Loss = 3.0928, Accuracy = 0.2900 Test Loss = 10.7962, Test Accuracy = 0.1936\n",
      "Iteration 1090: Loss = 2.9878, Accuracy = 0.3500 Test Loss = 10.7950, Test Accuracy = 0.1931\n",
      "Iteration 1091: Loss = 3.3128, Accuracy = 0.3200 Test Loss = 10.7856, Test Accuracy = 0.1919\n",
      "Iteration 1092: Loss = 3.3243, Accuracy = 0.2900 Test Loss = 10.7766, Test Accuracy = 0.1931\n",
      "Iteration 1093: Loss = 3.2761, Accuracy = 0.3300 Test Loss = 10.7752, Test Accuracy = 0.1934\n",
      "Iteration 1094: Loss = 3.1429, Accuracy = 0.3100 Test Loss = 10.7745, Test Accuracy = 0.1940\n",
      "Iteration 1095: Loss = 2.9619, Accuracy = 0.3000 Test Loss = 10.7670, Test Accuracy = 0.1944\n",
      "Iteration 1096: Loss = 3.5635, Accuracy = 0.2500 Test Loss = 10.7630, Test Accuracy = 0.1941\n",
      "Iteration 1097: Loss = 3.0723, Accuracy = 0.2500 Test Loss = 10.7544, Test Accuracy = 0.1938\n",
      "Iteration 1098: Loss = 3.0917, Accuracy = 0.3600 Test Loss = 10.7473, Test Accuracy = 0.1941\n",
      "Iteration 1099: Loss = 3.3730, Accuracy = 0.2800 Test Loss = 10.7431, Test Accuracy = 0.1937\n",
      "Iteration 1100: Loss = 3.3447, Accuracy = 0.3900 Test Loss = 10.7423, Test Accuracy = 0.1935\n",
      "Iteration 1101: Loss = 3.2131, Accuracy = 0.2800 Test Loss = 10.7274, Test Accuracy = 0.1934\n",
      "Iteration 1102: Loss = 3.1844, Accuracy = 0.3500 Test Loss = 10.7289, Test Accuracy = 0.1929\n",
      "Iteration 1103: Loss = 2.9980, Accuracy = 0.3000 Test Loss = 10.7340, Test Accuracy = 0.1930\n",
      "Iteration 1104: Loss = 3.1933, Accuracy = 0.2900 Test Loss = 10.7216, Test Accuracy = 0.1933\n",
      "Iteration 1105: Loss = 3.2122, Accuracy = 0.3000 Test Loss = 10.7208, Test Accuracy = 0.1934\n",
      "Iteration 1106: Loss = 2.8764, Accuracy = 0.3000 Test Loss = 10.7075, Test Accuracy = 0.1945\n",
      "Iteration 1107: Loss = 3.2056, Accuracy = 0.2900 Test Loss = 10.7085, Test Accuracy = 0.1937\n",
      "Iteration 1108: Loss = 3.2829, Accuracy = 0.2400 Test Loss = 10.7066, Test Accuracy = 0.1947\n",
      "Iteration 1109: Loss = 3.1646, Accuracy = 0.3300 Test Loss = 10.6989, Test Accuracy = 0.1925\n",
      "Iteration 1110: Loss = 3.2975, Accuracy = 0.3100 Test Loss = 10.7014, Test Accuracy = 0.1939\n",
      "Iteration 1111: Loss = 3.1228, Accuracy = 0.2900 Test Loss = 10.6974, Test Accuracy = 0.1934\n",
      "Iteration 1112: Loss = 3.0954, Accuracy = 0.3300 Test Loss = 10.6928, Test Accuracy = 0.1937\n",
      "Iteration 1113: Loss = 3.1658, Accuracy = 0.3200 Test Loss = 10.6804, Test Accuracy = 0.1935\n",
      "Iteration 1114: Loss = 3.1592, Accuracy = 0.2800 Test Loss = 10.6867, Test Accuracy = 0.1940\n",
      "Iteration 1115: Loss = 3.2196, Accuracy = 0.2300 Test Loss = 10.6718, Test Accuracy = 0.1937\n",
      "Iteration 1116: Loss = 3.1028, Accuracy = 0.3100 Test Loss = 10.6680, Test Accuracy = 0.1939\n",
      "Iteration 1117: Loss = 3.0950, Accuracy = 0.3200 Test Loss = 10.6733, Test Accuracy = 0.1932\n",
      "Iteration 1118: Loss = 3.4420, Accuracy = 0.2700 Test Loss = 10.6657, Test Accuracy = 0.1937\n",
      "Iteration 1119: Loss = 2.9896, Accuracy = 0.2800 Test Loss = 10.6609, Test Accuracy = 0.1943\n",
      "Iteration 1120: Loss = 2.9893, Accuracy = 0.3100 Test Loss = 10.6475, Test Accuracy = 0.1950\n",
      "Iteration 1121: Loss = 3.3992, Accuracy = 0.2800 Test Loss = 10.6474, Test Accuracy = 0.1926\n",
      "Iteration 1122: Loss = 3.1526, Accuracy = 0.3600 Test Loss = 10.6454, Test Accuracy = 0.1942\n",
      "Iteration 1123: Loss = 3.0029, Accuracy = 0.3300 Test Loss = 10.6333, Test Accuracy = 0.1943\n",
      "Iteration 1124: Loss = 3.1304, Accuracy = 0.2200 Test Loss = 10.6303, Test Accuracy = 0.1947\n",
      "Iteration 1125: Loss = 2.9693, Accuracy = 0.2800 Test Loss = 10.6361, Test Accuracy = 0.1932\n",
      "Iteration 1126: Loss = 2.9827, Accuracy = 0.3700 Test Loss = 10.6252, Test Accuracy = 0.1934\n",
      "Iteration 1127: Loss = 3.0683, Accuracy = 0.3400 Test Loss = 10.6234, Test Accuracy = 0.1935\n",
      "Iteration 1128: Loss = 3.0233, Accuracy = 0.3400 Test Loss = 10.6127, Test Accuracy = 0.1948\n",
      "Iteration 1129: Loss = 3.0905, Accuracy = 0.2000 Test Loss = 10.6141, Test Accuracy = 0.1941\n",
      "Iteration 1130: Loss = 3.0538, Accuracy = 0.2900 Test Loss = 10.6061, Test Accuracy = 0.1948\n",
      "Iteration 1131: Loss = 3.1353, Accuracy = 0.2500 Test Loss = 10.6035, Test Accuracy = 0.1952\n",
      "Iteration 1132: Loss = 2.9883, Accuracy = 0.2700 Test Loss = 10.6089, Test Accuracy = 0.1957\n",
      "Iteration 1133: Loss = 3.2029, Accuracy = 0.3700 Test Loss = 10.6017, Test Accuracy = 0.1947\n",
      "Iteration 1134: Loss = 3.0982, Accuracy = 0.3300 Test Loss = 10.5936, Test Accuracy = 0.1940\n",
      "Iteration 1135: Loss = 3.1580, Accuracy = 0.2400 Test Loss = 10.5859, Test Accuracy = 0.1947\n",
      "Iteration 1136: Loss = 3.1288, Accuracy = 0.3100 Test Loss = 10.5803, Test Accuracy = 0.1950\n",
      "Iteration 1137: Loss = 2.9058, Accuracy = 0.2200 Test Loss = 10.5738, Test Accuracy = 0.1944\n",
      "Iteration 1138: Loss = 3.0143, Accuracy = 0.2600 Test Loss = 10.5734, Test Accuracy = 0.1939\n",
      "Iteration 1139: Loss = 2.9870, Accuracy = 0.3000 Test Loss = 10.5764, Test Accuracy = 0.1947\n",
      "Iteration 1140: Loss = 3.0252, Accuracy = 0.3000 Test Loss = 10.5639, Test Accuracy = 0.1942\n",
      "Iteration 1141: Loss = 3.1081, Accuracy = 0.3600 Test Loss = 10.5644, Test Accuracy = 0.1941\n",
      "Iteration 1142: Loss = 2.9527, Accuracy = 0.3000 Test Loss = 10.5578, Test Accuracy = 0.1943\n",
      "Iteration 1143: Loss = 3.0936, Accuracy = 0.2500 Test Loss = 10.5553, Test Accuracy = 0.1949\n",
      "Iteration 1144: Loss = 3.1123, Accuracy = 0.3200 Test Loss = 10.5433, Test Accuracy = 0.1947\n",
      "Iteration 1145: Loss = 3.0422, Accuracy = 0.2800 Test Loss = 10.5452, Test Accuracy = 0.1940\n",
      "Iteration 1146: Loss = 3.0479, Accuracy = 0.3000 Test Loss = 10.5423, Test Accuracy = 0.1943\n",
      "Iteration 1147: Loss = 2.9694, Accuracy = 0.3800 Test Loss = 10.5330, Test Accuracy = 0.1947\n",
      "Iteration 1148: Loss = 3.0446, Accuracy = 0.3200 Test Loss = 10.5236, Test Accuracy = 0.1951\n",
      "Iteration 1149: Loss = 3.2303, Accuracy = 0.2900 Test Loss = 10.5353, Test Accuracy = 0.1948\n",
      "Iteration 1150: Loss = 3.1621, Accuracy = 0.3400 Test Loss = 10.5161, Test Accuracy = 0.1948\n",
      "Iteration 1151: Loss = 3.1539, Accuracy = 0.2900 Test Loss = 10.5115, Test Accuracy = 0.1952\n",
      "Iteration 1152: Loss = 3.0540, Accuracy = 0.3400 Test Loss = 10.5177, Test Accuracy = 0.1944\n",
      "Iteration 1153: Loss = 2.9163, Accuracy = 0.2700 Test Loss = 10.5086, Test Accuracy = 0.1945\n",
      "Iteration 1154: Loss = 3.0258, Accuracy = 0.3200 Test Loss = 10.4992, Test Accuracy = 0.1949\n",
      "Iteration 1155: Loss = 3.0947, Accuracy = 0.3400 Test Loss = 10.4942, Test Accuracy = 0.1949\n",
      "Iteration 1156: Loss = 3.0722, Accuracy = 0.2600 Test Loss = 10.4975, Test Accuracy = 0.1946\n",
      "Iteration 1157: Loss = 2.7935, Accuracy = 0.3500 Test Loss = 10.4907, Test Accuracy = 0.1953\n",
      "Iteration 1158: Loss = 2.9338, Accuracy = 0.3000 Test Loss = 10.4880, Test Accuracy = 0.1935\n",
      "Iteration 1159: Loss = 2.9873, Accuracy = 0.2700 Test Loss = 10.4837, Test Accuracy = 0.1962\n",
      "Iteration 1160: Loss = 3.1060, Accuracy = 0.3100 Test Loss = 10.4865, Test Accuracy = 0.1954\n",
      "Iteration 1161: Loss = 3.2021, Accuracy = 0.2700 Test Loss = 10.4819, Test Accuracy = 0.1946\n",
      "Iteration 1162: Loss = 2.7848, Accuracy = 0.3200 Test Loss = 10.4694, Test Accuracy = 0.1947\n",
      "Iteration 1163: Loss = 3.0589, Accuracy = 0.2900 Test Loss = 10.4759, Test Accuracy = 0.1946\n",
      "Iteration 1164: Loss = 3.2176, Accuracy = 0.2300 Test Loss = 10.4632, Test Accuracy = 0.1950\n",
      "Iteration 1165: Loss = 2.8471, Accuracy = 0.4000 Test Loss = 10.4663, Test Accuracy = 0.1943\n",
      "Iteration 1166: Loss = 3.0559, Accuracy = 0.3900 Test Loss = 10.4535, Test Accuracy = 0.1950\n",
      "Iteration 1167: Loss = 2.7723, Accuracy = 0.3100 Test Loss = 10.4545, Test Accuracy = 0.1942\n",
      "Iteration 1168: Loss = 3.0805, Accuracy = 0.3200 Test Loss = 10.4503, Test Accuracy = 0.1950\n",
      "Iteration 1169: Loss = 3.1217, Accuracy = 0.1900 Test Loss = 10.4350, Test Accuracy = 0.1948\n",
      "Iteration 1170: Loss = 2.9978, Accuracy = 0.3300 Test Loss = 10.4318, Test Accuracy = 0.1960\n",
      "Iteration 1171: Loss = 3.0048, Accuracy = 0.3100 Test Loss = 10.4251, Test Accuracy = 0.1956\n",
      "Iteration 1172: Loss = 2.8028, Accuracy = 0.3100 Test Loss = 10.4328, Test Accuracy = 0.1937\n",
      "Iteration 1173: Loss = 2.9819, Accuracy = 0.3400 Test Loss = 10.4217, Test Accuracy = 0.1953\n",
      "Iteration 1174: Loss = 3.1081, Accuracy = 0.2200 Test Loss = 10.4178, Test Accuracy = 0.1956\n",
      "Iteration 1175: Loss = 2.8207, Accuracy = 0.3600 Test Loss = 10.4216, Test Accuracy = 0.1955\n",
      "Iteration 1176: Loss = 3.2540, Accuracy = 0.2600 Test Loss = 10.4170, Test Accuracy = 0.1953\n",
      "Iteration 1177: Loss = 3.1639, Accuracy = 0.2900 Test Loss = 10.4001, Test Accuracy = 0.1964\n",
      "Iteration 1178: Loss = 2.8477, Accuracy = 0.3400 Test Loss = 10.3983, Test Accuracy = 0.1965\n",
      "Iteration 1179: Loss = 3.1180, Accuracy = 0.3000 Test Loss = 10.4052, Test Accuracy = 0.1954\n",
      "Iteration 1180: Loss = 2.9318, Accuracy = 0.3500 Test Loss = 10.3885, Test Accuracy = 0.1960\n",
      "Iteration 1181: Loss = 2.8734, Accuracy = 0.3500 Test Loss = 10.3912, Test Accuracy = 0.1960\n",
      "Iteration 1182: Loss = 2.9972, Accuracy = 0.2700 Test Loss = 10.3897, Test Accuracy = 0.1959\n",
      "Iteration 1183: Loss = 3.0407, Accuracy = 0.3000 Test Loss = 10.3823, Test Accuracy = 0.1960\n",
      "Iteration 1184: Loss = 2.9038, Accuracy = 0.2800 Test Loss = 10.3818, Test Accuracy = 0.1942\n",
      "Iteration 1185: Loss = 2.6215, Accuracy = 0.3900 Test Loss = 10.3695, Test Accuracy = 0.1959\n",
      "Iteration 1186: Loss = 2.8187, Accuracy = 0.2600 Test Loss = 10.3670, Test Accuracy = 0.1957\n",
      "Iteration 1187: Loss = 2.9752, Accuracy = 0.3000 Test Loss = 10.3649, Test Accuracy = 0.1958\n",
      "Iteration 1188: Loss = 2.8338, Accuracy = 0.3100 Test Loss = 10.3651, Test Accuracy = 0.1956\n",
      "Iteration 1189: Loss = 2.9719, Accuracy = 0.2300 Test Loss = 10.3560, Test Accuracy = 0.1971\n",
      "Iteration 1190: Loss = 2.8873, Accuracy = 0.2800 Test Loss = 10.3498, Test Accuracy = 0.1970\n",
      "Iteration 1191: Loss = 2.9501, Accuracy = 0.3200 Test Loss = 10.3617, Test Accuracy = 0.1959\n",
      "Iteration 1192: Loss = 2.9802, Accuracy = 0.2900 Test Loss = 10.3526, Test Accuracy = 0.1951\n",
      "Iteration 1193: Loss = 2.8277, Accuracy = 0.3400 Test Loss = 10.3397, Test Accuracy = 0.1956\n",
      "Iteration 1194: Loss = 3.0314, Accuracy = 0.3300 Test Loss = 10.3406, Test Accuracy = 0.1960\n",
      "Iteration 1195: Loss = 2.9323, Accuracy = 0.2900 Test Loss = 10.3293, Test Accuracy = 0.1960\n",
      "Iteration 1196: Loss = 2.9078, Accuracy = 0.3700 Test Loss = 10.3245, Test Accuracy = 0.1952\n",
      "Iteration 1197: Loss = 2.8858, Accuracy = 0.3000 Test Loss = 10.3224, Test Accuracy = 0.1951\n",
      "Iteration 1198: Loss = 3.2020, Accuracy = 0.3400 Test Loss = 10.3216, Test Accuracy = 0.1966\n",
      "Iteration 1199: Loss = 2.7702, Accuracy = 0.2700 Test Loss = 10.3232, Test Accuracy = 0.1951\n",
      "Iteration 1200: Loss = 3.0979, Accuracy = 0.3100 Test Loss = 10.3076, Test Accuracy = 0.1963\n",
      "Iteration 1201: Loss = 2.7512, Accuracy = 0.3700 Test Loss = 10.3079, Test Accuracy = 0.1955\n",
      "Iteration 1202: Loss = 2.8995, Accuracy = 0.2400 Test Loss = 10.3130, Test Accuracy = 0.1967\n",
      "Iteration 1203: Loss = 2.8473, Accuracy = 0.3000 Test Loss = 10.3066, Test Accuracy = 0.1959\n",
      "Iteration 1204: Loss = 2.7541, Accuracy = 0.3200 Test Loss = 10.2969, Test Accuracy = 0.1955\n",
      "Iteration 1205: Loss = 2.6823, Accuracy = 0.3600 Test Loss = 10.2926, Test Accuracy = 0.1963\n",
      "Iteration 1206: Loss = 2.9664, Accuracy = 0.2500 Test Loss = 10.2888, Test Accuracy = 0.1969\n",
      "Iteration 1207: Loss = 2.9499, Accuracy = 0.3400 Test Loss = 10.2832, Test Accuracy = 0.1964\n",
      "Iteration 1208: Loss = 3.0524, Accuracy = 0.1900 Test Loss = 10.2837, Test Accuracy = 0.1977\n",
      "Iteration 1209: Loss = 3.0185, Accuracy = 0.3100 Test Loss = 10.2805, Test Accuracy = 0.1964\n",
      "Iteration 1210: Loss = 3.0647, Accuracy = 0.2700 Test Loss = 10.2704, Test Accuracy = 0.1974\n",
      "Iteration 1211: Loss = 2.9197, Accuracy = 0.2800 Test Loss = 10.2673, Test Accuracy = 0.1966\n",
      "Iteration 1212: Loss = 2.7159, Accuracy = 0.3800 Test Loss = 10.2656, Test Accuracy = 0.1966\n",
      "Iteration 1213: Loss = 2.9174, Accuracy = 0.2700 Test Loss = 10.2656, Test Accuracy = 0.1960\n",
      "Iteration 1214: Loss = 2.7835, Accuracy = 0.2900 Test Loss = 10.2585, Test Accuracy = 0.1959\n",
      "Iteration 1215: Loss = 2.8834, Accuracy = 0.3200 Test Loss = 10.2590, Test Accuracy = 0.1968\n",
      "Iteration 1216: Loss = 2.8582, Accuracy = 0.2900 Test Loss = 10.2498, Test Accuracy = 0.1971\n",
      "Iteration 1217: Loss = 2.7609, Accuracy = 0.3000 Test Loss = 10.2459, Test Accuracy = 0.1971\n",
      "Iteration 1218: Loss = 2.6043, Accuracy = 0.3400 Test Loss = 10.2464, Test Accuracy = 0.1966\n",
      "Iteration 1219: Loss = 2.8307, Accuracy = 0.3300 Test Loss = 10.2417, Test Accuracy = 0.1966\n",
      "Iteration 1220: Loss = 2.9613, Accuracy = 0.3100 Test Loss = 10.2312, Test Accuracy = 0.1969\n",
      "Iteration 1221: Loss = 2.7215, Accuracy = 0.2800 Test Loss = 10.2350, Test Accuracy = 0.1968\n",
      "Iteration 1222: Loss = 3.0470, Accuracy = 0.2800 Test Loss = 10.2235, Test Accuracy = 0.1963\n",
      "Iteration 1223: Loss = 2.7984, Accuracy = 0.2800 Test Loss = 10.2222, Test Accuracy = 0.1968\n",
      "Iteration 1224: Loss = 2.7881, Accuracy = 0.3200 Test Loss = 10.2189, Test Accuracy = 0.1960\n",
      "Iteration 1225: Loss = 3.0566, Accuracy = 0.3200 Test Loss = 10.2176, Test Accuracy = 0.1970\n",
      "Iteration 1226: Loss = 2.9340, Accuracy = 0.2700 Test Loss = 10.2079, Test Accuracy = 0.1964\n",
      "Iteration 1227: Loss = 2.5521, Accuracy = 0.3300 Test Loss = 10.2076, Test Accuracy = 0.1971\n",
      "Iteration 1228: Loss = 2.6713, Accuracy = 0.3700 Test Loss = 10.1994, Test Accuracy = 0.1967\n",
      "Iteration 1229: Loss = 2.8482, Accuracy = 0.2900 Test Loss = 10.2031, Test Accuracy = 0.1976\n",
      "Iteration 1230: Loss = 2.7410, Accuracy = 0.3400 Test Loss = 10.1984, Test Accuracy = 0.1966\n",
      "Iteration 1231: Loss = 2.7791, Accuracy = 0.2700 Test Loss = 10.2024, Test Accuracy = 0.1959\n",
      "Iteration 1232: Loss = 2.9599, Accuracy = 0.2400 Test Loss = 10.1850, Test Accuracy = 0.1964\n",
      "Iteration 1233: Loss = 2.8155, Accuracy = 0.3500 Test Loss = 10.1741, Test Accuracy = 0.1961\n",
      "Iteration 1234: Loss = 2.6602, Accuracy = 0.3100 Test Loss = 10.1775, Test Accuracy = 0.1961\n",
      "Iteration 1235: Loss = 2.6189, Accuracy = 0.3300 Test Loss = 10.1791, Test Accuracy = 0.1966\n",
      "Iteration 1236: Loss = 2.8042, Accuracy = 0.2900 Test Loss = 10.1729, Test Accuracy = 0.1978\n",
      "Iteration 1237: Loss = 2.9171, Accuracy = 0.2800 Test Loss = 10.1742, Test Accuracy = 0.1952\n",
      "Iteration 1238: Loss = 2.7432, Accuracy = 0.2900 Test Loss = 10.1610, Test Accuracy = 0.1968\n",
      "Iteration 1239: Loss = 2.7650, Accuracy = 0.3800 Test Loss = 10.1640, Test Accuracy = 0.1961\n",
      "Iteration 1240: Loss = 2.6442, Accuracy = 0.3100 Test Loss = 10.1636, Test Accuracy = 0.1960\n",
      "Iteration 1241: Loss = 2.9753, Accuracy = 0.2700 Test Loss = 10.1541, Test Accuracy = 0.1975\n",
      "Iteration 1242: Loss = 2.7538, Accuracy = 0.3400 Test Loss = 10.1470, Test Accuracy = 0.1969\n",
      "Iteration 1243: Loss = 2.8643, Accuracy = 0.3200 Test Loss = 10.1400, Test Accuracy = 0.1965\n",
      "Iteration 1244: Loss = 2.7369, Accuracy = 0.2800 Test Loss = 10.1393, Test Accuracy = 0.1970\n",
      "Iteration 1245: Loss = 2.5113, Accuracy = 0.4200 Test Loss = 10.1381, Test Accuracy = 0.1977\n",
      "Iteration 1246: Loss = 2.7737, Accuracy = 0.2900 Test Loss = 10.1372, Test Accuracy = 0.1963\n",
      "Iteration 1247: Loss = 2.7388, Accuracy = 0.2900 Test Loss = 10.1293, Test Accuracy = 0.1964\n",
      "Iteration 1248: Loss = 2.7235, Accuracy = 0.3100 Test Loss = 10.1261, Test Accuracy = 0.1966\n",
      "Iteration 1249: Loss = 2.6858, Accuracy = 0.3400 Test Loss = 10.1199, Test Accuracy = 0.1961\n",
      "Iteration 1250: Loss = 2.8707, Accuracy = 0.3000 Test Loss = 10.1205, Test Accuracy = 0.1964\n",
      "Iteration 1251: Loss = 2.7828, Accuracy = 0.3800 Test Loss = 10.1119, Test Accuracy = 0.1963\n",
      "Iteration 1252: Loss = 2.7391, Accuracy = 0.2900 Test Loss = 10.1076, Test Accuracy = 0.1968\n",
      "Iteration 1253: Loss = 2.7548, Accuracy = 0.3400 Test Loss = 10.1182, Test Accuracy = 0.1968\n",
      "Iteration 1254: Loss = 2.5808, Accuracy = 0.3200 Test Loss = 10.0997, Test Accuracy = 0.1973\n",
      "Iteration 1255: Loss = 2.8272, Accuracy = 0.3300 Test Loss = 10.1002, Test Accuracy = 0.1959\n",
      "Iteration 1256: Loss = 2.7990, Accuracy = 0.3400 Test Loss = 10.0967, Test Accuracy = 0.1956\n",
      "Iteration 1257: Loss = 2.7629, Accuracy = 0.3400 Test Loss = 10.0944, Test Accuracy = 0.1966\n",
      "Iteration 1258: Loss = 2.6925, Accuracy = 0.3300 Test Loss = 10.0912, Test Accuracy = 0.1964\n",
      "Iteration 1259: Loss = 2.5590, Accuracy = 0.3700 Test Loss = 10.0811, Test Accuracy = 0.1960\n",
      "Iteration 1260: Loss = 2.6372, Accuracy = 0.3400 Test Loss = 10.0862, Test Accuracy = 0.1972\n",
      "Iteration 1261: Loss = 2.6218, Accuracy = 0.3200 Test Loss = 10.0809, Test Accuracy = 0.1960\n",
      "Iteration 1262: Loss = 2.6972, Accuracy = 0.3300 Test Loss = 10.0765, Test Accuracy = 0.1972\n",
      "Iteration 1263: Loss = 2.6944, Accuracy = 0.3100 Test Loss = 10.0799, Test Accuracy = 0.1966\n",
      "Iteration 1264: Loss = 2.6418, Accuracy = 0.3300 Test Loss = 10.0686, Test Accuracy = 0.1972\n",
      "Iteration 1265: Loss = 2.7698, Accuracy = 0.3300 Test Loss = 10.0597, Test Accuracy = 0.1962\n",
      "Iteration 1266: Loss = 2.8773, Accuracy = 0.3200 Test Loss = 10.0493, Test Accuracy = 0.1966\n",
      "Iteration 1267: Loss = 2.7059, Accuracy = 0.3900 Test Loss = 10.0590, Test Accuracy = 0.1966\n",
      "Iteration 1268: Loss = 2.6262, Accuracy = 0.3100 Test Loss = 10.0480, Test Accuracy = 0.1972\n",
      "Iteration 1269: Loss = 2.6730, Accuracy = 0.2700 Test Loss = 10.0484, Test Accuracy = 0.1977\n",
      "Iteration 1270: Loss = 2.9070, Accuracy = 0.3500 Test Loss = 10.0433, Test Accuracy = 0.1954\n",
      "Iteration 1271: Loss = 2.9272, Accuracy = 0.3200 Test Loss = 10.0329, Test Accuracy = 0.1969\n",
      "Iteration 1272: Loss = 2.6346, Accuracy = 0.3400 Test Loss = 10.0322, Test Accuracy = 0.1961\n",
      "Iteration 1273: Loss = 2.5148, Accuracy = 0.3500 Test Loss = 10.0358, Test Accuracy = 0.1973\n",
      "Iteration 1274: Loss = 2.8664, Accuracy = 0.3100 Test Loss = 10.0294, Test Accuracy = 0.1959\n",
      "Iteration 1275: Loss = 2.7843, Accuracy = 0.4000 Test Loss = 10.0329, Test Accuracy = 0.1964\n",
      "Iteration 1276: Loss = 2.5970, Accuracy = 0.3100 Test Loss = 10.0328, Test Accuracy = 0.1973\n",
      "Iteration 1277: Loss = 2.8375, Accuracy = 0.3600 Test Loss = 10.0207, Test Accuracy = 0.1968\n",
      "Iteration 1278: Loss = 2.5866, Accuracy = 0.3200 Test Loss = 10.0144, Test Accuracy = 0.1968\n",
      "Iteration 1279: Loss = 2.7926, Accuracy = 0.2700 Test Loss = 10.0122, Test Accuracy = 0.1967\n",
      "Iteration 1280: Loss = 2.6851, Accuracy = 0.3500 Test Loss = 10.0132, Test Accuracy = 0.1966\n",
      "Iteration 1281: Loss = 2.8274, Accuracy = 0.3100 Test Loss = 10.0076, Test Accuracy = 0.1974\n",
      "Iteration 1282: Loss = 2.5779, Accuracy = 0.4000 Test Loss = 10.0016, Test Accuracy = 0.1980\n",
      "Iteration 1283: Loss = 2.4205, Accuracy = 0.2900 Test Loss = 9.9972, Test Accuracy = 0.1968\n",
      "Iteration 1284: Loss = 2.5089, Accuracy = 0.3200 Test Loss = 9.9970, Test Accuracy = 0.1968\n",
      "Iteration 1285: Loss = 2.6514, Accuracy = 0.3300 Test Loss = 9.9845, Test Accuracy = 0.1973\n",
      "Iteration 1286: Loss = 2.5513, Accuracy = 0.3600 Test Loss = 9.9800, Test Accuracy = 0.1969\n",
      "Iteration 1287: Loss = 2.9286, Accuracy = 0.3100 Test Loss = 9.9874, Test Accuracy = 0.1981\n",
      "Iteration 1288: Loss = 2.6768, Accuracy = 0.3800 Test Loss = 9.9772, Test Accuracy = 0.1966\n",
      "Iteration 1289: Loss = 2.6096, Accuracy = 0.4000 Test Loss = 9.9776, Test Accuracy = 0.1967\n",
      "Iteration 1290: Loss = 2.7697, Accuracy = 0.3200 Test Loss = 9.9704, Test Accuracy = 0.1969\n",
      "Iteration 1291: Loss = 2.7428, Accuracy = 0.3900 Test Loss = 9.9669, Test Accuracy = 0.1981\n",
      "Iteration 1292: Loss = 2.6330, Accuracy = 0.4000 Test Loss = 9.9667, Test Accuracy = 0.1972\n",
      "Iteration 1293: Loss = 2.5672, Accuracy = 0.4100 Test Loss = 9.9593, Test Accuracy = 0.1968\n",
      "Iteration 1294: Loss = 2.8355, Accuracy = 0.3200 Test Loss = 9.9607, Test Accuracy = 0.1977\n",
      "Iteration 1295: Loss = 2.6761, Accuracy = 0.3400 Test Loss = 9.9513, Test Accuracy = 0.1978\n",
      "Iteration 1296: Loss = 2.7895, Accuracy = 0.3600 Test Loss = 9.9576, Test Accuracy = 0.1978\n",
      "Iteration 1297: Loss = 2.7376, Accuracy = 0.3400 Test Loss = 9.9522, Test Accuracy = 0.1971\n",
      "Iteration 1298: Loss = 2.7028, Accuracy = 0.3100 Test Loss = 9.9472, Test Accuracy = 0.1966\n",
      "Iteration 1299: Loss = 2.6635, Accuracy = 0.3700 Test Loss = 9.9365, Test Accuracy = 0.1974\n",
      "Iteration 1300: Loss = 2.6221, Accuracy = 0.2700 Test Loss = 9.9345, Test Accuracy = 0.1984\n",
      "Iteration 1301: Loss = 2.7833, Accuracy = 0.4300 Test Loss = 9.9307, Test Accuracy = 0.1979\n",
      "Iteration 1302: Loss = 2.7913, Accuracy = 0.2600 Test Loss = 9.9261, Test Accuracy = 0.1963\n",
      "Iteration 1303: Loss = 2.4893, Accuracy = 0.4500 Test Loss = 9.9277, Test Accuracy = 0.1975\n",
      "Iteration 1304: Loss = 2.7006, Accuracy = 0.3200 Test Loss = 9.9211, Test Accuracy = 0.1984\n",
      "Iteration 1305: Loss = 2.6590, Accuracy = 0.3400 Test Loss = 9.9201, Test Accuracy = 0.1982\n",
      "Iteration 1306: Loss = 2.9320, Accuracy = 0.2700 Test Loss = 9.9088, Test Accuracy = 0.1986\n",
      "Iteration 1307: Loss = 2.7480, Accuracy = 0.3100 Test Loss = 9.9087, Test Accuracy = 0.1968\n",
      "Iteration 1308: Loss = 2.5453, Accuracy = 0.3200 Test Loss = 9.9105, Test Accuracy = 0.1984\n",
      "Iteration 1309: Loss = 2.6036, Accuracy = 0.3400 Test Loss = 9.9018, Test Accuracy = 0.1971\n",
      "Iteration 1310: Loss = 2.8131, Accuracy = 0.3300 Test Loss = 9.9022, Test Accuracy = 0.1975\n",
      "Iteration 1311: Loss = 2.7284, Accuracy = 0.2600 Test Loss = 9.8961, Test Accuracy = 0.1973\n",
      "Iteration 1312: Loss = 2.4536, Accuracy = 0.4400 Test Loss = 9.8947, Test Accuracy = 0.1977\n",
      "Iteration 1313: Loss = 2.6946, Accuracy = 0.3000 Test Loss = 9.8879, Test Accuracy = 0.1967\n",
      "Iteration 1314: Loss = 2.6355, Accuracy = 0.4000 Test Loss = 9.8883, Test Accuracy = 0.1982\n",
      "Iteration 1315: Loss = 2.5744, Accuracy = 0.3600 Test Loss = 9.8831, Test Accuracy = 0.1969\n",
      "Iteration 1316: Loss = 2.6402, Accuracy = 0.3300 Test Loss = 9.8789, Test Accuracy = 0.1967\n",
      "Iteration 1317: Loss = 2.6400, Accuracy = 0.3200 Test Loss = 9.8751, Test Accuracy = 0.1980\n",
      "Iteration 1318: Loss = 2.6008, Accuracy = 0.3000 Test Loss = 9.8789, Test Accuracy = 0.1985\n",
      "Iteration 1319: Loss = 2.6673, Accuracy = 0.3600 Test Loss = 9.8687, Test Accuracy = 0.1983\n",
      "Iteration 1320: Loss = 2.6346, Accuracy = 0.3400 Test Loss = 9.8642, Test Accuracy = 0.1975\n",
      "Iteration 1321: Loss = 2.5424, Accuracy = 0.3600 Test Loss = 9.8556, Test Accuracy = 0.1973\n",
      "Iteration 1322: Loss = 2.7759, Accuracy = 0.2400 Test Loss = 9.8645, Test Accuracy = 0.1974\n",
      "Iteration 1323: Loss = 2.6772, Accuracy = 0.3200 Test Loss = 9.8557, Test Accuracy = 0.1972\n",
      "Iteration 1324: Loss = 2.5654, Accuracy = 0.3100 Test Loss = 9.8487, Test Accuracy = 0.1978\n",
      "Iteration 1325: Loss = 2.4996, Accuracy = 0.3200 Test Loss = 9.8495, Test Accuracy = 0.1976\n",
      "Iteration 1326: Loss = 2.5366, Accuracy = 0.3700 Test Loss = 9.8442, Test Accuracy = 0.1971\n",
      "Iteration 1327: Loss = 2.5977, Accuracy = 0.3500 Test Loss = 9.8415, Test Accuracy = 0.1983\n",
      "Iteration 1328: Loss = 2.5626, Accuracy = 0.3600 Test Loss = 9.8381, Test Accuracy = 0.1973\n",
      "Iteration 1329: Loss = 2.5765, Accuracy = 0.3400 Test Loss = 9.8346, Test Accuracy = 0.1971\n",
      "Iteration 1330: Loss = 2.4506, Accuracy = 0.3500 Test Loss = 9.8294, Test Accuracy = 0.1972\n",
      "Iteration 1331: Loss = 2.5645, Accuracy = 0.3800 Test Loss = 9.8291, Test Accuracy = 0.1968\n",
      "Iteration 1332: Loss = 2.6383, Accuracy = 0.4100 Test Loss = 9.8192, Test Accuracy = 0.1981\n",
      "Iteration 1333: Loss = 2.7946, Accuracy = 0.2800 Test Loss = 9.8206, Test Accuracy = 0.1977\n",
      "Iteration 1334: Loss = 2.4495, Accuracy = 0.3800 Test Loss = 9.8128, Test Accuracy = 0.1975\n",
      "Iteration 1335: Loss = 2.6971, Accuracy = 0.4000 Test Loss = 9.8137, Test Accuracy = 0.1985\n",
      "Iteration 1336: Loss = 2.8424, Accuracy = 0.3900 Test Loss = 9.8140, Test Accuracy = 0.1982\n",
      "Iteration 1337: Loss = 2.5360, Accuracy = 0.3100 Test Loss = 9.8089, Test Accuracy = 0.1980\n",
      "Iteration 1338: Loss = 2.4699, Accuracy = 0.4200 Test Loss = 9.8047, Test Accuracy = 0.1982\n",
      "Iteration 1339: Loss = 2.5542, Accuracy = 0.3800 Test Loss = 9.7963, Test Accuracy = 0.1981\n",
      "Iteration 1340: Loss = 2.7344, Accuracy = 0.3100 Test Loss = 9.8008, Test Accuracy = 0.1995\n",
      "Iteration 1341: Loss = 2.5267, Accuracy = 0.3100 Test Loss = 9.7964, Test Accuracy = 0.1983\n",
      "Iteration 1342: Loss = 2.5240, Accuracy = 0.3100 Test Loss = 9.7855, Test Accuracy = 0.1989\n",
      "Iteration 1343: Loss = 2.4105, Accuracy = 0.3300 Test Loss = 9.7874, Test Accuracy = 0.1987\n",
      "Iteration 1344: Loss = 2.5756, Accuracy = 0.2800 Test Loss = 9.7857, Test Accuracy = 0.1987\n",
      "Iteration 1345: Loss = 2.6179, Accuracy = 0.3400 Test Loss = 9.7811, Test Accuracy = 0.1995\n",
      "Iteration 1346: Loss = 2.5257, Accuracy = 0.2500 Test Loss = 9.7775, Test Accuracy = 0.1987\n",
      "Iteration 1347: Loss = 2.5670, Accuracy = 0.3300 Test Loss = 9.7734, Test Accuracy = 0.1991\n",
      "Iteration 1348: Loss = 2.6201, Accuracy = 0.4500 Test Loss = 9.7698, Test Accuracy = 0.1985\n",
      "Iteration 1349: Loss = 2.7465, Accuracy = 0.3100 Test Loss = 9.7648, Test Accuracy = 0.1989\n",
      "Iteration 1350: Loss = 2.7437, Accuracy = 0.3600 Test Loss = 9.7626, Test Accuracy = 0.1984\n",
      "Iteration 1351: Loss = 2.6676, Accuracy = 0.3800 Test Loss = 9.7625, Test Accuracy = 0.1990\n",
      "Iteration 1352: Loss = 2.6216, Accuracy = 0.2500 Test Loss = 9.7517, Test Accuracy = 0.1980\n",
      "Iteration 1353: Loss = 2.6518, Accuracy = 0.3600 Test Loss = 9.7549, Test Accuracy = 0.1989\n",
      "Iteration 1354: Loss = 2.4280, Accuracy = 0.2800 Test Loss = 9.7526, Test Accuracy = 0.1981\n",
      "Iteration 1355: Loss = 2.4857, Accuracy = 0.3800 Test Loss = 9.7517, Test Accuracy = 0.1989\n",
      "Iteration 1356: Loss = 2.3661, Accuracy = 0.3600 Test Loss = 9.7363, Test Accuracy = 0.1990\n",
      "Iteration 1357: Loss = 2.3900, Accuracy = 0.3600 Test Loss = 9.7326, Test Accuracy = 0.1985\n",
      "Iteration 1358: Loss = 2.8017, Accuracy = 0.3500 Test Loss = 9.7322, Test Accuracy = 0.1984\n",
      "Iteration 1359: Loss = 2.4131, Accuracy = 0.3200 Test Loss = 9.7343, Test Accuracy = 0.1988\n",
      "Iteration 1360: Loss = 2.5176, Accuracy = 0.3800 Test Loss = 9.7306, Test Accuracy = 0.1984\n",
      "Iteration 1361: Loss = 2.3942, Accuracy = 0.3900 Test Loss = 9.7311, Test Accuracy = 0.1995\n",
      "Iteration 1362: Loss = 2.3045, Accuracy = 0.4100 Test Loss = 9.7204, Test Accuracy = 0.1972\n",
      "Iteration 1363: Loss = 2.3778, Accuracy = 0.3500 Test Loss = 9.7176, Test Accuracy = 0.1991\n",
      "Iteration 1364: Loss = 2.5098, Accuracy = 0.3700 Test Loss = 9.7245, Test Accuracy = 0.1991\n",
      "Iteration 1365: Loss = 2.5505, Accuracy = 0.3000 Test Loss = 9.7124, Test Accuracy = 0.1980\n",
      "Iteration 1366: Loss = 2.4918, Accuracy = 0.2700 Test Loss = 9.7160, Test Accuracy = 0.1993\n",
      "Iteration 1367: Loss = 2.6016, Accuracy = 0.3500 Test Loss = 9.7033, Test Accuracy = 0.1987\n",
      "Iteration 1368: Loss = 2.5300, Accuracy = 0.3500 Test Loss = 9.7056, Test Accuracy = 0.1986\n",
      "Iteration 1369: Loss = 2.4013, Accuracy = 0.2800 Test Loss = 9.6973, Test Accuracy = 0.1992\n",
      "Iteration 1370: Loss = 2.4191, Accuracy = 0.3500 Test Loss = 9.7017, Test Accuracy = 0.1984\n",
      "Iteration 1371: Loss = 2.4277, Accuracy = 0.3900 Test Loss = 9.6964, Test Accuracy = 0.1995\n",
      "Iteration 1372: Loss = 2.4729, Accuracy = 0.3200 Test Loss = 9.6889, Test Accuracy = 0.1994\n",
      "Iteration 1373: Loss = 2.4449, Accuracy = 0.3300 Test Loss = 9.6852, Test Accuracy = 0.1998\n",
      "Iteration 1374: Loss = 2.2675, Accuracy = 0.3200 Test Loss = 9.6860, Test Accuracy = 0.1986\n",
      "Iteration 1375: Loss = 2.5220, Accuracy = 0.3100 Test Loss = 9.6831, Test Accuracy = 0.1992\n",
      "Iteration 1376: Loss = 2.5510, Accuracy = 0.3900 Test Loss = 9.6829, Test Accuracy = 0.1996\n",
      "Iteration 1377: Loss = 2.6435, Accuracy = 0.3100 Test Loss = 9.6754, Test Accuracy = 0.1992\n",
      "Iteration 1378: Loss = 2.5688, Accuracy = 0.3300 Test Loss = 9.6750, Test Accuracy = 0.2002\n",
      "Iteration 1379: Loss = 2.4517, Accuracy = 0.3500 Test Loss = 9.6762, Test Accuracy = 0.1990\n",
      "Iteration 1380: Loss = 2.5800, Accuracy = 0.3500 Test Loss = 9.6661, Test Accuracy = 0.1997\n",
      "Iteration 1381: Loss = 2.4863, Accuracy = 0.3300 Test Loss = 9.6655, Test Accuracy = 0.1995\n",
      "Iteration 1382: Loss = 2.5768, Accuracy = 0.3200 Test Loss = 9.6557, Test Accuracy = 0.1998\n",
      "Iteration 1383: Loss = 2.5285, Accuracy = 0.3100 Test Loss = 9.6516, Test Accuracy = 0.1998\n",
      "Iteration 1384: Loss = 2.5002, Accuracy = 0.3700 Test Loss = 9.6509, Test Accuracy = 0.1989\n",
      "Iteration 1385: Loss = 2.5095, Accuracy = 0.3600 Test Loss = 9.6497, Test Accuracy = 0.1996\n",
      "Iteration 1386: Loss = 2.3087, Accuracy = 0.4100 Test Loss = 9.6485, Test Accuracy = 0.1993\n",
      "Iteration 1387: Loss = 2.5645, Accuracy = 0.3500 Test Loss = 9.6436, Test Accuracy = 0.1992\n",
      "Iteration 1388: Loss = 2.4603, Accuracy = 0.3000 Test Loss = 9.6378, Test Accuracy = 0.1997\n",
      "Iteration 1389: Loss = 2.4147, Accuracy = 0.3700 Test Loss = 9.6445, Test Accuracy = 0.1994\n",
      "Iteration 1390: Loss = 2.3264, Accuracy = 0.3400 Test Loss = 9.6302, Test Accuracy = 0.1992\n",
      "Iteration 1391: Loss = 2.4708, Accuracy = 0.2800 Test Loss = 9.6356, Test Accuracy = 0.2002\n",
      "Iteration 1392: Loss = 2.3519, Accuracy = 0.3400 Test Loss = 9.6258, Test Accuracy = 0.2001\n",
      "Iteration 1393: Loss = 2.5638, Accuracy = 0.3500 Test Loss = 9.6195, Test Accuracy = 0.1995\n",
      "Iteration 1394: Loss = 2.6572, Accuracy = 0.3600 Test Loss = 9.6174, Test Accuracy = 0.2005\n",
      "Iteration 1395: Loss = 2.5109, Accuracy = 0.3200 Test Loss = 9.6176, Test Accuracy = 0.2004\n",
      "Iteration 1396: Loss = 2.5503, Accuracy = 0.3400 Test Loss = 9.6079, Test Accuracy = 0.1999\n",
      "Iteration 1397: Loss = 2.5747, Accuracy = 0.2500 Test Loss = 9.6103, Test Accuracy = 0.2005\n",
      "Iteration 1398: Loss = 2.5287, Accuracy = 0.3100 Test Loss = 9.6075, Test Accuracy = 0.2005\n",
      "Iteration 1399: Loss = 2.5272, Accuracy = 0.3200 Test Loss = 9.6028, Test Accuracy = 0.1995\n",
      "Iteration 1400: Loss = 2.2758, Accuracy = 0.3500 Test Loss = 9.6043, Test Accuracy = 0.1993\n",
      "Iteration 1401: Loss = 2.4698, Accuracy = 0.2500 Test Loss = 9.5998, Test Accuracy = 0.2007\n",
      "Iteration 1402: Loss = 2.5318, Accuracy = 0.3100 Test Loss = 9.5938, Test Accuracy = 0.2008\n",
      "Iteration 1403: Loss = 2.3659, Accuracy = 0.4000 Test Loss = 9.5867, Test Accuracy = 0.2003\n",
      "Iteration 1404: Loss = 2.3537, Accuracy = 0.4000 Test Loss = 9.5865, Test Accuracy = 0.2009\n",
      "Iteration 1405: Loss = 2.4645, Accuracy = 0.3700 Test Loss = 9.5882, Test Accuracy = 0.2005\n",
      "Iteration 1406: Loss = 2.4268, Accuracy = 0.3900 Test Loss = 9.5774, Test Accuracy = 0.2001\n",
      "Iteration 1407: Loss = 2.4631, Accuracy = 0.2700 Test Loss = 9.5803, Test Accuracy = 0.2007\n",
      "Iteration 1408: Loss = 2.4861, Accuracy = 0.2400 Test Loss = 9.5724, Test Accuracy = 0.2004\n",
      "Iteration 1409: Loss = 2.6201, Accuracy = 0.2900 Test Loss = 9.5667, Test Accuracy = 0.2006\n",
      "Iteration 1410: Loss = 2.3976, Accuracy = 0.2800 Test Loss = 9.5748, Test Accuracy = 0.2005\n",
      "Iteration 1411: Loss = 2.5022, Accuracy = 0.3300 Test Loss = 9.5691, Test Accuracy = 0.2001\n",
      "Iteration 1412: Loss = 2.4009, Accuracy = 0.3600 Test Loss = 9.5612, Test Accuracy = 0.2009\n",
      "Iteration 1413: Loss = 2.5613, Accuracy = 0.3500 Test Loss = 9.5548, Test Accuracy = 0.2010\n",
      "Iteration 1414: Loss = 2.4074, Accuracy = 0.3300 Test Loss = 9.5626, Test Accuracy = 0.2003\n",
      "Iteration 1415: Loss = 2.3318, Accuracy = 0.4200 Test Loss = 9.5606, Test Accuracy = 0.2016\n",
      "Iteration 1416: Loss = 2.4992, Accuracy = 0.3900 Test Loss = 9.5562, Test Accuracy = 0.2001\n",
      "Iteration 1417: Loss = 2.5762, Accuracy = 0.3700 Test Loss = 9.5511, Test Accuracy = 0.1989\n",
      "Iteration 1418: Loss = 2.4829, Accuracy = 0.3600 Test Loss = 9.5495, Test Accuracy = 0.2004\n",
      "Iteration 1419: Loss = 2.2863, Accuracy = 0.4200 Test Loss = 9.5362, Test Accuracy = 0.1998\n",
      "Iteration 1420: Loss = 2.4799, Accuracy = 0.2700 Test Loss = 9.5336, Test Accuracy = 0.2011\n",
      "Iteration 1421: Loss = 2.5076, Accuracy = 0.3400 Test Loss = 9.5370, Test Accuracy = 0.2004\n",
      "Iteration 1422: Loss = 2.4825, Accuracy = 0.3200 Test Loss = 9.5360, Test Accuracy = 0.2011\n",
      "Iteration 1423: Loss = 2.4155, Accuracy = 0.3200 Test Loss = 9.5256, Test Accuracy = 0.2006\n",
      "Iteration 1424: Loss = 2.4778, Accuracy = 0.3000 Test Loss = 9.5326, Test Accuracy = 0.2003\n",
      "Iteration 1425: Loss = 2.4613, Accuracy = 0.2900 Test Loss = 9.5265, Test Accuracy = 0.2019\n",
      "Iteration 1426: Loss = 2.4784, Accuracy = 0.4100 Test Loss = 9.5278, Test Accuracy = 0.2007\n",
      "Iteration 1427: Loss = 2.5630, Accuracy = 0.2600 Test Loss = 9.5179, Test Accuracy = 0.2010\n",
      "Iteration 1428: Loss = 2.4470, Accuracy = 0.3800 Test Loss = 9.5094, Test Accuracy = 0.2005\n",
      "Iteration 1429: Loss = 2.3309, Accuracy = 0.3800 Test Loss = 9.5092, Test Accuracy = 0.2014\n",
      "Iteration 1430: Loss = 2.4135, Accuracy = 0.3500 Test Loss = 9.5016, Test Accuracy = 0.1991\n",
      "Iteration 1431: Loss = 2.2982, Accuracy = 0.3400 Test Loss = 9.5031, Test Accuracy = 0.2002\n",
      "Iteration 1432: Loss = 2.2461, Accuracy = 0.3600 Test Loss = 9.4969, Test Accuracy = 0.2009\n",
      "Iteration 1433: Loss = 2.4819, Accuracy = 0.3200 Test Loss = 9.4964, Test Accuracy = 0.2006\n",
      "Iteration 1434: Loss = 2.4388, Accuracy = 0.3400 Test Loss = 9.4972, Test Accuracy = 0.1990\n",
      "Iteration 1435: Loss = 2.4515, Accuracy = 0.2900 Test Loss = 9.4855, Test Accuracy = 0.2007\n",
      "Iteration 1436: Loss = 2.3948, Accuracy = 0.3600 Test Loss = 9.4837, Test Accuracy = 0.2021\n",
      "Iteration 1437: Loss = 2.4083, Accuracy = 0.3000 Test Loss = 9.4846, Test Accuracy = 0.2004\n",
      "Iteration 1438: Loss = 2.3120, Accuracy = 0.3400 Test Loss = 9.4808, Test Accuracy = 0.2016\n",
      "Iteration 1439: Loss = 2.3040, Accuracy = 0.3900 Test Loss = 9.4859, Test Accuracy = 0.2007\n",
      "Iteration 1440: Loss = 2.3487, Accuracy = 0.3700 Test Loss = 9.4737, Test Accuracy = 0.2000\n",
      "Iteration 1441: Loss = 2.3824, Accuracy = 0.4000 Test Loss = 9.4677, Test Accuracy = 0.2010\n",
      "Iteration 1442: Loss = 2.3884, Accuracy = 0.2900 Test Loss = 9.4704, Test Accuracy = 0.2005\n",
      "Iteration 1443: Loss = 2.3869, Accuracy = 0.2800 Test Loss = 9.4698, Test Accuracy = 0.2004\n",
      "Iteration 1444: Loss = 2.4568, Accuracy = 0.3600 Test Loss = 9.4655, Test Accuracy = 0.2017\n",
      "Iteration 1445: Loss = 2.3078, Accuracy = 0.3600 Test Loss = 9.4559, Test Accuracy = 0.2004\n",
      "Iteration 1446: Loss = 2.2689, Accuracy = 0.3400 Test Loss = 9.4558, Test Accuracy = 0.2000\n",
      "Iteration 1447: Loss = 2.2674, Accuracy = 0.2800 Test Loss = 9.4530, Test Accuracy = 0.2005\n",
      "Iteration 1448: Loss = 2.4284, Accuracy = 0.3000 Test Loss = 9.4491, Test Accuracy = 0.2007\n",
      "Iteration 1449: Loss = 2.4799, Accuracy = 0.3300 Test Loss = 9.4566, Test Accuracy = 0.1998\n",
      "Iteration 1450: Loss = 2.3244, Accuracy = 0.3700 Test Loss = 9.4471, Test Accuracy = 0.2009\n",
      "Iteration 1451: Loss = 2.4810, Accuracy = 0.3000 Test Loss = 9.4389, Test Accuracy = 0.2015\n",
      "Iteration 1452: Loss = 2.3049, Accuracy = 0.4200 Test Loss = 9.4321, Test Accuracy = 0.2020\n",
      "Iteration 1453: Loss = 2.4204, Accuracy = 0.3200 Test Loss = 9.4303, Test Accuracy = 0.2012\n",
      "Iteration 1454: Loss = 2.2935, Accuracy = 0.3300 Test Loss = 9.4303, Test Accuracy = 0.2014\n",
      "Iteration 1455: Loss = 2.3504, Accuracy = 0.3700 Test Loss = 9.4238, Test Accuracy = 0.2019\n",
      "Iteration 1456: Loss = 2.2771, Accuracy = 0.3400 Test Loss = 9.4257, Test Accuracy = 0.2010\n",
      "Iteration 1457: Loss = 2.3033, Accuracy = 0.3100 Test Loss = 9.4276, Test Accuracy = 0.2010\n",
      "Iteration 1458: Loss = 2.1158, Accuracy = 0.4400 Test Loss = 9.4195, Test Accuracy = 0.2016\n",
      "Iteration 1459: Loss = 2.2222, Accuracy = 0.3800 Test Loss = 9.4149, Test Accuracy = 0.2018\n",
      "Iteration 1460: Loss = 2.5162, Accuracy = 0.3300 Test Loss = 9.4205, Test Accuracy = 0.2004\n",
      "Iteration 1461: Loss = 2.5293, Accuracy = 0.3000 Test Loss = 9.4147, Test Accuracy = 0.2027\n",
      "Iteration 1462: Loss = 2.3476, Accuracy = 0.3300 Test Loss = 9.4073, Test Accuracy = 0.2021\n",
      "Iteration 1463: Loss = 2.4175, Accuracy = 0.3900 Test Loss = 9.4082, Test Accuracy = 0.2012\n",
      "Iteration 1464: Loss = 2.3159, Accuracy = 0.4300 Test Loss = 9.3940, Test Accuracy = 0.2003\n",
      "Iteration 1465: Loss = 2.4042, Accuracy = 0.2900 Test Loss = 9.4040, Test Accuracy = 0.2018\n",
      "Iteration 1466: Loss = 2.4652, Accuracy = 0.2800 Test Loss = 9.3930, Test Accuracy = 0.2014\n",
      "Iteration 1467: Loss = 2.3826, Accuracy = 0.3200 Test Loss = 9.3961, Test Accuracy = 0.2009\n",
      "Iteration 1468: Loss = 2.3419, Accuracy = 0.2800 Test Loss = 9.3963, Test Accuracy = 0.2021\n",
      "Iteration 1469: Loss = 2.1390, Accuracy = 0.4500 Test Loss = 9.3948, Test Accuracy = 0.2008\n",
      "Iteration 1470: Loss = 2.2793, Accuracy = 0.4100 Test Loss = 9.3885, Test Accuracy = 0.2016\n",
      "Iteration 1471: Loss = 2.2270, Accuracy = 0.3700 Test Loss = 9.3894, Test Accuracy = 0.2017\n",
      "Iteration 1472: Loss = 2.3127, Accuracy = 0.3700 Test Loss = 9.3830, Test Accuracy = 0.2014\n",
      "Iteration 1473: Loss = 2.5354, Accuracy = 0.2800 Test Loss = 9.3835, Test Accuracy = 0.2005\n",
      "Iteration 1474: Loss = 2.3747, Accuracy = 0.3100 Test Loss = 9.3730, Test Accuracy = 0.2018\n",
      "Iteration 1475: Loss = 2.2218, Accuracy = 0.2800 Test Loss = 9.3748, Test Accuracy = 0.2006\n",
      "Iteration 1476: Loss = 2.2513, Accuracy = 0.3400 Test Loss = 9.3608, Test Accuracy = 0.2013\n",
      "Iteration 1477: Loss = 2.3934, Accuracy = 0.2900 Test Loss = 9.3595, Test Accuracy = 0.2023\n",
      "Iteration 1478: Loss = 2.3203, Accuracy = 0.3300 Test Loss = 9.3636, Test Accuracy = 0.2022\n",
      "Iteration 1479: Loss = 2.3587, Accuracy = 0.3500 Test Loss = 9.3569, Test Accuracy = 0.2010\n",
      "Iteration 1480: Loss = 2.4430, Accuracy = 0.4100 Test Loss = 9.3639, Test Accuracy = 0.2009\n",
      "Iteration 1481: Loss = 2.1136, Accuracy = 0.4300 Test Loss = 9.3641, Test Accuracy = 0.2019\n",
      "Iteration 1482: Loss = 2.3467, Accuracy = 0.3800 Test Loss = 9.3564, Test Accuracy = 0.2011\n",
      "Iteration 1483: Loss = 2.4132, Accuracy = 0.3600 Test Loss = 9.3467, Test Accuracy = 0.2022\n",
      "Iteration 1484: Loss = 2.2378, Accuracy = 0.3500 Test Loss = 9.3483, Test Accuracy = 0.2007\n",
      "Iteration 1485: Loss = 2.1036, Accuracy = 0.4200 Test Loss = 9.3401, Test Accuracy = 0.2019\n",
      "Iteration 1486: Loss = 2.2932, Accuracy = 0.3300 Test Loss = 9.3362, Test Accuracy = 0.2014\n",
      "Iteration 1487: Loss = 2.3405, Accuracy = 0.2800 Test Loss = 9.3358, Test Accuracy = 0.2016\n",
      "Iteration 1488: Loss = 2.2995, Accuracy = 0.3500 Test Loss = 9.3283, Test Accuracy = 0.2020\n",
      "Iteration 1489: Loss = 2.2602, Accuracy = 0.4000 Test Loss = 9.3278, Test Accuracy = 0.2010\n",
      "Iteration 1490: Loss = 2.1916, Accuracy = 0.3400 Test Loss = 9.3250, Test Accuracy = 0.2007\n",
      "Iteration 1491: Loss = 2.3689, Accuracy = 0.3400 Test Loss = 9.3265, Test Accuracy = 0.2015\n",
      "Iteration 1492: Loss = 2.4675, Accuracy = 0.3100 Test Loss = 9.3275, Test Accuracy = 0.2007\n",
      "Iteration 1493: Loss = 2.0765, Accuracy = 0.4400 Test Loss = 9.3170, Test Accuracy = 0.2013\n",
      "Iteration 1494: Loss = 2.2391, Accuracy = 0.3600 Test Loss = 9.3122, Test Accuracy = 0.2007\n",
      "Iteration 1495: Loss = 2.2492, Accuracy = 0.3200 Test Loss = 9.3109, Test Accuracy = 0.2016\n",
      "Iteration 1496: Loss = 2.3174, Accuracy = 0.3900 Test Loss = 9.3091, Test Accuracy = 0.2019\n",
      "Iteration 1497: Loss = 2.1615, Accuracy = 0.3800 Test Loss = 9.3103, Test Accuracy = 0.2016\n",
      "Iteration 1498: Loss = 2.1819, Accuracy = 0.3500 Test Loss = 9.3066, Test Accuracy = 0.2027\n",
      "Iteration 1499: Loss = 2.2785, Accuracy = 0.2800 Test Loss = 9.2991, Test Accuracy = 0.2022\n",
      "Iteration 1500: Loss = 2.2654, Accuracy = 0.3800 Test Loss = 9.2927, Test Accuracy = 0.2021\n",
      "Iteration 1501: Loss = 2.3990, Accuracy = 0.3100 Test Loss = 9.2898, Test Accuracy = 0.2017\n",
      "Iteration 1502: Loss = 2.1976, Accuracy = 0.4400 Test Loss = 9.2942, Test Accuracy = 0.2023\n",
      "Iteration 1503: Loss = 2.2846, Accuracy = 0.4500 Test Loss = 9.2890, Test Accuracy = 0.2026\n",
      "Iteration 1504: Loss = 2.2796, Accuracy = 0.3700 Test Loss = 9.2855, Test Accuracy = 0.2020\n",
      "Iteration 1505: Loss = 2.2714, Accuracy = 0.3300 Test Loss = 9.2815, Test Accuracy = 0.2022\n",
      "Iteration 1506: Loss = 2.2577, Accuracy = 0.4300 Test Loss = 9.2803, Test Accuracy = 0.2014\n",
      "Iteration 1507: Loss = 2.4177, Accuracy = 0.2600 Test Loss = 9.2787, Test Accuracy = 0.2015\n",
      "Iteration 1508: Loss = 2.1851, Accuracy = 0.3300 Test Loss = 9.2733, Test Accuracy = 0.2024\n",
      "Iteration 1509: Loss = 2.2455, Accuracy = 0.3800 Test Loss = 9.2694, Test Accuracy = 0.2011\n",
      "Iteration 1510: Loss = 2.2621, Accuracy = 0.2900 Test Loss = 9.2703, Test Accuracy = 0.2013\n",
      "Iteration 1511: Loss = 2.3052, Accuracy = 0.3200 Test Loss = 9.2677, Test Accuracy = 0.2016\n",
      "Iteration 1512: Loss = 2.1999, Accuracy = 0.3500 Test Loss = 9.2596, Test Accuracy = 0.2018\n",
      "Iteration 1513: Loss = 2.1685, Accuracy = 0.3700 Test Loss = 9.2570, Test Accuracy = 0.2012\n",
      "Iteration 1514: Loss = 2.3774, Accuracy = 0.4300 Test Loss = 9.2583, Test Accuracy = 0.2018\n",
      "Iteration 1515: Loss = 2.3486, Accuracy = 0.3600 Test Loss = 9.2606, Test Accuracy = 0.2015\n",
      "Iteration 1516: Loss = 2.2481, Accuracy = 0.4300 Test Loss = 9.2475, Test Accuracy = 0.2019\n",
      "Iteration 1517: Loss = 2.3216, Accuracy = 0.4100 Test Loss = 9.2538, Test Accuracy = 0.2027\n",
      "Iteration 1518: Loss = 2.2719, Accuracy = 0.3900 Test Loss = 9.2496, Test Accuracy = 0.2015\n",
      "Iteration 1519: Loss = 2.1227, Accuracy = 0.4500 Test Loss = 9.2456, Test Accuracy = 0.2011\n",
      "Iteration 1520: Loss = 2.2431, Accuracy = 0.2900 Test Loss = 9.2442, Test Accuracy = 0.2014\n",
      "Iteration 1521: Loss = 2.3326, Accuracy = 0.3400 Test Loss = 9.2488, Test Accuracy = 0.2016\n",
      "Iteration 1522: Loss = 2.2260, Accuracy = 0.4200 Test Loss = 9.2353, Test Accuracy = 0.2015\n",
      "Iteration 1523: Loss = 2.1706, Accuracy = 0.4200 Test Loss = 9.2320, Test Accuracy = 0.2025\n",
      "Iteration 1524: Loss = 2.1789, Accuracy = 0.4100 Test Loss = 9.2345, Test Accuracy = 0.2020\n",
      "Iteration 1525: Loss = 2.0597, Accuracy = 0.3500 Test Loss = 9.2269, Test Accuracy = 0.2020\n",
      "Iteration 1526: Loss = 2.2490, Accuracy = 0.3800 Test Loss = 9.2306, Test Accuracy = 0.2026\n",
      "Iteration 1527: Loss = 2.2437, Accuracy = 0.3400 Test Loss = 9.2209, Test Accuracy = 0.2022\n",
      "Iteration 1528: Loss = 2.0605, Accuracy = 0.4100 Test Loss = 9.2190, Test Accuracy = 0.2017\n",
      "Iteration 1529: Loss = 2.2974, Accuracy = 0.2800 Test Loss = 9.2252, Test Accuracy = 0.2018\n",
      "Iteration 1530: Loss = 2.3586, Accuracy = 0.3100 Test Loss = 9.2157, Test Accuracy = 0.2023\n",
      "Iteration 1531: Loss = 2.1112, Accuracy = 0.4200 Test Loss = 9.2040, Test Accuracy = 0.2014\n",
      "Iteration 1532: Loss = 2.1665, Accuracy = 0.3500 Test Loss = 9.2083, Test Accuracy = 0.2027\n",
      "Iteration 1533: Loss = 2.2308, Accuracy = 0.3900 Test Loss = 9.2025, Test Accuracy = 0.2027\n",
      "Iteration 1534: Loss = 2.1724, Accuracy = 0.3900 Test Loss = 9.2012, Test Accuracy = 0.2024\n",
      "Iteration 1535: Loss = 2.3695, Accuracy = 0.3700 Test Loss = 9.1969, Test Accuracy = 0.2029\n",
      "Iteration 1536: Loss = 2.2148, Accuracy = 0.3900 Test Loss = 9.1979, Test Accuracy = 0.2021\n",
      "Iteration 1537: Loss = 2.2051, Accuracy = 0.3300 Test Loss = 9.1997, Test Accuracy = 0.2026\n",
      "Iteration 1538: Loss = 2.2925, Accuracy = 0.2800 Test Loss = 9.1853, Test Accuracy = 0.2014\n",
      "Iteration 1539: Loss = 2.2225, Accuracy = 0.3500 Test Loss = 9.1855, Test Accuracy = 0.2013\n",
      "Iteration 1540: Loss = 2.2548, Accuracy = 0.3700 Test Loss = 9.1885, Test Accuracy = 0.2029\n",
      "Iteration 1541: Loss = 2.2849, Accuracy = 0.4200 Test Loss = 9.1871, Test Accuracy = 0.2020\n",
      "Iteration 1542: Loss = 2.3204, Accuracy = 0.3500 Test Loss = 9.1791, Test Accuracy = 0.2021\n",
      "Iteration 1543: Loss = 2.2128, Accuracy = 0.3200 Test Loss = 9.1803, Test Accuracy = 0.2033\n",
      "Iteration 1544: Loss = 2.0660, Accuracy = 0.4700 Test Loss = 9.1839, Test Accuracy = 0.2025\n",
      "Iteration 1545: Loss = 2.1717, Accuracy = 0.3500 Test Loss = 9.1713, Test Accuracy = 0.2017\n",
      "Iteration 1546: Loss = 2.1652, Accuracy = 0.3600 Test Loss = 9.1722, Test Accuracy = 0.2023\n",
      "Iteration 1547: Loss = 2.1730, Accuracy = 0.3700 Test Loss = 9.1721, Test Accuracy = 0.2027\n",
      "Iteration 1548: Loss = 2.2672, Accuracy = 0.3700 Test Loss = 9.1619, Test Accuracy = 0.2032\n",
      "Iteration 1549: Loss = 2.1508, Accuracy = 0.3900 Test Loss = 9.1602, Test Accuracy = 0.2019\n",
      "Iteration 1550: Loss = 2.3161, Accuracy = 0.3700 Test Loss = 9.1610, Test Accuracy = 0.2029\n",
      "Iteration 1551: Loss = 2.1262, Accuracy = 0.4400 Test Loss = 9.1561, Test Accuracy = 0.2014\n",
      "Iteration 1552: Loss = 2.3378, Accuracy = 0.4300 Test Loss = 9.1491, Test Accuracy = 0.2017\n",
      "Iteration 1553: Loss = 2.2877, Accuracy = 0.3700 Test Loss = 9.1548, Test Accuracy = 0.2025\n",
      "Iteration 1554: Loss = 2.2408, Accuracy = 0.2900 Test Loss = 9.1459, Test Accuracy = 0.2028\n",
      "Iteration 1555: Loss = 2.1886, Accuracy = 0.4300 Test Loss = 9.1531, Test Accuracy = 0.2027\n",
      "Iteration 1556: Loss = 2.1723, Accuracy = 0.3300 Test Loss = 9.1421, Test Accuracy = 0.2035\n",
      "Iteration 1557: Loss = 2.1607, Accuracy = 0.3600 Test Loss = 9.1479, Test Accuracy = 0.2028\n",
      "Iteration 1558: Loss = 2.1853, Accuracy = 0.3600 Test Loss = 9.1422, Test Accuracy = 0.2024\n",
      "Iteration 1559: Loss = 2.1968, Accuracy = 0.3500 Test Loss = 9.1344, Test Accuracy = 0.2030\n",
      "Iteration 1560: Loss = 2.0861, Accuracy = 0.3600 Test Loss = 9.1352, Test Accuracy = 0.2026\n",
      "Iteration 1561: Loss = 2.2719, Accuracy = 0.3800 Test Loss = 9.1320, Test Accuracy = 0.2020\n",
      "Iteration 1562: Loss = 2.2486, Accuracy = 0.3300 Test Loss = 9.1228, Test Accuracy = 0.2030\n",
      "Iteration 1563: Loss = 2.2802, Accuracy = 0.3800 Test Loss = 9.1249, Test Accuracy = 0.2033\n",
      "Iteration 1564: Loss = 2.2684, Accuracy = 0.3200 Test Loss = 9.1222, Test Accuracy = 0.2016\n",
      "Iteration 1565: Loss = 2.2662, Accuracy = 0.3000 Test Loss = 9.1216, Test Accuracy = 0.2026\n",
      "Iteration 1566: Loss = 2.2694, Accuracy = 0.3500 Test Loss = 9.1214, Test Accuracy = 0.2021\n",
      "Iteration 1567: Loss = 2.0417, Accuracy = 0.4300 Test Loss = 9.1131, Test Accuracy = 0.2029\n",
      "Iteration 1568: Loss = 2.2630, Accuracy = 0.4100 Test Loss = 9.1059, Test Accuracy = 0.2030\n",
      "Iteration 1569: Loss = 2.0930, Accuracy = 0.4000 Test Loss = 9.1102, Test Accuracy = 0.2030\n",
      "Iteration 1570: Loss = 2.1935, Accuracy = 0.4200 Test Loss = 9.1031, Test Accuracy = 0.2027\n",
      "Iteration 1571: Loss = 2.1528, Accuracy = 0.3300 Test Loss = 9.1004, Test Accuracy = 0.2026\n",
      "Iteration 1572: Loss = 2.1305, Accuracy = 0.3400 Test Loss = 9.1008, Test Accuracy = 0.2031\n",
      "Iteration 1573: Loss = 2.2485, Accuracy = 0.3200 Test Loss = 9.1009, Test Accuracy = 0.2014\n",
      "Iteration 1574: Loss = 2.0628, Accuracy = 0.3900 Test Loss = 9.0896, Test Accuracy = 0.2033\n",
      "Iteration 1575: Loss = 2.2343, Accuracy = 0.4100 Test Loss = 9.0981, Test Accuracy = 0.2019\n",
      "Iteration 1576: Loss = 2.0211, Accuracy = 0.3600 Test Loss = 9.0943, Test Accuracy = 0.2042\n",
      "Iteration 1577: Loss = 2.0053, Accuracy = 0.4900 Test Loss = 9.0886, Test Accuracy = 0.2031\n",
      "Iteration 1578: Loss = 2.3207, Accuracy = 0.4200 Test Loss = 9.0789, Test Accuracy = 0.2023\n",
      "Iteration 1579: Loss = 2.2750, Accuracy = 0.3200 Test Loss = 9.0805, Test Accuracy = 0.2032\n",
      "Iteration 1580: Loss = 2.1967, Accuracy = 0.3100 Test Loss = 9.0781, Test Accuracy = 0.2030\n",
      "Iteration 1581: Loss = 2.1320, Accuracy = 0.3500 Test Loss = 9.0755, Test Accuracy = 0.2036\n",
      "Iteration 1582: Loss = 2.2450, Accuracy = 0.4000 Test Loss = 9.0664, Test Accuracy = 0.2021\n",
      "Iteration 1583: Loss = 2.0948, Accuracy = 0.4300 Test Loss = 9.0726, Test Accuracy = 0.2036\n",
      "Iteration 1584: Loss = 1.9667, Accuracy = 0.4200 Test Loss = 9.0685, Test Accuracy = 0.2029\n",
      "Iteration 1585: Loss = 2.0671, Accuracy = 0.3500 Test Loss = 9.0681, Test Accuracy = 0.2032\n",
      "Iteration 1586: Loss = 2.1319, Accuracy = 0.3600 Test Loss = 9.0625, Test Accuracy = 0.2032\n",
      "Iteration 1587: Loss = 2.1013, Accuracy = 0.4000 Test Loss = 9.0651, Test Accuracy = 0.2039\n",
      "Iteration 1588: Loss = 2.2349, Accuracy = 0.3600 Test Loss = 9.0590, Test Accuracy = 0.2038\n",
      "Iteration 1589: Loss = 2.3320, Accuracy = 0.3600 Test Loss = 9.0637, Test Accuracy = 0.2046\n",
      "Iteration 1590: Loss = 2.0777, Accuracy = 0.3700 Test Loss = 9.0506, Test Accuracy = 0.2023\n",
      "Iteration 1591: Loss = 2.3429, Accuracy = 0.3500 Test Loss = 9.0536, Test Accuracy = 0.2019\n",
      "Iteration 1592: Loss = 2.1927, Accuracy = 0.3300 Test Loss = 9.0522, Test Accuracy = 0.2037\n",
      "Iteration 1593: Loss = 2.1557, Accuracy = 0.3600 Test Loss = 9.0479, Test Accuracy = 0.2035\n",
      "Iteration 1594: Loss = 2.2039, Accuracy = 0.4400 Test Loss = 9.0466, Test Accuracy = 0.2033\n",
      "Iteration 1595: Loss = 1.9687, Accuracy = 0.3900 Test Loss = 9.0370, Test Accuracy = 0.2028\n",
      "Iteration 1596: Loss = 2.0691, Accuracy = 0.2900 Test Loss = 9.0373, Test Accuracy = 0.2037\n",
      "Iteration 1597: Loss = 1.9648, Accuracy = 0.3300 Test Loss = 9.0284, Test Accuracy = 0.2030\n",
      "Iteration 1598: Loss = 2.1575, Accuracy = 0.3300 Test Loss = 9.0307, Test Accuracy = 0.2042\n",
      "Iteration 1599: Loss = 2.2618, Accuracy = 0.3900 Test Loss = 9.0257, Test Accuracy = 0.2035\n",
      "Iteration 1600: Loss = 2.1021, Accuracy = 0.4600 Test Loss = 9.0191, Test Accuracy = 0.2044\n",
      "Iteration 1601: Loss = 2.1295, Accuracy = 0.3100 Test Loss = 9.0259, Test Accuracy = 0.2030\n",
      "Iteration 1602: Loss = 2.2330, Accuracy = 0.3700 Test Loss = 9.0278, Test Accuracy = 0.2029\n",
      "Iteration 1603: Loss = 2.1637, Accuracy = 0.3900 Test Loss = 9.0193, Test Accuracy = 0.2033\n",
      "Iteration 1604: Loss = 2.0054, Accuracy = 0.4500 Test Loss = 9.0134, Test Accuracy = 0.2036\n",
      "Iteration 1605: Loss = 2.1305, Accuracy = 0.3800 Test Loss = 9.0132, Test Accuracy = 0.2031\n",
      "Iteration 1606: Loss = 2.1985, Accuracy = 0.3000 Test Loss = 9.0070, Test Accuracy = 0.2034\n",
      "Iteration 1607: Loss = 2.0529, Accuracy = 0.3700 Test Loss = 9.0109, Test Accuracy = 0.2045\n",
      "Iteration 1608: Loss = 2.0846, Accuracy = 0.4300 Test Loss = 9.0059, Test Accuracy = 0.2040\n",
      "Iteration 1609: Loss = 2.1062, Accuracy = 0.4300 Test Loss = 9.0028, Test Accuracy = 0.2030\n",
      "Iteration 1610: Loss = 2.2081, Accuracy = 0.4200 Test Loss = 8.9991, Test Accuracy = 0.2038\n",
      "Iteration 1611: Loss = 1.9946, Accuracy = 0.3500 Test Loss = 9.0008, Test Accuracy = 0.2044\n",
      "Iteration 1612: Loss = 2.0670, Accuracy = 0.3600 Test Loss = 8.9932, Test Accuracy = 0.2046\n",
      "Iteration 1613: Loss = 2.1820, Accuracy = 0.4000 Test Loss = 9.0055, Test Accuracy = 0.2046\n",
      "Iteration 1614: Loss = 2.0822, Accuracy = 0.3300 Test Loss = 8.9965, Test Accuracy = 0.2037\n",
      "Iteration 1615: Loss = 2.0454, Accuracy = 0.3900 Test Loss = 8.9896, Test Accuracy = 0.2023\n",
      "Iteration 1616: Loss = 2.1926, Accuracy = 0.3700 Test Loss = 8.9833, Test Accuracy = 0.2028\n",
      "Iteration 1617: Loss = 1.9972, Accuracy = 0.4200 Test Loss = 8.9823, Test Accuracy = 0.2033\n",
      "Iteration 1618: Loss = 2.3097, Accuracy = 0.4200 Test Loss = 8.9832, Test Accuracy = 0.2041\n",
      "Iteration 1619: Loss = 2.0372, Accuracy = 0.4000 Test Loss = 8.9800, Test Accuracy = 0.2045\n",
      "Iteration 1620: Loss = 2.0696, Accuracy = 0.3700 Test Loss = 8.9753, Test Accuracy = 0.2027\n",
      "Iteration 1621: Loss = 2.1185, Accuracy = 0.3600 Test Loss = 8.9728, Test Accuracy = 0.2048\n",
      "Iteration 1622: Loss = 2.1050, Accuracy = 0.3700 Test Loss = 8.9714, Test Accuracy = 0.2041\n",
      "Iteration 1623: Loss = 2.1330, Accuracy = 0.3100 Test Loss = 8.9654, Test Accuracy = 0.2037\n",
      "Iteration 1624: Loss = 2.0321, Accuracy = 0.4300 Test Loss = 8.9638, Test Accuracy = 0.2048\n",
      "Iteration 1625: Loss = 1.9621, Accuracy = 0.4500 Test Loss = 8.9587, Test Accuracy = 0.2037\n",
      "Iteration 1626: Loss = 2.1889, Accuracy = 0.3800 Test Loss = 8.9572, Test Accuracy = 0.2026\n",
      "Iteration 1627: Loss = 2.1204, Accuracy = 0.4000 Test Loss = 8.9544, Test Accuracy = 0.2031\n",
      "Iteration 1628: Loss = 2.1473, Accuracy = 0.4100 Test Loss = 8.9532, Test Accuracy = 0.2043\n",
      "Iteration 1629: Loss = 2.1049, Accuracy = 0.3100 Test Loss = 8.9550, Test Accuracy = 0.2058\n",
      "Iteration 1630: Loss = 2.2026, Accuracy = 0.3400 Test Loss = 8.9500, Test Accuracy = 0.2039\n",
      "Iteration 1631: Loss = 2.1030, Accuracy = 0.4800 Test Loss = 8.9474, Test Accuracy = 0.2040\n",
      "Iteration 1632: Loss = 2.0889, Accuracy = 0.3700 Test Loss = 8.9516, Test Accuracy = 0.2045\n",
      "Iteration 1633: Loss = 2.2333, Accuracy = 0.3700 Test Loss = 8.9434, Test Accuracy = 0.2043\n",
      "Iteration 1634: Loss = 2.0256, Accuracy = 0.4400 Test Loss = 8.9425, Test Accuracy = 0.2036\n",
      "Iteration 1635: Loss = 2.0371, Accuracy = 0.3500 Test Loss = 8.9334, Test Accuracy = 0.2046\n",
      "Iteration 1636: Loss = 1.9287, Accuracy = 0.3900 Test Loss = 8.9319, Test Accuracy = 0.2041\n",
      "Iteration 1637: Loss = 2.0293, Accuracy = 0.3800 Test Loss = 8.9371, Test Accuracy = 0.2035\n",
      "Iteration 1638: Loss = 2.2318, Accuracy = 0.3400 Test Loss = 8.9318, Test Accuracy = 0.2040\n",
      "Iteration 1639: Loss = 1.9854, Accuracy = 0.3800 Test Loss = 8.9243, Test Accuracy = 0.2032\n",
      "Iteration 1640: Loss = 2.0083, Accuracy = 0.3500 Test Loss = 8.9232, Test Accuracy = 0.2040\n",
      "Iteration 1641: Loss = 1.9538, Accuracy = 0.4100 Test Loss = 8.9212, Test Accuracy = 0.2049\n",
      "Iteration 1642: Loss = 2.2148, Accuracy = 0.3700 Test Loss = 8.9227, Test Accuracy = 0.2056\n",
      "Iteration 1643: Loss = 2.1275, Accuracy = 0.4300 Test Loss = 8.9139, Test Accuracy = 0.2038\n",
      "Iteration 1644: Loss = 2.0332, Accuracy = 0.4400 Test Loss = 8.9153, Test Accuracy = 0.2047\n",
      "Iteration 1645: Loss = 2.0578, Accuracy = 0.3600 Test Loss = 8.9142, Test Accuracy = 0.2034\n",
      "Iteration 1646: Loss = 1.9660, Accuracy = 0.3900 Test Loss = 8.9017, Test Accuracy = 0.2041\n",
      "Iteration 1647: Loss = 1.9912, Accuracy = 0.4100 Test Loss = 8.9069, Test Accuracy = 0.2043\n",
      "Iteration 1648: Loss = 2.1261, Accuracy = 0.5100 Test Loss = 8.9048, Test Accuracy = 0.2040\n",
      "Iteration 1649: Loss = 2.1515, Accuracy = 0.3800 Test Loss = 8.8998, Test Accuracy = 0.2048\n",
      "Iteration 1650: Loss = 2.0607, Accuracy = 0.3400 Test Loss = 8.9020, Test Accuracy = 0.2048\n",
      "Iteration 1651: Loss = 2.1723, Accuracy = 0.3500 Test Loss = 8.9007, Test Accuracy = 0.2028\n",
      "Iteration 1652: Loss = 1.9807, Accuracy = 0.4000 Test Loss = 8.8963, Test Accuracy = 0.2052\n",
      "Iteration 1653: Loss = 2.1114, Accuracy = 0.3500 Test Loss = 8.8977, Test Accuracy = 0.2048\n",
      "Iteration 1654: Loss = 2.0895, Accuracy = 0.4100 Test Loss = 8.8972, Test Accuracy = 0.2057\n",
      "Iteration 1655: Loss = 1.8550, Accuracy = 0.4000 Test Loss = 8.8847, Test Accuracy = 0.2033\n",
      "Iteration 1656: Loss = 1.9236, Accuracy = 0.4100 Test Loss = 8.8854, Test Accuracy = 0.2056\n",
      "Iteration 1657: Loss = 2.0522, Accuracy = 0.3000 Test Loss = 8.8834, Test Accuracy = 0.2044\n",
      "Iteration 1658: Loss = 1.9515, Accuracy = 0.4100 Test Loss = 8.8803, Test Accuracy = 0.2044\n",
      "Iteration 1659: Loss = 2.0617, Accuracy = 0.3700 Test Loss = 8.8761, Test Accuracy = 0.2047\n",
      "Iteration 1660: Loss = 2.0893, Accuracy = 0.3700 Test Loss = 8.8789, Test Accuracy = 0.2040\n",
      "Iteration 1661: Loss = 1.9248, Accuracy = 0.3500 Test Loss = 8.8808, Test Accuracy = 0.2047\n",
      "Iteration 1662: Loss = 1.8944, Accuracy = 0.4100 Test Loss = 8.8707, Test Accuracy = 0.2047\n",
      "Iteration 1663: Loss = 2.0752, Accuracy = 0.3600 Test Loss = 8.8718, Test Accuracy = 0.2050\n",
      "Iteration 1664: Loss = 2.1873, Accuracy = 0.4000 Test Loss = 8.8618, Test Accuracy = 0.2050\n",
      "Iteration 1665: Loss = 2.0344, Accuracy = 0.3000 Test Loss = 8.8616, Test Accuracy = 0.2046\n",
      "Iteration 1666: Loss = 2.0115, Accuracy = 0.4300 Test Loss = 8.8616, Test Accuracy = 0.2052\n",
      "Iteration 1667: Loss = 2.1080, Accuracy = 0.3900 Test Loss = 8.8615, Test Accuracy = 0.2047\n",
      "Iteration 1668: Loss = 2.0073, Accuracy = 0.4100 Test Loss = 8.8537, Test Accuracy = 0.2043\n",
      "Iteration 1669: Loss = 1.9694, Accuracy = 0.4600 Test Loss = 8.8532, Test Accuracy = 0.2038\n",
      "Iteration 1670: Loss = 1.9336, Accuracy = 0.3900 Test Loss = 8.8497, Test Accuracy = 0.2052\n",
      "Iteration 1671: Loss = 1.9771, Accuracy = 0.3800 Test Loss = 8.8431, Test Accuracy = 0.2036\n",
      "Iteration 1672: Loss = 1.9820, Accuracy = 0.3400 Test Loss = 8.8446, Test Accuracy = 0.2042\n",
      "Iteration 1673: Loss = 2.0423, Accuracy = 0.4000 Test Loss = 8.8450, Test Accuracy = 0.2046\n",
      "Iteration 1674: Loss = 2.0253, Accuracy = 0.3900 Test Loss = 8.8455, Test Accuracy = 0.2048\n",
      "Iteration 1675: Loss = 1.9978, Accuracy = 0.3900 Test Loss = 8.8390, Test Accuracy = 0.2055\n",
      "Iteration 1676: Loss = 1.9597, Accuracy = 0.4100 Test Loss = 8.8328, Test Accuracy = 0.2049\n",
      "Iteration 1677: Loss = 2.1003, Accuracy = 0.3800 Test Loss = 8.8361, Test Accuracy = 0.2055\n",
      "Iteration 1678: Loss = 2.1295, Accuracy = 0.4100 Test Loss = 8.8406, Test Accuracy = 0.2053\n",
      "Iteration 1679: Loss = 1.9251, Accuracy = 0.4100 Test Loss = 8.8354, Test Accuracy = 0.2058\n",
      "Iteration 1680: Loss = 1.9653, Accuracy = 0.4200 Test Loss = 8.8291, Test Accuracy = 0.2057\n",
      "Iteration 1681: Loss = 1.9692, Accuracy = 0.4300 Test Loss = 8.8217, Test Accuracy = 0.2050\n",
      "Iteration 1682: Loss = 2.1050, Accuracy = 0.4100 Test Loss = 8.8205, Test Accuracy = 0.2050\n",
      "Iteration 1683: Loss = 1.9620, Accuracy = 0.3800 Test Loss = 8.8212, Test Accuracy = 0.2058\n",
      "Iteration 1684: Loss = 2.1272, Accuracy = 0.3800 Test Loss = 8.8152, Test Accuracy = 0.2049\n",
      "Iteration 1685: Loss = 2.0325, Accuracy = 0.4600 Test Loss = 8.8144, Test Accuracy = 0.2049\n",
      "Iteration 1686: Loss = 1.9946, Accuracy = 0.4300 Test Loss = 8.8119, Test Accuracy = 0.2055\n",
      "Iteration 1687: Loss = 2.1081, Accuracy = 0.4300 Test Loss = 8.8079, Test Accuracy = 0.2058\n",
      "Iteration 1688: Loss = 2.0477, Accuracy = 0.3700 Test Loss = 8.8078, Test Accuracy = 0.2051\n",
      "Iteration 1689: Loss = 2.0027, Accuracy = 0.3900 Test Loss = 8.8057, Test Accuracy = 0.2049\n",
      "Iteration 1690: Loss = 2.2013, Accuracy = 0.3800 Test Loss = 8.8001, Test Accuracy = 0.2049\n",
      "Iteration 1691: Loss = 2.0276, Accuracy = 0.3700 Test Loss = 8.8011, Test Accuracy = 0.2047\n",
      "Iteration 1692: Loss = 1.8896, Accuracy = 0.3900 Test Loss = 8.7998, Test Accuracy = 0.2052\n",
      "Iteration 1693: Loss = 2.0127, Accuracy = 0.4700 Test Loss = 8.7973, Test Accuracy = 0.2053\n",
      "Iteration 1694: Loss = 1.9447, Accuracy = 0.4000 Test Loss = 8.7940, Test Accuracy = 0.2060\n",
      "Iteration 1695: Loss = 1.8402, Accuracy = 0.4300 Test Loss = 8.7891, Test Accuracy = 0.2052\n",
      "Iteration 1696: Loss = 1.9491, Accuracy = 0.4500 Test Loss = 8.7870, Test Accuracy = 0.2043\n",
      "Iteration 1697: Loss = 2.0266, Accuracy = 0.3900 Test Loss = 8.7849, Test Accuracy = 0.2044\n",
      "Iteration 1698: Loss = 1.9768, Accuracy = 0.3100 Test Loss = 8.7865, Test Accuracy = 0.2057\n",
      "Iteration 1699: Loss = 2.0382, Accuracy = 0.3300 Test Loss = 8.7851, Test Accuracy = 0.2048\n",
      "Iteration 1700: Loss = 1.9933, Accuracy = 0.4100 Test Loss = 8.7803, Test Accuracy = 0.2057\n",
      "Iteration 1701: Loss = 1.8760, Accuracy = 0.4400 Test Loss = 8.7742, Test Accuracy = 0.2049\n",
      "Iteration 1702: Loss = 2.0513, Accuracy = 0.4100 Test Loss = 8.7708, Test Accuracy = 0.2056\n",
      "Iteration 1703: Loss = 1.8799, Accuracy = 0.3900 Test Loss = 8.7639, Test Accuracy = 0.2055\n",
      "Iteration 1704: Loss = 2.0501, Accuracy = 0.3300 Test Loss = 8.7689, Test Accuracy = 0.2052\n",
      "Iteration 1705: Loss = 2.0063, Accuracy = 0.3700 Test Loss = 8.7633, Test Accuracy = 0.2052\n",
      "Iteration 1706: Loss = 1.9560, Accuracy = 0.4100 Test Loss = 8.7637, Test Accuracy = 0.2055\n",
      "Iteration 1707: Loss = 1.9248, Accuracy = 0.3800 Test Loss = 8.7645, Test Accuracy = 0.2065\n",
      "Iteration 1708: Loss = 1.9027, Accuracy = 0.4200 Test Loss = 8.7622, Test Accuracy = 0.2059\n",
      "Iteration 1709: Loss = 1.9671, Accuracy = 0.4100 Test Loss = 8.7578, Test Accuracy = 0.2060\n",
      "Iteration 1710: Loss = 2.0760, Accuracy = 0.4300 Test Loss = 8.7593, Test Accuracy = 0.2066\n",
      "Iteration 1711: Loss = 1.8625, Accuracy = 0.3800 Test Loss = 8.7500, Test Accuracy = 0.2057\n",
      "Iteration 1712: Loss = 1.9952, Accuracy = 0.4200 Test Loss = 8.7518, Test Accuracy = 0.2048\n",
      "Iteration 1713: Loss = 1.9789, Accuracy = 0.5000 Test Loss = 8.7495, Test Accuracy = 0.2060\n",
      "Iteration 1714: Loss = 2.1049, Accuracy = 0.3600 Test Loss = 8.7424, Test Accuracy = 0.2056\n",
      "Iteration 1715: Loss = 1.9644, Accuracy = 0.3900 Test Loss = 8.7453, Test Accuracy = 0.2063\n",
      "Iteration 1716: Loss = 1.9087, Accuracy = 0.4100 Test Loss = 8.7473, Test Accuracy = 0.2063\n",
      "Iteration 1717: Loss = 2.0840, Accuracy = 0.4200 Test Loss = 8.7472, Test Accuracy = 0.2056\n",
      "Iteration 1718: Loss = 1.9554, Accuracy = 0.3600 Test Loss = 8.7389, Test Accuracy = 0.2066\n",
      "Iteration 1719: Loss = 1.9198, Accuracy = 0.4000 Test Loss = 8.7361, Test Accuracy = 0.2064\n",
      "Iteration 1720: Loss = 1.9827, Accuracy = 0.4200 Test Loss = 8.7381, Test Accuracy = 0.2067\n",
      "Iteration 1721: Loss = 1.8923, Accuracy = 0.4200 Test Loss = 8.7336, Test Accuracy = 0.2063\n",
      "Iteration 1722: Loss = 1.9111, Accuracy = 0.4600 Test Loss = 8.7315, Test Accuracy = 0.2065\n",
      "Iteration 1723: Loss = 1.9429, Accuracy = 0.3900 Test Loss = 8.7257, Test Accuracy = 0.2062\n",
      "Iteration 1724: Loss = 2.0905, Accuracy = 0.4000 Test Loss = 8.7246, Test Accuracy = 0.2058\n",
      "Iteration 1725: Loss = 2.0180, Accuracy = 0.3900 Test Loss = 8.7217, Test Accuracy = 0.2054\n",
      "Iteration 1726: Loss = 1.8672, Accuracy = 0.4400 Test Loss = 8.7220, Test Accuracy = 0.2059\n",
      "Iteration 1727: Loss = 2.0754, Accuracy = 0.3700 Test Loss = 8.7140, Test Accuracy = 0.2057\n",
      "Iteration 1728: Loss = 1.9757, Accuracy = 0.4000 Test Loss = 8.7094, Test Accuracy = 0.2059\n",
      "Iteration 1729: Loss = 1.9801, Accuracy = 0.4500 Test Loss = 8.7115, Test Accuracy = 0.2057\n",
      "Iteration 1730: Loss = 1.8836, Accuracy = 0.4400 Test Loss = 8.7119, Test Accuracy = 0.2054\n",
      "Iteration 1731: Loss = 1.8537, Accuracy = 0.4400 Test Loss = 8.7066, Test Accuracy = 0.2065\n",
      "Iteration 1732: Loss = 2.0157, Accuracy = 0.3900 Test Loss = 8.7064, Test Accuracy = 0.2065\n",
      "Iteration 1733: Loss = 2.0887, Accuracy = 0.3100 Test Loss = 8.7021, Test Accuracy = 0.2064\n",
      "Iteration 1734: Loss = 1.9102, Accuracy = 0.3700 Test Loss = 8.7012, Test Accuracy = 0.2061\n",
      "Iteration 1735: Loss = 1.9199, Accuracy = 0.3900 Test Loss = 8.6966, Test Accuracy = 0.2062\n",
      "Iteration 1736: Loss = 1.8131, Accuracy = 0.4000 Test Loss = 8.6923, Test Accuracy = 0.2067\n",
      "Iteration 1737: Loss = 2.0211, Accuracy = 0.4300 Test Loss = 8.6961, Test Accuracy = 0.2072\n",
      "Iteration 1738: Loss = 2.0386, Accuracy = 0.4000 Test Loss = 8.6900, Test Accuracy = 0.2073\n",
      "Iteration 1739: Loss = 2.0499, Accuracy = 0.3400 Test Loss = 8.6901, Test Accuracy = 0.2061\n",
      "Iteration 1740: Loss = 1.9804, Accuracy = 0.3700 Test Loss = 8.6857, Test Accuracy = 0.2061\n",
      "Iteration 1741: Loss = 1.9647, Accuracy = 0.3700 Test Loss = 8.6821, Test Accuracy = 0.2068\n",
      "Iteration 1742: Loss = 1.8521, Accuracy = 0.4400 Test Loss = 8.6831, Test Accuracy = 0.2057\n",
      "Iteration 1743: Loss = 2.0526, Accuracy = 0.3900 Test Loss = 8.6797, Test Accuracy = 0.2076\n",
      "Iteration 1744: Loss = 1.6949, Accuracy = 0.3800 Test Loss = 8.6777, Test Accuracy = 0.2072\n",
      "Iteration 1745: Loss = 2.0812, Accuracy = 0.4200 Test Loss = 8.6757, Test Accuracy = 0.2060\n",
      "Iteration 1746: Loss = 1.8623, Accuracy = 0.4400 Test Loss = 8.6731, Test Accuracy = 0.2065\n",
      "Iteration 1747: Loss = 1.8351, Accuracy = 0.4400 Test Loss = 8.6729, Test Accuracy = 0.2066\n",
      "Iteration 1748: Loss = 1.9929, Accuracy = 0.4200 Test Loss = 8.6705, Test Accuracy = 0.2069\n",
      "Iteration 1749: Loss = 1.8384, Accuracy = 0.4200 Test Loss = 8.6683, Test Accuracy = 0.2066\n",
      "Iteration 1750: Loss = 1.8650, Accuracy = 0.3400 Test Loss = 8.6630, Test Accuracy = 0.2066\n",
      "Iteration 1751: Loss = 1.9876, Accuracy = 0.4300 Test Loss = 8.6680, Test Accuracy = 0.2075\n",
      "Iteration 1752: Loss = 1.9287, Accuracy = 0.4800 Test Loss = 8.6590, Test Accuracy = 0.2067\n",
      "Iteration 1753: Loss = 2.0478, Accuracy = 0.4000 Test Loss = 8.6621, Test Accuracy = 0.2074\n",
      "Iteration 1754: Loss = 1.8801, Accuracy = 0.3900 Test Loss = 8.6592, Test Accuracy = 0.2080\n",
      "Iteration 1755: Loss = 1.9026, Accuracy = 0.4700 Test Loss = 8.6565, Test Accuracy = 0.2067\n",
      "Iteration 1756: Loss = 1.9370, Accuracy = 0.4400 Test Loss = 8.6426, Test Accuracy = 0.2067\n",
      "Iteration 1757: Loss = 1.9578, Accuracy = 0.3800 Test Loss = 8.6476, Test Accuracy = 0.2066\n",
      "Iteration 1758: Loss = 1.9206, Accuracy = 0.3600 Test Loss = 8.6408, Test Accuracy = 0.2066\n",
      "Iteration 1759: Loss = 1.8577, Accuracy = 0.4500 Test Loss = 8.6445, Test Accuracy = 0.2080\n",
      "Iteration 1760: Loss = 1.9010, Accuracy = 0.4000 Test Loss = 8.6390, Test Accuracy = 0.2061\n",
      "Iteration 1761: Loss = 1.8967, Accuracy = 0.4000 Test Loss = 8.6354, Test Accuracy = 0.2072\n",
      "Iteration 1762: Loss = 1.9433, Accuracy = 0.3500 Test Loss = 8.6398, Test Accuracy = 0.2066\n",
      "Iteration 1763: Loss = 1.9584, Accuracy = 0.3800 Test Loss = 8.6331, Test Accuracy = 0.2060\n",
      "Iteration 1764: Loss = 1.9289, Accuracy = 0.4100 Test Loss = 8.6296, Test Accuracy = 0.2069\n",
      "Iteration 1765: Loss = 1.9174, Accuracy = 0.4600 Test Loss = 8.6290, Test Accuracy = 0.2072\n",
      "Iteration 1766: Loss = 1.8039, Accuracy = 0.4500 Test Loss = 8.6296, Test Accuracy = 0.2074\n",
      "Iteration 1767: Loss = 1.9157, Accuracy = 0.4400 Test Loss = 8.6254, Test Accuracy = 0.2083\n",
      "Iteration 1768: Loss = 1.7614, Accuracy = 0.4600 Test Loss = 8.6181, Test Accuracy = 0.2071\n",
      "Iteration 1769: Loss = 1.9208, Accuracy = 0.4000 Test Loss = 8.6175, Test Accuracy = 0.2072\n",
      "Iteration 1770: Loss = 1.9384, Accuracy = 0.4000 Test Loss = 8.6186, Test Accuracy = 0.2082\n",
      "Iteration 1771: Loss = 1.8156, Accuracy = 0.3600 Test Loss = 8.6183, Test Accuracy = 0.2067\n",
      "Iteration 1772: Loss = 1.7658, Accuracy = 0.4000 Test Loss = 8.6107, Test Accuracy = 0.2073\n",
      "Iteration 1773: Loss = 1.8028, Accuracy = 0.5300 Test Loss = 8.6108, Test Accuracy = 0.2077\n",
      "Iteration 1774: Loss = 2.0362, Accuracy = 0.4400 Test Loss = 8.6085, Test Accuracy = 0.2086\n",
      "Iteration 1775: Loss = 1.8602, Accuracy = 0.3700 Test Loss = 8.6066, Test Accuracy = 0.2076\n",
      "Iteration 1776: Loss = 1.9364, Accuracy = 0.3800 Test Loss = 8.6047, Test Accuracy = 0.2079\n",
      "Iteration 1777: Loss = 2.0234, Accuracy = 0.3600 Test Loss = 8.6011, Test Accuracy = 0.2074\n",
      "Iteration 1778: Loss = 1.8710, Accuracy = 0.3500 Test Loss = 8.5990, Test Accuracy = 0.2074\n",
      "Iteration 1779: Loss = 1.7640, Accuracy = 0.4600 Test Loss = 8.5958, Test Accuracy = 0.2075\n",
      "Iteration 1780: Loss = 1.9884, Accuracy = 0.3900 Test Loss = 8.5960, Test Accuracy = 0.2073\n",
      "Iteration 1781: Loss = 1.8442, Accuracy = 0.4000 Test Loss = 8.5939, Test Accuracy = 0.2071\n",
      "Iteration 1782: Loss = 1.8324, Accuracy = 0.4200 Test Loss = 8.5939, Test Accuracy = 0.2072\n",
      "Iteration 1783: Loss = 1.8596, Accuracy = 0.4200 Test Loss = 8.5946, Test Accuracy = 0.2084\n",
      "Iteration 1784: Loss = 1.7641, Accuracy = 0.4100 Test Loss = 8.5884, Test Accuracy = 0.2080\n",
      "Iteration 1785: Loss = 1.7753, Accuracy = 0.5000 Test Loss = 8.5885, Test Accuracy = 0.2073\n",
      "Iteration 1786: Loss = 1.8833, Accuracy = 0.3900 Test Loss = 8.5827, Test Accuracy = 0.2081\n",
      "Iteration 1787: Loss = 1.9993, Accuracy = 0.3800 Test Loss = 8.5796, Test Accuracy = 0.2074\n",
      "Iteration 1788: Loss = 1.8062, Accuracy = 0.5000 Test Loss = 8.5789, Test Accuracy = 0.2074\n",
      "Iteration 1789: Loss = 1.9553, Accuracy = 0.4000 Test Loss = 8.5756, Test Accuracy = 0.2083\n",
      "Iteration 1790: Loss = 1.8056, Accuracy = 0.4100 Test Loss = 8.5742, Test Accuracy = 0.2075\n",
      "Iteration 1791: Loss = 1.8250, Accuracy = 0.4900 Test Loss = 8.5751, Test Accuracy = 0.2070\n",
      "Iteration 1792: Loss = 1.8353, Accuracy = 0.4400 Test Loss = 8.5715, Test Accuracy = 0.2079\n",
      "Iteration 1793: Loss = 1.7161, Accuracy = 0.4300 Test Loss = 8.5689, Test Accuracy = 0.2073\n",
      "Iteration 1794: Loss = 1.9529, Accuracy = 0.3400 Test Loss = 8.5663, Test Accuracy = 0.2076\n",
      "Iteration 1795: Loss = 1.8540, Accuracy = 0.4200 Test Loss = 8.5625, Test Accuracy = 0.2085\n",
      "Iteration 1796: Loss = 1.8360, Accuracy = 0.4400 Test Loss = 8.5603, Test Accuracy = 0.2081\n",
      "Iteration 1797: Loss = 1.7417, Accuracy = 0.4900 Test Loss = 8.5649, Test Accuracy = 0.2085\n",
      "Iteration 1798: Loss = 1.9195, Accuracy = 0.3900 Test Loss = 8.5581, Test Accuracy = 0.2082\n",
      "Iteration 1799: Loss = 1.8901, Accuracy = 0.4000 Test Loss = 8.5556, Test Accuracy = 0.2080\n",
      "Iteration 1800: Loss = 1.9135, Accuracy = 0.4000 Test Loss = 8.5481, Test Accuracy = 0.2067\n",
      "Iteration 1801: Loss = 1.9792, Accuracy = 0.3800 Test Loss = 8.5488, Test Accuracy = 0.2086\n",
      "Iteration 1802: Loss = 1.8184, Accuracy = 0.4600 Test Loss = 8.5510, Test Accuracy = 0.2084\n",
      "Iteration 1803: Loss = 1.7936, Accuracy = 0.4600 Test Loss = 8.5473, Test Accuracy = 0.2084\n",
      "Iteration 1804: Loss = 1.7981, Accuracy = 0.3800 Test Loss = 8.5401, Test Accuracy = 0.2071\n",
      "Iteration 1805: Loss = 1.8990, Accuracy = 0.4000 Test Loss = 8.5377, Test Accuracy = 0.2067\n",
      "Iteration 1806: Loss = 1.8558, Accuracy = 0.4300 Test Loss = 8.5399, Test Accuracy = 0.2083\n",
      "Iteration 1807: Loss = 1.7132, Accuracy = 0.3800 Test Loss = 8.5407, Test Accuracy = 0.2084\n",
      "Iteration 1808: Loss = 1.8763, Accuracy = 0.4100 Test Loss = 8.5405, Test Accuracy = 0.2073\n",
      "Iteration 1809: Loss = 1.8133, Accuracy = 0.3400 Test Loss = 8.5331, Test Accuracy = 0.2078\n",
      "Iteration 1810: Loss = 1.9837, Accuracy = 0.3800 Test Loss = 8.5363, Test Accuracy = 0.2086\n",
      "Iteration 1811: Loss = 1.8711, Accuracy = 0.4100 Test Loss = 8.5323, Test Accuracy = 0.2080\n",
      "Iteration 1812: Loss = 1.8421, Accuracy = 0.4300 Test Loss = 8.5304, Test Accuracy = 0.2080\n",
      "Iteration 1813: Loss = 1.8956, Accuracy = 0.4200 Test Loss = 8.5255, Test Accuracy = 0.2077\n",
      "Iteration 1814: Loss = 1.8899, Accuracy = 0.5200 Test Loss = 8.5201, Test Accuracy = 0.2084\n",
      "Iteration 1815: Loss = 1.7713, Accuracy = 0.4500 Test Loss = 8.5242, Test Accuracy = 0.2083\n",
      "Iteration 1816: Loss = 1.6589, Accuracy = 0.4300 Test Loss = 8.5229, Test Accuracy = 0.2080\n",
      "Iteration 1817: Loss = 1.9254, Accuracy = 0.4000 Test Loss = 8.5115, Test Accuracy = 0.2083\n",
      "Iteration 1818: Loss = 1.9703, Accuracy = 0.4300 Test Loss = 8.5166, Test Accuracy = 0.2078\n",
      "Iteration 1819: Loss = 1.7620, Accuracy = 0.4300 Test Loss = 8.5170, Test Accuracy = 0.2092\n",
      "Iteration 1820: Loss = 1.9202, Accuracy = 0.3600 Test Loss = 8.5137, Test Accuracy = 0.2086\n",
      "Iteration 1821: Loss = 1.8421, Accuracy = 0.4300 Test Loss = 8.5141, Test Accuracy = 0.2090\n",
      "Iteration 1822: Loss = 1.8760, Accuracy = 0.4200 Test Loss = 8.5093, Test Accuracy = 0.2088\n",
      "Iteration 1823: Loss = 1.8392, Accuracy = 0.4000 Test Loss = 8.5051, Test Accuracy = 0.2086\n",
      "Iteration 1824: Loss = 1.8884, Accuracy = 0.3800 Test Loss = 8.4993, Test Accuracy = 0.2078\n",
      "Iteration 1825: Loss = 1.8824, Accuracy = 0.3300 Test Loss = 8.4996, Test Accuracy = 0.2083\n",
      "Iteration 1826: Loss = 1.7561, Accuracy = 0.4400 Test Loss = 8.4989, Test Accuracy = 0.2085\n",
      "Iteration 1827: Loss = 1.8331, Accuracy = 0.4000 Test Loss = 8.5012, Test Accuracy = 0.2091\n",
      "Iteration 1828: Loss = 1.8535, Accuracy = 0.4100 Test Loss = 8.4943, Test Accuracy = 0.2083\n",
      "Iteration 1829: Loss = 1.9213, Accuracy = 0.5000 Test Loss = 8.4876, Test Accuracy = 0.2087\n",
      "Iteration 1830: Loss = 1.9398, Accuracy = 0.3500 Test Loss = 8.4894, Test Accuracy = 0.2091\n",
      "Iteration 1831: Loss = 1.7940, Accuracy = 0.3900 Test Loss = 8.4820, Test Accuracy = 0.2083\n",
      "Iteration 1832: Loss = 1.7148, Accuracy = 0.4500 Test Loss = 8.4858, Test Accuracy = 0.2088\n",
      "Iteration 1833: Loss = 1.8426, Accuracy = 0.4100 Test Loss = 8.4786, Test Accuracy = 0.2078\n",
      "Iteration 1834: Loss = 1.7748, Accuracy = 0.4700 Test Loss = 8.4804, Test Accuracy = 0.2086\n",
      "Iteration 1835: Loss = 1.8321, Accuracy = 0.4400 Test Loss = 8.4759, Test Accuracy = 0.2093\n",
      "Iteration 1836: Loss = 1.8931, Accuracy = 0.3300 Test Loss = 8.4746, Test Accuracy = 0.2084\n",
      "Iteration 1837: Loss = 1.8410, Accuracy = 0.4600 Test Loss = 8.4748, Test Accuracy = 0.2086\n",
      "Iteration 1838: Loss = 1.9167, Accuracy = 0.4600 Test Loss = 8.4767, Test Accuracy = 0.2096\n",
      "Iteration 1839: Loss = 2.0229, Accuracy = 0.3700 Test Loss = 8.4678, Test Accuracy = 0.2086\n",
      "Iteration 1840: Loss = 1.7046, Accuracy = 0.4500 Test Loss = 8.4648, Test Accuracy = 0.2088\n",
      "Iteration 1841: Loss = 1.9111, Accuracy = 0.4100 Test Loss = 8.4641, Test Accuracy = 0.2094\n",
      "Iteration 1842: Loss = 1.8118, Accuracy = 0.4400 Test Loss = 8.4650, Test Accuracy = 0.2095\n",
      "Iteration 1843: Loss = 1.8905, Accuracy = 0.3700 Test Loss = 8.4633, Test Accuracy = 0.2087\n",
      "Iteration 1844: Loss = 1.8031, Accuracy = 0.4500 Test Loss = 8.4612, Test Accuracy = 0.2096\n",
      "Iteration 1845: Loss = 1.8971, Accuracy = 0.4000 Test Loss = 8.4585, Test Accuracy = 0.2094\n",
      "Iteration 1846: Loss = 1.9677, Accuracy = 0.4300 Test Loss = 8.4555, Test Accuracy = 0.2097\n",
      "Iteration 1847: Loss = 1.7863, Accuracy = 0.4200 Test Loss = 8.4510, Test Accuracy = 0.2091\n",
      "Iteration 1848: Loss = 1.8485, Accuracy = 0.4500 Test Loss = 8.4492, Test Accuracy = 0.2099\n",
      "Iteration 1849: Loss = 1.8708, Accuracy = 0.3700 Test Loss = 8.4475, Test Accuracy = 0.2094\n",
      "Iteration 1850: Loss = 1.9101, Accuracy = 0.3700 Test Loss = 8.4479, Test Accuracy = 0.2100\n",
      "Iteration 1851: Loss = 1.8722, Accuracy = 0.3300 Test Loss = 8.4449, Test Accuracy = 0.2095\n",
      "Iteration 1852: Loss = 1.8373, Accuracy = 0.4200 Test Loss = 8.4399, Test Accuracy = 0.2098\n",
      "Iteration 1853: Loss = 1.7227, Accuracy = 0.5000 Test Loss = 8.4421, Test Accuracy = 0.2094\n",
      "Iteration 1854: Loss = 1.7860, Accuracy = 0.4900 Test Loss = 8.4406, Test Accuracy = 0.2100\n",
      "Iteration 1855: Loss = 1.7489, Accuracy = 0.4800 Test Loss = 8.4345, Test Accuracy = 0.2093\n",
      "Iteration 1856: Loss = 1.9660, Accuracy = 0.4400 Test Loss = 8.4348, Test Accuracy = 0.2084\n",
      "Iteration 1857: Loss = 1.8013, Accuracy = 0.4900 Test Loss = 8.4322, Test Accuracy = 0.2099\n",
      "Iteration 1858: Loss = 1.7887, Accuracy = 0.4200 Test Loss = 8.4328, Test Accuracy = 0.2106\n",
      "Iteration 1859: Loss = 1.7971, Accuracy = 0.4200 Test Loss = 8.4258, Test Accuracy = 0.2100\n",
      "Iteration 1860: Loss = 1.7940, Accuracy = 0.3300 Test Loss = 8.4218, Test Accuracy = 0.2092\n",
      "Iteration 1861: Loss = 1.9129, Accuracy = 0.3800 Test Loss = 8.4276, Test Accuracy = 0.2100\n",
      "Iteration 1862: Loss = 1.7613, Accuracy = 0.4200 Test Loss = 8.4218, Test Accuracy = 0.2093\n",
      "Iteration 1863: Loss = 1.8231, Accuracy = 0.4200 Test Loss = 8.4197, Test Accuracy = 0.2098\n",
      "Iteration 1864: Loss = 1.7675, Accuracy = 0.4000 Test Loss = 8.4184, Test Accuracy = 0.2090\n",
      "Iteration 1865: Loss = 1.7939, Accuracy = 0.5200 Test Loss = 8.4190, Test Accuracy = 0.2096\n",
      "Iteration 1866: Loss = 1.8210, Accuracy = 0.4000 Test Loss = 8.4091, Test Accuracy = 0.2092\n",
      "Iteration 1867: Loss = 1.7632, Accuracy = 0.4600 Test Loss = 8.4139, Test Accuracy = 0.2091\n",
      "Iteration 1868: Loss = 1.6498, Accuracy = 0.4400 Test Loss = 8.4079, Test Accuracy = 0.2096\n",
      "Iteration 1869: Loss = 1.7123, Accuracy = 0.4400 Test Loss = 8.4082, Test Accuracy = 0.2093\n",
      "Iteration 1870: Loss = 1.7790, Accuracy = 0.4100 Test Loss = 8.4008, Test Accuracy = 0.2095\n",
      "Iteration 1871: Loss = 1.8125, Accuracy = 0.3500 Test Loss = 8.3996, Test Accuracy = 0.2095\n",
      "Iteration 1872: Loss = 1.8309, Accuracy = 0.4400 Test Loss = 8.3971, Test Accuracy = 0.2084\n",
      "Iteration 1873: Loss = 1.8880, Accuracy = 0.3700 Test Loss = 8.3991, Test Accuracy = 0.2092\n",
      "Iteration 1874: Loss = 1.9263, Accuracy = 0.4300 Test Loss = 8.3923, Test Accuracy = 0.2090\n",
      "Iteration 1875: Loss = 1.7952, Accuracy = 0.4100 Test Loss = 8.3926, Test Accuracy = 0.2096\n",
      "Iteration 1876: Loss = 1.6380, Accuracy = 0.4700 Test Loss = 8.3930, Test Accuracy = 0.2106\n",
      "Iteration 1877: Loss = 1.6139, Accuracy = 0.4200 Test Loss = 8.3932, Test Accuracy = 0.2108\n",
      "Iteration 1878: Loss = 1.8385, Accuracy = 0.4100 Test Loss = 8.3922, Test Accuracy = 0.2104\n",
      "Iteration 1879: Loss = 1.7748, Accuracy = 0.3700 Test Loss = 8.3903, Test Accuracy = 0.2103\n",
      "Iteration 1880: Loss = 1.8255, Accuracy = 0.3600 Test Loss = 8.3898, Test Accuracy = 0.2102\n",
      "Iteration 1881: Loss = 1.8062, Accuracy = 0.3800 Test Loss = 8.3920, Test Accuracy = 0.2100\n",
      "Iteration 1882: Loss = 1.7002, Accuracy = 0.3600 Test Loss = 8.3883, Test Accuracy = 0.2111\n",
      "Iteration 1883: Loss = 1.7079, Accuracy = 0.5000 Test Loss = 8.3783, Test Accuracy = 0.2101\n",
      "Iteration 1884: Loss = 1.7238, Accuracy = 0.3800 Test Loss = 8.3772, Test Accuracy = 0.2095\n",
      "Iteration 1885: Loss = 1.6798, Accuracy = 0.4500 Test Loss = 8.3794, Test Accuracy = 0.2103\n",
      "Iteration 1886: Loss = 1.7838, Accuracy = 0.4700 Test Loss = 8.3688, Test Accuracy = 0.2101\n",
      "Iteration 1887: Loss = 1.8244, Accuracy = 0.4400 Test Loss = 8.3719, Test Accuracy = 0.2095\n",
      "Iteration 1888: Loss = 1.7718, Accuracy = 0.4200 Test Loss = 8.3671, Test Accuracy = 0.2097\n",
      "Iteration 1889: Loss = 1.7601, Accuracy = 0.4600 Test Loss = 8.3664, Test Accuracy = 0.2102\n",
      "Iteration 1890: Loss = 1.8895, Accuracy = 0.4100 Test Loss = 8.3648, Test Accuracy = 0.2104\n",
      "Iteration 1891: Loss = 1.8129, Accuracy = 0.4700 Test Loss = 8.3661, Test Accuracy = 0.2106\n",
      "Iteration 1892: Loss = 1.7089, Accuracy = 0.4800 Test Loss = 8.3606, Test Accuracy = 0.2096\n",
      "Iteration 1893: Loss = 1.7800, Accuracy = 0.4100 Test Loss = 8.3635, Test Accuracy = 0.2114\n",
      "Iteration 1894: Loss = 1.7722, Accuracy = 0.3500 Test Loss = 8.3573, Test Accuracy = 0.2114\n",
      "Iteration 1895: Loss = 1.8538, Accuracy = 0.4400 Test Loss = 8.3520, Test Accuracy = 0.2102\n",
      "Iteration 1896: Loss = 1.9118, Accuracy = 0.3800 Test Loss = 8.3536, Test Accuracy = 0.2116\n",
      "Iteration 1897: Loss = 1.6432, Accuracy = 0.4000 Test Loss = 8.3496, Test Accuracy = 0.2097\n",
      "Iteration 1898: Loss = 1.9068, Accuracy = 0.3400 Test Loss = 8.3474, Test Accuracy = 0.2102\n",
      "Iteration 1899: Loss = 1.7236, Accuracy = 0.4000 Test Loss = 8.3460, Test Accuracy = 0.2100\n",
      "Iteration 1900: Loss = 1.7894, Accuracy = 0.4100 Test Loss = 8.3446, Test Accuracy = 0.2115\n",
      "Iteration 1901: Loss = 1.7175, Accuracy = 0.4500 Test Loss = 8.3435, Test Accuracy = 0.2108\n",
      "Iteration 1902: Loss = 1.6203, Accuracy = 0.4300 Test Loss = 8.3371, Test Accuracy = 0.2103\n",
      "Iteration 1903: Loss = 1.6893, Accuracy = 0.4900 Test Loss = 8.3362, Test Accuracy = 0.2100\n",
      "Iteration 1904: Loss = 1.8351, Accuracy = 0.4500 Test Loss = 8.3359, Test Accuracy = 0.2109\n",
      "Iteration 1905: Loss = 1.7670, Accuracy = 0.4000 Test Loss = 8.3389, Test Accuracy = 0.2111\n",
      "Iteration 1906: Loss = 1.7462, Accuracy = 0.4300 Test Loss = 8.3341, Test Accuracy = 0.2106\n",
      "Iteration 1907: Loss = 1.6929, Accuracy = 0.3700 Test Loss = 8.3303, Test Accuracy = 0.2104\n",
      "Iteration 1908: Loss = 1.7996, Accuracy = 0.4600 Test Loss = 8.3241, Test Accuracy = 0.2105\n",
      "Iteration 1909: Loss = 1.7467, Accuracy = 0.4100 Test Loss = 8.3259, Test Accuracy = 0.2100\n",
      "Iteration 1910: Loss = 1.7650, Accuracy = 0.4300 Test Loss = 8.3233, Test Accuracy = 0.2113\n",
      "Iteration 1911: Loss = 1.7642, Accuracy = 0.4400 Test Loss = 8.3265, Test Accuracy = 0.2108\n",
      "Iteration 1912: Loss = 1.7088, Accuracy = 0.4500 Test Loss = 8.3221, Test Accuracy = 0.2103\n",
      "Iteration 1913: Loss = 1.8429, Accuracy = 0.4900 Test Loss = 8.3205, Test Accuracy = 0.2103\n",
      "Iteration 1914: Loss = 1.7598, Accuracy = 0.4500 Test Loss = 8.3157, Test Accuracy = 0.2100\n",
      "Iteration 1915: Loss = 1.6234, Accuracy = 0.4800 Test Loss = 8.3145, Test Accuracy = 0.2109\n",
      "Iteration 1916: Loss = 1.7637, Accuracy = 0.4600 Test Loss = 8.3149, Test Accuracy = 0.2104\n",
      "Iteration 1917: Loss = 1.7457, Accuracy = 0.4600 Test Loss = 8.3201, Test Accuracy = 0.2102\n",
      "Iteration 1918: Loss = 1.6438, Accuracy = 0.4300 Test Loss = 8.3129, Test Accuracy = 0.2107\n",
      "Iteration 1919: Loss = 1.8090, Accuracy = 0.4600 Test Loss = 8.3076, Test Accuracy = 0.2104\n",
      "Iteration 1920: Loss = 1.7234, Accuracy = 0.4400 Test Loss = 8.3012, Test Accuracy = 0.2110\n",
      "Iteration 1921: Loss = 1.7099, Accuracy = 0.4200 Test Loss = 8.3052, Test Accuracy = 0.2110\n",
      "Iteration 1922: Loss = 1.8007, Accuracy = 0.4100 Test Loss = 8.3008, Test Accuracy = 0.2105\n",
      "Iteration 1923: Loss = 1.6418, Accuracy = 0.5100 Test Loss = 8.2956, Test Accuracy = 0.2112\n",
      "Iteration 1924: Loss = 1.6506, Accuracy = 0.4300 Test Loss = 8.2988, Test Accuracy = 0.2114\n",
      "Iteration 1925: Loss = 1.7049, Accuracy = 0.4900 Test Loss = 8.2943, Test Accuracy = 0.2107\n",
      "Iteration 1926: Loss = 1.6212, Accuracy = 0.5300 Test Loss = 8.2994, Test Accuracy = 0.2119\n",
      "Iteration 1927: Loss = 1.7632, Accuracy = 0.4800 Test Loss = 8.2879, Test Accuracy = 0.2119\n",
      "Iteration 1928: Loss = 1.7277, Accuracy = 0.5000 Test Loss = 8.2919, Test Accuracy = 0.2114\n",
      "Iteration 1929: Loss = 1.7692, Accuracy = 0.4500 Test Loss = 8.2871, Test Accuracy = 0.2101\n",
      "Iteration 1930: Loss = 1.6456, Accuracy = 0.4000 Test Loss = 8.2874, Test Accuracy = 0.2109\n",
      "Iteration 1931: Loss = 1.7152, Accuracy = 0.4400 Test Loss = 8.2863, Test Accuracy = 0.2097\n",
      "Iteration 1932: Loss = 1.7275, Accuracy = 0.4600 Test Loss = 8.2772, Test Accuracy = 0.2108\n",
      "Iteration 1933: Loss = 1.7738, Accuracy = 0.4200 Test Loss = 8.2815, Test Accuracy = 0.2115\n",
      "Iteration 1934: Loss = 1.7345, Accuracy = 0.3800 Test Loss = 8.2774, Test Accuracy = 0.2103\n",
      "Iteration 1935: Loss = 1.6941, Accuracy = 0.4800 Test Loss = 8.2754, Test Accuracy = 0.2117\n",
      "Iteration 1936: Loss = 1.7428, Accuracy = 0.4100 Test Loss = 8.2742, Test Accuracy = 0.2114\n",
      "Iteration 1937: Loss = 1.6333, Accuracy = 0.4800 Test Loss = 8.2701, Test Accuracy = 0.2109\n",
      "Iteration 1938: Loss = 1.8317, Accuracy = 0.4600 Test Loss = 8.2657, Test Accuracy = 0.2106\n",
      "Iteration 1939: Loss = 1.7758, Accuracy = 0.4600 Test Loss = 8.2694, Test Accuracy = 0.2111\n",
      "Iteration 1940: Loss = 1.6465, Accuracy = 0.4400 Test Loss = 8.2662, Test Accuracy = 0.2109\n",
      "Iteration 1941: Loss = 1.8066, Accuracy = 0.4200 Test Loss = 8.2637, Test Accuracy = 0.2112\n",
      "Iteration 1942: Loss = 1.6982, Accuracy = 0.4900 Test Loss = 8.2606, Test Accuracy = 0.2108\n",
      "Iteration 1943: Loss = 1.7460, Accuracy = 0.4200 Test Loss = 8.2593, Test Accuracy = 0.2120\n",
      "Iteration 1944: Loss = 1.6869, Accuracy = 0.4300 Test Loss = 8.2602, Test Accuracy = 0.2112\n",
      "Iteration 1945: Loss = 1.6100, Accuracy = 0.4200 Test Loss = 8.2559, Test Accuracy = 0.2112\n",
      "Iteration 1946: Loss = 1.6776, Accuracy = 0.4700 Test Loss = 8.2536, Test Accuracy = 0.2112\n",
      "Iteration 1947: Loss = 1.8036, Accuracy = 0.3600 Test Loss = 8.2478, Test Accuracy = 0.2099\n",
      "Iteration 1948: Loss = 1.7720, Accuracy = 0.4400 Test Loss = 8.2449, Test Accuracy = 0.2110\n",
      "Iteration 1949: Loss = 1.7072, Accuracy = 0.4200 Test Loss = 8.2464, Test Accuracy = 0.2104\n",
      "Iteration 1950: Loss = 1.7413, Accuracy = 0.4100 Test Loss = 8.2440, Test Accuracy = 0.2112\n",
      "Iteration 1951: Loss = 1.6714, Accuracy = 0.4500 Test Loss = 8.2439, Test Accuracy = 0.2112\n",
      "Iteration 1952: Loss = 1.7995, Accuracy = 0.4700 Test Loss = 8.2465, Test Accuracy = 0.2112\n",
      "Iteration 1953: Loss = 1.8401, Accuracy = 0.4400 Test Loss = 8.2453, Test Accuracy = 0.2121\n",
      "Iteration 1954: Loss = 1.6942, Accuracy = 0.4300 Test Loss = 8.2424, Test Accuracy = 0.2125\n",
      "Iteration 1955: Loss = 1.7844, Accuracy = 0.4100 Test Loss = 8.2411, Test Accuracy = 0.2114\n",
      "Iteration 1956: Loss = 1.8066, Accuracy = 0.4300 Test Loss = 8.2417, Test Accuracy = 0.2115\n",
      "Iteration 1957: Loss = 1.7461, Accuracy = 0.4700 Test Loss = 8.2389, Test Accuracy = 0.2106\n",
      "Iteration 1958: Loss = 1.7101, Accuracy = 0.3800 Test Loss = 8.2325, Test Accuracy = 0.2111\n",
      "Iteration 1959: Loss = 1.6981, Accuracy = 0.4200 Test Loss = 8.2279, Test Accuracy = 0.2115\n",
      "Iteration 1960: Loss = 1.7222, Accuracy = 0.4500 Test Loss = 8.2263, Test Accuracy = 0.2123\n",
      "Iteration 1961: Loss = 1.7637, Accuracy = 0.3800 Test Loss = 8.2335, Test Accuracy = 0.2116\n",
      "Iteration 1962: Loss = 1.6991, Accuracy = 0.5000 Test Loss = 8.2230, Test Accuracy = 0.2121\n",
      "Iteration 1963: Loss = 1.6988, Accuracy = 0.3800 Test Loss = 8.2185, Test Accuracy = 0.2116\n",
      "Iteration 1964: Loss = 1.7983, Accuracy = 0.3700 Test Loss = 8.2272, Test Accuracy = 0.2126\n",
      "Iteration 1965: Loss = 1.7691, Accuracy = 0.4500 Test Loss = 8.2183, Test Accuracy = 0.2118\n",
      "Iteration 1966: Loss = 1.6149, Accuracy = 0.4600 Test Loss = 8.2199, Test Accuracy = 0.2119\n",
      "Iteration 1967: Loss = 1.6500, Accuracy = 0.3900 Test Loss = 8.2165, Test Accuracy = 0.2120\n",
      "Iteration 1968: Loss = 1.6805, Accuracy = 0.4200 Test Loss = 8.2087, Test Accuracy = 0.2108\n",
      "Iteration 1969: Loss = 1.8455, Accuracy = 0.3400 Test Loss = 8.2084, Test Accuracy = 0.2116\n",
      "Iteration 1970: Loss = 1.7215, Accuracy = 0.4100 Test Loss = 8.2123, Test Accuracy = 0.2101\n",
      "Iteration 1971: Loss = 1.6341, Accuracy = 0.4800 Test Loss = 8.2065, Test Accuracy = 0.2109\n",
      "Iteration 1972: Loss = 1.6838, Accuracy = 0.4800 Test Loss = 8.2020, Test Accuracy = 0.2117\n",
      "Iteration 1973: Loss = 1.7669, Accuracy = 0.3700 Test Loss = 8.2002, Test Accuracy = 0.2108\n",
      "Iteration 1974: Loss = 1.6169, Accuracy = 0.5000 Test Loss = 8.2021, Test Accuracy = 0.2114\n",
      "Iteration 1975: Loss = 1.6429, Accuracy = 0.4300 Test Loss = 8.2029, Test Accuracy = 0.2121\n",
      "Iteration 1976: Loss = 1.6221, Accuracy = 0.4500 Test Loss = 8.1931, Test Accuracy = 0.2121\n",
      "Iteration 1977: Loss = 1.7746, Accuracy = 0.3800 Test Loss = 8.2017, Test Accuracy = 0.2127\n",
      "Iteration 1978: Loss = 1.6374, Accuracy = 0.4000 Test Loss = 8.1973, Test Accuracy = 0.2125\n",
      "Iteration 1979: Loss = 1.7660, Accuracy = 0.4200 Test Loss = 8.1906, Test Accuracy = 0.2121\n",
      "Iteration 1980: Loss = 1.8025, Accuracy = 0.3800 Test Loss = 8.1922, Test Accuracy = 0.2118\n",
      "Iteration 1981: Loss = 1.7247, Accuracy = 0.4500 Test Loss = 8.1860, Test Accuracy = 0.2120\n",
      "Iteration 1982: Loss = 1.6119, Accuracy = 0.4300 Test Loss = 8.1851, Test Accuracy = 0.2123\n",
      "Iteration 1983: Loss = 1.6624, Accuracy = 0.3900 Test Loss = 8.1868, Test Accuracy = 0.2120\n",
      "Iteration 1984: Loss = 1.6506, Accuracy = 0.4400 Test Loss = 8.1859, Test Accuracy = 0.2122\n",
      "Iteration 1985: Loss = 1.5927, Accuracy = 0.5000 Test Loss = 8.1915, Test Accuracy = 0.2124\n",
      "Iteration 1986: Loss = 1.5826, Accuracy = 0.4800 Test Loss = 8.1812, Test Accuracy = 0.2124\n",
      "Iteration 1987: Loss = 1.6799, Accuracy = 0.4800 Test Loss = 8.1745, Test Accuracy = 0.2121\n",
      "Iteration 1988: Loss = 1.5904, Accuracy = 0.4300 Test Loss = 8.1742, Test Accuracy = 0.2121\n",
      "Iteration 1989: Loss = 1.7112, Accuracy = 0.3900 Test Loss = 8.1763, Test Accuracy = 0.2113\n",
      "Iteration 1990: Loss = 1.6459, Accuracy = 0.5100 Test Loss = 8.1747, Test Accuracy = 0.2125\n",
      "Iteration 1991: Loss = 1.7434, Accuracy = 0.4700 Test Loss = 8.1763, Test Accuracy = 0.2115\n",
      "Iteration 1992: Loss = 1.6879, Accuracy = 0.4300 Test Loss = 8.1667, Test Accuracy = 0.2126\n",
      "Iteration 1993: Loss = 1.7044, Accuracy = 0.3000 Test Loss = 8.1636, Test Accuracy = 0.2119\n",
      "Iteration 1994: Loss = 1.6649, Accuracy = 0.4100 Test Loss = 8.1643, Test Accuracy = 0.2120\n",
      "Iteration 1995: Loss = 1.6959, Accuracy = 0.4300 Test Loss = 8.1628, Test Accuracy = 0.2117\n",
      "Iteration 1996: Loss = 1.6236, Accuracy = 0.4900 Test Loss = 8.1602, Test Accuracy = 0.2122\n",
      "Iteration 1997: Loss = 1.6973, Accuracy = 0.4100 Test Loss = 8.1566, Test Accuracy = 0.2125\n",
      "Iteration 1998: Loss = 1.7369, Accuracy = 0.4300 Test Loss = 8.1610, Test Accuracy = 0.2121\n",
      "Iteration 1999: Loss = 1.7490, Accuracy = 0.4400 Test Loss = 8.1607, Test Accuracy = 0.2124\n",
      "Total training time: 2.97s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = make_train_test_data(train_dataset, test_dataset, n=500)\n",
    "print(X_tr.shape, X_ts.shape)\n",
    "history6 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=2000)\n",
    "plot_history(history6) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training Data = 1000` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "torch.Size([1000, 28, 28]) torch.Size([10000, 28, 28])\n",
      "Iteration 0: Loss = 211.8099, Accuracy = 0.1300 Test Loss = 204.2894, Test Accuracy = 0.1085\n",
      "Iteration 1: Loss = 173.6725, Accuracy = 0.1000 Test Loss = 164.9772, Test Accuracy = 0.1139\n",
      "Iteration 2: Loss = 142.2278, Accuracy = 0.1600 Test Loss = 139.7649, Test Accuracy = 0.1146\n",
      "Iteration 3: Loss = 127.1781, Accuracy = 0.1100 Test Loss = 122.8500, Test Accuracy = 0.1196\n",
      "Iteration 4: Loss = 112.7187, Accuracy = 0.1200 Test Loss = 109.9587, Test Accuracy = 0.1206\n",
      "Iteration 5: Loss = 104.5184, Accuracy = 0.1100 Test Loss = 100.2168, Test Accuracy = 0.1251\n",
      "Iteration 6: Loss = 89.9840, Accuracy = 0.1200 Test Loss = 92.7577, Test Accuracy = 0.1260\n",
      "Iteration 7: Loss = 84.9498, Accuracy = 0.1100 Test Loss = 86.3153, Test Accuracy = 0.1265\n",
      "Iteration 8: Loss = 86.9755, Accuracy = 0.1700 Test Loss = 81.2492, Test Accuracy = 0.1264\n",
      "Iteration 9: Loss = 75.5122, Accuracy = 0.1300 Test Loss = 76.6333, Test Accuracy = 0.1273\n",
      "Iteration 10: Loss = 77.3219, Accuracy = 0.1700 Test Loss = 72.6294, Test Accuracy = 0.1281\n",
      "Iteration 11: Loss = 60.1979, Accuracy = 0.1600 Test Loss = 69.1633, Test Accuracy = 0.1281\n",
      "Iteration 12: Loss = 66.4873, Accuracy = 0.1400 Test Loss = 66.0242, Test Accuracy = 0.1290\n",
      "Iteration 13: Loss = 59.3085, Accuracy = 0.1200 Test Loss = 63.2285, Test Accuracy = 0.1279\n",
      "Iteration 14: Loss = 60.2098, Accuracy = 0.1300 Test Loss = 60.7963, Test Accuracy = 0.1288\n",
      "Iteration 15: Loss = 59.2853, Accuracy = 0.1800 Test Loss = 58.6831, Test Accuracy = 0.1300\n",
      "Iteration 16: Loss = 47.4837, Accuracy = 0.1500 Test Loss = 56.4901, Test Accuracy = 0.1307\n",
      "Iteration 17: Loss = 57.2454, Accuracy = 0.0800 Test Loss = 54.6748, Test Accuracy = 0.1300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor(train_dataset.data, dtype=torch.float32) / 255\n",
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = torch.tensor(test_dataset.data, dtype=torch.float32) / 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18: Loss = 50.1843, Accuracy = 0.1000 Test Loss = 52.9601, Test Accuracy = 0.1313\n",
      "Iteration 19: Loss = 49.5442, Accuracy = 0.0900 Test Loss = 51.4115, Test Accuracy = 0.1303\n",
      "Iteration 20: Loss = 47.3929, Accuracy = 0.1500 Test Loss = 49.9079, Test Accuracy = 0.1294\n",
      "Iteration 21: Loss = 45.5690, Accuracy = 0.1100 Test Loss = 48.6352, Test Accuracy = 0.1317\n",
      "Iteration 22: Loss = 44.8870, Accuracy = 0.1600 Test Loss = 47.3045, Test Accuracy = 0.1316\n",
      "Iteration 23: Loss = 41.4384, Accuracy = 0.1200 Test Loss = 46.1868, Test Accuracy = 0.1323\n",
      "Iteration 24: Loss = 44.6404, Accuracy = 0.1100 Test Loss = 44.9626, Test Accuracy = 0.1317\n",
      "Iteration 25: Loss = 40.4354, Accuracy = 0.1800 Test Loss = 44.0280, Test Accuracy = 0.1310\n",
      "Iteration 26: Loss = 38.2566, Accuracy = 0.1600 Test Loss = 43.0590, Test Accuracy = 0.1316\n",
      "Iteration 27: Loss = 40.9470, Accuracy = 0.1400 Test Loss = 42.0694, Test Accuracy = 0.1322\n",
      "Iteration 28: Loss = 38.6458, Accuracy = 0.2100 Test Loss = 41.3177, Test Accuracy = 0.1337\n",
      "Iteration 29: Loss = 38.6603, Accuracy = 0.1200 Test Loss = 40.4735, Test Accuracy = 0.1314\n",
      "Iteration 30: Loss = 34.2715, Accuracy = 0.1600 Test Loss = 39.6534, Test Accuracy = 0.1342\n",
      "Iteration 31: Loss = 38.0047, Accuracy = 0.0900 Test Loss = 38.9383, Test Accuracy = 0.1328\n",
      "Iteration 32: Loss = 32.5996, Accuracy = 0.1200 Test Loss = 38.2074, Test Accuracy = 0.1336\n",
      "Iteration 33: Loss = 32.2712, Accuracy = 0.1300 Test Loss = 37.5897, Test Accuracy = 0.1344\n",
      "Iteration 34: Loss = 34.0955, Accuracy = 0.1000 Test Loss = 36.9453, Test Accuracy = 0.1341\n",
      "Iteration 35: Loss = 32.6664, Accuracy = 0.1600 Test Loss = 36.3747, Test Accuracy = 0.1379\n",
      "Iteration 36: Loss = 33.9507, Accuracy = 0.2100 Test Loss = 35.7976, Test Accuracy = 0.1347\n",
      "Iteration 37: Loss = 29.6369, Accuracy = 0.1200 Test Loss = 35.2395, Test Accuracy = 0.1356\n",
      "Iteration 38: Loss = 29.9483, Accuracy = 0.1600 Test Loss = 34.7864, Test Accuracy = 0.1348\n",
      "Iteration 39: Loss = 31.3946, Accuracy = 0.1000 Test Loss = 34.1965, Test Accuracy = 0.1375\n",
      "Iteration 40: Loss = 30.2020, Accuracy = 0.1500 Test Loss = 33.7982, Test Accuracy = 0.1373\n",
      "Iteration 41: Loss = 33.5652, Accuracy = 0.1800 Test Loss = 33.3003, Test Accuracy = 0.1368\n",
      "Iteration 42: Loss = 30.8941, Accuracy = 0.1100 Test Loss = 32.8046, Test Accuracy = 0.1378\n",
      "Iteration 43: Loss = 28.4852, Accuracy = 0.1000 Test Loss = 32.4522, Test Accuracy = 0.1384\n",
      "Iteration 44: Loss = 28.2710, Accuracy = 0.1500 Test Loss = 32.0731, Test Accuracy = 0.1388\n",
      "Iteration 45: Loss = 30.2269, Accuracy = 0.1700 Test Loss = 31.5768, Test Accuracy = 0.1398\n",
      "Iteration 46: Loss = 27.3603, Accuracy = 0.1400 Test Loss = 31.1921, Test Accuracy = 0.1408\n",
      "Iteration 47: Loss = 28.7300, Accuracy = 0.1600 Test Loss = 30.8882, Test Accuracy = 0.1408\n",
      "Iteration 48: Loss = 26.3481, Accuracy = 0.1600 Test Loss = 30.4895, Test Accuracy = 0.1416\n",
      "Iteration 49: Loss = 26.7363, Accuracy = 0.1600 Test Loss = 30.1164, Test Accuracy = 0.1421\n",
      "Iteration 50: Loss = 27.2655, Accuracy = 0.1800 Test Loss = 29.7801, Test Accuracy = 0.1421\n",
      "Iteration 51: Loss = 25.7345, Accuracy = 0.0900 Test Loss = 29.4434, Test Accuracy = 0.1423\n",
      "Iteration 52: Loss = 22.9213, Accuracy = 0.2300 Test Loss = 29.1716, Test Accuracy = 0.1443\n",
      "Iteration 53: Loss = 23.6556, Accuracy = 0.1900 Test Loss = 28.8304, Test Accuracy = 0.1419\n",
      "Iteration 54: Loss = 25.5178, Accuracy = 0.1400 Test Loss = 28.5726, Test Accuracy = 0.1450\n",
      "Iteration 55: Loss = 23.1589, Accuracy = 0.1700 Test Loss = 28.2721, Test Accuracy = 0.1450\n",
      "Iteration 56: Loss = 25.8454, Accuracy = 0.1800 Test Loss = 28.0417, Test Accuracy = 0.1451\n",
      "Iteration 57: Loss = 24.3822, Accuracy = 0.1100 Test Loss = 27.7626, Test Accuracy = 0.1465\n",
      "Iteration 58: Loss = 24.1231, Accuracy = 0.1700 Test Loss = 27.4266, Test Accuracy = 0.1447\n",
      "Iteration 59: Loss = 21.8136, Accuracy = 0.1400 Test Loss = 27.1707, Test Accuracy = 0.1442\n",
      "Iteration 60: Loss = 20.5788, Accuracy = 0.1300 Test Loss = 26.9571, Test Accuracy = 0.1446\n",
      "Iteration 61: Loss = 24.5571, Accuracy = 0.1200 Test Loss = 26.7096, Test Accuracy = 0.1448\n",
      "Iteration 62: Loss = 23.7277, Accuracy = 0.1500 Test Loss = 26.4548, Test Accuracy = 0.1461\n",
      "Iteration 63: Loss = 22.7192, Accuracy = 0.1900 Test Loss = 26.2174, Test Accuracy = 0.1453\n",
      "Iteration 64: Loss = 22.6601, Accuracy = 0.1900 Test Loss = 26.0243, Test Accuracy = 0.1468\n",
      "Iteration 65: Loss = 22.7937, Accuracy = 0.1500 Test Loss = 25.7947, Test Accuracy = 0.1452\n",
      "Iteration 66: Loss = 20.9526, Accuracy = 0.1400 Test Loss = 25.5336, Test Accuracy = 0.1468\n",
      "Iteration 67: Loss = 21.3378, Accuracy = 0.1800 Test Loss = 25.3498, Test Accuracy = 0.1467\n",
      "Iteration 68: Loss = 20.8986, Accuracy = 0.1700 Test Loss = 25.1346, Test Accuracy = 0.1463\n",
      "Iteration 69: Loss = 19.5579, Accuracy = 0.1100 Test Loss = 24.9819, Test Accuracy = 0.1497\n",
      "Iteration 70: Loss = 19.9931, Accuracy = 0.1300 Test Loss = 24.7612, Test Accuracy = 0.1476\n",
      "Iteration 71: Loss = 22.6522, Accuracy = 0.1500 Test Loss = 24.5939, Test Accuracy = 0.1505\n",
      "Iteration 72: Loss = 21.0730, Accuracy = 0.1200 Test Loss = 24.3626, Test Accuracy = 0.1490\n",
      "Iteration 73: Loss = 19.8260, Accuracy = 0.2300 Test Loss = 24.2105, Test Accuracy = 0.1499\n",
      "Iteration 74: Loss = 20.1595, Accuracy = 0.1700 Test Loss = 24.0301, Test Accuracy = 0.1488\n",
      "Iteration 75: Loss = 20.4779, Accuracy = 0.1200 Test Loss = 23.8806, Test Accuracy = 0.1490\n",
      "Iteration 76: Loss = 19.0714, Accuracy = 0.2000 Test Loss = 23.6950, Test Accuracy = 0.1497\n",
      "Iteration 77: Loss = 20.0711, Accuracy = 0.1300 Test Loss = 23.5227, Test Accuracy = 0.1515\n",
      "Iteration 78: Loss = 16.9733, Accuracy = 0.1900 Test Loss = 23.3460, Test Accuracy = 0.1511\n",
      "Iteration 79: Loss = 19.3074, Accuracy = 0.1500 Test Loss = 23.1791, Test Accuracy = 0.1514\n",
      "Iteration 80: Loss = 18.7136, Accuracy = 0.1600 Test Loss = 23.0199, Test Accuracy = 0.1520\n",
      "Iteration 81: Loss = 17.1040, Accuracy = 0.2100 Test Loss = 22.8401, Test Accuracy = 0.1508\n",
      "Iteration 82: Loss = 19.0282, Accuracy = 0.1800 Test Loss = 22.7400, Test Accuracy = 0.1520\n",
      "Iteration 83: Loss = 18.1022, Accuracy = 0.1600 Test Loss = 22.5370, Test Accuracy = 0.1515\n",
      "Iteration 84: Loss = 19.1183, Accuracy = 0.1600 Test Loss = 22.3939, Test Accuracy = 0.1516\n",
      "Iteration 85: Loss = 18.7933, Accuracy = 0.1800 Test Loss = 22.2786, Test Accuracy = 0.1522\n",
      "Iteration 86: Loss = 18.7021, Accuracy = 0.1300 Test Loss = 22.1140, Test Accuracy = 0.1523\n",
      "Iteration 87: Loss = 19.5872, Accuracy = 0.1400 Test Loss = 21.9656, Test Accuracy = 0.1526\n",
      "Iteration 88: Loss = 17.8528, Accuracy = 0.1900 Test Loss = 21.8552, Test Accuracy = 0.1517\n",
      "Iteration 89: Loss = 17.3556, Accuracy = 0.1500 Test Loss = 21.7061, Test Accuracy = 0.1521\n",
      "Iteration 90: Loss = 17.4277, Accuracy = 0.2400 Test Loss = 21.6005, Test Accuracy = 0.1517\n",
      "Iteration 91: Loss = 16.8148, Accuracy = 0.1100 Test Loss = 21.4574, Test Accuracy = 0.1538\n",
      "Iteration 92: Loss = 18.7162, Accuracy = 0.2200 Test Loss = 21.3403, Test Accuracy = 0.1533\n",
      "Iteration 93: Loss = 17.3051, Accuracy = 0.1400 Test Loss = 21.1767, Test Accuracy = 0.1548\n",
      "Iteration 94: Loss = 17.3185, Accuracy = 0.2100 Test Loss = 21.0448, Test Accuracy = 0.1544\n",
      "Iteration 95: Loss = 16.9593, Accuracy = 0.1700 Test Loss = 20.9511, Test Accuracy = 0.1559\n",
      "Iteration 96: Loss = 15.7046, Accuracy = 0.2100 Test Loss = 20.8292, Test Accuracy = 0.1553\n",
      "Iteration 97: Loss = 14.8618, Accuracy = 0.1400 Test Loss = 20.6871, Test Accuracy = 0.1541\n",
      "Iteration 98: Loss = 17.6311, Accuracy = 0.1900 Test Loss = 20.5922, Test Accuracy = 0.1569\n",
      "Iteration 99: Loss = 16.0142, Accuracy = 0.2000 Test Loss = 20.4699, Test Accuracy = 0.1560\n",
      "Iteration 100: Loss = 17.3854, Accuracy = 0.1100 Test Loss = 20.3615, Test Accuracy = 0.1554\n",
      "Iteration 101: Loss = 15.9966, Accuracy = 0.2000 Test Loss = 20.2451, Test Accuracy = 0.1559\n",
      "Iteration 102: Loss = 16.1202, Accuracy = 0.1700 Test Loss = 20.1565, Test Accuracy = 0.1544\n",
      "Iteration 103: Loss = 15.8273, Accuracy = 0.1500 Test Loss = 20.0380, Test Accuracy = 0.1565\n",
      "Iteration 104: Loss = 15.2052, Accuracy = 0.1700 Test Loss = 19.9319, Test Accuracy = 0.1584\n",
      "Iteration 105: Loss = 16.9064, Accuracy = 0.1500 Test Loss = 19.8162, Test Accuracy = 0.1588\n",
      "Iteration 106: Loss = 16.9805, Accuracy = 0.1600 Test Loss = 19.7131, Test Accuracy = 0.1577\n",
      "Iteration 107: Loss = 15.8945, Accuracy = 0.1500 Test Loss = 19.6091, Test Accuracy = 0.1588\n",
      "Iteration 108: Loss = 14.6701, Accuracy = 0.1600 Test Loss = 19.5307, Test Accuracy = 0.1587\n",
      "Iteration 109: Loss = 13.2499, Accuracy = 0.2000 Test Loss = 19.4149, Test Accuracy = 0.1574\n",
      "Iteration 110: Loss = 15.1205, Accuracy = 0.1900 Test Loss = 19.3085, Test Accuracy = 0.1584\n",
      "Iteration 111: Loss = 14.1579, Accuracy = 0.2000 Test Loss = 19.2150, Test Accuracy = 0.1580\n",
      "Iteration 112: Loss = 15.0302, Accuracy = 0.1200 Test Loss = 19.1411, Test Accuracy = 0.1576\n",
      "Iteration 113: Loss = 14.2532, Accuracy = 0.1800 Test Loss = 19.0472, Test Accuracy = 0.1562\n",
      "Iteration 114: Loss = 16.1424, Accuracy = 0.1600 Test Loss = 18.9701, Test Accuracy = 0.1598\n",
      "Iteration 115: Loss = 14.4980, Accuracy = 0.1100 Test Loss = 18.8399, Test Accuracy = 0.1611\n",
      "Iteration 116: Loss = 14.5479, Accuracy = 0.2000 Test Loss = 18.7845, Test Accuracy = 0.1605\n",
      "Iteration 117: Loss = 15.1603, Accuracy = 0.2500 Test Loss = 18.6697, Test Accuracy = 0.1577\n",
      "Iteration 118: Loss = 12.9956, Accuracy = 0.1400 Test Loss = 18.5971, Test Accuracy = 0.1585\n",
      "Iteration 119: Loss = 13.7867, Accuracy = 0.1900 Test Loss = 18.5076, Test Accuracy = 0.1588\n",
      "Iteration 120: Loss = 14.4515, Accuracy = 0.1800 Test Loss = 18.4023, Test Accuracy = 0.1623\n",
      "Iteration 121: Loss = 13.4026, Accuracy = 0.2300 Test Loss = 18.3354, Test Accuracy = 0.1611\n",
      "Iteration 122: Loss = 14.2778, Accuracy = 0.1800 Test Loss = 18.2417, Test Accuracy = 0.1598\n",
      "Iteration 123: Loss = 15.2196, Accuracy = 0.1300 Test Loss = 18.1649, Test Accuracy = 0.1614\n",
      "Iteration 124: Loss = 14.4561, Accuracy = 0.1100 Test Loss = 18.0921, Test Accuracy = 0.1604\n",
      "Iteration 125: Loss = 13.5715, Accuracy = 0.2300 Test Loss = 18.0331, Test Accuracy = 0.1613\n",
      "Iteration 126: Loss = 14.4655, Accuracy = 0.1700 Test Loss = 17.9466, Test Accuracy = 0.1614\n",
      "Iteration 127: Loss = 12.9541, Accuracy = 0.1200 Test Loss = 17.8554, Test Accuracy = 0.1609\n",
      "Iteration 128: Loss = 13.1261, Accuracy = 0.1800 Test Loss = 17.7824, Test Accuracy = 0.1633\n",
      "Iteration 129: Loss = 13.1696, Accuracy = 0.2400 Test Loss = 17.7093, Test Accuracy = 0.1624\n",
      "Iteration 130: Loss = 14.0075, Accuracy = 0.1800 Test Loss = 17.6302, Test Accuracy = 0.1632\n",
      "Iteration 131: Loss = 13.3278, Accuracy = 0.1300 Test Loss = 17.5557, Test Accuracy = 0.1642\n",
      "Iteration 132: Loss = 13.8085, Accuracy = 0.1100 Test Loss = 17.4631, Test Accuracy = 0.1647\n",
      "Iteration 133: Loss = 13.4001, Accuracy = 0.1800 Test Loss = 17.4130, Test Accuracy = 0.1645\n",
      "Iteration 134: Loss = 14.0931, Accuracy = 0.2100 Test Loss = 17.3214, Test Accuracy = 0.1628\n",
      "Iteration 135: Loss = 13.2297, Accuracy = 0.1600 Test Loss = 17.2636, Test Accuracy = 0.1660\n",
      "Iteration 136: Loss = 13.5333, Accuracy = 0.1400 Test Loss = 17.1704, Test Accuracy = 0.1661\n",
      "Iteration 137: Loss = 11.5892, Accuracy = 0.1600 Test Loss = 17.1221, Test Accuracy = 0.1638\n",
      "Iteration 138: Loss = 13.0150, Accuracy = 0.1900 Test Loss = 17.0394, Test Accuracy = 0.1622\n",
      "Iteration 139: Loss = 12.8747, Accuracy = 0.2200 Test Loss = 17.0014, Test Accuracy = 0.1670\n",
      "Iteration 140: Loss = 12.1729, Accuracy = 0.1400 Test Loss = 16.9070, Test Accuracy = 0.1650\n",
      "Iteration 141: Loss = 12.2359, Accuracy = 0.1800 Test Loss = 16.8543, Test Accuracy = 0.1667\n",
      "Iteration 142: Loss = 13.1414, Accuracy = 0.1700 Test Loss = 16.7990, Test Accuracy = 0.1681\n",
      "Iteration 143: Loss = 12.3914, Accuracy = 0.2700 Test Loss = 16.7200, Test Accuracy = 0.1675\n",
      "Iteration 144: Loss = 13.7709, Accuracy = 0.1700 Test Loss = 16.6467, Test Accuracy = 0.1654\n",
      "Iteration 145: Loss = 11.9262, Accuracy = 0.1400 Test Loss = 16.5853, Test Accuracy = 0.1682\n",
      "Iteration 146: Loss = 12.8210, Accuracy = 0.2600 Test Loss = 16.5735, Test Accuracy = 0.1684\n",
      "Iteration 147: Loss = 12.7375, Accuracy = 0.1800 Test Loss = 16.4403, Test Accuracy = 0.1658\n",
      "Iteration 148: Loss = 11.4578, Accuracy = 0.1900 Test Loss = 16.4059, Test Accuracy = 0.1681\n",
      "Iteration 149: Loss = 11.6915, Accuracy = 0.1300 Test Loss = 16.3365, Test Accuracy = 0.1690\n",
      "Iteration 150: Loss = 12.0829, Accuracy = 0.1800 Test Loss = 16.2769, Test Accuracy = 0.1690\n",
      "Iteration 151: Loss = 11.9303, Accuracy = 0.1500 Test Loss = 16.2009, Test Accuracy = 0.1693\n",
      "Iteration 152: Loss = 11.4114, Accuracy = 0.1900 Test Loss = 16.1700, Test Accuracy = 0.1700\n",
      "Iteration 153: Loss = 12.2654, Accuracy = 0.1400 Test Loss = 16.0985, Test Accuracy = 0.1690\n",
      "Iteration 154: Loss = 11.4201, Accuracy = 0.2600 Test Loss = 16.0576, Test Accuracy = 0.1702\n",
      "Iteration 155: Loss = 13.2836, Accuracy = 0.1800 Test Loss = 15.9777, Test Accuracy = 0.1704\n",
      "Iteration 156: Loss = 11.6266, Accuracy = 0.2100 Test Loss = 15.9221, Test Accuracy = 0.1707\n",
      "Iteration 157: Loss = 11.3473, Accuracy = 0.1800 Test Loss = 15.8549, Test Accuracy = 0.1691\n",
      "Iteration 158: Loss = 11.6340, Accuracy = 0.2400 Test Loss = 15.8208, Test Accuracy = 0.1717\n",
      "Iteration 159: Loss = 11.7309, Accuracy = 0.1800 Test Loss = 15.7415, Test Accuracy = 0.1705\n",
      "Iteration 160: Loss = 11.7030, Accuracy = 0.1900 Test Loss = 15.6934, Test Accuracy = 0.1717\n",
      "Iteration 161: Loss = 12.0504, Accuracy = 0.1200 Test Loss = 15.6435, Test Accuracy = 0.1707\n",
      "Iteration 162: Loss = 11.4878, Accuracy = 0.1900 Test Loss = 15.5841, Test Accuracy = 0.1694\n",
      "Iteration 163: Loss = 11.7159, Accuracy = 0.1700 Test Loss = 15.5232, Test Accuracy = 0.1718\n",
      "Iteration 164: Loss = 11.3995, Accuracy = 0.2000 Test Loss = 15.5147, Test Accuracy = 0.1733\n",
      "Iteration 165: Loss = 11.5339, Accuracy = 0.2100 Test Loss = 15.4252, Test Accuracy = 0.1727\n",
      "Iteration 166: Loss = 12.0804, Accuracy = 0.1200 Test Loss = 15.3797, Test Accuracy = 0.1730\n",
      "Iteration 167: Loss = 11.1251, Accuracy = 0.2200 Test Loss = 15.3186, Test Accuracy = 0.1726\n",
      "Iteration 168: Loss = 11.5208, Accuracy = 0.1900 Test Loss = 15.2952, Test Accuracy = 0.1740\n",
      "Iteration 169: Loss = 10.8475, Accuracy = 0.1800 Test Loss = 15.2336, Test Accuracy = 0.1732\n",
      "Iteration 170: Loss = 11.0695, Accuracy = 0.2500 Test Loss = 15.1678, Test Accuracy = 0.1746\n",
      "Iteration 171: Loss = 10.9642, Accuracy = 0.2600 Test Loss = 15.1231, Test Accuracy = 0.1729\n",
      "Iteration 172: Loss = 10.5297, Accuracy = 0.1700 Test Loss = 15.0810, Test Accuracy = 0.1750\n",
      "Iteration 173: Loss = 11.4319, Accuracy = 0.2000 Test Loss = 15.0247, Test Accuracy = 0.1738\n",
      "Iteration 174: Loss = 11.5570, Accuracy = 0.2000 Test Loss = 15.0159, Test Accuracy = 0.1744\n",
      "Iteration 175: Loss = 11.3144, Accuracy = 0.1500 Test Loss = 14.9397, Test Accuracy = 0.1749\n",
      "Iteration 176: Loss = 11.0920, Accuracy = 0.1900 Test Loss = 14.8838, Test Accuracy = 0.1754\n",
      "Iteration 177: Loss = 10.5287, Accuracy = 0.1700 Test Loss = 14.8348, Test Accuracy = 0.1766\n",
      "Iteration 178: Loss = 9.8435, Accuracy = 0.1100 Test Loss = 14.7829, Test Accuracy = 0.1768\n",
      "Iteration 179: Loss = 10.3719, Accuracy = 0.1600 Test Loss = 14.7654, Test Accuracy = 0.1764\n",
      "Iteration 180: Loss = 10.3443, Accuracy = 0.1700 Test Loss = 14.6904, Test Accuracy = 0.1766\n",
      "Iteration 181: Loss = 10.6254, Accuracy = 0.2100 Test Loss = 14.6433, Test Accuracy = 0.1760\n",
      "Iteration 182: Loss = 10.3580, Accuracy = 0.1200 Test Loss = 14.6120, Test Accuracy = 0.1777\n",
      "Iteration 183: Loss = 10.5127, Accuracy = 0.1900 Test Loss = 14.5662, Test Accuracy = 0.1769\n",
      "Iteration 184: Loss = 9.8864, Accuracy = 0.1200 Test Loss = 14.5249, Test Accuracy = 0.1784\n",
      "Iteration 185: Loss = 10.8054, Accuracy = 0.2000 Test Loss = 14.4556, Test Accuracy = 0.1775\n",
      "Iteration 186: Loss = 10.8499, Accuracy = 0.2200 Test Loss = 14.4349, Test Accuracy = 0.1779\n",
      "Iteration 187: Loss = 10.2100, Accuracy = 0.1600 Test Loss = 14.3778, Test Accuracy = 0.1781\n",
      "Iteration 188: Loss = 10.1182, Accuracy = 0.1800 Test Loss = 14.3269, Test Accuracy = 0.1775\n",
      "Iteration 189: Loss = 9.7265, Accuracy = 0.2000 Test Loss = 14.3100, Test Accuracy = 0.1790\n",
      "Iteration 190: Loss = 9.7608, Accuracy = 0.1900 Test Loss = 14.2681, Test Accuracy = 0.1787\n",
      "Iteration 191: Loss = 9.3898, Accuracy = 0.2100 Test Loss = 14.1924, Test Accuracy = 0.1780\n",
      "Iteration 192: Loss = 10.6678, Accuracy = 0.1200 Test Loss = 14.1660, Test Accuracy = 0.1794\n",
      "Iteration 193: Loss = 10.1493, Accuracy = 0.2200 Test Loss = 14.1234, Test Accuracy = 0.1801\n",
      "Iteration 194: Loss = 10.7468, Accuracy = 0.1300 Test Loss = 14.0978, Test Accuracy = 0.1786\n",
      "Iteration 195: Loss = 9.7886, Accuracy = 0.1300 Test Loss = 14.0477, Test Accuracy = 0.1792\n",
      "Iteration 196: Loss = 10.3652, Accuracy = 0.2200 Test Loss = 14.0069, Test Accuracy = 0.1816\n",
      "Iteration 197: Loss = 10.3683, Accuracy = 0.1600 Test Loss = 13.9614, Test Accuracy = 0.1802\n",
      "Iteration 198: Loss = 9.9595, Accuracy = 0.1400 Test Loss = 13.9171, Test Accuracy = 0.1809\n",
      "Iteration 199: Loss = 9.6434, Accuracy = 0.1700 Test Loss = 13.8937, Test Accuracy = 0.1805\n",
      "Iteration 200: Loss = 9.3988, Accuracy = 0.2100 Test Loss = 13.8426, Test Accuracy = 0.1802\n",
      "Iteration 201: Loss = 10.0488, Accuracy = 0.1500 Test Loss = 13.8014, Test Accuracy = 0.1818\n",
      "Iteration 202: Loss = 9.8539, Accuracy = 0.1600 Test Loss = 13.7498, Test Accuracy = 0.1802\n",
      "Iteration 203: Loss = 9.6835, Accuracy = 0.2500 Test Loss = 13.7185, Test Accuracy = 0.1814\n",
      "Iteration 204: Loss = 9.0097, Accuracy = 0.1700 Test Loss = 13.6909, Test Accuracy = 0.1815\n",
      "Iteration 205: Loss = 9.5117, Accuracy = 0.1300 Test Loss = 13.6433, Test Accuracy = 0.1817\n",
      "Iteration 206: Loss = 8.7140, Accuracy = 0.1800 Test Loss = 13.5960, Test Accuracy = 0.1810\n",
      "Iteration 207: Loss = 9.6386, Accuracy = 0.1500 Test Loss = 13.5822, Test Accuracy = 0.1820\n",
      "Iteration 208: Loss = 8.8273, Accuracy = 0.1900 Test Loss = 13.5705, Test Accuracy = 0.1823\n",
      "Iteration 209: Loss = 9.5723, Accuracy = 0.1400 Test Loss = 13.5142, Test Accuracy = 0.1809\n",
      "Iteration 210: Loss = 10.0198, Accuracy = 0.2100 Test Loss = 13.4724, Test Accuracy = 0.1805\n",
      "Iteration 211: Loss = 9.9307, Accuracy = 0.1400 Test Loss = 13.4265, Test Accuracy = 0.1819\n",
      "Iteration 212: Loss = 9.2131, Accuracy = 0.1900 Test Loss = 13.3884, Test Accuracy = 0.1823\n",
      "Iteration 213: Loss = 8.9148, Accuracy = 0.1700 Test Loss = 13.3518, Test Accuracy = 0.1825\n",
      "Iteration 214: Loss = 9.7411, Accuracy = 0.2300 Test Loss = 13.3197, Test Accuracy = 0.1819\n",
      "Iteration 215: Loss = 9.1028, Accuracy = 0.2200 Test Loss = 13.2863, Test Accuracy = 0.1841\n",
      "Iteration 216: Loss = 8.7365, Accuracy = 0.1800 Test Loss = 13.2543, Test Accuracy = 0.1808\n",
      "Iteration 217: Loss = 9.5352, Accuracy = 0.1600 Test Loss = 13.2169, Test Accuracy = 0.1824\n",
      "Iteration 218: Loss = 9.1684, Accuracy = 0.1700 Test Loss = 13.1874, Test Accuracy = 0.1836\n",
      "Iteration 219: Loss = 8.5819, Accuracy = 0.1700 Test Loss = 13.1598, Test Accuracy = 0.1825\n",
      "Iteration 220: Loss = 9.5432, Accuracy = 0.2000 Test Loss = 13.1267, Test Accuracy = 0.1825\n",
      "Iteration 221: Loss = 8.8244, Accuracy = 0.2100 Test Loss = 13.0818, Test Accuracy = 0.1837\n",
      "Iteration 222: Loss = 8.2546, Accuracy = 0.1900 Test Loss = 13.0407, Test Accuracy = 0.1831\n",
      "Iteration 223: Loss = 8.5645, Accuracy = 0.2100 Test Loss = 13.0039, Test Accuracy = 0.1835\n",
      "Iteration 224: Loss = 8.8158, Accuracy = 0.2200 Test Loss = 12.9997, Test Accuracy = 0.1829\n",
      "Iteration 225: Loss = 8.4197, Accuracy = 0.1700 Test Loss = 12.9254, Test Accuracy = 0.1834\n",
      "Iteration 226: Loss = 8.0362, Accuracy = 0.2000 Test Loss = 12.8892, Test Accuracy = 0.1843\n",
      "Iteration 227: Loss = 10.2082, Accuracy = 0.2700 Test Loss = 12.8655, Test Accuracy = 0.1856\n",
      "Iteration 228: Loss = 9.5408, Accuracy = 0.1600 Test Loss = 12.8540, Test Accuracy = 0.1853\n",
      "Iteration 229: Loss = 8.4329, Accuracy = 0.2700 Test Loss = 12.8110, Test Accuracy = 0.1859\n",
      "Iteration 230: Loss = 7.9108, Accuracy = 0.1900 Test Loss = 12.7849, Test Accuracy = 0.1863\n",
      "Iteration 231: Loss = 8.5714, Accuracy = 0.2200 Test Loss = 12.7292, Test Accuracy = 0.1864\n",
      "Iteration 232: Loss = 8.8128, Accuracy = 0.2500 Test Loss = 12.6938, Test Accuracy = 0.1864\n",
      "Iteration 233: Loss = 8.5465, Accuracy = 0.2100 Test Loss = 12.6820, Test Accuracy = 0.1839\n",
      "Iteration 234: Loss = 9.3930, Accuracy = 0.2500 Test Loss = 12.6679, Test Accuracy = 0.1865\n",
      "Iteration 235: Loss = 8.7411, Accuracy = 0.1900 Test Loss = 12.6208, Test Accuracy = 0.1871\n",
      "Iteration 236: Loss = 9.2239, Accuracy = 0.1400 Test Loss = 12.5814, Test Accuracy = 0.1836\n",
      "Iteration 237: Loss = 7.9829, Accuracy = 0.2500 Test Loss = 12.5327, Test Accuracy = 0.1866\n",
      "Iteration 238: Loss = 8.4475, Accuracy = 0.1500 Test Loss = 12.5088, Test Accuracy = 0.1863\n",
      "Iteration 239: Loss = 8.8731, Accuracy = 0.2500 Test Loss = 12.4957, Test Accuracy = 0.1846\n",
      "Iteration 240: Loss = 8.8558, Accuracy = 0.2100 Test Loss = 12.4629, Test Accuracy = 0.1872\n",
      "Iteration 241: Loss = 8.8695, Accuracy = 0.1700 Test Loss = 12.4567, Test Accuracy = 0.1870\n",
      "Iteration 242: Loss = 9.0472, Accuracy = 0.2200 Test Loss = 12.3908, Test Accuracy = 0.1867\n",
      "Iteration 243: Loss = 8.7726, Accuracy = 0.1800 Test Loss = 12.3745, Test Accuracy = 0.1894\n",
      "Iteration 244: Loss = 8.0571, Accuracy = 0.1900 Test Loss = 12.3358, Test Accuracy = 0.1856\n",
      "Iteration 245: Loss = 8.4684, Accuracy = 0.1400 Test Loss = 12.3316, Test Accuracy = 0.1891\n",
      "Iteration 246: Loss = 8.1449, Accuracy = 0.1800 Test Loss = 12.2769, Test Accuracy = 0.1868\n",
      "Iteration 247: Loss = 7.9409, Accuracy = 0.2400 Test Loss = 12.2644, Test Accuracy = 0.1886\n",
      "Iteration 248: Loss = 7.9489, Accuracy = 0.2300 Test Loss = 12.2305, Test Accuracy = 0.1879\n",
      "Iteration 249: Loss = 7.9885, Accuracy = 0.1900 Test Loss = 12.1869, Test Accuracy = 0.1889\n",
      "Iteration 250: Loss = 7.5777, Accuracy = 0.2300 Test Loss = 12.1559, Test Accuracy = 0.1892\n",
      "Iteration 251: Loss = 9.2396, Accuracy = 0.1800 Test Loss = 12.1600, Test Accuracy = 0.1910\n",
      "Iteration 252: Loss = 8.0658, Accuracy = 0.2500 Test Loss = 12.1173, Test Accuracy = 0.1887\n",
      "Iteration 253: Loss = 8.1489, Accuracy = 0.2500 Test Loss = 12.0850, Test Accuracy = 0.1888\n",
      "Iteration 254: Loss = 7.1743, Accuracy = 0.2100 Test Loss = 12.0544, Test Accuracy = 0.1885\n",
      "Iteration 255: Loss = 8.2423, Accuracy = 0.1800 Test Loss = 12.0152, Test Accuracy = 0.1882\n",
      "Iteration 256: Loss = 7.7585, Accuracy = 0.1900 Test Loss = 11.9854, Test Accuracy = 0.1903\n",
      "Iteration 257: Loss = 8.4877, Accuracy = 0.2600 Test Loss = 11.9730, Test Accuracy = 0.1897\n",
      "Iteration 258: Loss = 7.5891, Accuracy = 0.2100 Test Loss = 11.9434, Test Accuracy = 0.1888\n",
      "Iteration 259: Loss = 6.9980, Accuracy = 0.2500 Test Loss = 11.9066, Test Accuracy = 0.1915\n",
      "Iteration 260: Loss = 8.4294, Accuracy = 0.2300 Test Loss = 11.8948, Test Accuracy = 0.1911\n",
      "Iteration 261: Loss = 7.9488, Accuracy = 0.2800 Test Loss = 11.8697, Test Accuracy = 0.1898\n",
      "Iteration 262: Loss = 8.4311, Accuracy = 0.2200 Test Loss = 11.8463, Test Accuracy = 0.1911\n",
      "Iteration 263: Loss = 8.0979, Accuracy = 0.1900 Test Loss = 11.7952, Test Accuracy = 0.1918\n",
      "Iteration 264: Loss = 7.9686, Accuracy = 0.2000 Test Loss = 11.7700, Test Accuracy = 0.1913\n",
      "Iteration 265: Loss = 8.5906, Accuracy = 0.2300 Test Loss = 11.7479, Test Accuracy = 0.1913\n",
      "Iteration 266: Loss = 7.5321, Accuracy = 0.1900 Test Loss = 11.7245, Test Accuracy = 0.1915\n",
      "Iteration 267: Loss = 7.9030, Accuracy = 0.2200 Test Loss = 11.6971, Test Accuracy = 0.1917\n",
      "Iteration 268: Loss = 7.1757, Accuracy = 0.1700 Test Loss = 11.6698, Test Accuracy = 0.1914\n",
      "Iteration 269: Loss = 7.6187, Accuracy = 0.2200 Test Loss = 11.6593, Test Accuracy = 0.1908\n",
      "Iteration 270: Loss = 7.8483, Accuracy = 0.1700 Test Loss = 11.6223, Test Accuracy = 0.1918\n",
      "Iteration 271: Loss = 7.2083, Accuracy = 0.2200 Test Loss = 11.6056, Test Accuracy = 0.1928\n",
      "Iteration 272: Loss = 7.3035, Accuracy = 0.2200 Test Loss = 11.5596, Test Accuracy = 0.1902\n",
      "Iteration 273: Loss = 7.5136, Accuracy = 0.2500 Test Loss = 11.5555, Test Accuracy = 0.1928\n",
      "Iteration 274: Loss = 7.9540, Accuracy = 0.2000 Test Loss = 11.5244, Test Accuracy = 0.1918\n",
      "Iteration 275: Loss = 7.6006, Accuracy = 0.2300 Test Loss = 11.4992, Test Accuracy = 0.1920\n",
      "Iteration 276: Loss = 7.3884, Accuracy = 0.2400 Test Loss = 11.4692, Test Accuracy = 0.1914\n",
      "Iteration 277: Loss = 7.1063, Accuracy = 0.1700 Test Loss = 11.4723, Test Accuracy = 0.1921\n",
      "Iteration 278: Loss = 7.2404, Accuracy = 0.2300 Test Loss = 11.4110, Test Accuracy = 0.1929\n",
      "Iteration 279: Loss = 8.2286, Accuracy = 0.1300 Test Loss = 11.4112, Test Accuracy = 0.1923\n",
      "Iteration 280: Loss = 7.5317, Accuracy = 0.2700 Test Loss = 11.3614, Test Accuracy = 0.1923\n",
      "Iteration 281: Loss = 7.5252, Accuracy = 0.2100 Test Loss = 11.3463, Test Accuracy = 0.1922\n",
      "Iteration 282: Loss = 7.2313, Accuracy = 0.2900 Test Loss = 11.3159, Test Accuracy = 0.1941\n",
      "Iteration 283: Loss = 7.8973, Accuracy = 0.2200 Test Loss = 11.2939, Test Accuracy = 0.1942\n",
      "Iteration 284: Loss = 7.2692, Accuracy = 0.2400 Test Loss = 11.2781, Test Accuracy = 0.1941\n",
      "Iteration 285: Loss = 7.2481, Accuracy = 0.2100 Test Loss = 11.2551, Test Accuracy = 0.1955\n",
      "Iteration 286: Loss = 7.0760, Accuracy = 0.2200 Test Loss = 11.2280, Test Accuracy = 0.1928\n",
      "Iteration 287: Loss = 7.3948, Accuracy = 0.2000 Test Loss = 11.2058, Test Accuracy = 0.1936\n",
      "Iteration 288: Loss = 7.2363, Accuracy = 0.1600 Test Loss = 11.1964, Test Accuracy = 0.1931\n",
      "Iteration 289: Loss = 7.2672, Accuracy = 0.2000 Test Loss = 11.1597, Test Accuracy = 0.1947\n",
      "Iteration 290: Loss = 7.3269, Accuracy = 0.1800 Test Loss = 11.1359, Test Accuracy = 0.1944\n",
      "Iteration 291: Loss = 6.9570, Accuracy = 0.2300 Test Loss = 11.1038, Test Accuracy = 0.1959\n",
      "Iteration 292: Loss = 7.4151, Accuracy = 0.2200 Test Loss = 11.0814, Test Accuracy = 0.1949\n",
      "Iteration 293: Loss = 6.9844, Accuracy = 0.2200 Test Loss = 11.0704, Test Accuracy = 0.1952\n",
      "Iteration 294: Loss = 7.0231, Accuracy = 0.1700 Test Loss = 11.0410, Test Accuracy = 0.1956\n",
      "Iteration 295: Loss = 7.3810, Accuracy = 0.1900 Test Loss = 11.0169, Test Accuracy = 0.1932\n",
      "Iteration 296: Loss = 7.0122, Accuracy = 0.2200 Test Loss = 10.9966, Test Accuracy = 0.1952\n",
      "Iteration 297: Loss = 7.5178, Accuracy = 0.1900 Test Loss = 10.9854, Test Accuracy = 0.1946\n",
      "Iteration 298: Loss = 6.6048, Accuracy = 0.1900 Test Loss = 10.9457, Test Accuracy = 0.1959\n",
      "Iteration 299: Loss = 7.0298, Accuracy = 0.2500 Test Loss = 10.9447, Test Accuracy = 0.1946\n",
      "Iteration 300: Loss = 6.9708, Accuracy = 0.2000 Test Loss = 10.9257, Test Accuracy = 0.1934\n",
      "Iteration 301: Loss = 6.5865, Accuracy = 0.2300 Test Loss = 10.8874, Test Accuracy = 0.1960\n",
      "Iteration 302: Loss = 6.9065, Accuracy = 0.1900 Test Loss = 10.8564, Test Accuracy = 0.1960\n",
      "Iteration 303: Loss = 7.0160, Accuracy = 0.2200 Test Loss = 10.8379, Test Accuracy = 0.1953\n",
      "Iteration 304: Loss = 6.6747, Accuracy = 0.2900 Test Loss = 10.8144, Test Accuracy = 0.1965\n",
      "Iteration 305: Loss = 7.0890, Accuracy = 0.2200 Test Loss = 10.8042, Test Accuracy = 0.1958\n",
      "Iteration 306: Loss = 6.5569, Accuracy = 0.2200 Test Loss = 10.7940, Test Accuracy = 0.1962\n",
      "Iteration 307: Loss = 7.2220, Accuracy = 0.1900 Test Loss = 10.7639, Test Accuracy = 0.1972\n",
      "Iteration 308: Loss = 6.9021, Accuracy = 0.2300 Test Loss = 10.7448, Test Accuracy = 0.1972\n",
      "Iteration 309: Loss = 6.3483, Accuracy = 0.1700 Test Loss = 10.7063, Test Accuracy = 0.1975\n",
      "Iteration 310: Loss = 6.1071, Accuracy = 0.2700 Test Loss = 10.6952, Test Accuracy = 0.1968\n",
      "Iteration 311: Loss = 6.3931, Accuracy = 0.2500 Test Loss = 10.6770, Test Accuracy = 0.1954\n",
      "Iteration 312: Loss = 6.0737, Accuracy = 0.2500 Test Loss = 10.6459, Test Accuracy = 0.1962\n",
      "Iteration 313: Loss = 6.3109, Accuracy = 0.2600 Test Loss = 10.6282, Test Accuracy = 0.1979\n",
      "Iteration 314: Loss = 6.6692, Accuracy = 0.1800 Test Loss = 10.6132, Test Accuracy = 0.1954\n",
      "Iteration 315: Loss = 7.0953, Accuracy = 0.1500 Test Loss = 10.6035, Test Accuracy = 0.1965\n",
      "Iteration 316: Loss = 6.8914, Accuracy = 0.2200 Test Loss = 10.5851, Test Accuracy = 0.1973\n",
      "Iteration 317: Loss = 6.5509, Accuracy = 0.2000 Test Loss = 10.5469, Test Accuracy = 0.1967\n",
      "Iteration 318: Loss = 7.1522, Accuracy = 0.2200 Test Loss = 10.5279, Test Accuracy = 0.1973\n",
      "Iteration 319: Loss = 7.2037, Accuracy = 0.2400 Test Loss = 10.5163, Test Accuracy = 0.1965\n",
      "Iteration 320: Loss = 6.3478, Accuracy = 0.2500 Test Loss = 10.4876, Test Accuracy = 0.1982\n",
      "Iteration 321: Loss = 6.5126, Accuracy = 0.2300 Test Loss = 10.4709, Test Accuracy = 0.1970\n",
      "Iteration 322: Loss = 6.2547, Accuracy = 0.2500 Test Loss = 10.4486, Test Accuracy = 0.1983\n",
      "Iteration 323: Loss = 6.3214, Accuracy = 0.3000 Test Loss = 10.4307, Test Accuracy = 0.1987\n",
      "Iteration 324: Loss = 6.6096, Accuracy = 0.2400 Test Loss = 10.4140, Test Accuracy = 0.1975\n",
      "Iteration 325: Loss = 7.1644, Accuracy = 0.2000 Test Loss = 10.4108, Test Accuracy = 0.1959\n",
      "Iteration 326: Loss = 6.9441, Accuracy = 0.1600 Test Loss = 10.3848, Test Accuracy = 0.1962\n",
      "Iteration 327: Loss = 7.0464, Accuracy = 0.2100 Test Loss = 10.3531, Test Accuracy = 0.1977\n",
      "Iteration 328: Loss = 6.7908, Accuracy = 0.2700 Test Loss = 10.3473, Test Accuracy = 0.1978\n",
      "Iteration 329: Loss = 6.6780, Accuracy = 0.1600 Test Loss = 10.3198, Test Accuracy = 0.1996\n",
      "Iteration 330: Loss = 6.2006, Accuracy = 0.2000 Test Loss = 10.2930, Test Accuracy = 0.1990\n",
      "Iteration 331: Loss = 6.5468, Accuracy = 0.2500 Test Loss = 10.2665, Test Accuracy = 0.1986\n",
      "Iteration 332: Loss = 6.1760, Accuracy = 0.2300 Test Loss = 10.2500, Test Accuracy = 0.1996\n",
      "Iteration 333: Loss = 5.9020, Accuracy = 0.2200 Test Loss = 10.2334, Test Accuracy = 0.1994\n",
      "Iteration 334: Loss = 6.2121, Accuracy = 0.2100 Test Loss = 10.2212, Test Accuracy = 0.1988\n",
      "Iteration 335: Loss = 6.2508, Accuracy = 0.2400 Test Loss = 10.2104, Test Accuracy = 0.1991\n",
      "Iteration 336: Loss = 6.6168, Accuracy = 0.3100 Test Loss = 10.1724, Test Accuracy = 0.2002\n",
      "Iteration 337: Loss = 6.3260, Accuracy = 0.1600 Test Loss = 10.1577, Test Accuracy = 0.2007\n",
      "Iteration 338: Loss = 5.9680, Accuracy = 0.2900 Test Loss = 10.1356, Test Accuracy = 0.1984\n",
      "Iteration 339: Loss = 6.4880, Accuracy = 0.1800 Test Loss = 10.1247, Test Accuracy = 0.1992\n",
      "Iteration 340: Loss = 6.8115, Accuracy = 0.1800 Test Loss = 10.1073, Test Accuracy = 0.1984\n",
      "Iteration 341: Loss = 6.4354, Accuracy = 0.1500 Test Loss = 10.0751, Test Accuracy = 0.2008\n",
      "Iteration 342: Loss = 6.2162, Accuracy = 0.2900 Test Loss = 10.0805, Test Accuracy = 0.1992\n",
      "Iteration 343: Loss = 6.0320, Accuracy = 0.2800 Test Loss = 10.0539, Test Accuracy = 0.1979\n",
      "Iteration 344: Loss = 6.2577, Accuracy = 0.2000 Test Loss = 10.0383, Test Accuracy = 0.2013\n",
      "Iteration 345: Loss = 5.9516, Accuracy = 0.2900 Test Loss = 10.0201, Test Accuracy = 0.2016\n",
      "Iteration 346: Loss = 6.1824, Accuracy = 0.2400 Test Loss = 10.0069, Test Accuracy = 0.1993\n",
      "Iteration 347: Loss = 5.6281, Accuracy = 0.2500 Test Loss = 9.9842, Test Accuracy = 0.1988\n",
      "Iteration 348: Loss = 6.7614, Accuracy = 0.2000 Test Loss = 9.9472, Test Accuracy = 0.2006\n",
      "Iteration 349: Loss = 5.9849, Accuracy = 0.1900 Test Loss = 9.9376, Test Accuracy = 0.2010\n",
      "Iteration 350: Loss = 6.4081, Accuracy = 0.2300 Test Loss = 9.9336, Test Accuracy = 0.1995\n",
      "Iteration 351: Loss = 6.2769, Accuracy = 0.1800 Test Loss = 9.9008, Test Accuracy = 0.2002\n",
      "Iteration 352: Loss = 6.2863, Accuracy = 0.2100 Test Loss = 9.8834, Test Accuracy = 0.2000\n",
      "Iteration 353: Loss = 6.1134, Accuracy = 0.2500 Test Loss = 9.8700, Test Accuracy = 0.2020\n",
      "Iteration 354: Loss = 6.4751, Accuracy = 0.2300 Test Loss = 9.8635, Test Accuracy = 0.1994\n",
      "Iteration 355: Loss = 6.4954, Accuracy = 0.1800 Test Loss = 9.8358, Test Accuracy = 0.1996\n",
      "Iteration 356: Loss = 5.8939, Accuracy = 0.2100 Test Loss = 9.8110, Test Accuracy = 0.1993\n",
      "Iteration 357: Loss = 6.3087, Accuracy = 0.2200 Test Loss = 9.7959, Test Accuracy = 0.2009\n",
      "Iteration 358: Loss = 6.5876, Accuracy = 0.1700 Test Loss = 9.7771, Test Accuracy = 0.1994\n",
      "Iteration 359: Loss = 5.7702, Accuracy = 0.1900 Test Loss = 9.7728, Test Accuracy = 0.1993\n",
      "Iteration 360: Loss = 6.1960, Accuracy = 0.2200 Test Loss = 9.7498, Test Accuracy = 0.2004\n",
      "Iteration 361: Loss = 6.2235, Accuracy = 0.2300 Test Loss = 9.7405, Test Accuracy = 0.1972\n",
      "Iteration 362: Loss = 6.1350, Accuracy = 0.3300 Test Loss = 9.7160, Test Accuracy = 0.1993\n",
      "Iteration 363: Loss = 6.3423, Accuracy = 0.2600 Test Loss = 9.6965, Test Accuracy = 0.1996\n",
      "Iteration 364: Loss = 5.9224, Accuracy = 0.1900 Test Loss = 9.6870, Test Accuracy = 0.1995\n",
      "Iteration 365: Loss = 5.4716, Accuracy = 0.3100 Test Loss = 9.6658, Test Accuracy = 0.1993\n",
      "Iteration 366: Loss = 5.6805, Accuracy = 0.1700 Test Loss = 9.6545, Test Accuracy = 0.2031\n",
      "Iteration 367: Loss = 6.3069, Accuracy = 0.1800 Test Loss = 9.6336, Test Accuracy = 0.2014\n",
      "Iteration 368: Loss = 5.6438, Accuracy = 0.2800 Test Loss = 9.6111, Test Accuracy = 0.2005\n",
      "Iteration 369: Loss = 6.6597, Accuracy = 0.2300 Test Loss = 9.5968, Test Accuracy = 0.2029\n",
      "Iteration 370: Loss = 5.9916, Accuracy = 0.2500 Test Loss = 9.5855, Test Accuracy = 0.1990\n",
      "Iteration 371: Loss = 5.8620, Accuracy = 0.2300 Test Loss = 9.5613, Test Accuracy = 0.2011\n",
      "Iteration 372: Loss = 5.5567, Accuracy = 0.2000 Test Loss = 9.5556, Test Accuracy = 0.2020\n",
      "Iteration 373: Loss = 6.1108, Accuracy = 0.2200 Test Loss = 9.5485, Test Accuracy = 0.1995\n",
      "Iteration 374: Loss = 5.1875, Accuracy = 0.2700 Test Loss = 9.5259, Test Accuracy = 0.2019\n",
      "Iteration 375: Loss = 5.3593, Accuracy = 0.2400 Test Loss = 9.5103, Test Accuracy = 0.2016\n",
      "Iteration 376: Loss = 5.3750, Accuracy = 0.2300 Test Loss = 9.4974, Test Accuracy = 0.2045\n",
      "Iteration 377: Loss = 5.4326, Accuracy = 0.2700 Test Loss = 9.4700, Test Accuracy = 0.2013\n",
      "Iteration 378: Loss = 5.2633, Accuracy = 0.2600 Test Loss = 9.4581, Test Accuracy = 0.2006\n",
      "Iteration 379: Loss = 5.3822, Accuracy = 0.2300 Test Loss = 9.4459, Test Accuracy = 0.2016\n",
      "Iteration 380: Loss = 5.6390, Accuracy = 0.2500 Test Loss = 9.4283, Test Accuracy = 0.2011\n",
      "Iteration 381: Loss = 5.6564, Accuracy = 0.2400 Test Loss = 9.4036, Test Accuracy = 0.2016\n",
      "Iteration 382: Loss = 5.6789, Accuracy = 0.2000 Test Loss = 9.3944, Test Accuracy = 0.2017\n",
      "Iteration 383: Loss = 5.4602, Accuracy = 0.2200 Test Loss = 9.3770, Test Accuracy = 0.2036\n",
      "Iteration 384: Loss = 5.6107, Accuracy = 0.1900 Test Loss = 9.3660, Test Accuracy = 0.2036\n",
      "Iteration 385: Loss = 5.2739, Accuracy = 0.2600 Test Loss = 9.3549, Test Accuracy = 0.2017\n",
      "Iteration 386: Loss = 5.3854, Accuracy = 0.2400 Test Loss = 9.3298, Test Accuracy = 0.2017\n",
      "Iteration 387: Loss = 5.8072, Accuracy = 0.2400 Test Loss = 9.3408, Test Accuracy = 0.2033\n",
      "Iteration 388: Loss = 5.4460, Accuracy = 0.2100 Test Loss = 9.2963, Test Accuracy = 0.2008\n",
      "Iteration 389: Loss = 6.2561, Accuracy = 0.2000 Test Loss = 9.2903, Test Accuracy = 0.2024\n",
      "Iteration 390: Loss = 5.3260, Accuracy = 0.2200 Test Loss = 9.2732, Test Accuracy = 0.2017\n",
      "Iteration 391: Loss = 5.4481, Accuracy = 0.2700 Test Loss = 9.2555, Test Accuracy = 0.2037\n",
      "Iteration 392: Loss = 5.7810, Accuracy = 0.1600 Test Loss = 9.2449, Test Accuracy = 0.2012\n",
      "Iteration 393: Loss = 5.3907, Accuracy = 0.2500 Test Loss = 9.2402, Test Accuracy = 0.2027\n",
      "Iteration 394: Loss = 5.3233, Accuracy = 0.2700 Test Loss = 9.2107, Test Accuracy = 0.2052\n",
      "Iteration 395: Loss = 5.1680, Accuracy = 0.2500 Test Loss = 9.2040, Test Accuracy = 0.2024\n",
      "Iteration 396: Loss = 5.4079, Accuracy = 0.2600 Test Loss = 9.1783, Test Accuracy = 0.2015\n",
      "Iteration 397: Loss = 5.4515, Accuracy = 0.2500 Test Loss = 9.1704, Test Accuracy = 0.2041\n",
      "Iteration 398: Loss = 5.7776, Accuracy = 0.2000 Test Loss = 9.1622, Test Accuracy = 0.2050\n",
      "Iteration 399: Loss = 5.8266, Accuracy = 0.1900 Test Loss = 9.1409, Test Accuracy = 0.2052\n",
      "Iteration 400: Loss = 5.7836, Accuracy = 0.2400 Test Loss = 9.1257, Test Accuracy = 0.2022\n",
      "Iteration 401: Loss = 5.8626, Accuracy = 0.2600 Test Loss = 9.1029, Test Accuracy = 0.2026\n",
      "Iteration 402: Loss = 6.1882, Accuracy = 0.3200 Test Loss = 9.0862, Test Accuracy = 0.2040\n",
      "Iteration 403: Loss = 5.4555, Accuracy = 0.2300 Test Loss = 9.0840, Test Accuracy = 0.2051\n",
      "Iteration 404: Loss = 5.6536, Accuracy = 0.2500 Test Loss = 9.0664, Test Accuracy = 0.2036\n",
      "Iteration 405: Loss = 5.3639, Accuracy = 0.2300 Test Loss = 9.0489, Test Accuracy = 0.2026\n",
      "Iteration 406: Loss = 5.0284, Accuracy = 0.2300 Test Loss = 9.0340, Test Accuracy = 0.2044\n",
      "Iteration 407: Loss = 5.2178, Accuracy = 0.1800 Test Loss = 9.0193, Test Accuracy = 0.2037\n",
      "Iteration 408: Loss = 5.5441, Accuracy = 0.2700 Test Loss = 9.0134, Test Accuracy = 0.2043\n",
      "Iteration 409: Loss = 5.0222, Accuracy = 0.2600 Test Loss = 9.0114, Test Accuracy = 0.2053\n",
      "Iteration 410: Loss = 5.2100, Accuracy = 0.2900 Test Loss = 8.9749, Test Accuracy = 0.2054\n",
      "Iteration 411: Loss = 5.3407, Accuracy = 0.2900 Test Loss = 8.9709, Test Accuracy = 0.2012\n",
      "Iteration 412: Loss = 5.5054, Accuracy = 0.2500 Test Loss = 8.9558, Test Accuracy = 0.2044\n",
      "Iteration 413: Loss = 5.8075, Accuracy = 0.2400 Test Loss = 8.9371, Test Accuracy = 0.2044\n",
      "Iteration 414: Loss = 5.3306, Accuracy = 0.2200 Test Loss = 8.9247, Test Accuracy = 0.2051\n",
      "Iteration 415: Loss = 4.7942, Accuracy = 0.2800 Test Loss = 8.9118, Test Accuracy = 0.2042\n",
      "Iteration 416: Loss = 4.8692, Accuracy = 0.2700 Test Loss = 8.8937, Test Accuracy = 0.2048\n",
      "Iteration 417: Loss = 5.4127, Accuracy = 0.2100 Test Loss = 8.8870, Test Accuracy = 0.2058\n",
      "Iteration 418: Loss = 5.5738, Accuracy = 0.2100 Test Loss = 8.8717, Test Accuracy = 0.2029\n",
      "Iteration 419: Loss = 5.3886, Accuracy = 0.2300 Test Loss = 8.8609, Test Accuracy = 0.2063\n",
      "Iteration 420: Loss = 5.1101, Accuracy = 0.2200 Test Loss = 8.8469, Test Accuracy = 0.2061\n",
      "Iteration 421: Loss = 5.3419, Accuracy = 0.2100 Test Loss = 8.8304, Test Accuracy = 0.2052\n",
      "Iteration 422: Loss = 5.4404, Accuracy = 0.2700 Test Loss = 8.8210, Test Accuracy = 0.2034\n",
      "Iteration 423: Loss = 5.2082, Accuracy = 0.2100 Test Loss = 8.8180, Test Accuracy = 0.2040\n",
      "Iteration 424: Loss = 5.0930, Accuracy = 0.2600 Test Loss = 8.7968, Test Accuracy = 0.2072\n",
      "Iteration 425: Loss = 5.2465, Accuracy = 0.2300 Test Loss = 8.7754, Test Accuracy = 0.2049\n",
      "Iteration 426: Loss = 5.1005, Accuracy = 0.2700 Test Loss = 8.7655, Test Accuracy = 0.2054\n",
      "Iteration 427: Loss = 5.2573, Accuracy = 0.2300 Test Loss = 8.7628, Test Accuracy = 0.2078\n",
      "Iteration 428: Loss = 5.5675, Accuracy = 0.2500 Test Loss = 8.7332, Test Accuracy = 0.2073\n",
      "Iteration 429: Loss = 5.1003, Accuracy = 0.2200 Test Loss = 8.7283, Test Accuracy = 0.2050\n",
      "Iteration 430: Loss = 5.4962, Accuracy = 0.2000 Test Loss = 8.7099, Test Accuracy = 0.2049\n",
      "Iteration 431: Loss = 4.6166, Accuracy = 0.2700 Test Loss = 8.7015, Test Accuracy = 0.2079\n",
      "Iteration 432: Loss = 5.2707, Accuracy = 0.2500 Test Loss = 8.6828, Test Accuracy = 0.2061\n",
      "Iteration 433: Loss = 5.2929, Accuracy = 0.2500 Test Loss = 8.6793, Test Accuracy = 0.2079\n",
      "Iteration 434: Loss = 5.2020, Accuracy = 0.2600 Test Loss = 8.6604, Test Accuracy = 0.2065\n",
      "Iteration 435: Loss = 4.9430, Accuracy = 0.1900 Test Loss = 8.6473, Test Accuracy = 0.2068\n",
      "Iteration 436: Loss = 5.3743, Accuracy = 0.1800 Test Loss = 8.6402, Test Accuracy = 0.2083\n",
      "Iteration 437: Loss = 5.3960, Accuracy = 0.2500 Test Loss = 8.6195, Test Accuracy = 0.2068\n",
      "Iteration 438: Loss = 5.1197, Accuracy = 0.2300 Test Loss = 8.6066, Test Accuracy = 0.2063\n",
      "Iteration 439: Loss = 5.2804, Accuracy = 0.1900 Test Loss = 8.5892, Test Accuracy = 0.2072\n",
      "Iteration 440: Loss = 4.9190, Accuracy = 0.2600 Test Loss = 8.5778, Test Accuracy = 0.2086\n",
      "Iteration 441: Loss = 4.9885, Accuracy = 0.2600 Test Loss = 8.5639, Test Accuracy = 0.2060\n",
      "Iteration 442: Loss = 5.5337, Accuracy = 0.2900 Test Loss = 8.5773, Test Accuracy = 0.2097\n",
      "Iteration 443: Loss = 5.0312, Accuracy = 0.2000 Test Loss = 8.5418, Test Accuracy = 0.2078\n",
      "Iteration 444: Loss = 5.1721, Accuracy = 0.2800 Test Loss = 8.5456, Test Accuracy = 0.2083\n",
      "Iteration 445: Loss = 4.9928, Accuracy = 0.2500 Test Loss = 8.5289, Test Accuracy = 0.2080\n",
      "Iteration 446: Loss = 4.9294, Accuracy = 0.2100 Test Loss = 8.5194, Test Accuracy = 0.2086\n",
      "Iteration 447: Loss = 4.6816, Accuracy = 0.2900 Test Loss = 8.5054, Test Accuracy = 0.2066\n",
      "Iteration 448: Loss = 4.6633, Accuracy = 0.3700 Test Loss = 8.4776, Test Accuracy = 0.2069\n",
      "Iteration 449: Loss = 4.9293, Accuracy = 0.1800 Test Loss = 8.4641, Test Accuracy = 0.2095\n",
      "Iteration 450: Loss = 4.3815, Accuracy = 0.2800 Test Loss = 8.4583, Test Accuracy = 0.2089\n",
      "Iteration 451: Loss = 4.6347, Accuracy = 0.2900 Test Loss = 8.4486, Test Accuracy = 0.2087\n",
      "Iteration 452: Loss = 4.8549, Accuracy = 0.2000 Test Loss = 8.4299, Test Accuracy = 0.2081\n",
      "Iteration 453: Loss = 4.9742, Accuracy = 0.3000 Test Loss = 8.4314, Test Accuracy = 0.2084\n",
      "Iteration 454: Loss = 4.6083, Accuracy = 0.2800 Test Loss = 8.4112, Test Accuracy = 0.2086\n",
      "Iteration 455: Loss = 4.6434, Accuracy = 0.2500 Test Loss = 8.4063, Test Accuracy = 0.2080\n",
      "Iteration 456: Loss = 5.0475, Accuracy = 0.2600 Test Loss = 8.3930, Test Accuracy = 0.2091\n",
      "Iteration 457: Loss = 4.8335, Accuracy = 0.2900 Test Loss = 8.3736, Test Accuracy = 0.2083\n",
      "Iteration 458: Loss = 4.4737, Accuracy = 0.2600 Test Loss = 8.3709, Test Accuracy = 0.2084\n",
      "Iteration 459: Loss = 4.8551, Accuracy = 0.3000 Test Loss = 8.3490, Test Accuracy = 0.2077\n",
      "Iteration 460: Loss = 4.8826, Accuracy = 0.2700 Test Loss = 8.3311, Test Accuracy = 0.2086\n",
      "Iteration 461: Loss = 4.6973, Accuracy = 0.3300 Test Loss = 8.3418, Test Accuracy = 0.2089\n",
      "Iteration 462: Loss = 4.7109, Accuracy = 0.2500 Test Loss = 8.3155, Test Accuracy = 0.2124\n",
      "Iteration 463: Loss = 4.9963, Accuracy = 0.2100 Test Loss = 8.3102, Test Accuracy = 0.2117\n",
      "Iteration 464: Loss = 4.7689, Accuracy = 0.1800 Test Loss = 8.2877, Test Accuracy = 0.2112\n",
      "Iteration 465: Loss = 4.7310, Accuracy = 0.2400 Test Loss = 8.2853, Test Accuracy = 0.2096\n",
      "Iteration 466: Loss = 4.9943, Accuracy = 0.2200 Test Loss = 8.2675, Test Accuracy = 0.2114\n",
      "Iteration 467: Loss = 5.0732, Accuracy = 0.2000 Test Loss = 8.2681, Test Accuracy = 0.2109\n",
      "Iteration 468: Loss = 4.9399, Accuracy = 0.2300 Test Loss = 8.2403, Test Accuracy = 0.2100\n",
      "Iteration 469: Loss = 4.8969, Accuracy = 0.2200 Test Loss = 8.2299, Test Accuracy = 0.2097\n",
      "Iteration 470: Loss = 4.9999, Accuracy = 0.3100 Test Loss = 8.2167, Test Accuracy = 0.2104\n",
      "Iteration 471: Loss = 4.3172, Accuracy = 0.2400 Test Loss = 8.2142, Test Accuracy = 0.2114\n",
      "Iteration 472: Loss = 5.0410, Accuracy = 0.1500 Test Loss = 8.1926, Test Accuracy = 0.2100\n",
      "Iteration 473: Loss = 5.0819, Accuracy = 0.2400 Test Loss = 8.1894, Test Accuracy = 0.2100\n",
      "Iteration 474: Loss = 4.9876, Accuracy = 0.2200 Test Loss = 8.1776, Test Accuracy = 0.2102\n",
      "Iteration 475: Loss = 4.7009, Accuracy = 0.2000 Test Loss = 8.1643, Test Accuracy = 0.2116\n",
      "Iteration 476: Loss = 5.0204, Accuracy = 0.2100 Test Loss = 8.1593, Test Accuracy = 0.2117\n",
      "Iteration 477: Loss = 4.6315, Accuracy = 0.2500 Test Loss = 8.1365, Test Accuracy = 0.2119\n",
      "Iteration 478: Loss = 4.8218, Accuracy = 0.2700 Test Loss = 8.1248, Test Accuracy = 0.2101\n",
      "Iteration 479: Loss = 4.6960, Accuracy = 0.2500 Test Loss = 8.1148, Test Accuracy = 0.2113\n",
      "Iteration 480: Loss = 4.4082, Accuracy = 0.3000 Test Loss = 8.1044, Test Accuracy = 0.2109\n",
      "Iteration 481: Loss = 4.5853, Accuracy = 0.2800 Test Loss = 8.1007, Test Accuracy = 0.2124\n",
      "Iteration 482: Loss = 4.5292, Accuracy = 0.3200 Test Loss = 8.0854, Test Accuracy = 0.2106\n",
      "Iteration 483: Loss = 4.5032, Accuracy = 0.2800 Test Loss = 8.0740, Test Accuracy = 0.2129\n",
      "Iteration 484: Loss = 4.6476, Accuracy = 0.3000 Test Loss = 8.0763, Test Accuracy = 0.2110\n",
      "Iteration 485: Loss = 4.5361, Accuracy = 0.1700 Test Loss = 8.0587, Test Accuracy = 0.2119\n",
      "Iteration 486: Loss = 4.5112, Accuracy = 0.2500 Test Loss = 8.0482, Test Accuracy = 0.2131\n",
      "Iteration 487: Loss = 4.6513, Accuracy = 0.3300 Test Loss = 8.0302, Test Accuracy = 0.2116\n",
      "Iteration 488: Loss = 4.6569, Accuracy = 0.3200 Test Loss = 8.0200, Test Accuracy = 0.2098\n",
      "Iteration 489: Loss = 4.5906, Accuracy = 0.2200 Test Loss = 8.0161, Test Accuracy = 0.2110\n",
      "Iteration 490: Loss = 4.9033, Accuracy = 0.2600 Test Loss = 7.9988, Test Accuracy = 0.2132\n",
      "Iteration 491: Loss = 4.8179, Accuracy = 0.1800 Test Loss = 7.9841, Test Accuracy = 0.2132\n",
      "Iteration 492: Loss = 4.9273, Accuracy = 0.2800 Test Loss = 7.9740, Test Accuracy = 0.2136\n",
      "Iteration 493: Loss = 4.8614, Accuracy = 0.2700 Test Loss = 7.9635, Test Accuracy = 0.2137\n",
      "Iteration 494: Loss = 4.8990, Accuracy = 0.3100 Test Loss = 7.9536, Test Accuracy = 0.2125\n",
      "Iteration 495: Loss = 4.5154, Accuracy = 0.2800 Test Loss = 7.9479, Test Accuracy = 0.2125\n",
      "Iteration 496: Loss = 4.4626, Accuracy = 0.2700 Test Loss = 7.9322, Test Accuracy = 0.2132\n",
      "Iteration 497: Loss = 4.4999, Accuracy = 0.3500 Test Loss = 7.9270, Test Accuracy = 0.2136\n",
      "Iteration 498: Loss = 4.8161, Accuracy = 0.2200 Test Loss = 7.9118, Test Accuracy = 0.2142\n",
      "Iteration 499: Loss = 4.2713, Accuracy = 0.2600 Test Loss = 7.9149, Test Accuracy = 0.2141\n",
      "Iteration 500: Loss = 4.3734, Accuracy = 0.2600 Test Loss = 7.8983, Test Accuracy = 0.2135\n",
      "Iteration 501: Loss = 4.3164, Accuracy = 0.2700 Test Loss = 7.8881, Test Accuracy = 0.2141\n",
      "Iteration 502: Loss = 4.3591, Accuracy = 0.2200 Test Loss = 7.8728, Test Accuracy = 0.2153\n",
      "Iteration 503: Loss = 4.3426, Accuracy = 0.2700 Test Loss = 7.8647, Test Accuracy = 0.2136\n",
      "Iteration 504: Loss = 4.5543, Accuracy = 0.2700 Test Loss = 7.8703, Test Accuracy = 0.2139\n",
      "Iteration 505: Loss = 4.6538, Accuracy = 0.1800 Test Loss = 7.8403, Test Accuracy = 0.2145\n",
      "Iteration 506: Loss = 4.0157, Accuracy = 0.2800 Test Loss = 7.8306, Test Accuracy = 0.2142\n",
      "Iteration 507: Loss = 4.4434, Accuracy = 0.2300 Test Loss = 7.8320, Test Accuracy = 0.2150\n",
      "Iteration 508: Loss = 4.4788, Accuracy = 0.2600 Test Loss = 7.8033, Test Accuracy = 0.2138\n",
      "Iteration 509: Loss = 4.7771, Accuracy = 0.2700 Test Loss = 7.7973, Test Accuracy = 0.2144\n",
      "Iteration 510: Loss = 4.5775, Accuracy = 0.3300 Test Loss = 7.7862, Test Accuracy = 0.2145\n",
      "Iteration 511: Loss = 4.0762, Accuracy = 0.3500 Test Loss = 7.7884, Test Accuracy = 0.2139\n",
      "Iteration 512: Loss = 4.3862, Accuracy = 0.2900 Test Loss = 7.7639, Test Accuracy = 0.2150\n",
      "Iteration 513: Loss = 3.9969, Accuracy = 0.3300 Test Loss = 7.7519, Test Accuracy = 0.2151\n",
      "Iteration 514: Loss = 4.4563, Accuracy = 0.2600 Test Loss = 7.7474, Test Accuracy = 0.2159\n",
      "Iteration 515: Loss = 4.3300, Accuracy = 0.3200 Test Loss = 7.7407, Test Accuracy = 0.2164\n",
      "Iteration 516: Loss = 4.5129, Accuracy = 0.2600 Test Loss = 7.7280, Test Accuracy = 0.2153\n",
      "Iteration 517: Loss = 4.4250, Accuracy = 0.2300 Test Loss = 7.7225, Test Accuracy = 0.2161\n",
      "Iteration 518: Loss = 4.4208, Accuracy = 0.2400 Test Loss = 7.7030, Test Accuracy = 0.2158\n",
      "Iteration 519: Loss = 4.5796, Accuracy = 0.2000 Test Loss = 7.6966, Test Accuracy = 0.2171\n",
      "Iteration 520: Loss = 4.5021, Accuracy = 0.2500 Test Loss = 7.7016, Test Accuracy = 0.2160\n",
      "Iteration 521: Loss = 4.7324, Accuracy = 0.2600 Test Loss = 7.6933, Test Accuracy = 0.2153\n",
      "Iteration 522: Loss = 4.4280, Accuracy = 0.1400 Test Loss = 7.6689, Test Accuracy = 0.2163\n",
      "Iteration 523: Loss = 4.4170, Accuracy = 0.3200 Test Loss = 7.6716, Test Accuracy = 0.2162\n",
      "Iteration 524: Loss = 3.9932, Accuracy = 0.2100 Test Loss = 7.6480, Test Accuracy = 0.2161\n",
      "Iteration 525: Loss = 4.0262, Accuracy = 0.2200 Test Loss = 7.6401, Test Accuracy = 0.2185\n",
      "Iteration 526: Loss = 4.3810, Accuracy = 0.2300 Test Loss = 7.6284, Test Accuracy = 0.2151\n",
      "Iteration 527: Loss = 4.0847, Accuracy = 0.3000 Test Loss = 7.6204, Test Accuracy = 0.2190\n",
      "Iteration 528: Loss = 4.4405, Accuracy = 0.1700 Test Loss = 7.6246, Test Accuracy = 0.2147\n",
      "Iteration 529: Loss = 4.5005, Accuracy = 0.2500 Test Loss = 7.5945, Test Accuracy = 0.2173\n",
      "Iteration 530: Loss = 4.3941, Accuracy = 0.3500 Test Loss = 7.5839, Test Accuracy = 0.2166\n",
      "Iteration 531: Loss = 4.4798, Accuracy = 0.2200 Test Loss = 7.5796, Test Accuracy = 0.2157\n",
      "Iteration 532: Loss = 4.2822, Accuracy = 0.3200 Test Loss = 7.5782, Test Accuracy = 0.2185\n",
      "Iteration 533: Loss = 4.2808, Accuracy = 0.2700 Test Loss = 7.5632, Test Accuracy = 0.2167\n",
      "Iteration 534: Loss = 4.1373, Accuracy = 0.2800 Test Loss = 7.5572, Test Accuracy = 0.2170\n",
      "Iteration 535: Loss = 4.0766, Accuracy = 0.2400 Test Loss = 7.5402, Test Accuracy = 0.2174\n",
      "Iteration 536: Loss = 4.0739, Accuracy = 0.2500 Test Loss = 7.5364, Test Accuracy = 0.2189\n",
      "Iteration 537: Loss = 4.4181, Accuracy = 0.2100 Test Loss = 7.5328, Test Accuracy = 0.2162\n",
      "Iteration 538: Loss = 4.1291, Accuracy = 0.2200 Test Loss = 7.5207, Test Accuracy = 0.2173\n",
      "Iteration 539: Loss = 3.9237, Accuracy = 0.2200 Test Loss = 7.5048, Test Accuracy = 0.2183\n",
      "Iteration 540: Loss = 4.1813, Accuracy = 0.2900 Test Loss = 7.4898, Test Accuracy = 0.2174\n",
      "Iteration 541: Loss = 4.3078, Accuracy = 0.2000 Test Loss = 7.4814, Test Accuracy = 0.2187\n",
      "Iteration 542: Loss = 4.0534, Accuracy = 0.2900 Test Loss = 7.4914, Test Accuracy = 0.2189\n",
      "Iteration 543: Loss = 4.3388, Accuracy = 0.2600 Test Loss = 7.4706, Test Accuracy = 0.2177\n",
      "Iteration 544: Loss = 4.5895, Accuracy = 0.3200 Test Loss = 7.4709, Test Accuracy = 0.2194\n",
      "Iteration 545: Loss = 4.0899, Accuracy = 0.2800 Test Loss = 7.4484, Test Accuracy = 0.2184\n",
      "Iteration 546: Loss = 4.7481, Accuracy = 0.2100 Test Loss = 7.4417, Test Accuracy = 0.2201\n",
      "Iteration 547: Loss = 4.0493, Accuracy = 0.2500 Test Loss = 7.4289, Test Accuracy = 0.2170\n",
      "Iteration 548: Loss = 4.1664, Accuracy = 0.2200 Test Loss = 7.4247, Test Accuracy = 0.2194\n",
      "Iteration 549: Loss = 3.8578, Accuracy = 0.3100 Test Loss = 7.4080, Test Accuracy = 0.2177\n",
      "Iteration 550: Loss = 4.4992, Accuracy = 0.1900 Test Loss = 7.4065, Test Accuracy = 0.2177\n",
      "Iteration 551: Loss = 4.0213, Accuracy = 0.2900 Test Loss = 7.3934, Test Accuracy = 0.2182\n",
      "Iteration 552: Loss = 4.3291, Accuracy = 0.3000 Test Loss = 7.3853, Test Accuracy = 0.2207\n",
      "Iteration 553: Loss = 4.0609, Accuracy = 0.2800 Test Loss = 7.3694, Test Accuracy = 0.2184\n",
      "Iteration 554: Loss = 3.8877, Accuracy = 0.2400 Test Loss = 7.3717, Test Accuracy = 0.2189\n",
      "Iteration 555: Loss = 3.8648, Accuracy = 0.2900 Test Loss = 7.3627, Test Accuracy = 0.2192\n",
      "Iteration 556: Loss = 3.8180, Accuracy = 0.3100 Test Loss = 7.3476, Test Accuracy = 0.2191\n",
      "Iteration 557: Loss = 4.4275, Accuracy = 0.2100 Test Loss = 7.3587, Test Accuracy = 0.2213\n",
      "Iteration 558: Loss = 4.1589, Accuracy = 0.2000 Test Loss = 7.3306, Test Accuracy = 0.2191\n",
      "Iteration 559: Loss = 4.3887, Accuracy = 0.1900 Test Loss = 7.3253, Test Accuracy = 0.2182\n",
      "Iteration 560: Loss = 4.2206, Accuracy = 0.3500 Test Loss = 7.3164, Test Accuracy = 0.2196\n",
      "Iteration 561: Loss = 3.8858, Accuracy = 0.2500 Test Loss = 7.3068, Test Accuracy = 0.2220\n",
      "Iteration 562: Loss = 3.8693, Accuracy = 0.3200 Test Loss = 7.3104, Test Accuracy = 0.2195\n",
      "Iteration 563: Loss = 4.0394, Accuracy = 0.2800 Test Loss = 7.2930, Test Accuracy = 0.2194\n",
      "Iteration 564: Loss = 3.9129, Accuracy = 0.1900 Test Loss = 7.2822, Test Accuracy = 0.2189\n",
      "Iteration 565: Loss = 3.9636, Accuracy = 0.3000 Test Loss = 7.2734, Test Accuracy = 0.2227\n",
      "Iteration 566: Loss = 3.9368, Accuracy = 0.2300 Test Loss = 7.2699, Test Accuracy = 0.2224\n",
      "Iteration 567: Loss = 4.0187, Accuracy = 0.2800 Test Loss = 7.2548, Test Accuracy = 0.2221\n",
      "Iteration 568: Loss = 3.9667, Accuracy = 0.2600 Test Loss = 7.2439, Test Accuracy = 0.2202\n",
      "Iteration 569: Loss = 4.1806, Accuracy = 0.2700 Test Loss = 7.2382, Test Accuracy = 0.2219\n",
      "Iteration 570: Loss = 4.2328, Accuracy = 0.2800 Test Loss = 7.2264, Test Accuracy = 0.2222\n",
      "Iteration 571: Loss = 3.9698, Accuracy = 0.1800 Test Loss = 7.2408, Test Accuracy = 0.2242\n",
      "Iteration 572: Loss = 3.8665, Accuracy = 0.3300 Test Loss = 7.2098, Test Accuracy = 0.2197\n",
      "Iteration 573: Loss = 3.7568, Accuracy = 0.3000 Test Loss = 7.2088, Test Accuracy = 0.2223\n",
      "Iteration 574: Loss = 3.9389, Accuracy = 0.2400 Test Loss = 7.1971, Test Accuracy = 0.2204\n",
      "Iteration 575: Loss = 4.0551, Accuracy = 0.2300 Test Loss = 7.1850, Test Accuracy = 0.2215\n",
      "Iteration 576: Loss = 3.8597, Accuracy = 0.2500 Test Loss = 7.1805, Test Accuracy = 0.2231\n",
      "Iteration 577: Loss = 3.8224, Accuracy = 0.1800 Test Loss = 7.1706, Test Accuracy = 0.2241\n",
      "Iteration 578: Loss = 4.1564, Accuracy = 0.3200 Test Loss = 7.1655, Test Accuracy = 0.2212\n",
      "Iteration 579: Loss = 3.6664, Accuracy = 0.2400 Test Loss = 7.1468, Test Accuracy = 0.2233\n",
      "Iteration 580: Loss = 3.9341, Accuracy = 0.2400 Test Loss = 7.1453, Test Accuracy = 0.2209\n",
      "Iteration 581: Loss = 4.2189, Accuracy = 0.2500 Test Loss = 7.1334, Test Accuracy = 0.2223\n",
      "Iteration 582: Loss = 4.1680, Accuracy = 0.3000 Test Loss = 7.1275, Test Accuracy = 0.2223\n",
      "Iteration 583: Loss = 3.9402, Accuracy = 0.2900 Test Loss = 7.1152, Test Accuracy = 0.2242\n",
      "Iteration 584: Loss = 4.1962, Accuracy = 0.2800 Test Loss = 7.1077, Test Accuracy = 0.2240\n",
      "Iteration 585: Loss = 3.9975, Accuracy = 0.2000 Test Loss = 7.1059, Test Accuracy = 0.2248\n",
      "Iteration 586: Loss = 3.8346, Accuracy = 0.2100 Test Loss = 7.0965, Test Accuracy = 0.2219\n",
      "Iteration 587: Loss = 3.5125, Accuracy = 0.2800 Test Loss = 7.0955, Test Accuracy = 0.2228\n",
      "Iteration 588: Loss = 4.0452, Accuracy = 0.2200 Test Loss = 7.0712, Test Accuracy = 0.2232\n",
      "Iteration 589: Loss = 3.7538, Accuracy = 0.2800 Test Loss = 7.0702, Test Accuracy = 0.2223\n",
      "Iteration 590: Loss = 4.0975, Accuracy = 0.2700 Test Loss = 7.0667, Test Accuracy = 0.2234\n",
      "Iteration 591: Loss = 3.8692, Accuracy = 0.3300 Test Loss = 7.0485, Test Accuracy = 0.2236\n",
      "Iteration 592: Loss = 3.7067, Accuracy = 0.2500 Test Loss = 7.0407, Test Accuracy = 0.2243\n",
      "Iteration 593: Loss = 3.8947, Accuracy = 0.2800 Test Loss = 7.0329, Test Accuracy = 0.2232\n",
      "Iteration 594: Loss = 4.2118, Accuracy = 0.2600 Test Loss = 7.0284, Test Accuracy = 0.2242\n",
      "Iteration 595: Loss = 3.9059, Accuracy = 0.3100 Test Loss = 7.0284, Test Accuracy = 0.2265\n",
      "Iteration 596: Loss = 3.7172, Accuracy = 0.2700 Test Loss = 7.0106, Test Accuracy = 0.2240\n",
      "Iteration 597: Loss = 3.7246, Accuracy = 0.2500 Test Loss = 7.0098, Test Accuracy = 0.2253\n",
      "Iteration 598: Loss = 3.8951, Accuracy = 0.2700 Test Loss = 6.9942, Test Accuracy = 0.2236\n",
      "Iteration 599: Loss = 3.7686, Accuracy = 0.2900 Test Loss = 6.9860, Test Accuracy = 0.2250\n",
      "Iteration 600: Loss = 3.8358, Accuracy = 0.2800 Test Loss = 6.9815, Test Accuracy = 0.2258\n",
      "Iteration 601: Loss = 3.7687, Accuracy = 0.2900 Test Loss = 6.9708, Test Accuracy = 0.2243\n",
      "Iteration 602: Loss = 3.6922, Accuracy = 0.2500 Test Loss = 6.9601, Test Accuracy = 0.2255\n",
      "Iteration 603: Loss = 4.1689, Accuracy = 0.2900 Test Loss = 6.9551, Test Accuracy = 0.2269\n",
      "Iteration 604: Loss = 3.5618, Accuracy = 0.3400 Test Loss = 6.9442, Test Accuracy = 0.2275\n",
      "Iteration 605: Loss = 3.9639, Accuracy = 0.2100 Test Loss = 6.9359, Test Accuracy = 0.2269\n",
      "Iteration 606: Loss = 3.8657, Accuracy = 0.3100 Test Loss = 6.9358, Test Accuracy = 0.2247\n",
      "Iteration 607: Loss = 3.8046, Accuracy = 0.2600 Test Loss = 6.9299, Test Accuracy = 0.2261\n",
      "Iteration 608: Loss = 3.8154, Accuracy = 0.3400 Test Loss = 6.9176, Test Accuracy = 0.2255\n",
      "Iteration 609: Loss = 3.6469, Accuracy = 0.2700 Test Loss = 6.9112, Test Accuracy = 0.2251\n",
      "Iteration 610: Loss = 3.9806, Accuracy = 0.2800 Test Loss = 6.9045, Test Accuracy = 0.2271\n",
      "Iteration 611: Loss = 4.0085, Accuracy = 0.2600 Test Loss = 6.8942, Test Accuracy = 0.2257\n",
      "Iteration 612: Loss = 3.5789, Accuracy = 0.3000 Test Loss = 6.8818, Test Accuracy = 0.2266\n",
      "Iteration 613: Loss = 3.3998, Accuracy = 0.2500 Test Loss = 6.8786, Test Accuracy = 0.2271\n",
      "Iteration 614: Loss = 3.7349, Accuracy = 0.2000 Test Loss = 6.8728, Test Accuracy = 0.2278\n",
      "Iteration 615: Loss = 3.3788, Accuracy = 0.2000 Test Loss = 6.8677, Test Accuracy = 0.2276\n",
      "Iteration 616: Loss = 3.5107, Accuracy = 0.2600 Test Loss = 6.8510, Test Accuracy = 0.2274\n",
      "Iteration 617: Loss = 3.6596, Accuracy = 0.2800 Test Loss = 6.8519, Test Accuracy = 0.2288\n",
      "Iteration 618: Loss = 3.6221, Accuracy = 0.2400 Test Loss = 6.8347, Test Accuracy = 0.2277\n",
      "Iteration 619: Loss = 3.4225, Accuracy = 0.3300 Test Loss = 6.8388, Test Accuracy = 0.2262\n",
      "Iteration 620: Loss = 3.4584, Accuracy = 0.2700 Test Loss = 6.8224, Test Accuracy = 0.2263\n",
      "Iteration 621: Loss = 3.4977, Accuracy = 0.3300 Test Loss = 6.8239, Test Accuracy = 0.2298\n",
      "Iteration 622: Loss = 3.6460, Accuracy = 0.3500 Test Loss = 6.8098, Test Accuracy = 0.2269\n",
      "Iteration 623: Loss = 3.7542, Accuracy = 0.2700 Test Loss = 6.7978, Test Accuracy = 0.2275\n",
      "Iteration 624: Loss = 3.7697, Accuracy = 0.2900 Test Loss = 6.7969, Test Accuracy = 0.2277\n",
      "Iteration 625: Loss = 3.3414, Accuracy = 0.2800 Test Loss = 6.7840, Test Accuracy = 0.2271\n",
      "Iteration 626: Loss = 3.5512, Accuracy = 0.3400 Test Loss = 6.7821, Test Accuracy = 0.2253\n",
      "Iteration 627: Loss = 3.7215, Accuracy = 0.3400 Test Loss = 6.7717, Test Accuracy = 0.2279\n",
      "Iteration 628: Loss = 3.3406, Accuracy = 0.2500 Test Loss = 6.7591, Test Accuracy = 0.2282\n",
      "Iteration 629: Loss = 3.5091, Accuracy = 0.2700 Test Loss = 6.7624, Test Accuracy = 0.2297\n",
      "Iteration 630: Loss = 3.4693, Accuracy = 0.2600 Test Loss = 6.7461, Test Accuracy = 0.2280\n",
      "Iteration 631: Loss = 3.3716, Accuracy = 0.3000 Test Loss = 6.7361, Test Accuracy = 0.2289\n",
      "Iteration 632: Loss = 3.3435, Accuracy = 0.2500 Test Loss = 6.7350, Test Accuracy = 0.2309\n",
      "Iteration 633: Loss = 3.4944, Accuracy = 0.2700 Test Loss = 6.7303, Test Accuracy = 0.2277\n",
      "Iteration 634: Loss = 3.6787, Accuracy = 0.2600 Test Loss = 6.7182, Test Accuracy = 0.2298\n",
      "Iteration 635: Loss = 3.6614, Accuracy = 0.2800 Test Loss = 6.7164, Test Accuracy = 0.2321\n",
      "Iteration 636: Loss = 3.7329, Accuracy = 0.2700 Test Loss = 6.7026, Test Accuracy = 0.2288\n",
      "Iteration 637: Loss = 3.5468, Accuracy = 0.2800 Test Loss = 6.6946, Test Accuracy = 0.2317\n",
      "Iteration 638: Loss = 3.4093, Accuracy = 0.2800 Test Loss = 6.6931, Test Accuracy = 0.2320\n",
      "Iteration 639: Loss = 3.9317, Accuracy = 0.2800 Test Loss = 6.6821, Test Accuracy = 0.2292\n",
      "Iteration 640: Loss = 3.5144, Accuracy = 0.3000 Test Loss = 6.6744, Test Accuracy = 0.2302\n",
      "Iteration 641: Loss = 3.5223, Accuracy = 0.2400 Test Loss = 6.6746, Test Accuracy = 0.2286\n",
      "Iteration 642: Loss = 3.4355, Accuracy = 0.2300 Test Loss = 6.6562, Test Accuracy = 0.2291\n",
      "Iteration 643: Loss = 3.6738, Accuracy = 0.2900 Test Loss = 6.6656, Test Accuracy = 0.2316\n",
      "Iteration 644: Loss = 3.6514, Accuracy = 0.2700 Test Loss = 6.6456, Test Accuracy = 0.2299\n",
      "Iteration 645: Loss = 3.3328, Accuracy = 0.2600 Test Loss = 6.6376, Test Accuracy = 0.2297\n",
      "Iteration 646: Loss = 3.4295, Accuracy = 0.2700 Test Loss = 6.6375, Test Accuracy = 0.2327\n",
      "Iteration 647: Loss = 3.6219, Accuracy = 0.2600 Test Loss = 6.6221, Test Accuracy = 0.2307\n",
      "Iteration 648: Loss = 3.6754, Accuracy = 0.2300 Test Loss = 6.6215, Test Accuracy = 0.2290\n",
      "Iteration 649: Loss = 3.1841, Accuracy = 0.2900 Test Loss = 6.6119, Test Accuracy = 0.2328\n",
      "Iteration 650: Loss = 3.7951, Accuracy = 0.2600 Test Loss = 6.6121, Test Accuracy = 0.2305\n",
      "Iteration 651: Loss = 3.6953, Accuracy = 0.2600 Test Loss = 6.5967, Test Accuracy = 0.2309\n",
      "Iteration 652: Loss = 3.0160, Accuracy = 0.2800 Test Loss = 6.5859, Test Accuracy = 0.2306\n",
      "Iteration 653: Loss = 3.2387, Accuracy = 0.3500 Test Loss = 6.5867, Test Accuracy = 0.2304\n",
      "Iteration 654: Loss = 3.7218, Accuracy = 0.2800 Test Loss = 6.5712, Test Accuracy = 0.2312\n",
      "Iteration 655: Loss = 3.2957, Accuracy = 0.2800 Test Loss = 6.5650, Test Accuracy = 0.2314\n",
      "Iteration 656: Loss = 3.5833, Accuracy = 0.2900 Test Loss = 6.5682, Test Accuracy = 0.2308\n",
      "Iteration 657: Loss = 3.4699, Accuracy = 0.2400 Test Loss = 6.5690, Test Accuracy = 0.2313\n",
      "Iteration 658: Loss = 3.5359, Accuracy = 0.2800 Test Loss = 6.5506, Test Accuracy = 0.2321\n",
      "Iteration 659: Loss = 3.4264, Accuracy = 0.3100 Test Loss = 6.5403, Test Accuracy = 0.2323\n",
      "Iteration 660: Loss = 3.3017, Accuracy = 0.2400 Test Loss = 6.5315, Test Accuracy = 0.2337\n",
      "Iteration 661: Loss = 3.5457, Accuracy = 0.3400 Test Loss = 6.5248, Test Accuracy = 0.2337\n",
      "Iteration 662: Loss = 3.2291, Accuracy = 0.2600 Test Loss = 6.5239, Test Accuracy = 0.2336\n",
      "Iteration 663: Loss = 3.4000, Accuracy = 0.2300 Test Loss = 6.5127, Test Accuracy = 0.2323\n",
      "Iteration 664: Loss = 3.5911, Accuracy = 0.2500 Test Loss = 6.5100, Test Accuracy = 0.2326\n",
      "Iteration 665: Loss = 3.2999, Accuracy = 0.3300 Test Loss = 6.5068, Test Accuracy = 0.2331\n",
      "Iteration 666: Loss = 3.6076, Accuracy = 0.1900 Test Loss = 6.4975, Test Accuracy = 0.2338\n",
      "Iteration 667: Loss = 3.4263, Accuracy = 0.2400 Test Loss = 6.4866, Test Accuracy = 0.2326\n",
      "Iteration 668: Loss = 3.4119, Accuracy = 0.3200 Test Loss = 6.4801, Test Accuracy = 0.2324\n",
      "Iteration 669: Loss = 3.4928, Accuracy = 0.2800 Test Loss = 6.4772, Test Accuracy = 0.2323\n",
      "Iteration 670: Loss = 3.2908, Accuracy = 0.3200 Test Loss = 6.4618, Test Accuracy = 0.2331\n",
      "Iteration 671: Loss = 3.4127, Accuracy = 0.2900 Test Loss = 6.4603, Test Accuracy = 0.2346\n",
      "Iteration 672: Loss = 3.2391, Accuracy = 0.3100 Test Loss = 6.4617, Test Accuracy = 0.2334\n",
      "Iteration 673: Loss = 3.5346, Accuracy = 0.2700 Test Loss = 6.4398, Test Accuracy = 0.2336\n",
      "Iteration 674: Loss = 3.1058, Accuracy = 0.2800 Test Loss = 6.4430, Test Accuracy = 0.2335\n",
      "Iteration 675: Loss = 3.4185, Accuracy = 0.3500 Test Loss = 6.4411, Test Accuracy = 0.2333\n",
      "Iteration 676: Loss = 3.5500, Accuracy = 0.2700 Test Loss = 6.4281, Test Accuracy = 0.2320\n",
      "Iteration 677: Loss = 3.3897, Accuracy = 0.2100 Test Loss = 6.4174, Test Accuracy = 0.2357\n",
      "Iteration 678: Loss = 3.3091, Accuracy = 0.3500 Test Loss = 6.4148, Test Accuracy = 0.2355\n",
      "Iteration 679: Loss = 2.9139, Accuracy = 0.3100 Test Loss = 6.4105, Test Accuracy = 0.2354\n",
      "Iteration 680: Loss = 3.4117, Accuracy = 0.2900 Test Loss = 6.4017, Test Accuracy = 0.2367\n",
      "Iteration 681: Loss = 3.3463, Accuracy = 0.2100 Test Loss = 6.3940, Test Accuracy = 0.2349\n",
      "Iteration 682: Loss = 3.4172, Accuracy = 0.3000 Test Loss = 6.3925, Test Accuracy = 0.2346\n",
      "Iteration 683: Loss = 3.1538, Accuracy = 0.3200 Test Loss = 6.3793, Test Accuracy = 0.2334\n",
      "Iteration 684: Loss = 3.4622, Accuracy = 0.3300 Test Loss = 6.3776, Test Accuracy = 0.2361\n",
      "Iteration 685: Loss = 3.2702, Accuracy = 0.2700 Test Loss = 6.3631, Test Accuracy = 0.2349\n",
      "Iteration 686: Loss = 3.2529, Accuracy = 0.2600 Test Loss = 6.3654, Test Accuracy = 0.2350\n",
      "Iteration 687: Loss = 3.2402, Accuracy = 0.2500 Test Loss = 6.3613, Test Accuracy = 0.2340\n",
      "Iteration 688: Loss = 3.2622, Accuracy = 0.2900 Test Loss = 6.3510, Test Accuracy = 0.2343\n",
      "Iteration 689: Loss = 3.4155, Accuracy = 0.2600 Test Loss = 6.3482, Test Accuracy = 0.2357\n",
      "Iteration 690: Loss = 3.4230, Accuracy = 0.2800 Test Loss = 6.3421, Test Accuracy = 0.2368\n",
      "Iteration 691: Loss = 2.9532, Accuracy = 0.3000 Test Loss = 6.3312, Test Accuracy = 0.2360\n",
      "Iteration 692: Loss = 3.1660, Accuracy = 0.3200 Test Loss = 6.3210, Test Accuracy = 0.2353\n",
      "Iteration 693: Loss = 3.1244, Accuracy = 0.3400 Test Loss = 6.3114, Test Accuracy = 0.2358\n",
      "Iteration 694: Loss = 2.6750, Accuracy = 0.3400 Test Loss = 6.3056, Test Accuracy = 0.2370\n",
      "Iteration 695: Loss = 3.3432, Accuracy = 0.3000 Test Loss = 6.3068, Test Accuracy = 0.2372\n",
      "Iteration 696: Loss = 2.8623, Accuracy = 0.3200 Test Loss = 6.2924, Test Accuracy = 0.2366\n",
      "Iteration 697: Loss = 3.0571, Accuracy = 0.3100 Test Loss = 6.2925, Test Accuracy = 0.2342\n",
      "Iteration 698: Loss = 3.5274, Accuracy = 0.2700 Test Loss = 6.2821, Test Accuracy = 0.2372\n",
      "Iteration 699: Loss = 3.1259, Accuracy = 0.3700 Test Loss = 6.2747, Test Accuracy = 0.2371\n",
      "Iteration 700: Loss = 3.1723, Accuracy = 0.2900 Test Loss = 6.2676, Test Accuracy = 0.2368\n",
      "Iteration 701: Loss = 3.2920, Accuracy = 0.3700 Test Loss = 6.2791, Test Accuracy = 0.2360\n",
      "Iteration 702: Loss = 2.9629, Accuracy = 0.2800 Test Loss = 6.2554, Test Accuracy = 0.2377\n",
      "Iteration 703: Loss = 3.4772, Accuracy = 0.2800 Test Loss = 6.2503, Test Accuracy = 0.2381\n",
      "Iteration 704: Loss = 3.2001, Accuracy = 0.3600 Test Loss = 6.2533, Test Accuracy = 0.2370\n",
      "Iteration 705: Loss = 3.3646, Accuracy = 0.3100 Test Loss = 6.2358, Test Accuracy = 0.2381\n",
      "Iteration 706: Loss = 3.1005, Accuracy = 0.2600 Test Loss = 6.2435, Test Accuracy = 0.2379\n",
      "Iteration 707: Loss = 3.0848, Accuracy = 0.2700 Test Loss = 6.2324, Test Accuracy = 0.2382\n",
      "Iteration 708: Loss = 3.0957, Accuracy = 0.3200 Test Loss = 6.2229, Test Accuracy = 0.2392\n",
      "Iteration 709: Loss = 3.2231, Accuracy = 0.3900 Test Loss = 6.2143, Test Accuracy = 0.2356\n",
      "Iteration 710: Loss = 2.9876, Accuracy = 0.3600 Test Loss = 6.2176, Test Accuracy = 0.2358\n",
      "Iteration 711: Loss = 3.0803, Accuracy = 0.3400 Test Loss = 6.2128, Test Accuracy = 0.2384\n",
      "Iteration 712: Loss = 3.3263, Accuracy = 0.3200 Test Loss = 6.1981, Test Accuracy = 0.2365\n",
      "Iteration 713: Loss = 2.8285, Accuracy = 0.2700 Test Loss = 6.1872, Test Accuracy = 0.2387\n",
      "Iteration 714: Loss = 3.4588, Accuracy = 0.2600 Test Loss = 6.1916, Test Accuracy = 0.2374\n",
      "Iteration 715: Loss = 3.0631, Accuracy = 0.2900 Test Loss = 6.1838, Test Accuracy = 0.2377\n",
      "Iteration 716: Loss = 3.1581, Accuracy = 0.2200 Test Loss = 6.1796, Test Accuracy = 0.2381\n",
      "Iteration 717: Loss = 3.1612, Accuracy = 0.3500 Test Loss = 6.1690, Test Accuracy = 0.2387\n",
      "Iteration 718: Loss = 3.2237, Accuracy = 0.3200 Test Loss = 6.1659, Test Accuracy = 0.2391\n",
      "Iteration 719: Loss = 3.0715, Accuracy = 0.2700 Test Loss = 6.1659, Test Accuracy = 0.2377\n",
      "Iteration 720: Loss = 3.1897, Accuracy = 0.2900 Test Loss = 6.1462, Test Accuracy = 0.2392\n",
      "Iteration 721: Loss = 3.1892, Accuracy = 0.3400 Test Loss = 6.1409, Test Accuracy = 0.2391\n",
      "Iteration 722: Loss = 3.3228, Accuracy = 0.3300 Test Loss = 6.1412, Test Accuracy = 0.2384\n",
      "Iteration 723: Loss = 3.2857, Accuracy = 0.3200 Test Loss = 6.1385, Test Accuracy = 0.2377\n",
      "Iteration 724: Loss = 2.9529, Accuracy = 0.2700 Test Loss = 6.1250, Test Accuracy = 0.2379\n",
      "Iteration 725: Loss = 3.0569, Accuracy = 0.2600 Test Loss = 6.1214, Test Accuracy = 0.2389\n",
      "Iteration 726: Loss = 3.1690, Accuracy = 0.2800 Test Loss = 6.1098, Test Accuracy = 0.2388\n",
      "Iteration 727: Loss = 3.1626, Accuracy = 0.4000 Test Loss = 6.1103, Test Accuracy = 0.2388\n",
      "Iteration 728: Loss = 3.2377, Accuracy = 0.3000 Test Loss = 6.0998, Test Accuracy = 0.2400\n",
      "Iteration 729: Loss = 2.8583, Accuracy = 0.2300 Test Loss = 6.0957, Test Accuracy = 0.2382\n",
      "Iteration 730: Loss = 3.1910, Accuracy = 0.2900 Test Loss = 6.0934, Test Accuracy = 0.2391\n",
      "Iteration 731: Loss = 3.0957, Accuracy = 0.2900 Test Loss = 6.0836, Test Accuracy = 0.2397\n",
      "Iteration 732: Loss = 2.8016, Accuracy = 0.3200 Test Loss = 6.0843, Test Accuracy = 0.2397\n",
      "Iteration 733: Loss = 3.1096, Accuracy = 0.3600 Test Loss = 6.0703, Test Accuracy = 0.2389\n",
      "Iteration 734: Loss = 3.1706, Accuracy = 0.4100 Test Loss = 6.0606, Test Accuracy = 0.2373\n",
      "Iteration 735: Loss = 2.9182, Accuracy = 0.3400 Test Loss = 6.0571, Test Accuracy = 0.2400\n",
      "Iteration 736: Loss = 3.1898, Accuracy = 0.3200 Test Loss = 6.0589, Test Accuracy = 0.2392\n",
      "Iteration 737: Loss = 2.8800, Accuracy = 0.3900 Test Loss = 6.0482, Test Accuracy = 0.2381\n",
      "Iteration 738: Loss = 2.8557, Accuracy = 0.3300 Test Loss = 6.0416, Test Accuracy = 0.2388\n",
      "Iteration 739: Loss = 3.0331, Accuracy = 0.3500 Test Loss = 6.0381, Test Accuracy = 0.2411\n",
      "Iteration 740: Loss = 2.9890, Accuracy = 0.2700 Test Loss = 6.0366, Test Accuracy = 0.2411\n",
      "Iteration 741: Loss = 2.8874, Accuracy = 0.3200 Test Loss = 6.0294, Test Accuracy = 0.2396\n",
      "Iteration 742: Loss = 3.0375, Accuracy = 0.2800 Test Loss = 6.0250, Test Accuracy = 0.2416\n",
      "Iteration 743: Loss = 3.2156, Accuracy = 0.2200 Test Loss = 6.0113, Test Accuracy = 0.2390\n",
      "Iteration 744: Loss = 3.1331, Accuracy = 0.3000 Test Loss = 6.0077, Test Accuracy = 0.2398\n",
      "Iteration 745: Loss = 3.4537, Accuracy = 0.2400 Test Loss = 6.0082, Test Accuracy = 0.2393\n",
      "Iteration 746: Loss = 2.9466, Accuracy = 0.3000 Test Loss = 5.9951, Test Accuracy = 0.2407\n",
      "Iteration 747: Loss = 2.8821, Accuracy = 0.2600 Test Loss = 5.9964, Test Accuracy = 0.2396\n",
      "Iteration 748: Loss = 2.7511, Accuracy = 0.2900 Test Loss = 5.9896, Test Accuracy = 0.2412\n",
      "Iteration 749: Loss = 3.1906, Accuracy = 0.2800 Test Loss = 5.9879, Test Accuracy = 0.2455\n",
      "Iteration 750: Loss = 3.0463, Accuracy = 0.2800 Test Loss = 5.9714, Test Accuracy = 0.2406\n",
      "Iteration 751: Loss = 3.1489, Accuracy = 0.2500 Test Loss = 5.9756, Test Accuracy = 0.2400\n",
      "Iteration 752: Loss = 2.7218, Accuracy = 0.3800 Test Loss = 5.9656, Test Accuracy = 0.2411\n",
      "Iteration 753: Loss = 3.1975, Accuracy = 0.3200 Test Loss = 5.9572, Test Accuracy = 0.2426\n",
      "Iteration 754: Loss = 2.6254, Accuracy = 0.3300 Test Loss = 5.9545, Test Accuracy = 0.2417\n",
      "Iteration 755: Loss = 3.1931, Accuracy = 0.4000 Test Loss = 5.9537, Test Accuracy = 0.2405\n",
      "Iteration 756: Loss = 2.8275, Accuracy = 0.3500 Test Loss = 5.9449, Test Accuracy = 0.2405\n",
      "Iteration 757: Loss = 2.8419, Accuracy = 0.3200 Test Loss = 5.9368, Test Accuracy = 0.2420\n",
      "Iteration 758: Loss = 2.9547, Accuracy = 0.3800 Test Loss = 5.9303, Test Accuracy = 0.2423\n",
      "Iteration 759: Loss = 2.7639, Accuracy = 0.2500 Test Loss = 5.9273, Test Accuracy = 0.2422\n",
      "Iteration 760: Loss = 3.0045, Accuracy = 0.3500 Test Loss = 5.9203, Test Accuracy = 0.2429\n",
      "Iteration 761: Loss = 3.1238, Accuracy = 0.3100 Test Loss = 5.9175, Test Accuracy = 0.2430\n",
      "Iteration 762: Loss = 2.7197, Accuracy = 0.3500 Test Loss = 5.9080, Test Accuracy = 0.2423\n",
      "Iteration 763: Loss = 2.9917, Accuracy = 0.2500 Test Loss = 5.9104, Test Accuracy = 0.2420\n",
      "Iteration 764: Loss = 2.7756, Accuracy = 0.3000 Test Loss = 5.9001, Test Accuracy = 0.2443\n",
      "Iteration 765: Loss = 3.2298, Accuracy = 0.2700 Test Loss = 5.8944, Test Accuracy = 0.2422\n",
      "Iteration 766: Loss = 3.1166, Accuracy = 0.3000 Test Loss = 5.8832, Test Accuracy = 0.2446\n",
      "Iteration 767: Loss = 2.8970, Accuracy = 0.3300 Test Loss = 5.8871, Test Accuracy = 0.2419\n",
      "Iteration 768: Loss = 2.8323, Accuracy = 0.3300 Test Loss = 5.8745, Test Accuracy = 0.2434\n",
      "Iteration 769: Loss = 3.0747, Accuracy = 0.3200 Test Loss = 5.8658, Test Accuracy = 0.2428\n",
      "Iteration 770: Loss = 2.8337, Accuracy = 0.2600 Test Loss = 5.8743, Test Accuracy = 0.2430\n",
      "Iteration 771: Loss = 2.9659, Accuracy = 0.3500 Test Loss = 5.8711, Test Accuracy = 0.2434\n",
      "Iteration 772: Loss = 3.0217, Accuracy = 0.3400 Test Loss = 5.8498, Test Accuracy = 0.2446\n",
      "Iteration 773: Loss = 3.1634, Accuracy = 0.2900 Test Loss = 5.8507, Test Accuracy = 0.2436\n",
      "Iteration 774: Loss = 2.8954, Accuracy = 0.3300 Test Loss = 5.8438, Test Accuracy = 0.2422\n",
      "Iteration 775: Loss = 2.9691, Accuracy = 0.3500 Test Loss = 5.8355, Test Accuracy = 0.2426\n",
      "Iteration 776: Loss = 3.0739, Accuracy = 0.3300 Test Loss = 5.8226, Test Accuracy = 0.2438\n",
      "Iteration 777: Loss = 2.9036, Accuracy = 0.3100 Test Loss = 5.8262, Test Accuracy = 0.2417\n",
      "Iteration 778: Loss = 3.0255, Accuracy = 0.3300 Test Loss = 5.8236, Test Accuracy = 0.2456\n",
      "Iteration 779: Loss = 2.7354, Accuracy = 0.3300 Test Loss = 5.8170, Test Accuracy = 0.2447\n",
      "Iteration 780: Loss = 2.6389, Accuracy = 0.3500 Test Loss = 5.8050, Test Accuracy = 0.2446\n",
      "Iteration 781: Loss = 2.6723, Accuracy = 0.3100 Test Loss = 5.8057, Test Accuracy = 0.2427\n",
      "Iteration 782: Loss = 2.8003, Accuracy = 0.3500 Test Loss = 5.7960, Test Accuracy = 0.2435\n",
      "Iteration 783: Loss = 3.0207, Accuracy = 0.3500 Test Loss = 5.7956, Test Accuracy = 0.2447\n",
      "Iteration 784: Loss = 2.6963, Accuracy = 0.3200 Test Loss = 5.7875, Test Accuracy = 0.2439\n",
      "Iteration 785: Loss = 2.7245, Accuracy = 0.3600 Test Loss = 5.7848, Test Accuracy = 0.2459\n",
      "Iteration 786: Loss = 2.8072, Accuracy = 0.3600 Test Loss = 5.7719, Test Accuracy = 0.2462\n",
      "Iteration 787: Loss = 2.8519, Accuracy = 0.3800 Test Loss = 5.7740, Test Accuracy = 0.2437\n",
      "Iteration 788: Loss = 2.7940, Accuracy = 0.4100 Test Loss = 5.7651, Test Accuracy = 0.2436\n",
      "Iteration 789: Loss = 2.7991, Accuracy = 0.3500 Test Loss = 5.7701, Test Accuracy = 0.2439\n",
      "Iteration 790: Loss = 2.9063, Accuracy = 0.3400 Test Loss = 5.7593, Test Accuracy = 0.2432\n",
      "Iteration 791: Loss = 2.8676, Accuracy = 0.3200 Test Loss = 5.7492, Test Accuracy = 0.2471\n",
      "Iteration 792: Loss = 3.0544, Accuracy = 0.2600 Test Loss = 5.7435, Test Accuracy = 0.2459\n",
      "Iteration 793: Loss = 2.8800, Accuracy = 0.3500 Test Loss = 5.7455, Test Accuracy = 0.2459\n",
      "Iteration 794: Loss = 2.9755, Accuracy = 0.2800 Test Loss = 5.7377, Test Accuracy = 0.2448\n",
      "Iteration 795: Loss = 2.7601, Accuracy = 0.3600 Test Loss = 5.7282, Test Accuracy = 0.2453\n",
      "Iteration 796: Loss = 3.0767, Accuracy = 0.2700 Test Loss = 5.7336, Test Accuracy = 0.2447\n",
      "Iteration 797: Loss = 2.9259, Accuracy = 0.3200 Test Loss = 5.7210, Test Accuracy = 0.2441\n",
      "Iteration 798: Loss = 2.6279, Accuracy = 0.3600 Test Loss = 5.7204, Test Accuracy = 0.2443\n",
      "Iteration 799: Loss = 2.7829, Accuracy = 0.3300 Test Loss = 5.7094, Test Accuracy = 0.2449\n",
      "Iteration 800: Loss = 2.6843, Accuracy = 0.2700 Test Loss = 5.7077, Test Accuracy = 0.2464\n",
      "Iteration 801: Loss = 2.6773, Accuracy = 0.3200 Test Loss = 5.7041, Test Accuracy = 0.2464\n",
      "Iteration 802: Loss = 3.0313, Accuracy = 0.3300 Test Loss = 5.6956, Test Accuracy = 0.2461\n",
      "Iteration 803: Loss = 2.7161, Accuracy = 0.3300 Test Loss = 5.6893, Test Accuracy = 0.2452\n",
      "Iteration 804: Loss = 2.7361, Accuracy = 0.2600 Test Loss = 5.6806, Test Accuracy = 0.2464\n",
      "Iteration 805: Loss = 2.7512, Accuracy = 0.3000 Test Loss = 5.6823, Test Accuracy = 0.2470\n",
      "Iteration 806: Loss = 2.7574, Accuracy = 0.2900 Test Loss = 5.6777, Test Accuracy = 0.2466\n",
      "Iteration 807: Loss = 2.6789, Accuracy = 0.4200 Test Loss = 5.6706, Test Accuracy = 0.2466\n",
      "Iteration 808: Loss = 2.4047, Accuracy = 0.4000 Test Loss = 5.6750, Test Accuracy = 0.2472\n",
      "Iteration 809: Loss = 2.6025, Accuracy = 0.3700 Test Loss = 5.6519, Test Accuracy = 0.2491\n",
      "Iteration 810: Loss = 2.7059, Accuracy = 0.3300 Test Loss = 5.6535, Test Accuracy = 0.2460\n",
      "Iteration 811: Loss = 2.7787, Accuracy = 0.2800 Test Loss = 5.6530, Test Accuracy = 0.2463\n",
      "Iteration 812: Loss = 3.0646, Accuracy = 0.2700 Test Loss = 5.6422, Test Accuracy = 0.2459\n",
      "Iteration 813: Loss = 3.0749, Accuracy = 0.2400 Test Loss = 5.6403, Test Accuracy = 0.2460\n",
      "Iteration 814: Loss = 2.7385, Accuracy = 0.3400 Test Loss = 5.6390, Test Accuracy = 0.2474\n",
      "Iteration 815: Loss = 3.0657, Accuracy = 0.3000 Test Loss = 5.6271, Test Accuracy = 0.2486\n",
      "Iteration 816: Loss = 2.7880, Accuracy = 0.3600 Test Loss = 5.6253, Test Accuracy = 0.2486\n",
      "Iteration 817: Loss = 2.7924, Accuracy = 0.2700 Test Loss = 5.6214, Test Accuracy = 0.2458\n",
      "Iteration 818: Loss = 2.9181, Accuracy = 0.3100 Test Loss = 5.6154, Test Accuracy = 0.2460\n",
      "Iteration 819: Loss = 2.8318, Accuracy = 0.3500 Test Loss = 5.6117, Test Accuracy = 0.2479\n",
      "Iteration 820: Loss = 2.7653, Accuracy = 0.2800 Test Loss = 5.6177, Test Accuracy = 0.2489\n",
      "Iteration 821: Loss = 2.6805, Accuracy = 0.3600 Test Loss = 5.6019, Test Accuracy = 0.2488\n",
      "Iteration 822: Loss = 2.4959, Accuracy = 0.3600 Test Loss = 5.5955, Test Accuracy = 0.2476\n",
      "Iteration 823: Loss = 2.9652, Accuracy = 0.3000 Test Loss = 5.5907, Test Accuracy = 0.2493\n",
      "Iteration 824: Loss = 2.6861, Accuracy = 0.3600 Test Loss = 5.5893, Test Accuracy = 0.2480\n",
      "Iteration 825: Loss = 2.6738, Accuracy = 0.3200 Test Loss = 5.5828, Test Accuracy = 0.2505\n",
      "Iteration 826: Loss = 2.9390, Accuracy = 0.3300 Test Loss = 5.5807, Test Accuracy = 0.2496\n",
      "Iteration 827: Loss = 2.5841, Accuracy = 0.3100 Test Loss = 5.5729, Test Accuracy = 0.2487\n",
      "Iteration 828: Loss = 2.6541, Accuracy = 0.2500 Test Loss = 5.5657, Test Accuracy = 0.2492\n",
      "Iteration 829: Loss = 2.9348, Accuracy = 0.3000 Test Loss = 5.5636, Test Accuracy = 0.2486\n",
      "Iteration 830: Loss = 2.6198, Accuracy = 0.2900 Test Loss = 5.5607, Test Accuracy = 0.2496\n",
      "Iteration 831: Loss = 2.8713, Accuracy = 0.3700 Test Loss = 5.5545, Test Accuracy = 0.2511\n",
      "Iteration 832: Loss = 2.6739, Accuracy = 0.3400 Test Loss = 5.5426, Test Accuracy = 0.2495\n",
      "Iteration 833: Loss = 2.4627, Accuracy = 0.3700 Test Loss = 5.5452, Test Accuracy = 0.2491\n",
      "Iteration 834: Loss = 2.8846, Accuracy = 0.2300 Test Loss = 5.5338, Test Accuracy = 0.2488\n",
      "Iteration 835: Loss = 2.9970, Accuracy = 0.3000 Test Loss = 5.5363, Test Accuracy = 0.2490\n",
      "Iteration 836: Loss = 2.6446, Accuracy = 0.3700 Test Loss = 5.5361, Test Accuracy = 0.2508\n",
      "Iteration 837: Loss = 2.5220, Accuracy = 0.3700 Test Loss = 5.5192, Test Accuracy = 0.2492\n",
      "Iteration 838: Loss = 2.6578, Accuracy = 0.3600 Test Loss = 5.5239, Test Accuracy = 0.2501\n",
      "Iteration 839: Loss = 2.7122, Accuracy = 0.3700 Test Loss = 5.5146, Test Accuracy = 0.2501\n",
      "Iteration 840: Loss = 2.7048, Accuracy = 0.3200 Test Loss = 5.5109, Test Accuracy = 0.2494\n",
      "Iteration 841: Loss = 2.5428, Accuracy = 0.2500 Test Loss = 5.5093, Test Accuracy = 0.2510\n",
      "Iteration 842: Loss = 2.5056, Accuracy = 0.3100 Test Loss = 5.5019, Test Accuracy = 0.2502\n",
      "Iteration 843: Loss = 2.7735, Accuracy = 0.2800 Test Loss = 5.4991, Test Accuracy = 0.2513\n",
      "Iteration 844: Loss = 2.5871, Accuracy = 0.2800 Test Loss = 5.4902, Test Accuracy = 0.2511\n",
      "Iteration 845: Loss = 2.6698, Accuracy = 0.3100 Test Loss = 5.4790, Test Accuracy = 0.2502\n",
      "Iteration 846: Loss = 2.6058, Accuracy = 0.3200 Test Loss = 5.4829, Test Accuracy = 0.2519\n",
      "Iteration 847: Loss = 2.5834, Accuracy = 0.3000 Test Loss = 5.4760, Test Accuracy = 0.2494\n",
      "Iteration 848: Loss = 2.4997, Accuracy = 0.3300 Test Loss = 5.4754, Test Accuracy = 0.2511\n",
      "Iteration 849: Loss = 2.8398, Accuracy = 0.3600 Test Loss = 5.4693, Test Accuracy = 0.2495\n",
      "Iteration 850: Loss = 2.5352, Accuracy = 0.4100 Test Loss = 5.4711, Test Accuracy = 0.2501\n",
      "Iteration 851: Loss = 2.4823, Accuracy = 0.4000 Test Loss = 5.4559, Test Accuracy = 0.2504\n",
      "Iteration 852: Loss = 2.7508, Accuracy = 0.3200 Test Loss = 5.4571, Test Accuracy = 0.2507\n",
      "Iteration 853: Loss = 2.6234, Accuracy = 0.3000 Test Loss = 5.4447, Test Accuracy = 0.2517\n",
      "Iteration 854: Loss = 2.6571, Accuracy = 0.2900 Test Loss = 5.4415, Test Accuracy = 0.2501\n",
      "Iteration 855: Loss = 2.9961, Accuracy = 0.3400 Test Loss = 5.4366, Test Accuracy = 0.2504\n",
      "Iteration 856: Loss = 2.7373, Accuracy = 0.3800 Test Loss = 5.4318, Test Accuracy = 0.2512\n",
      "Iteration 857: Loss = 2.5330, Accuracy = 0.3400 Test Loss = 5.4299, Test Accuracy = 0.2499\n",
      "Iteration 858: Loss = 2.8902, Accuracy = 0.3300 Test Loss = 5.4221, Test Accuracy = 0.2511\n",
      "Iteration 859: Loss = 2.5075, Accuracy = 0.2900 Test Loss = 5.4187, Test Accuracy = 0.2517\n",
      "Iteration 860: Loss = 2.6438, Accuracy = 0.3100 Test Loss = 5.4177, Test Accuracy = 0.2520\n",
      "Iteration 861: Loss = 2.2948, Accuracy = 0.3800 Test Loss = 5.4079, Test Accuracy = 0.2515\n",
      "Iteration 862: Loss = 2.7614, Accuracy = 0.4300 Test Loss = 5.4097, Test Accuracy = 0.2513\n",
      "Iteration 863: Loss = 2.6809, Accuracy = 0.2200 Test Loss = 5.3988, Test Accuracy = 0.2518\n",
      "Iteration 864: Loss = 2.7382, Accuracy = 0.2700 Test Loss = 5.3999, Test Accuracy = 0.2522\n",
      "Iteration 865: Loss = 2.6471, Accuracy = 0.3300 Test Loss = 5.3879, Test Accuracy = 0.2519\n",
      "Iteration 866: Loss = 2.3167, Accuracy = 0.3300 Test Loss = 5.3949, Test Accuracy = 0.2522\n",
      "Iteration 867: Loss = 2.4391, Accuracy = 0.3300 Test Loss = 5.3901, Test Accuracy = 0.2527\n",
      "Iteration 868: Loss = 2.4317, Accuracy = 0.3300 Test Loss = 5.3835, Test Accuracy = 0.2532\n",
      "Iteration 869: Loss = 2.7291, Accuracy = 0.2600 Test Loss = 5.3785, Test Accuracy = 0.2553\n",
      "Iteration 870: Loss = 2.5801, Accuracy = 0.3600 Test Loss = 5.3702, Test Accuracy = 0.2536\n",
      "Iteration 871: Loss = 2.6831, Accuracy = 0.4000 Test Loss = 5.3631, Test Accuracy = 0.2540\n",
      "Iteration 872: Loss = 2.5026, Accuracy = 0.3200 Test Loss = 5.3629, Test Accuracy = 0.2523\n",
      "Iteration 873: Loss = 2.8615, Accuracy = 0.2100 Test Loss = 5.3563, Test Accuracy = 0.2541\n",
      "Iteration 874: Loss = 2.8477, Accuracy = 0.2500 Test Loss = 5.3571, Test Accuracy = 0.2523\n",
      "Iteration 875: Loss = 2.7198, Accuracy = 0.3300 Test Loss = 5.3515, Test Accuracy = 0.2516\n",
      "Iteration 876: Loss = 2.6257, Accuracy = 0.3900 Test Loss = 5.3408, Test Accuracy = 0.2548\n",
      "Iteration 877: Loss = 2.6628, Accuracy = 0.3400 Test Loss = 5.3363, Test Accuracy = 0.2538\n",
      "Iteration 878: Loss = 2.5343, Accuracy = 0.3400 Test Loss = 5.3333, Test Accuracy = 0.2540\n",
      "Iteration 879: Loss = 2.5669, Accuracy = 0.3400 Test Loss = 5.3280, Test Accuracy = 0.2535\n",
      "Iteration 880: Loss = 2.4266, Accuracy = 0.4000 Test Loss = 5.3212, Test Accuracy = 0.2535\n",
      "Iteration 881: Loss = 2.5570, Accuracy = 0.2800 Test Loss = 5.3213, Test Accuracy = 0.2537\n",
      "Iteration 882: Loss = 2.7117, Accuracy = 0.3000 Test Loss = 5.3179, Test Accuracy = 0.2533\n",
      "Iteration 883: Loss = 2.8247, Accuracy = 0.2800 Test Loss = 5.3133, Test Accuracy = 0.2543\n",
      "Iteration 884: Loss = 2.3436, Accuracy = 0.3000 Test Loss = 5.3128, Test Accuracy = 0.2545\n",
      "Iteration 885: Loss = 2.6093, Accuracy = 0.2900 Test Loss = 5.3111, Test Accuracy = 0.2560\n",
      "Iteration 886: Loss = 2.7784, Accuracy = 0.3100 Test Loss = 5.2982, Test Accuracy = 0.2542\n",
      "Iteration 887: Loss = 2.4464, Accuracy = 0.3400 Test Loss = 5.2977, Test Accuracy = 0.2540\n",
      "Iteration 888: Loss = 2.6571, Accuracy = 0.3100 Test Loss = 5.2918, Test Accuracy = 0.2541\n",
      "Iteration 889: Loss = 2.4341, Accuracy = 0.3400 Test Loss = 5.2820, Test Accuracy = 0.2554\n",
      "Iteration 890: Loss = 2.4059, Accuracy = 0.3000 Test Loss = 5.2832, Test Accuracy = 0.2566\n",
      "Iteration 891: Loss = 2.4227, Accuracy = 0.3500 Test Loss = 5.2763, Test Accuracy = 0.2555\n",
      "Iteration 892: Loss = 2.4062, Accuracy = 0.3400 Test Loss = 5.2787, Test Accuracy = 0.2551\n",
      "Iteration 893: Loss = 2.5511, Accuracy = 0.3800 Test Loss = 5.2781, Test Accuracy = 0.2549\n",
      "Iteration 894: Loss = 2.6575, Accuracy = 0.3400 Test Loss = 5.2672, Test Accuracy = 0.2570\n",
      "Iteration 895: Loss = 2.5145, Accuracy = 0.3200 Test Loss = 5.2549, Test Accuracy = 0.2552\n",
      "Iteration 896: Loss = 2.3196, Accuracy = 0.3300 Test Loss = 5.2509, Test Accuracy = 0.2551\n",
      "Iteration 897: Loss = 2.4417, Accuracy = 0.3000 Test Loss = 5.2504, Test Accuracy = 0.2563\n",
      "Iteration 898: Loss = 2.7036, Accuracy = 0.3200 Test Loss = 5.2473, Test Accuracy = 0.2548\n",
      "Iteration 899: Loss = 2.7179, Accuracy = 0.3000 Test Loss = 5.2436, Test Accuracy = 0.2552\n",
      "Iteration 900: Loss = 2.4041, Accuracy = 0.3500 Test Loss = 5.2400, Test Accuracy = 0.2554\n",
      "Iteration 901: Loss = 2.2813, Accuracy = 0.3700 Test Loss = 5.2330, Test Accuracy = 0.2564\n",
      "Iteration 902: Loss = 2.4858, Accuracy = 0.3900 Test Loss = 5.2336, Test Accuracy = 0.2558\n",
      "Iteration 903: Loss = 2.6197, Accuracy = 0.3100 Test Loss = 5.2282, Test Accuracy = 0.2572\n",
      "Iteration 904: Loss = 2.6540, Accuracy = 0.3500 Test Loss = 5.2192, Test Accuracy = 0.2559\n",
      "Iteration 905: Loss = 2.2349, Accuracy = 0.4100 Test Loss = 5.2213, Test Accuracy = 0.2561\n",
      "Iteration 906: Loss = 2.6428, Accuracy = 0.3400 Test Loss = 5.2145, Test Accuracy = 0.2564\n",
      "Iteration 907: Loss = 2.3264, Accuracy = 0.3600 Test Loss = 5.2114, Test Accuracy = 0.2572\n",
      "Iteration 908: Loss = 2.6039, Accuracy = 0.3900 Test Loss = 5.2093, Test Accuracy = 0.2576\n",
      "Iteration 909: Loss = 2.2428, Accuracy = 0.3200 Test Loss = 5.2068, Test Accuracy = 0.2570\n",
      "Iteration 910: Loss = 2.7105, Accuracy = 0.3400 Test Loss = 5.1997, Test Accuracy = 0.2578\n",
      "Iteration 911: Loss = 2.5238, Accuracy = 0.3700 Test Loss = 5.1920, Test Accuracy = 0.2594\n",
      "Iteration 912: Loss = 2.3498, Accuracy = 0.3100 Test Loss = 5.1888, Test Accuracy = 0.2573\n",
      "Iteration 913: Loss = 2.5763, Accuracy = 0.3300 Test Loss = 5.1822, Test Accuracy = 0.2570\n",
      "Iteration 914: Loss = 2.6452, Accuracy = 0.3300 Test Loss = 5.1810, Test Accuracy = 0.2586\n",
      "Iteration 915: Loss = 2.5843, Accuracy = 0.2700 Test Loss = 5.1807, Test Accuracy = 0.2573\n",
      "Iteration 916: Loss = 2.5296, Accuracy = 0.3000 Test Loss = 5.1805, Test Accuracy = 0.2589\n",
      "Iteration 917: Loss = 2.4657, Accuracy = 0.2500 Test Loss = 5.1748, Test Accuracy = 0.2575\n",
      "Iteration 918: Loss = 2.2989, Accuracy = 0.2400 Test Loss = 5.1709, Test Accuracy = 0.2570\n",
      "Iteration 919: Loss = 2.4427, Accuracy = 0.4200 Test Loss = 5.1615, Test Accuracy = 0.2581\n",
      "Iteration 920: Loss = 2.6704, Accuracy = 0.3400 Test Loss = 5.1588, Test Accuracy = 0.2577\n",
      "Iteration 921: Loss = 2.4472, Accuracy = 0.3900 Test Loss = 5.1576, Test Accuracy = 0.2579\n",
      "Iteration 922: Loss = 2.2654, Accuracy = 0.3700 Test Loss = 5.1520, Test Accuracy = 0.2574\n",
      "Iteration 923: Loss = 2.2329, Accuracy = 0.3800 Test Loss = 5.1441, Test Accuracy = 0.2586\n",
      "Iteration 924: Loss = 2.3244, Accuracy = 0.3200 Test Loss = 5.1417, Test Accuracy = 0.2584\n",
      "Iteration 925: Loss = 2.2346, Accuracy = 0.3700 Test Loss = 5.1386, Test Accuracy = 0.2609\n",
      "Iteration 926: Loss = 2.2566, Accuracy = 0.3500 Test Loss = 5.1420, Test Accuracy = 0.2589\n",
      "Iteration 927: Loss = 2.1965, Accuracy = 0.4500 Test Loss = 5.1257, Test Accuracy = 0.2598\n",
      "Iteration 928: Loss = 2.3193, Accuracy = 0.3700 Test Loss = 5.1202, Test Accuracy = 0.2595\n",
      "Iteration 929: Loss = 2.3986, Accuracy = 0.3800 Test Loss = 5.1215, Test Accuracy = 0.2598\n",
      "Iteration 930: Loss = 2.3891, Accuracy = 0.3400 Test Loss = 5.1208, Test Accuracy = 0.2595\n",
      "Iteration 931: Loss = 2.5795, Accuracy = 0.3600 Test Loss = 5.1096, Test Accuracy = 0.2620\n",
      "Iteration 932: Loss = 2.5425, Accuracy = 0.3200 Test Loss = 5.1132, Test Accuracy = 0.2577\n",
      "Iteration 933: Loss = 2.3513, Accuracy = 0.3600 Test Loss = 5.1011, Test Accuracy = 0.2593\n",
      "Iteration 934: Loss = 2.2723, Accuracy = 0.4500 Test Loss = 5.1003, Test Accuracy = 0.2604\n",
      "Iteration 935: Loss = 2.3933, Accuracy = 0.3500 Test Loss = 5.0930, Test Accuracy = 0.2602\n",
      "Iteration 936: Loss = 2.3126, Accuracy = 0.3400 Test Loss = 5.0888, Test Accuracy = 0.2604\n",
      "Iteration 937: Loss = 2.2946, Accuracy = 0.2900 Test Loss = 5.0865, Test Accuracy = 0.2613\n",
      "Iteration 938: Loss = 2.3401, Accuracy = 0.4500 Test Loss = 5.0827, Test Accuracy = 0.2613\n",
      "Iteration 939: Loss = 2.5961, Accuracy = 0.2800 Test Loss = 5.0763, Test Accuracy = 0.2598\n",
      "Iteration 940: Loss = 2.3218, Accuracy = 0.3800 Test Loss = 5.0747, Test Accuracy = 0.2599\n",
      "Iteration 941: Loss = 2.4430, Accuracy = 0.3600 Test Loss = 5.0777, Test Accuracy = 0.2619\n",
      "Iteration 942: Loss = 2.4955, Accuracy = 0.3500 Test Loss = 5.0687, Test Accuracy = 0.2609\n",
      "Iteration 943: Loss = 2.2525, Accuracy = 0.3700 Test Loss = 5.0653, Test Accuracy = 0.2627\n",
      "Iteration 944: Loss = 2.4199, Accuracy = 0.3300 Test Loss = 5.0593, Test Accuracy = 0.2617\n",
      "Iteration 945: Loss = 2.4325, Accuracy = 0.2700 Test Loss = 5.0539, Test Accuracy = 0.2628\n",
      "Iteration 946: Loss = 2.3801, Accuracy = 0.3400 Test Loss = 5.0536, Test Accuracy = 0.2623\n",
      "Iteration 947: Loss = 2.4077, Accuracy = 0.3500 Test Loss = 5.0465, Test Accuracy = 0.2615\n",
      "Iteration 948: Loss = 2.2506, Accuracy = 0.3300 Test Loss = 5.0481, Test Accuracy = 0.2621\n",
      "Iteration 949: Loss = 2.2741, Accuracy = 0.3100 Test Loss = 5.0394, Test Accuracy = 0.2622\n",
      "Iteration 950: Loss = 2.3940, Accuracy = 0.3900 Test Loss = 5.0324, Test Accuracy = 0.2629\n",
      "Iteration 951: Loss = 2.2867, Accuracy = 0.3800 Test Loss = 5.0353, Test Accuracy = 0.2621\n",
      "Iteration 952: Loss = 2.2499, Accuracy = 0.3700 Test Loss = 5.0292, Test Accuracy = 0.2652\n",
      "Iteration 953: Loss = 2.4218, Accuracy = 0.3200 Test Loss = 5.0275, Test Accuracy = 0.2635\n",
      "Iteration 954: Loss = 2.2943, Accuracy = 0.3600 Test Loss = 5.0276, Test Accuracy = 0.2635\n",
      "Iteration 955: Loss = 2.5990, Accuracy = 0.2800 Test Loss = 5.0217, Test Accuracy = 0.2627\n",
      "Iteration 956: Loss = 2.2208, Accuracy = 0.4000 Test Loss = 5.0155, Test Accuracy = 0.2626\n",
      "Iteration 957: Loss = 2.1902, Accuracy = 0.3700 Test Loss = 5.0090, Test Accuracy = 0.2638\n",
      "Iteration 958: Loss = 2.2997, Accuracy = 0.3200 Test Loss = 5.0040, Test Accuracy = 0.2635\n",
      "Iteration 959: Loss = 2.3520, Accuracy = 0.3800 Test Loss = 5.0035, Test Accuracy = 0.2650\n",
      "Iteration 960: Loss = 2.4388, Accuracy = 0.3000 Test Loss = 5.0063, Test Accuracy = 0.2645\n",
      "Iteration 961: Loss = 2.3221, Accuracy = 0.3600 Test Loss = 5.0020, Test Accuracy = 0.2636\n",
      "Iteration 962: Loss = 2.3917, Accuracy = 0.3500 Test Loss = 4.9936, Test Accuracy = 0.2646\n",
      "Iteration 963: Loss = 2.4486, Accuracy = 0.4100 Test Loss = 4.9852, Test Accuracy = 0.2639\n",
      "Iteration 964: Loss = 2.5263, Accuracy = 0.3300 Test Loss = 4.9839, Test Accuracy = 0.2633\n",
      "Iteration 965: Loss = 2.1723, Accuracy = 0.3700 Test Loss = 4.9783, Test Accuracy = 0.2643\n",
      "Iteration 966: Loss = 2.1834, Accuracy = 0.4000 Test Loss = 4.9763, Test Accuracy = 0.2649\n",
      "Iteration 967: Loss = 2.3553, Accuracy = 0.2500 Test Loss = 4.9785, Test Accuracy = 0.2650\n",
      "Iteration 968: Loss = 2.1898, Accuracy = 0.3600 Test Loss = 4.9742, Test Accuracy = 0.2642\n",
      "Iteration 969: Loss = 2.0893, Accuracy = 0.4100 Test Loss = 4.9654, Test Accuracy = 0.2653\n",
      "Iteration 970: Loss = 2.1181, Accuracy = 0.3900 Test Loss = 4.9683, Test Accuracy = 0.2648\n",
      "Iteration 971: Loss = 2.2298, Accuracy = 0.3700 Test Loss = 4.9615, Test Accuracy = 0.2634\n",
      "Iteration 972: Loss = 2.0787, Accuracy = 0.3400 Test Loss = 4.9502, Test Accuracy = 0.2634\n",
      "Iteration 973: Loss = 2.4437, Accuracy = 0.3900 Test Loss = 4.9525, Test Accuracy = 0.2640\n",
      "Iteration 974: Loss = 2.1297, Accuracy = 0.3300 Test Loss = 4.9502, Test Accuracy = 0.2649\n",
      "Iteration 975: Loss = 1.9982, Accuracy = 0.4400 Test Loss = 4.9435, Test Accuracy = 0.2647\n",
      "Iteration 976: Loss = 2.4155, Accuracy = 0.3100 Test Loss = 4.9390, Test Accuracy = 0.2643\n",
      "Iteration 977: Loss = 2.1691, Accuracy = 0.3200 Test Loss = 4.9366, Test Accuracy = 0.2664\n",
      "Iteration 978: Loss = 2.3305, Accuracy = 0.3100 Test Loss = 4.9382, Test Accuracy = 0.2652\n",
      "Iteration 979: Loss = 2.2327, Accuracy = 0.3700 Test Loss = 4.9301, Test Accuracy = 0.2656\n",
      "Iteration 980: Loss = 2.1513, Accuracy = 0.3500 Test Loss = 4.9321, Test Accuracy = 0.2645\n",
      "Iteration 981: Loss = 2.2710, Accuracy = 0.4400 Test Loss = 4.9227, Test Accuracy = 0.2659\n",
      "Iteration 982: Loss = 2.1238, Accuracy = 0.3300 Test Loss = 4.9159, Test Accuracy = 0.2649\n",
      "Iteration 983: Loss = 2.2450, Accuracy = 0.3200 Test Loss = 4.9190, Test Accuracy = 0.2669\n",
      "Iteration 984: Loss = 2.2374, Accuracy = 0.3400 Test Loss = 4.9077, Test Accuracy = 0.2650\n",
      "Iteration 985: Loss = 2.4615, Accuracy = 0.3800 Test Loss = 4.9048, Test Accuracy = 0.2669\n",
      "Iteration 986: Loss = 2.2554, Accuracy = 0.4100 Test Loss = 4.8979, Test Accuracy = 0.2656\n",
      "Iteration 987: Loss = 2.2066, Accuracy = 0.3700 Test Loss = 4.8996, Test Accuracy = 0.2665\n",
      "Iteration 988: Loss = 2.2366, Accuracy = 0.3800 Test Loss = 4.8931, Test Accuracy = 0.2676\n",
      "Iteration 989: Loss = 2.2531, Accuracy = 0.3300 Test Loss = 4.8970, Test Accuracy = 0.2651\n",
      "Iteration 990: Loss = 2.4270, Accuracy = 0.3200 Test Loss = 4.8857, Test Accuracy = 0.2667\n",
      "Iteration 991: Loss = 2.1816, Accuracy = 0.3700 Test Loss = 4.8874, Test Accuracy = 0.2676\n",
      "Iteration 992: Loss = 2.2359, Accuracy = 0.3200 Test Loss = 4.8857, Test Accuracy = 0.2673\n",
      "Iteration 993: Loss = 2.0731, Accuracy = 0.3400 Test Loss = 4.8801, Test Accuracy = 0.2682\n",
      "Iteration 994: Loss = 2.3083, Accuracy = 0.3100 Test Loss = 4.8708, Test Accuracy = 0.2672\n",
      "Iteration 995: Loss = 2.0394, Accuracy = 0.4200 Test Loss = 4.8675, Test Accuracy = 0.2658\n",
      "Iteration 996: Loss = 2.3330, Accuracy = 0.3700 Test Loss = 4.8645, Test Accuracy = 0.2671\n",
      "Iteration 997: Loss = 2.2660, Accuracy = 0.3600 Test Loss = 4.8665, Test Accuracy = 0.2667\n",
      "Iteration 998: Loss = 2.2115, Accuracy = 0.3900 Test Loss = 4.8615, Test Accuracy = 0.2684\n",
      "Iteration 999: Loss = 2.2113, Accuracy = 0.3600 Test Loss = 4.8544, Test Accuracy = 0.2677\n",
      "Iteration 1000: Loss = 1.9991, Accuracy = 0.3200 Test Loss = 4.8544, Test Accuracy = 0.2687\n",
      "Iteration 1001: Loss = 2.3278, Accuracy = 0.4100 Test Loss = 4.8464, Test Accuracy = 0.2691\n",
      "Iteration 1002: Loss = 2.3055, Accuracy = 0.3400 Test Loss = 4.8450, Test Accuracy = 0.2678\n",
      "Iteration 1003: Loss = 2.1318, Accuracy = 0.3100 Test Loss = 4.8383, Test Accuracy = 0.2662\n",
      "Iteration 1004: Loss = 2.2451, Accuracy = 0.3600 Test Loss = 4.8361, Test Accuracy = 0.2682\n",
      "Iteration 1005: Loss = 2.1439, Accuracy = 0.4200 Test Loss = 4.8343, Test Accuracy = 0.2673\n",
      "Iteration 1006: Loss = 2.1947, Accuracy = 0.3800 Test Loss = 4.8327, Test Accuracy = 0.2686\n",
      "Iteration 1007: Loss = 2.2083, Accuracy = 0.3200 Test Loss = 4.8214, Test Accuracy = 0.2675\n",
      "Iteration 1008: Loss = 2.3277, Accuracy = 0.3500 Test Loss = 4.8187, Test Accuracy = 0.2684\n",
      "Iteration 1009: Loss = 2.1124, Accuracy = 0.3400 Test Loss = 4.8175, Test Accuracy = 0.2697\n",
      "Iteration 1010: Loss = 2.1338, Accuracy = 0.4200 Test Loss = 4.8181, Test Accuracy = 0.2679\n",
      "Iteration 1011: Loss = 2.2019, Accuracy = 0.3900 Test Loss = 4.8124, Test Accuracy = 0.2679\n",
      "Iteration 1012: Loss = 2.1882, Accuracy = 0.3100 Test Loss = 4.8169, Test Accuracy = 0.2706\n",
      "Iteration 1013: Loss = 2.1128, Accuracy = 0.3900 Test Loss = 4.8062, Test Accuracy = 0.2695\n",
      "Iteration 1014: Loss = 2.1907, Accuracy = 0.3800 Test Loss = 4.7999, Test Accuracy = 0.2707\n",
      "Iteration 1015: Loss = 2.2226, Accuracy = 0.3300 Test Loss = 4.7931, Test Accuracy = 0.2695\n",
      "Iteration 1016: Loss = 2.4607, Accuracy = 0.3400 Test Loss = 4.7913, Test Accuracy = 0.2685\n",
      "Iteration 1017: Loss = 2.0774, Accuracy = 0.4000 Test Loss = 4.7902, Test Accuracy = 0.2696\n",
      "Iteration 1018: Loss = 1.9980, Accuracy = 0.3700 Test Loss = 4.7913, Test Accuracy = 0.2698\n",
      "Iteration 1019: Loss = 2.1888, Accuracy = 0.4200 Test Loss = 4.7793, Test Accuracy = 0.2703\n",
      "Iteration 1020: Loss = 2.3833, Accuracy = 0.3000 Test Loss = 4.7845, Test Accuracy = 0.2694\n",
      "Iteration 1021: Loss = 2.1325, Accuracy = 0.3700 Test Loss = 4.7809, Test Accuracy = 0.2704\n",
      "Iteration 1022: Loss = 2.2858, Accuracy = 0.3800 Test Loss = 4.7725, Test Accuracy = 0.2704\n",
      "Iteration 1023: Loss = 2.1630, Accuracy = 0.3200 Test Loss = 4.7667, Test Accuracy = 0.2693\n",
      "Iteration 1024: Loss = 2.1953, Accuracy = 0.3700 Test Loss = 4.7667, Test Accuracy = 0.2696\n",
      "Iteration 1025: Loss = 2.1600, Accuracy = 0.3600 Test Loss = 4.7630, Test Accuracy = 0.2699\n",
      "Iteration 1026: Loss = 2.2434, Accuracy = 0.3100 Test Loss = 4.7599, Test Accuracy = 0.2704\n",
      "Iteration 1027: Loss = 2.1457, Accuracy = 0.3100 Test Loss = 4.7545, Test Accuracy = 0.2708\n",
      "Iteration 1028: Loss = 2.2490, Accuracy = 0.3800 Test Loss = 4.7544, Test Accuracy = 0.2724\n",
      "Iteration 1029: Loss = 2.0053, Accuracy = 0.3200 Test Loss = 4.7515, Test Accuracy = 0.2718\n",
      "Iteration 1030: Loss = 2.0438, Accuracy = 0.2300 Test Loss = 4.7440, Test Accuracy = 0.2712\n",
      "Iteration 1031: Loss = 2.2122, Accuracy = 0.3500 Test Loss = 4.7374, Test Accuracy = 0.2714\n",
      "Iteration 1032: Loss = 2.2173, Accuracy = 0.4000 Test Loss = 4.7350, Test Accuracy = 0.2725\n",
      "Iteration 1033: Loss = 2.1734, Accuracy = 0.3700 Test Loss = 4.7394, Test Accuracy = 0.2737\n",
      "Iteration 1034: Loss = 2.1181, Accuracy = 0.4100 Test Loss = 4.7344, Test Accuracy = 0.2705\n",
      "Iteration 1035: Loss = 2.0710, Accuracy = 0.4100 Test Loss = 4.7259, Test Accuracy = 0.2718\n",
      "Iteration 1036: Loss = 1.9657, Accuracy = 0.3500 Test Loss = 4.7245, Test Accuracy = 0.2735\n",
      "Iteration 1037: Loss = 2.3388, Accuracy = 0.3400 Test Loss = 4.7191, Test Accuracy = 0.2732\n",
      "Iteration 1038: Loss = 2.1364, Accuracy = 0.3400 Test Loss = 4.7168, Test Accuracy = 0.2719\n",
      "Iteration 1039: Loss = 2.0400, Accuracy = 0.4400 Test Loss = 4.7161, Test Accuracy = 0.2720\n",
      "Iteration 1040: Loss = 2.2541, Accuracy = 0.3800 Test Loss = 4.7126, Test Accuracy = 0.2707\n",
      "Iteration 1041: Loss = 2.0056, Accuracy = 0.4400 Test Loss = 4.7064, Test Accuracy = 0.2716\n",
      "Iteration 1042: Loss = 2.1396, Accuracy = 0.3500 Test Loss = 4.7034, Test Accuracy = 0.2714\n",
      "Iteration 1043: Loss = 1.9338, Accuracy = 0.3500 Test Loss = 4.6985, Test Accuracy = 0.2715\n",
      "Iteration 1044: Loss = 2.0956, Accuracy = 0.4200 Test Loss = 4.6960, Test Accuracy = 0.2722\n",
      "Iteration 1045: Loss = 2.2043, Accuracy = 0.2900 Test Loss = 4.6929, Test Accuracy = 0.2719\n",
      "Iteration 1046: Loss = 2.3861, Accuracy = 0.3700 Test Loss = 4.6893, Test Accuracy = 0.2734\n",
      "Iteration 1047: Loss = 2.1436, Accuracy = 0.4200 Test Loss = 4.6831, Test Accuracy = 0.2712\n",
      "Iteration 1048: Loss = 2.0332, Accuracy = 0.3000 Test Loss = 4.6911, Test Accuracy = 0.2716\n",
      "Iteration 1049: Loss = 2.0522, Accuracy = 0.3500 Test Loss = 4.6836, Test Accuracy = 0.2719\n",
      "Iteration 1050: Loss = 2.1408, Accuracy = 0.2900 Test Loss = 4.6775, Test Accuracy = 0.2729\n",
      "Iteration 1051: Loss = 2.0554, Accuracy = 0.3800 Test Loss = 4.6827, Test Accuracy = 0.2748\n",
      "Iteration 1052: Loss = 1.9887, Accuracy = 0.3400 Test Loss = 4.6702, Test Accuracy = 0.2726\n",
      "Iteration 1053: Loss = 2.2412, Accuracy = 0.3700 Test Loss = 4.6639, Test Accuracy = 0.2729\n",
      "Iteration 1054: Loss = 2.1104, Accuracy = 0.3300 Test Loss = 4.6717, Test Accuracy = 0.2729\n",
      "Iteration 1055: Loss = 2.1451, Accuracy = 0.3700 Test Loss = 4.6630, Test Accuracy = 0.2728\n",
      "Iteration 1056: Loss = 2.1239, Accuracy = 0.3700 Test Loss = 4.6597, Test Accuracy = 0.2747\n",
      "Iteration 1057: Loss = 1.9839, Accuracy = 0.4600 Test Loss = 4.6528, Test Accuracy = 0.2734\n",
      "Iteration 1058: Loss = 2.0413, Accuracy = 0.4400 Test Loss = 4.6502, Test Accuracy = 0.2749\n",
      "Iteration 1059: Loss = 2.0232, Accuracy = 0.3800 Test Loss = 4.6477, Test Accuracy = 0.2741\n",
      "Iteration 1060: Loss = 1.9494, Accuracy = 0.4700 Test Loss = 4.6449, Test Accuracy = 0.2749\n",
      "Iteration 1061: Loss = 1.9396, Accuracy = 0.4300 Test Loss = 4.6473, Test Accuracy = 0.2739\n",
      "Iteration 1062: Loss = 2.2696, Accuracy = 0.3800 Test Loss = 4.6362, Test Accuracy = 0.2760\n",
      "Iteration 1063: Loss = 1.9794, Accuracy = 0.3500 Test Loss = 4.6356, Test Accuracy = 0.2737\n",
      "Iteration 1064: Loss = 1.9360, Accuracy = 0.3800 Test Loss = 4.6350, Test Accuracy = 0.2752\n",
      "Iteration 1065: Loss = 2.1516, Accuracy = 0.3700 Test Loss = 4.6300, Test Accuracy = 0.2744\n",
      "Iteration 1066: Loss = 2.1599, Accuracy = 0.3100 Test Loss = 4.6283, Test Accuracy = 0.2740\n",
      "Iteration 1067: Loss = 1.9980, Accuracy = 0.4800 Test Loss = 4.6300, Test Accuracy = 0.2740\n",
      "Iteration 1068: Loss = 1.8876, Accuracy = 0.3600 Test Loss = 4.6217, Test Accuracy = 0.2741\n",
      "Iteration 1069: Loss = 2.1212, Accuracy = 0.4400 Test Loss = 4.6154, Test Accuracy = 0.2749\n",
      "Iteration 1070: Loss = 2.2100, Accuracy = 0.3600 Test Loss = 4.6198, Test Accuracy = 0.2742\n",
      "Iteration 1071: Loss = 2.0386, Accuracy = 0.3500 Test Loss = 4.6103, Test Accuracy = 0.2743\n",
      "Iteration 1072: Loss = 1.9861, Accuracy = 0.3600 Test Loss = 4.6078, Test Accuracy = 0.2749\n",
      "Iteration 1073: Loss = 1.9700, Accuracy = 0.3300 Test Loss = 4.6033, Test Accuracy = 0.2750\n",
      "Iteration 1074: Loss = 2.1025, Accuracy = 0.3800 Test Loss = 4.6042, Test Accuracy = 0.2753\n",
      "Iteration 1075: Loss = 2.1107, Accuracy = 0.3700 Test Loss = 4.6007, Test Accuracy = 0.2732\n",
      "Iteration 1076: Loss = 1.9946, Accuracy = 0.3900 Test Loss = 4.5961, Test Accuracy = 0.2749\n",
      "Iteration 1077: Loss = 2.0920, Accuracy = 0.3800 Test Loss = 4.5925, Test Accuracy = 0.2743\n",
      "Iteration 1078: Loss = 2.0881, Accuracy = 0.3600 Test Loss = 4.5992, Test Accuracy = 0.2749\n",
      "Iteration 1079: Loss = 2.2034, Accuracy = 0.3900 Test Loss = 4.5924, Test Accuracy = 0.2740\n",
      "Iteration 1080: Loss = 2.0299, Accuracy = 0.3400 Test Loss = 4.5837, Test Accuracy = 0.2766\n",
      "Iteration 1081: Loss = 1.9491, Accuracy = 0.4200 Test Loss = 4.5774, Test Accuracy = 0.2756\n",
      "Iteration 1082: Loss = 2.2530, Accuracy = 0.4300 Test Loss = 4.5751, Test Accuracy = 0.2749\n",
      "Iteration 1083: Loss = 1.9933, Accuracy = 0.3400 Test Loss = 4.5763, Test Accuracy = 0.2740\n",
      "Iteration 1084: Loss = 2.1798, Accuracy = 0.4000 Test Loss = 4.5711, Test Accuracy = 0.2777\n",
      "Iteration 1085: Loss = 2.0843, Accuracy = 0.4100 Test Loss = 4.5632, Test Accuracy = 0.2774\n",
      "Iteration 1086: Loss = 2.1430, Accuracy = 0.3200 Test Loss = 4.5691, Test Accuracy = 0.2755\n",
      "Iteration 1087: Loss = 2.0250, Accuracy = 0.3700 Test Loss = 4.5609, Test Accuracy = 0.2764\n",
      "Iteration 1088: Loss = 1.9815, Accuracy = 0.3800 Test Loss = 4.5569, Test Accuracy = 0.2755\n",
      "Iteration 1089: Loss = 2.1002, Accuracy = 0.3500 Test Loss = 4.5551, Test Accuracy = 0.2764\n",
      "Iteration 1090: Loss = 1.8757, Accuracy = 0.3800 Test Loss = 4.5590, Test Accuracy = 0.2762\n",
      "Iteration 1091: Loss = 2.2624, Accuracy = 0.3500 Test Loss = 4.5442, Test Accuracy = 0.2774\n",
      "Iteration 1092: Loss = 2.0120, Accuracy = 0.3400 Test Loss = 4.5482, Test Accuracy = 0.2769\n",
      "Iteration 1093: Loss = 1.9057, Accuracy = 0.3800 Test Loss = 4.5398, Test Accuracy = 0.2770\n",
      "Iteration 1094: Loss = 2.0042, Accuracy = 0.4000 Test Loss = 4.5380, Test Accuracy = 0.2758\n",
      "Iteration 1095: Loss = 1.9440, Accuracy = 0.4700 Test Loss = 4.5359, Test Accuracy = 0.2760\n",
      "Iteration 1096: Loss = 2.0822, Accuracy = 0.3200 Test Loss = 4.5341, Test Accuracy = 0.2763\n",
      "Iteration 1097: Loss = 1.9924, Accuracy = 0.4300 Test Loss = 4.5312, Test Accuracy = 0.2757\n",
      "Iteration 1098: Loss = 2.0054, Accuracy = 0.3800 Test Loss = 4.5226, Test Accuracy = 0.2777\n",
      "Iteration 1099: Loss = 1.8845, Accuracy = 0.4200 Test Loss = 4.5283, Test Accuracy = 0.2763\n",
      "Iteration 1100: Loss = 1.8558, Accuracy = 0.3300 Test Loss = 4.5210, Test Accuracy = 0.2757\n",
      "Iteration 1101: Loss = 1.9841, Accuracy = 0.3500 Test Loss = 4.5160, Test Accuracy = 0.2758\n",
      "Iteration 1102: Loss = 1.9233, Accuracy = 0.3600 Test Loss = 4.5184, Test Accuracy = 0.2780\n",
      "Iteration 1103: Loss = 2.0203, Accuracy = 0.3600 Test Loss = 4.5104, Test Accuracy = 0.2773\n",
      "Iteration 1104: Loss = 2.0811, Accuracy = 0.3000 Test Loss = 4.5093, Test Accuracy = 0.2782\n",
      "Iteration 1105: Loss = 2.3432, Accuracy = 0.3100 Test Loss = 4.5099, Test Accuracy = 0.2764\n",
      "Iteration 1106: Loss = 1.9020, Accuracy = 0.4300 Test Loss = 4.5004, Test Accuracy = 0.2795\n",
      "Iteration 1107: Loss = 1.9223, Accuracy = 0.3800 Test Loss = 4.4970, Test Accuracy = 0.2793\n",
      "Iteration 1108: Loss = 1.8987, Accuracy = 0.3300 Test Loss = 4.4956, Test Accuracy = 0.2780\n",
      "Iteration 1109: Loss = 1.9268, Accuracy = 0.4500 Test Loss = 4.4903, Test Accuracy = 0.2797\n",
      "Iteration 1110: Loss = 1.8577, Accuracy = 0.5400 Test Loss = 4.4869, Test Accuracy = 0.2783\n",
      "Iteration 1111: Loss = 1.8169, Accuracy = 0.4200 Test Loss = 4.4842, Test Accuracy = 0.2781\n",
      "Iteration 1112: Loss = 2.0322, Accuracy = 0.3300 Test Loss = 4.4843, Test Accuracy = 0.2781\n",
      "Iteration 1113: Loss = 1.9722, Accuracy = 0.4100 Test Loss = 4.4792, Test Accuracy = 0.2788\n",
      "Iteration 1114: Loss = 1.9556, Accuracy = 0.4000 Test Loss = 4.4800, Test Accuracy = 0.2789\n",
      "Iteration 1115: Loss = 1.7783, Accuracy = 0.4400 Test Loss = 4.4779, Test Accuracy = 0.2782\n",
      "Iteration 1116: Loss = 2.0620, Accuracy = 0.3700 Test Loss = 4.4723, Test Accuracy = 0.2798\n",
      "Iteration 1117: Loss = 1.8751, Accuracy = 0.4400 Test Loss = 4.4712, Test Accuracy = 0.2788\n",
      "Iteration 1118: Loss = 2.1420, Accuracy = 0.4100 Test Loss = 4.4665, Test Accuracy = 0.2781\n",
      "Iteration 1119: Loss = 2.0638, Accuracy = 0.3400 Test Loss = 4.4597, Test Accuracy = 0.2800\n",
      "Iteration 1120: Loss = 2.0679, Accuracy = 0.4100 Test Loss = 4.4574, Test Accuracy = 0.2788\n",
      "Iteration 1121: Loss = 1.9634, Accuracy = 0.3600 Test Loss = 4.4522, Test Accuracy = 0.2790\n",
      "Iteration 1122: Loss = 2.0437, Accuracy = 0.3500 Test Loss = 4.4501, Test Accuracy = 0.2796\n",
      "Iteration 1123: Loss = 2.0323, Accuracy = 0.2900 Test Loss = 4.4480, Test Accuracy = 0.2774\n",
      "Iteration 1124: Loss = 1.8386, Accuracy = 0.4000 Test Loss = 4.4474, Test Accuracy = 0.2804\n",
      "Iteration 1125: Loss = 1.8595, Accuracy = 0.4300 Test Loss = 4.4496, Test Accuracy = 0.2786\n",
      "Iteration 1126: Loss = 1.8821, Accuracy = 0.4200 Test Loss = 4.4446, Test Accuracy = 0.2774\n",
      "Iteration 1127: Loss = 1.9669, Accuracy = 0.4100 Test Loss = 4.4432, Test Accuracy = 0.2788\n",
      "Iteration 1128: Loss = 2.0826, Accuracy = 0.4000 Test Loss = 4.4398, Test Accuracy = 0.2803\n",
      "Iteration 1129: Loss = 1.8285, Accuracy = 0.3300 Test Loss = 4.4367, Test Accuracy = 0.2796\n",
      "Iteration 1130: Loss = 1.8220, Accuracy = 0.4000 Test Loss = 4.4313, Test Accuracy = 0.2812\n",
      "Iteration 1131: Loss = 1.9231, Accuracy = 0.3200 Test Loss = 4.4282, Test Accuracy = 0.2794\n",
      "Iteration 1132: Loss = 1.9349, Accuracy = 0.4200 Test Loss = 4.4213, Test Accuracy = 0.2789\n",
      "Iteration 1133: Loss = 1.9823, Accuracy = 0.3300 Test Loss = 4.4236, Test Accuracy = 0.2783\n",
      "Iteration 1134: Loss = 2.1453, Accuracy = 0.3400 Test Loss = 4.4213, Test Accuracy = 0.2800\n",
      "Iteration 1135: Loss = 1.9950, Accuracy = 0.3600 Test Loss = 4.4175, Test Accuracy = 0.2789\n",
      "Iteration 1136: Loss = 1.7108, Accuracy = 0.4100 Test Loss = 4.4080, Test Accuracy = 0.2811\n",
      "Iteration 1137: Loss = 1.7595, Accuracy = 0.4700 Test Loss = 4.4107, Test Accuracy = 0.2819\n",
      "Iteration 1138: Loss = 1.9677, Accuracy = 0.3700 Test Loss = 4.4056, Test Accuracy = 0.2789\n",
      "Iteration 1139: Loss = 1.9058, Accuracy = 0.4400 Test Loss = 4.4032, Test Accuracy = 0.2799\n",
      "Iteration 1140: Loss = 2.0582, Accuracy = 0.3800 Test Loss = 4.3985, Test Accuracy = 0.2804\n",
      "Iteration 1141: Loss = 1.9298, Accuracy = 0.4000 Test Loss = 4.4039, Test Accuracy = 0.2794\n",
      "Iteration 1142: Loss = 1.9538, Accuracy = 0.4300 Test Loss = 4.3989, Test Accuracy = 0.2799\n",
      "Iteration 1143: Loss = 1.9786, Accuracy = 0.3800 Test Loss = 4.4011, Test Accuracy = 0.2809\n",
      "Iteration 1144: Loss = 1.8629, Accuracy = 0.3800 Test Loss = 4.3862, Test Accuracy = 0.2821\n",
      "Iteration 1145: Loss = 1.7666, Accuracy = 0.3700 Test Loss = 4.3839, Test Accuracy = 0.2833\n",
      "Iteration 1146: Loss = 1.9593, Accuracy = 0.3400 Test Loss = 4.3880, Test Accuracy = 0.2800\n",
      "Iteration 1147: Loss = 1.7750, Accuracy = 0.4100 Test Loss = 4.3855, Test Accuracy = 0.2813\n",
      "Iteration 1148: Loss = 1.7329, Accuracy = 0.4600 Test Loss = 4.3760, Test Accuracy = 0.2812\n",
      "Iteration 1149: Loss = 1.7805, Accuracy = 0.3900 Test Loss = 4.3751, Test Accuracy = 0.2818\n",
      "Iteration 1150: Loss = 2.0251, Accuracy = 0.4100 Test Loss = 4.3703, Test Accuracy = 0.2833\n",
      "Iteration 1151: Loss = 2.0264, Accuracy = 0.3400 Test Loss = 4.3694, Test Accuracy = 0.2811\n",
      "Iteration 1152: Loss = 1.9340, Accuracy = 0.4100 Test Loss = 4.3657, Test Accuracy = 0.2821\n",
      "Iteration 1153: Loss = 1.9245, Accuracy = 0.3700 Test Loss = 4.3626, Test Accuracy = 0.2815\n",
      "Iteration 1154: Loss = 1.8926, Accuracy = 0.3900 Test Loss = 4.3664, Test Accuracy = 0.2817\n",
      "Iteration 1155: Loss = 1.9666, Accuracy = 0.3700 Test Loss = 4.3598, Test Accuracy = 0.2827\n",
      "Iteration 1156: Loss = 1.9307, Accuracy = 0.3600 Test Loss = 4.3533, Test Accuracy = 0.2831\n",
      "Iteration 1157: Loss = 1.8480, Accuracy = 0.3400 Test Loss = 4.3562, Test Accuracy = 0.2808\n",
      "Iteration 1158: Loss = 1.7207, Accuracy = 0.3900 Test Loss = 4.3525, Test Accuracy = 0.2821\n",
      "Iteration 1159: Loss = 1.8038, Accuracy = 0.3500 Test Loss = 4.3503, Test Accuracy = 0.2836\n",
      "Iteration 1160: Loss = 1.8808, Accuracy = 0.3900 Test Loss = 4.3445, Test Accuracy = 0.2840\n",
      "Iteration 1161: Loss = 1.7455, Accuracy = 0.4300 Test Loss = 4.3425, Test Accuracy = 0.2829\n",
      "Iteration 1162: Loss = 1.8271, Accuracy = 0.4200 Test Loss = 4.3359, Test Accuracy = 0.2832\n",
      "Iteration 1163: Loss = 2.0628, Accuracy = 0.3100 Test Loss = 4.3344, Test Accuracy = 0.2821\n",
      "Iteration 1164: Loss = 1.9979, Accuracy = 0.4300 Test Loss = 4.3332, Test Accuracy = 0.2836\n",
      "Iteration 1165: Loss = 1.7948, Accuracy = 0.4600 Test Loss = 4.3287, Test Accuracy = 0.2824\n",
      "Iteration 1166: Loss = 1.7996, Accuracy = 0.5300 Test Loss = 4.3278, Test Accuracy = 0.2831\n",
      "Iteration 1167: Loss = 1.7410, Accuracy = 0.4200 Test Loss = 4.3306, Test Accuracy = 0.2832\n",
      "Iteration 1168: Loss = 1.9179, Accuracy = 0.3500 Test Loss = 4.3205, Test Accuracy = 0.2835\n",
      "Iteration 1169: Loss = 1.9401, Accuracy = 0.3600 Test Loss = 4.3183, Test Accuracy = 0.2819\n",
      "Iteration 1170: Loss = 1.8404, Accuracy = 0.4700 Test Loss = 4.3148, Test Accuracy = 0.2809\n",
      "Iteration 1171: Loss = 1.7973, Accuracy = 0.4500 Test Loss = 4.3140, Test Accuracy = 0.2820\n",
      "Iteration 1172: Loss = 1.8885, Accuracy = 0.2900 Test Loss = 4.3072, Test Accuracy = 0.2824\n",
      "Iteration 1173: Loss = 2.1411, Accuracy = 0.3100 Test Loss = 4.3117, Test Accuracy = 0.2827\n",
      "Iteration 1174: Loss = 1.7905, Accuracy = 0.4700 Test Loss = 4.3027, Test Accuracy = 0.2847\n",
      "Iteration 1175: Loss = 1.9791, Accuracy = 0.4300 Test Loss = 4.3087, Test Accuracy = 0.2831\n",
      "Iteration 1176: Loss = 1.8172, Accuracy = 0.4300 Test Loss = 4.3045, Test Accuracy = 0.2826\n",
      "Iteration 1177: Loss = 2.1415, Accuracy = 0.3700 Test Loss = 4.3015, Test Accuracy = 0.2841\n",
      "Iteration 1178: Loss = 1.7027, Accuracy = 0.4300 Test Loss = 4.3019, Test Accuracy = 0.2833\n",
      "Iteration 1179: Loss = 1.9151, Accuracy = 0.4200 Test Loss = 4.2931, Test Accuracy = 0.2838\n",
      "Iteration 1180: Loss = 1.8054, Accuracy = 0.4100 Test Loss = 4.2900, Test Accuracy = 0.2828\n",
      "Iteration 1181: Loss = 1.6415, Accuracy = 0.4400 Test Loss = 4.2850, Test Accuracy = 0.2833\n",
      "Iteration 1182: Loss = 1.7515, Accuracy = 0.4700 Test Loss = 4.2857, Test Accuracy = 0.2853\n",
      "Iteration 1183: Loss = 1.7652, Accuracy = 0.5000 Test Loss = 4.2845, Test Accuracy = 0.2827\n",
      "Iteration 1184: Loss = 1.8955, Accuracy = 0.3700 Test Loss = 4.2768, Test Accuracy = 0.2858\n",
      "Iteration 1185: Loss = 1.8193, Accuracy = 0.3900 Test Loss = 4.2737, Test Accuracy = 0.2846\n",
      "Iteration 1186: Loss = 1.9299, Accuracy = 0.3800 Test Loss = 4.2716, Test Accuracy = 0.2834\n",
      "Iteration 1187: Loss = 1.7212, Accuracy = 0.4300 Test Loss = 4.2688, Test Accuracy = 0.2843\n",
      "Iteration 1188: Loss = 1.8903, Accuracy = 0.3600 Test Loss = 4.2667, Test Accuracy = 0.2842\n",
      "Iteration 1189: Loss = 1.7818, Accuracy = 0.4000 Test Loss = 4.2642, Test Accuracy = 0.2843\n",
      "Iteration 1190: Loss = 1.5522, Accuracy = 0.4500 Test Loss = 4.2633, Test Accuracy = 0.2845\n",
      "Iteration 1191: Loss = 1.9206, Accuracy = 0.4300 Test Loss = 4.2590, Test Accuracy = 0.2865\n",
      "Iteration 1192: Loss = 1.8624, Accuracy = 0.3400 Test Loss = 4.2589, Test Accuracy = 0.2849\n",
      "Iteration 1193: Loss = 1.7861, Accuracy = 0.4200 Test Loss = 4.2542, Test Accuracy = 0.2877\n",
      "Iteration 1194: Loss = 1.8014, Accuracy = 0.4200 Test Loss = 4.2561, Test Accuracy = 0.2864\n",
      "Iteration 1195: Loss = 1.9287, Accuracy = 0.4300 Test Loss = 4.2460, Test Accuracy = 0.2853\n",
      "Iteration 1196: Loss = 1.9043, Accuracy = 0.4000 Test Loss = 4.2453, Test Accuracy = 0.2840\n",
      "Iteration 1197: Loss = 1.9133, Accuracy = 0.4100 Test Loss = 4.2407, Test Accuracy = 0.2871\n",
      "Iteration 1198: Loss = 1.7943, Accuracy = 0.4200 Test Loss = 4.2410, Test Accuracy = 0.2867\n",
      "Iteration 1199: Loss = 1.8776, Accuracy = 0.4100 Test Loss = 4.2377, Test Accuracy = 0.2850\n",
      "Iteration 1200: Loss = 1.9072, Accuracy = 0.4100 Test Loss = 4.2394, Test Accuracy = 0.2855\n",
      "Iteration 1201: Loss = 1.6976, Accuracy = 0.3400 Test Loss = 4.2315, Test Accuracy = 0.2842\n",
      "Iteration 1202: Loss = 1.9033, Accuracy = 0.3000 Test Loss = 4.2299, Test Accuracy = 0.2851\n",
      "Iteration 1203: Loss = 1.8435, Accuracy = 0.4800 Test Loss = 4.2283, Test Accuracy = 0.2850\n",
      "Iteration 1204: Loss = 1.7939, Accuracy = 0.4200 Test Loss = 4.2253, Test Accuracy = 0.2858\n",
      "Iteration 1205: Loss = 1.7242, Accuracy = 0.3900 Test Loss = 4.2218, Test Accuracy = 0.2864\n",
      "Iteration 1206: Loss = 1.6921, Accuracy = 0.5400 Test Loss = 4.2204, Test Accuracy = 0.2871\n",
      "Iteration 1207: Loss = 1.7036, Accuracy = 0.3800 Test Loss = 4.2139, Test Accuracy = 0.2863\n",
      "Iteration 1208: Loss = 1.8382, Accuracy = 0.3700 Test Loss = 4.2158, Test Accuracy = 0.2856\n",
      "Iteration 1209: Loss = 1.9706, Accuracy = 0.4200 Test Loss = 4.2076, Test Accuracy = 0.2856\n",
      "Iteration 1210: Loss = 1.8426, Accuracy = 0.4200 Test Loss = 4.2062, Test Accuracy = 0.2862\n",
      "Iteration 1211: Loss = 1.7965, Accuracy = 0.3000 Test Loss = 4.2062, Test Accuracy = 0.2863\n",
      "Iteration 1212: Loss = 1.8321, Accuracy = 0.5500 Test Loss = 4.2098, Test Accuracy = 0.2858\n",
      "Iteration 1213: Loss = 1.8642, Accuracy = 0.3800 Test Loss = 4.2049, Test Accuracy = 0.2872\n",
      "Iteration 1214: Loss = 1.9579, Accuracy = 0.2600 Test Loss = 4.1988, Test Accuracy = 0.2861\n",
      "Iteration 1215: Loss = 1.8196, Accuracy = 0.3400 Test Loss = 4.1922, Test Accuracy = 0.2885\n",
      "Iteration 1216: Loss = 1.6909, Accuracy = 0.4100 Test Loss = 4.1901, Test Accuracy = 0.2865\n",
      "Iteration 1217: Loss = 1.6695, Accuracy = 0.4200 Test Loss = 4.1894, Test Accuracy = 0.2872\n",
      "Iteration 1218: Loss = 1.8186, Accuracy = 0.3500 Test Loss = 4.1874, Test Accuracy = 0.2878\n",
      "Iteration 1219: Loss = 1.8114, Accuracy = 0.4900 Test Loss = 4.1851, Test Accuracy = 0.2869\n",
      "Iteration 1220: Loss = 1.8281, Accuracy = 0.3500 Test Loss = 4.1828, Test Accuracy = 0.2880\n",
      "Iteration 1221: Loss = 1.7553, Accuracy = 0.3700 Test Loss = 4.1805, Test Accuracy = 0.2868\n",
      "Iteration 1222: Loss = 1.8336, Accuracy = 0.4800 Test Loss = 4.1786, Test Accuracy = 0.2860\n",
      "Iteration 1223: Loss = 1.9336, Accuracy = 0.4000 Test Loss = 4.1754, Test Accuracy = 0.2869\n",
      "Iteration 1224: Loss = 1.8082, Accuracy = 0.3900 Test Loss = 4.1765, Test Accuracy = 0.2856\n",
      "Iteration 1225: Loss = 1.7496, Accuracy = 0.4400 Test Loss = 4.1676, Test Accuracy = 0.2892\n",
      "Iteration 1226: Loss = 1.7268, Accuracy = 0.4500 Test Loss = 4.1660, Test Accuracy = 0.2880\n",
      "Iteration 1227: Loss = 1.8068, Accuracy = 0.3500 Test Loss = 4.1632, Test Accuracy = 0.2881\n",
      "Iteration 1228: Loss = 1.6926, Accuracy = 0.3700 Test Loss = 4.1636, Test Accuracy = 0.2882\n",
      "Iteration 1229: Loss = 1.7363, Accuracy = 0.4400 Test Loss = 4.1583, Test Accuracy = 0.2884\n",
      "Iteration 1230: Loss = 1.8206, Accuracy = 0.3600 Test Loss = 4.1541, Test Accuracy = 0.2885\n",
      "Iteration 1231: Loss = 1.8319, Accuracy = 0.3400 Test Loss = 4.1532, Test Accuracy = 0.2895\n",
      "Iteration 1232: Loss = 1.7124, Accuracy = 0.3300 Test Loss = 4.1502, Test Accuracy = 0.2902\n",
      "Iteration 1233: Loss = 1.6914, Accuracy = 0.5000 Test Loss = 4.1506, Test Accuracy = 0.2904\n",
      "Iteration 1234: Loss = 1.8888, Accuracy = 0.3900 Test Loss = 4.1451, Test Accuracy = 0.2887\n",
      "Iteration 1235: Loss = 1.8811, Accuracy = 0.4600 Test Loss = 4.1434, Test Accuracy = 0.2897\n",
      "Iteration 1236: Loss = 1.8817, Accuracy = 0.3900 Test Loss = 4.1433, Test Accuracy = 0.2884\n",
      "Iteration 1237: Loss = 1.5759, Accuracy = 0.4000 Test Loss = 4.1417, Test Accuracy = 0.2886\n",
      "Iteration 1238: Loss = 1.6246, Accuracy = 0.3300 Test Loss = 4.1383, Test Accuracy = 0.2876\n",
      "Iteration 1239: Loss = 1.6568, Accuracy = 0.4100 Test Loss = 4.1352, Test Accuracy = 0.2886\n",
      "Iteration 1240: Loss = 1.6972, Accuracy = 0.4000 Test Loss = 4.1345, Test Accuracy = 0.2891\n",
      "Iteration 1241: Loss = 1.6749, Accuracy = 0.4200 Test Loss = 4.1260, Test Accuracy = 0.2894\n",
      "Iteration 1242: Loss = 1.6956, Accuracy = 0.3500 Test Loss = 4.1281, Test Accuracy = 0.2904\n",
      "Iteration 1243: Loss = 1.7546, Accuracy = 0.4100 Test Loss = 4.1212, Test Accuracy = 0.2887\n",
      "Iteration 1244: Loss = 1.8168, Accuracy = 0.3700 Test Loss = 4.1268, Test Accuracy = 0.2899\n",
      "Iteration 1245: Loss = 1.8912, Accuracy = 0.4300 Test Loss = 4.1214, Test Accuracy = 0.2898\n",
      "Iteration 1246: Loss = 1.7612, Accuracy = 0.3200 Test Loss = 4.1172, Test Accuracy = 0.2897\n",
      "Iteration 1247: Loss = 1.7732, Accuracy = 0.4400 Test Loss = 4.1186, Test Accuracy = 0.2891\n",
      "Iteration 1248: Loss = 1.8329, Accuracy = 0.4700 Test Loss = 4.1146, Test Accuracy = 0.2903\n",
      "Iteration 1249: Loss = 1.8108, Accuracy = 0.3900 Test Loss = 4.1103, Test Accuracy = 0.2905\n",
      "Iteration 1250: Loss = 1.8201, Accuracy = 0.3600 Test Loss = 4.1091, Test Accuracy = 0.2907\n",
      "Iteration 1251: Loss = 1.5974, Accuracy = 0.4600 Test Loss = 4.1111, Test Accuracy = 0.2898\n",
      "Iteration 1252: Loss = 1.6630, Accuracy = 0.4100 Test Loss = 4.1053, Test Accuracy = 0.2908\n",
      "Iteration 1253: Loss = 1.7306, Accuracy = 0.4900 Test Loss = 4.1020, Test Accuracy = 0.2903\n",
      "Iteration 1254: Loss = 1.7681, Accuracy = 0.3600 Test Loss = 4.0945, Test Accuracy = 0.2900\n",
      "Iteration 1255: Loss = 1.8172, Accuracy = 0.4400 Test Loss = 4.0941, Test Accuracy = 0.2906\n",
      "Iteration 1256: Loss = 1.9587, Accuracy = 0.3700 Test Loss = 4.0910, Test Accuracy = 0.2900\n",
      "Iteration 1257: Loss = 1.6009, Accuracy = 0.4200 Test Loss = 4.0928, Test Accuracy = 0.2918\n",
      "Iteration 1258: Loss = 1.8366, Accuracy = 0.4500 Test Loss = 4.0896, Test Accuracy = 0.2899\n",
      "Iteration 1259: Loss = 1.6819, Accuracy = 0.3800 Test Loss = 4.0817, Test Accuracy = 0.2892\n",
      "Iteration 1260: Loss = 1.7032, Accuracy = 0.4000 Test Loss = 4.0825, Test Accuracy = 0.2913\n",
      "Iteration 1261: Loss = 1.6536, Accuracy = 0.3900 Test Loss = 4.0776, Test Accuracy = 0.2916\n",
      "Iteration 1262: Loss = 1.6771, Accuracy = 0.3900 Test Loss = 4.0760, Test Accuracy = 0.2917\n",
      "Iteration 1263: Loss = 1.8188, Accuracy = 0.3400 Test Loss = 4.0733, Test Accuracy = 0.2897\n",
      "Iteration 1264: Loss = 1.7229, Accuracy = 0.4500 Test Loss = 4.0704, Test Accuracy = 0.2909\n",
      "Iteration 1265: Loss = 1.7449, Accuracy = 0.3800 Test Loss = 4.0694, Test Accuracy = 0.2936\n",
      "Iteration 1266: Loss = 1.7757, Accuracy = 0.3800 Test Loss = 4.0695, Test Accuracy = 0.2917\n",
      "Iteration 1267: Loss = 1.7655, Accuracy = 0.4100 Test Loss = 4.0658, Test Accuracy = 0.2912\n",
      "Iteration 1268: Loss = 1.6877, Accuracy = 0.4400 Test Loss = 4.0691, Test Accuracy = 0.2897\n",
      "Iteration 1269: Loss = 1.9268, Accuracy = 0.3600 Test Loss = 4.0612, Test Accuracy = 0.2930\n",
      "Iteration 1270: Loss = 1.7143, Accuracy = 0.3900 Test Loss = 4.0561, Test Accuracy = 0.2919\n",
      "Iteration 1271: Loss = 1.7696, Accuracy = 0.3700 Test Loss = 4.0550, Test Accuracy = 0.2918\n",
      "Iteration 1272: Loss = 1.7616, Accuracy = 0.4200 Test Loss = 4.0540, Test Accuracy = 0.2924\n",
      "Iteration 1273: Loss = 1.6487, Accuracy = 0.5100 Test Loss = 4.0521, Test Accuracy = 0.2920\n",
      "Iteration 1274: Loss = 1.7041, Accuracy = 0.3700 Test Loss = 4.0493, Test Accuracy = 0.2928\n",
      "Iteration 1275: Loss = 1.8002, Accuracy = 0.3200 Test Loss = 4.0473, Test Accuracy = 0.2912\n",
      "Iteration 1276: Loss = 1.6999, Accuracy = 0.4500 Test Loss = 4.0475, Test Accuracy = 0.2915\n",
      "Iteration 1277: Loss = 1.7340, Accuracy = 0.4300 Test Loss = 4.0374, Test Accuracy = 0.2931\n",
      "Iteration 1278: Loss = 1.8410, Accuracy = 0.3900 Test Loss = 4.0345, Test Accuracy = 0.2921\n",
      "Iteration 1279: Loss = 1.4191, Accuracy = 0.4400 Test Loss = 4.0353, Test Accuracy = 0.2928\n",
      "Iteration 1280: Loss = 1.6333, Accuracy = 0.4200 Test Loss = 4.0359, Test Accuracy = 0.2922\n",
      "Iteration 1281: Loss = 1.7025, Accuracy = 0.3900 Test Loss = 4.0290, Test Accuracy = 0.2918\n",
      "Iteration 1282: Loss = 1.4933, Accuracy = 0.5000 Test Loss = 4.0249, Test Accuracy = 0.2924\n",
      "Iteration 1283: Loss = 1.8286, Accuracy = 0.3200 Test Loss = 4.0255, Test Accuracy = 0.2930\n",
      "Iteration 1284: Loss = 1.7072, Accuracy = 0.4800 Test Loss = 4.0268, Test Accuracy = 0.2939\n",
      "Iteration 1285: Loss = 1.7392, Accuracy = 0.3600 Test Loss = 4.0202, Test Accuracy = 0.2935\n",
      "Iteration 1286: Loss = 1.7613, Accuracy = 0.4300 Test Loss = 4.0224, Test Accuracy = 0.2941\n",
      "Iteration 1287: Loss = 1.8907, Accuracy = 0.3000 Test Loss = 4.0196, Test Accuracy = 0.2953\n",
      "Iteration 1288: Loss = 1.7005, Accuracy = 0.4100 Test Loss = 4.0120, Test Accuracy = 0.2934\n",
      "Iteration 1289: Loss = 1.6540, Accuracy = 0.4400 Test Loss = 4.0140, Test Accuracy = 0.2926\n",
      "Iteration 1290: Loss = 1.6648, Accuracy = 0.3400 Test Loss = 4.0097, Test Accuracy = 0.2939\n",
      "Iteration 1291: Loss = 1.7210, Accuracy = 0.3800 Test Loss = 4.0111, Test Accuracy = 0.2941\n",
      "Iteration 1292: Loss = 1.6921, Accuracy = 0.3700 Test Loss = 4.0053, Test Accuracy = 0.2941\n",
      "Iteration 1293: Loss = 1.7454, Accuracy = 0.4600 Test Loss = 4.0070, Test Accuracy = 0.2937\n",
      "Iteration 1294: Loss = 1.6908, Accuracy = 0.4200 Test Loss = 4.0074, Test Accuracy = 0.2937\n",
      "Iteration 1295: Loss = 1.7580, Accuracy = 0.4400 Test Loss = 3.9991, Test Accuracy = 0.2938\n",
      "Iteration 1296: Loss = 1.6663, Accuracy = 0.4700 Test Loss = 3.9933, Test Accuracy = 0.2947\n",
      "Iteration 1297: Loss = 1.7086, Accuracy = 0.4900 Test Loss = 3.9924, Test Accuracy = 0.2946\n",
      "Iteration 1298: Loss = 1.6361, Accuracy = 0.4200 Test Loss = 3.9951, Test Accuracy = 0.2949\n",
      "Iteration 1299: Loss = 1.7695, Accuracy = 0.4000 Test Loss = 3.9923, Test Accuracy = 0.2939\n",
      "Iteration 1300: Loss = 1.5946, Accuracy = 0.3500 Test Loss = 3.9865, Test Accuracy = 0.2932\n",
      "Iteration 1301: Loss = 1.6819, Accuracy = 0.3700 Test Loss = 3.9809, Test Accuracy = 0.2943\n",
      "Iteration 1302: Loss = 1.6578, Accuracy = 0.4700 Test Loss = 3.9822, Test Accuracy = 0.2953\n",
      "Iteration 1303: Loss = 1.8078, Accuracy = 0.4000 Test Loss = 3.9842, Test Accuracy = 0.2946\n",
      "Iteration 1304: Loss = 1.6467, Accuracy = 0.4100 Test Loss = 3.9787, Test Accuracy = 0.2948\n",
      "Iteration 1305: Loss = 1.6309, Accuracy = 0.4100 Test Loss = 3.9786, Test Accuracy = 0.2933\n",
      "Iteration 1306: Loss = 1.6381, Accuracy = 0.3400 Test Loss = 3.9730, Test Accuracy = 0.2942\n",
      "Iteration 1307: Loss = 1.5689, Accuracy = 0.4500 Test Loss = 3.9687, Test Accuracy = 0.2951\n",
      "Iteration 1308: Loss = 1.5911, Accuracy = 0.4800 Test Loss = 3.9683, Test Accuracy = 0.2937\n",
      "Iteration 1309: Loss = 1.5682, Accuracy = 0.4200 Test Loss = 3.9643, Test Accuracy = 0.2959\n",
      "Iteration 1310: Loss = 1.7035, Accuracy = 0.4200 Test Loss = 3.9617, Test Accuracy = 0.2944\n",
      "Iteration 1311: Loss = 1.5191, Accuracy = 0.4700 Test Loss = 3.9641, Test Accuracy = 0.2939\n",
      "Iteration 1312: Loss = 1.7194, Accuracy = 0.4000 Test Loss = 3.9572, Test Accuracy = 0.2965\n",
      "Iteration 1313: Loss = 1.5054, Accuracy = 0.4000 Test Loss = 3.9574, Test Accuracy = 0.2938\n",
      "Iteration 1314: Loss = 1.5680, Accuracy = 0.4400 Test Loss = 3.9558, Test Accuracy = 0.2956\n",
      "Iteration 1315: Loss = 1.6342, Accuracy = 0.4500 Test Loss = 3.9522, Test Accuracy = 0.2945\n",
      "Iteration 1316: Loss = 1.5883, Accuracy = 0.4200 Test Loss = 3.9487, Test Accuracy = 0.2947\n",
      "Iteration 1317: Loss = 1.6378, Accuracy = 0.5100 Test Loss = 3.9490, Test Accuracy = 0.2952\n",
      "Iteration 1318: Loss = 1.6363, Accuracy = 0.3400 Test Loss = 3.9460, Test Accuracy = 0.2955\n",
      "Iteration 1319: Loss = 1.8544, Accuracy = 0.3500 Test Loss = 3.9404, Test Accuracy = 0.2966\n",
      "Iteration 1320: Loss = 1.6850, Accuracy = 0.4400 Test Loss = 3.9431, Test Accuracy = 0.2949\n",
      "Iteration 1321: Loss = 1.6697, Accuracy = 0.3600 Test Loss = 3.9448, Test Accuracy = 0.2939\n",
      "Iteration 1322: Loss = 1.7399, Accuracy = 0.3900 Test Loss = 3.9373, Test Accuracy = 0.2945\n",
      "Iteration 1323: Loss = 1.9733, Accuracy = 0.4000 Test Loss = 3.9391, Test Accuracy = 0.2952\n",
      "Iteration 1324: Loss = 1.5592, Accuracy = 0.3500 Test Loss = 3.9316, Test Accuracy = 0.2961\n",
      "Iteration 1325: Loss = 1.5066, Accuracy = 0.4000 Test Loss = 3.9307, Test Accuracy = 0.2950\n",
      "Iteration 1326: Loss = 1.7028, Accuracy = 0.3500 Test Loss = 3.9264, Test Accuracy = 0.2966\n",
      "Iteration 1327: Loss = 1.6683, Accuracy = 0.3900 Test Loss = 3.9241, Test Accuracy = 0.2967\n",
      "Iteration 1328: Loss = 1.6409, Accuracy = 0.4800 Test Loss = 3.9211, Test Accuracy = 0.2954\n",
      "Iteration 1329: Loss = 1.5667, Accuracy = 0.5000 Test Loss = 3.9179, Test Accuracy = 0.2970\n",
      "Iteration 1330: Loss = 1.7502, Accuracy = 0.4200 Test Loss = 3.9165, Test Accuracy = 0.2981\n",
      "Iteration 1331: Loss = 1.6068, Accuracy = 0.4400 Test Loss = 3.9185, Test Accuracy = 0.2988\n",
      "Iteration 1332: Loss = 1.6535, Accuracy = 0.4300 Test Loss = 3.9130, Test Accuracy = 0.2975\n",
      "Iteration 1333: Loss = 1.6262, Accuracy = 0.4300 Test Loss = 3.9141, Test Accuracy = 0.2964\n",
      "Iteration 1334: Loss = 1.6977, Accuracy = 0.3400 Test Loss = 3.9071, Test Accuracy = 0.2975\n",
      "Iteration 1335: Loss = 1.6373, Accuracy = 0.4100 Test Loss = 3.9069, Test Accuracy = 0.2979\n",
      "Iteration 1336: Loss = 1.7705, Accuracy = 0.3600 Test Loss = 3.9061, Test Accuracy = 0.2975\n",
      "Iteration 1337: Loss = 1.5337, Accuracy = 0.4500 Test Loss = 3.9035, Test Accuracy = 0.2976\n",
      "Iteration 1338: Loss = 1.6763, Accuracy = 0.4500 Test Loss = 3.9044, Test Accuracy = 0.2966\n",
      "Iteration 1339: Loss = 1.5729, Accuracy = 0.3700 Test Loss = 3.8975, Test Accuracy = 0.2984\n",
      "Iteration 1340: Loss = 1.7374, Accuracy = 0.3800 Test Loss = 3.8937, Test Accuracy = 0.2971\n",
      "Iteration 1341: Loss = 1.4557, Accuracy = 0.5000 Test Loss = 3.8949, Test Accuracy = 0.2993\n",
      "Iteration 1342: Loss = 1.5213, Accuracy = 0.4700 Test Loss = 3.8920, Test Accuracy = 0.2987\n",
      "Iteration 1343: Loss = 1.6182, Accuracy = 0.4400 Test Loss = 3.8894, Test Accuracy = 0.2971\n",
      "Iteration 1344: Loss = 1.5282, Accuracy = 0.3900 Test Loss = 3.8859, Test Accuracy = 0.2990\n",
      "Iteration 1345: Loss = 1.3918, Accuracy = 0.4500 Test Loss = 3.8889, Test Accuracy = 0.2973\n",
      "Iteration 1346: Loss = 1.6388, Accuracy = 0.4800 Test Loss = 3.8888, Test Accuracy = 0.2968\n",
      "Iteration 1347: Loss = 1.5965, Accuracy = 0.4500 Test Loss = 3.8850, Test Accuracy = 0.2977\n",
      "Iteration 1348: Loss = 1.6395, Accuracy = 0.4400 Test Loss = 3.8819, Test Accuracy = 0.2987\n",
      "Iteration 1349: Loss = 1.4956, Accuracy = 0.4600 Test Loss = 3.8770, Test Accuracy = 0.2972\n",
      "Iteration 1350: Loss = 1.5806, Accuracy = 0.3700 Test Loss = 3.8732, Test Accuracy = 0.2979\n",
      "Iteration 1351: Loss = 1.4175, Accuracy = 0.4400 Test Loss = 3.8735, Test Accuracy = 0.2978\n",
      "Iteration 1352: Loss = 1.6541, Accuracy = 0.4400 Test Loss = 3.8682, Test Accuracy = 0.2983\n",
      "Iteration 1353: Loss = 1.6401, Accuracy = 0.4000 Test Loss = 3.8673, Test Accuracy = 0.2975\n",
      "Iteration 1354: Loss = 1.4829, Accuracy = 0.4100 Test Loss = 3.8633, Test Accuracy = 0.2988\n",
      "Iteration 1355: Loss = 1.5405, Accuracy = 0.4700 Test Loss = 3.8631, Test Accuracy = 0.2994\n",
      "Iteration 1356: Loss = 1.4893, Accuracy = 0.4300 Test Loss = 3.8615, Test Accuracy = 0.2969\n",
      "Iteration 1357: Loss = 1.6048, Accuracy = 0.4500 Test Loss = 3.8618, Test Accuracy = 0.2981\n",
      "Iteration 1358: Loss = 1.4930, Accuracy = 0.5100 Test Loss = 3.8618, Test Accuracy = 0.3001\n",
      "Iteration 1359: Loss = 1.4905, Accuracy = 0.4600 Test Loss = 3.8554, Test Accuracy = 0.3005\n",
      "Iteration 1360: Loss = 1.4675, Accuracy = 0.4800 Test Loss = 3.8534, Test Accuracy = 0.2986\n",
      "Iteration 1361: Loss = 1.7277, Accuracy = 0.3500 Test Loss = 3.8488, Test Accuracy = 0.2998\n",
      "Iteration 1362: Loss = 1.6066, Accuracy = 0.3900 Test Loss = 3.8465, Test Accuracy = 0.2971\n",
      "Iteration 1363: Loss = 1.5136, Accuracy = 0.4500 Test Loss = 3.8466, Test Accuracy = 0.2988\n",
      "Iteration 1364: Loss = 1.3534, Accuracy = 0.4400 Test Loss = 3.8488, Test Accuracy = 0.2993\n",
      "Iteration 1365: Loss = 1.4071, Accuracy = 0.5000 Test Loss = 3.8403, Test Accuracy = 0.2988\n",
      "Iteration 1366: Loss = 1.6618, Accuracy = 0.4600 Test Loss = 3.8376, Test Accuracy = 0.3002\n",
      "Iteration 1367: Loss = 1.4590, Accuracy = 0.5600 Test Loss = 3.8390, Test Accuracy = 0.2987\n",
      "Iteration 1368: Loss = 1.5525, Accuracy = 0.4200 Test Loss = 3.8399, Test Accuracy = 0.2999\n",
      "Iteration 1369: Loss = 1.4850, Accuracy = 0.5300 Test Loss = 3.8335, Test Accuracy = 0.2991\n",
      "Iteration 1370: Loss = 1.3899, Accuracy = 0.4600 Test Loss = 3.8373, Test Accuracy = 0.3018\n",
      "Iteration 1371: Loss = 1.4294, Accuracy = 0.4800 Test Loss = 3.8293, Test Accuracy = 0.2988\n",
      "Iteration 1372: Loss = 1.4854, Accuracy = 0.4100 Test Loss = 3.8244, Test Accuracy = 0.3000\n",
      "Iteration 1373: Loss = 1.6482, Accuracy = 0.4200 Test Loss = 3.8269, Test Accuracy = 0.3001\n",
      "Iteration 1374: Loss = 1.7332, Accuracy = 0.4400 Test Loss = 3.8213, Test Accuracy = 0.2994\n",
      "Iteration 1375: Loss = 1.5657, Accuracy = 0.4800 Test Loss = 3.8205, Test Accuracy = 0.3001\n",
      "Iteration 1376: Loss = 1.5384, Accuracy = 0.4300 Test Loss = 3.8179, Test Accuracy = 0.2998\n",
      "Iteration 1377: Loss = 1.3943, Accuracy = 0.5600 Test Loss = 3.8198, Test Accuracy = 0.3010\n",
      "Iteration 1378: Loss = 1.6334, Accuracy = 0.4700 Test Loss = 3.8191, Test Accuracy = 0.2997\n",
      "Iteration 1379: Loss = 1.3898, Accuracy = 0.4800 Test Loss = 3.8106, Test Accuracy = 0.2991\n",
      "Iteration 1380: Loss = 1.4934, Accuracy = 0.4100 Test Loss = 3.8116, Test Accuracy = 0.3014\n",
      "Iteration 1381: Loss = 1.6584, Accuracy = 0.3900 Test Loss = 3.8058, Test Accuracy = 0.2998\n",
      "Iteration 1382: Loss = 1.6924, Accuracy = 0.3500 Test Loss = 3.8084, Test Accuracy = 0.2990\n",
      "Iteration 1383: Loss = 1.7670, Accuracy = 0.4800 Test Loss = 3.8046, Test Accuracy = 0.2991\n",
      "Iteration 1384: Loss = 1.5335, Accuracy = 0.5200 Test Loss = 3.8006, Test Accuracy = 0.2993\n",
      "Iteration 1385: Loss = 1.7334, Accuracy = 0.4300 Test Loss = 3.8012, Test Accuracy = 0.2994\n",
      "Iteration 1386: Loss = 1.6477, Accuracy = 0.3500 Test Loss = 3.7941, Test Accuracy = 0.2988\n",
      "Iteration 1387: Loss = 1.6924, Accuracy = 0.4100 Test Loss = 3.7979, Test Accuracy = 0.3022\n",
      "Iteration 1388: Loss = 1.5001, Accuracy = 0.4400 Test Loss = 3.7932, Test Accuracy = 0.2995\n",
      "Iteration 1389: Loss = 1.5551, Accuracy = 0.4600 Test Loss = 3.7901, Test Accuracy = 0.3025\n",
      "Iteration 1390: Loss = 1.4325, Accuracy = 0.3900 Test Loss = 3.7904, Test Accuracy = 0.3010\n",
      "Iteration 1391: Loss = 1.5304, Accuracy = 0.4600 Test Loss = 3.7878, Test Accuracy = 0.3002\n",
      "Iteration 1392: Loss = 1.4581, Accuracy = 0.4600 Test Loss = 3.7832, Test Accuracy = 0.2990\n",
      "Iteration 1393: Loss = 1.4392, Accuracy = 0.4100 Test Loss = 3.7854, Test Accuracy = 0.3014\n",
      "Iteration 1394: Loss = 1.6764, Accuracy = 0.4000 Test Loss = 3.7813, Test Accuracy = 0.3026\n",
      "Iteration 1395: Loss = 1.5967, Accuracy = 0.4900 Test Loss = 3.7752, Test Accuracy = 0.3014\n",
      "Iteration 1396: Loss = 1.5228, Accuracy = 0.4600 Test Loss = 3.7790, Test Accuracy = 0.3003\n",
      "Iteration 1397: Loss = 1.6328, Accuracy = 0.4400 Test Loss = 3.7748, Test Accuracy = 0.3045\n",
      "Iteration 1398: Loss = 1.4697, Accuracy = 0.4700 Test Loss = 3.7734, Test Accuracy = 0.3006\n",
      "Iteration 1399: Loss = 1.4454, Accuracy = 0.4400 Test Loss = 3.7691, Test Accuracy = 0.3023\n",
      "Iteration 1400: Loss = 1.5341, Accuracy = 0.4700 Test Loss = 3.7693, Test Accuracy = 0.3009\n",
      "Iteration 1401: Loss = 1.3935, Accuracy = 0.5000 Test Loss = 3.7640, Test Accuracy = 0.3028\n",
      "Iteration 1402: Loss = 1.5695, Accuracy = 0.4000 Test Loss = 3.7705, Test Accuracy = 0.3022\n",
      "Iteration 1403: Loss = 1.6313, Accuracy = 0.4300 Test Loss = 3.7602, Test Accuracy = 0.3008\n",
      "Iteration 1404: Loss = 1.6440, Accuracy = 0.3900 Test Loss = 3.7590, Test Accuracy = 0.3032\n",
      "Iteration 1405: Loss = 1.6321, Accuracy = 0.4500 Test Loss = 3.7592, Test Accuracy = 0.3022\n",
      "Iteration 1406: Loss = 1.5332, Accuracy = 0.4700 Test Loss = 3.7543, Test Accuracy = 0.3024\n",
      "Iteration 1407: Loss = 1.4576, Accuracy = 0.4700 Test Loss = 3.7565, Test Accuracy = 0.3030\n",
      "Iteration 1408: Loss = 1.4570, Accuracy = 0.4300 Test Loss = 3.7528, Test Accuracy = 0.3035\n",
      "Iteration 1409: Loss = 1.6655, Accuracy = 0.3800 Test Loss = 3.7488, Test Accuracy = 0.3048\n",
      "Iteration 1410: Loss = 1.4604, Accuracy = 0.4600 Test Loss = 3.7474, Test Accuracy = 0.3048\n",
      "Iteration 1411: Loss = 1.3865, Accuracy = 0.4400 Test Loss = 3.7484, Test Accuracy = 0.3049\n",
      "Iteration 1412: Loss = 1.4265, Accuracy = 0.4800 Test Loss = 3.7465, Test Accuracy = 0.3034\n",
      "Iteration 1413: Loss = 1.5613, Accuracy = 0.4700 Test Loss = 3.7399, Test Accuracy = 0.3018\n",
      "Iteration 1414: Loss = 1.6905, Accuracy = 0.4100 Test Loss = 3.7426, Test Accuracy = 0.3021\n",
      "Iteration 1415: Loss = 1.5621, Accuracy = 0.4500 Test Loss = 3.7380, Test Accuracy = 0.3031\n",
      "Iteration 1416: Loss = 1.4027, Accuracy = 0.4300 Test Loss = 3.7394, Test Accuracy = 0.3017\n",
      "Iteration 1417: Loss = 1.3854, Accuracy = 0.4700 Test Loss = 3.7348, Test Accuracy = 0.3026\n",
      "Iteration 1418: Loss = 1.3377, Accuracy = 0.4900 Test Loss = 3.7288, Test Accuracy = 0.3053\n",
      "Iteration 1419: Loss = 1.4790, Accuracy = 0.3900 Test Loss = 3.7276, Test Accuracy = 0.3045\n",
      "Iteration 1420: Loss = 1.4096, Accuracy = 0.4200 Test Loss = 3.7282, Test Accuracy = 0.3032\n",
      "Iteration 1421: Loss = 1.4545, Accuracy = 0.5300 Test Loss = 3.7239, Test Accuracy = 0.3039\n",
      "Iteration 1422: Loss = 1.4941, Accuracy = 0.4200 Test Loss = 3.7260, Test Accuracy = 0.3033\n",
      "Iteration 1423: Loss = 1.3896, Accuracy = 0.4400 Test Loss = 3.7256, Test Accuracy = 0.3036\n",
      "Iteration 1424: Loss = 1.5232, Accuracy = 0.4800 Test Loss = 3.7173, Test Accuracy = 0.3035\n",
      "Iteration 1425: Loss = 1.5225, Accuracy = 0.3500 Test Loss = 3.7161, Test Accuracy = 0.3051\n",
      "Iteration 1426: Loss = 1.5577, Accuracy = 0.4100 Test Loss = 3.7169, Test Accuracy = 0.3050\n",
      "Iteration 1427: Loss = 1.5383, Accuracy = 0.4900 Test Loss = 3.7125, Test Accuracy = 0.3041\n",
      "Iteration 1428: Loss = 1.3480, Accuracy = 0.5100 Test Loss = 3.7093, Test Accuracy = 0.3038\n",
      "Iteration 1429: Loss = 1.5689, Accuracy = 0.4500 Test Loss = 3.7136, Test Accuracy = 0.3015\n",
      "Iteration 1430: Loss = 1.3242, Accuracy = 0.4400 Test Loss = 3.7067, Test Accuracy = 0.3062\n",
      "Iteration 1431: Loss = 1.6098, Accuracy = 0.3800 Test Loss = 3.7056, Test Accuracy = 0.3043\n",
      "Iteration 1432: Loss = 1.5741, Accuracy = 0.3900 Test Loss = 3.7032, Test Accuracy = 0.3038\n",
      "Iteration 1433: Loss = 1.4679, Accuracy = 0.4100 Test Loss = 3.7022, Test Accuracy = 0.3034\n",
      "Iteration 1434: Loss = 1.5009, Accuracy = 0.5100 Test Loss = 3.7000, Test Accuracy = 0.3044\n",
      "Iteration 1435: Loss = 1.5855, Accuracy = 0.4300 Test Loss = 3.6963, Test Accuracy = 0.3067\n",
      "Iteration 1436: Loss = 1.6390, Accuracy = 0.3600 Test Loss = 3.6947, Test Accuracy = 0.3050\n",
      "Iteration 1437: Loss = 1.5897, Accuracy = 0.3700 Test Loss = 3.6970, Test Accuracy = 0.3039\n",
      "Iteration 1438: Loss = 1.4577, Accuracy = 0.4700 Test Loss = 3.6927, Test Accuracy = 0.3035\n",
      "Iteration 1439: Loss = 1.5325, Accuracy = 0.4200 Test Loss = 3.6912, Test Accuracy = 0.3049\n",
      "Iteration 1440: Loss = 1.4114, Accuracy = 0.3500 Test Loss = 3.6868, Test Accuracy = 0.3052\n",
      "Iteration 1441: Loss = 1.5881, Accuracy = 0.4700 Test Loss = 3.6861, Test Accuracy = 0.3050\n",
      "Iteration 1442: Loss = 1.4222, Accuracy = 0.4800 Test Loss = 3.6848, Test Accuracy = 0.3045\n",
      "Iteration 1443: Loss = 1.3654, Accuracy = 0.4600 Test Loss = 3.6852, Test Accuracy = 0.3058\n",
      "Iteration 1444: Loss = 1.4218, Accuracy = 0.5400 Test Loss = 3.6837, Test Accuracy = 0.3034\n",
      "Iteration 1445: Loss = 1.4920, Accuracy = 0.4900 Test Loss = 3.6820, Test Accuracy = 0.3045\n",
      "Iteration 1446: Loss = 1.5203, Accuracy = 0.4100 Test Loss = 3.6750, Test Accuracy = 0.3055\n",
      "Iteration 1447: Loss = 1.6523, Accuracy = 0.4800 Test Loss = 3.6757, Test Accuracy = 0.3050\n",
      "Iteration 1448: Loss = 1.3919, Accuracy = 0.4500 Test Loss = 3.6731, Test Accuracy = 0.3069\n",
      "Iteration 1449: Loss = 1.4200, Accuracy = 0.5200 Test Loss = 3.6696, Test Accuracy = 0.3069\n",
      "Iteration 1450: Loss = 1.4735, Accuracy = 0.4700 Test Loss = 3.6658, Test Accuracy = 0.3073\n",
      "Iteration 1451: Loss = 1.4775, Accuracy = 0.4100 Test Loss = 3.6698, Test Accuracy = 0.3054\n",
      "Iteration 1452: Loss = 1.4426, Accuracy = 0.4300 Test Loss = 3.6650, Test Accuracy = 0.3057\n",
      "Iteration 1453: Loss = 1.4739, Accuracy = 0.4600 Test Loss = 3.6645, Test Accuracy = 0.3041\n",
      "Iteration 1454: Loss = 1.5354, Accuracy = 0.4200 Test Loss = 3.6621, Test Accuracy = 0.3060\n",
      "Iteration 1455: Loss = 1.4873, Accuracy = 0.3300 Test Loss = 3.6572, Test Accuracy = 0.3057\n",
      "Iteration 1456: Loss = 1.3712, Accuracy = 0.4700 Test Loss = 3.6594, Test Accuracy = 0.3065\n",
      "Iteration 1457: Loss = 1.4980, Accuracy = 0.3300 Test Loss = 3.6580, Test Accuracy = 0.3073\n",
      "Iteration 1458: Loss = 1.4603, Accuracy = 0.4600 Test Loss = 3.6527, Test Accuracy = 0.3070\n",
      "Iteration 1459: Loss = 1.4894, Accuracy = 0.4600 Test Loss = 3.6500, Test Accuracy = 0.3065\n",
      "Iteration 1460: Loss = 1.5812, Accuracy = 0.3800 Test Loss = 3.6488, Test Accuracy = 0.3058\n",
      "Iteration 1461: Loss = 1.4102, Accuracy = 0.3900 Test Loss = 3.6455, Test Accuracy = 0.3078\n",
      "Iteration 1462: Loss = 1.4399, Accuracy = 0.3800 Test Loss = 3.6543, Test Accuracy = 0.3035\n",
      "Iteration 1463: Loss = 1.3623, Accuracy = 0.3600 Test Loss = 3.6429, Test Accuracy = 0.3054\n",
      "Iteration 1464: Loss = 1.4711, Accuracy = 0.4700 Test Loss = 3.6396, Test Accuracy = 0.3065\n",
      "Iteration 1465: Loss = 1.4362, Accuracy = 0.4000 Test Loss = 3.6395, Test Accuracy = 0.3057\n",
      "Iteration 1466: Loss = 1.4170, Accuracy = 0.4700 Test Loss = 3.6387, Test Accuracy = 0.3063\n",
      "Iteration 1467: Loss = 1.3913, Accuracy = 0.3700 Test Loss = 3.6353, Test Accuracy = 0.3064\n",
      "Iteration 1468: Loss = 1.3742, Accuracy = 0.4900 Test Loss = 3.6326, Test Accuracy = 0.3079\n",
      "Iteration 1469: Loss = 1.4812, Accuracy = 0.4400 Test Loss = 3.6331, Test Accuracy = 0.3061\n",
      "Iteration 1470: Loss = 1.4831, Accuracy = 0.4200 Test Loss = 3.6309, Test Accuracy = 0.3069\n",
      "Iteration 1471: Loss = 1.5109, Accuracy = 0.4800 Test Loss = 3.6271, Test Accuracy = 0.3082\n",
      "Iteration 1472: Loss = 1.4699, Accuracy = 0.5200 Test Loss = 3.6268, Test Accuracy = 0.3076\n",
      "Iteration 1473: Loss = 1.4068, Accuracy = 0.4700 Test Loss = 3.6240, Test Accuracy = 0.3069\n",
      "Iteration 1474: Loss = 1.4841, Accuracy = 0.4100 Test Loss = 3.6260, Test Accuracy = 0.3082\n",
      "Iteration 1475: Loss = 1.5096, Accuracy = 0.4000 Test Loss = 3.6225, Test Accuracy = 0.3068\n",
      "Iteration 1476: Loss = 1.3526, Accuracy = 0.5400 Test Loss = 3.6224, Test Accuracy = 0.3074\n",
      "Iteration 1477: Loss = 1.5408, Accuracy = 0.3900 Test Loss = 3.6197, Test Accuracy = 0.3079\n",
      "Iteration 1478: Loss = 1.4432, Accuracy = 0.3900 Test Loss = 3.6190, Test Accuracy = 0.3076\n",
      "Iteration 1479: Loss = 1.5052, Accuracy = 0.4500 Test Loss = 3.6145, Test Accuracy = 0.3073\n",
      "Iteration 1480: Loss = 1.5697, Accuracy = 0.4900 Test Loss = 3.6139, Test Accuracy = 0.3080\n",
      "Iteration 1481: Loss = 1.5322, Accuracy = 0.5000 Test Loss = 3.6136, Test Accuracy = 0.3096\n",
      "Iteration 1482: Loss = 1.3985, Accuracy = 0.5000 Test Loss = 3.6054, Test Accuracy = 0.3076\n",
      "Iteration 1483: Loss = 1.3271, Accuracy = 0.5100 Test Loss = 3.6091, Test Accuracy = 0.3068\n",
      "Iteration 1484: Loss = 1.4096, Accuracy = 0.4400 Test Loss = 3.6053, Test Accuracy = 0.3071\n",
      "Iteration 1485: Loss = 1.4427, Accuracy = 0.5000 Test Loss = 3.6037, Test Accuracy = 0.3059\n",
      "Iteration 1486: Loss = 1.4363, Accuracy = 0.4800 Test Loss = 3.5999, Test Accuracy = 0.3092\n",
      "Iteration 1487: Loss = 1.4804, Accuracy = 0.4500 Test Loss = 3.6020, Test Accuracy = 0.3084\n",
      "Iteration 1488: Loss = 1.3940, Accuracy = 0.4300 Test Loss = 3.5954, Test Accuracy = 0.3080\n",
      "Iteration 1489: Loss = 1.4126, Accuracy = 0.4300 Test Loss = 3.5939, Test Accuracy = 0.3087\n",
      "Iteration 1490: Loss = 1.2938, Accuracy = 0.5200 Test Loss = 3.5929, Test Accuracy = 0.3089\n",
      "Iteration 1491: Loss = 1.5159, Accuracy = 0.4800 Test Loss = 3.5914, Test Accuracy = 0.3113\n",
      "Iteration 1492: Loss = 1.4075, Accuracy = 0.4300 Test Loss = 3.5853, Test Accuracy = 0.3099\n",
      "Iteration 1493: Loss = 1.4950, Accuracy = 0.5200 Test Loss = 3.5862, Test Accuracy = 0.3089\n",
      "Iteration 1494: Loss = 1.4439, Accuracy = 0.4100 Test Loss = 3.5864, Test Accuracy = 0.3096\n",
      "Iteration 1495: Loss = 1.3843, Accuracy = 0.4900 Test Loss = 3.5841, Test Accuracy = 0.3102\n",
      "Iteration 1496: Loss = 1.3147, Accuracy = 0.4300 Test Loss = 3.5821, Test Accuracy = 0.3085\n",
      "Iteration 1497: Loss = 1.4342, Accuracy = 0.4300 Test Loss = 3.5792, Test Accuracy = 0.3100\n",
      "Iteration 1498: Loss = 1.3549, Accuracy = 0.4600 Test Loss = 3.5868, Test Accuracy = 0.3086\n",
      "Iteration 1499: Loss = 1.3272, Accuracy = 0.4900 Test Loss = 3.5780, Test Accuracy = 0.3090\n",
      "Iteration 1500: Loss = 1.4154, Accuracy = 0.5100 Test Loss = 3.5763, Test Accuracy = 0.3091\n",
      "Iteration 1501: Loss = 1.4759, Accuracy = 0.5100 Test Loss = 3.5763, Test Accuracy = 0.3099\n",
      "Iteration 1502: Loss = 1.4707, Accuracy = 0.4600 Test Loss = 3.5676, Test Accuracy = 0.3097\n",
      "Iteration 1503: Loss = 1.4331, Accuracy = 0.4700 Test Loss = 3.5682, Test Accuracy = 0.3094\n",
      "Iteration 1504: Loss = 1.4368, Accuracy = 0.4500 Test Loss = 3.5682, Test Accuracy = 0.3095\n",
      "Iteration 1505: Loss = 1.5549, Accuracy = 0.4600 Test Loss = 3.5632, Test Accuracy = 0.3104\n",
      "Iteration 1506: Loss = 1.3948, Accuracy = 0.4600 Test Loss = 3.5629, Test Accuracy = 0.3098\n",
      "Iteration 1507: Loss = 1.5304, Accuracy = 0.4400 Test Loss = 3.5590, Test Accuracy = 0.3109\n",
      "Iteration 1508: Loss = 1.5295, Accuracy = 0.4300 Test Loss = 3.5604, Test Accuracy = 0.3104\n",
      "Iteration 1509: Loss = 1.3128, Accuracy = 0.4800 Test Loss = 3.5573, Test Accuracy = 0.3088\n",
      "Iteration 1510: Loss = 1.4645, Accuracy = 0.4400 Test Loss = 3.5608, Test Accuracy = 0.3088\n",
      "Iteration 1511: Loss = 1.3409, Accuracy = 0.4800 Test Loss = 3.5535, Test Accuracy = 0.3111\n",
      "Iteration 1512: Loss = 1.3059, Accuracy = 0.4400 Test Loss = 3.5500, Test Accuracy = 0.3119\n",
      "Iteration 1513: Loss = 1.5033, Accuracy = 0.4200 Test Loss = 3.5492, Test Accuracy = 0.3112\n",
      "Iteration 1514: Loss = 1.3313, Accuracy = 0.5000 Test Loss = 3.5482, Test Accuracy = 0.3102\n",
      "Iteration 1515: Loss = 1.3407, Accuracy = 0.4600 Test Loss = 3.5501, Test Accuracy = 0.3099\n",
      "Iteration 1516: Loss = 1.4943, Accuracy = 0.4700 Test Loss = 3.5479, Test Accuracy = 0.3117\n",
      "Iteration 1517: Loss = 1.4168, Accuracy = 0.4600 Test Loss = 3.5413, Test Accuracy = 0.3123\n",
      "Iteration 1518: Loss = 1.4296, Accuracy = 0.4100 Test Loss = 3.5419, Test Accuracy = 0.3116\n",
      "Iteration 1519: Loss = 1.2542, Accuracy = 0.4200 Test Loss = 3.5426, Test Accuracy = 0.3101\n",
      "Iteration 1520: Loss = 1.4344, Accuracy = 0.3700 Test Loss = 3.5377, Test Accuracy = 0.3121\n",
      "Iteration 1521: Loss = 1.5175, Accuracy = 0.3900 Test Loss = 3.5352, Test Accuracy = 0.3105\n",
      "Iteration 1522: Loss = 1.4144, Accuracy = 0.4500 Test Loss = 3.5339, Test Accuracy = 0.3123\n",
      "Iteration 1523: Loss = 1.2693, Accuracy = 0.5000 Test Loss = 3.5324, Test Accuracy = 0.3123\n",
      "Iteration 1524: Loss = 1.3891, Accuracy = 0.4600 Test Loss = 3.5313, Test Accuracy = 0.3123\n",
      "Iteration 1525: Loss = 1.2457, Accuracy = 0.5300 Test Loss = 3.5343, Test Accuracy = 0.3105\n",
      "Iteration 1526: Loss = 1.4006, Accuracy = 0.5000 Test Loss = 3.5279, Test Accuracy = 0.3112\n",
      "Iteration 1527: Loss = 1.4577, Accuracy = 0.4700 Test Loss = 3.5261, Test Accuracy = 0.3115\n",
      "Iteration 1528: Loss = 1.2490, Accuracy = 0.5500 Test Loss = 3.5263, Test Accuracy = 0.3114\n",
      "Iteration 1529: Loss = 1.4837, Accuracy = 0.3900 Test Loss = 3.5234, Test Accuracy = 0.3128\n",
      "Iteration 1530: Loss = 1.3831, Accuracy = 0.4700 Test Loss = 3.5221, Test Accuracy = 0.3107\n",
      "Iteration 1531: Loss = 1.2599, Accuracy = 0.4500 Test Loss = 3.5170, Test Accuracy = 0.3117\n",
      "Iteration 1532: Loss = 1.3559, Accuracy = 0.4900 Test Loss = 3.5141, Test Accuracy = 0.3130\n",
      "Iteration 1533: Loss = 1.3115, Accuracy = 0.5000 Test Loss = 3.5125, Test Accuracy = 0.3114\n",
      "Iteration 1534: Loss = 1.3232, Accuracy = 0.4700 Test Loss = 3.5146, Test Accuracy = 0.3126\n",
      "Iteration 1535: Loss = 1.2983, Accuracy = 0.4800 Test Loss = 3.5152, Test Accuracy = 0.3107\n",
      "Iteration 1536: Loss = 1.4514, Accuracy = 0.4400 Test Loss = 3.5103, Test Accuracy = 0.3114\n",
      "Iteration 1537: Loss = 1.3631, Accuracy = 0.4500 Test Loss = 3.5115, Test Accuracy = 0.3121\n",
      "Iteration 1538: Loss = 1.4544, Accuracy = 0.4500 Test Loss = 3.5048, Test Accuracy = 0.3122\n",
      "Iteration 1539: Loss = 1.4321, Accuracy = 0.4100 Test Loss = 3.5071, Test Accuracy = 0.3128\n",
      "Iteration 1540: Loss = 1.3136, Accuracy = 0.5600 Test Loss = 3.5024, Test Accuracy = 0.3134\n",
      "Iteration 1541: Loss = 1.4063, Accuracy = 0.4300 Test Loss = 3.4985, Test Accuracy = 0.3141\n",
      "Iteration 1542: Loss = 1.4040, Accuracy = 0.4500 Test Loss = 3.4982, Test Accuracy = 0.3133\n",
      "Iteration 1543: Loss = 1.3770, Accuracy = 0.4800 Test Loss = 3.4966, Test Accuracy = 0.3140\n",
      "Iteration 1544: Loss = 1.4153, Accuracy = 0.4400 Test Loss = 3.4958, Test Accuracy = 0.3131\n",
      "Iteration 1545: Loss = 1.3698, Accuracy = 0.4600 Test Loss = 3.4930, Test Accuracy = 0.3145\n",
      "Iteration 1546: Loss = 1.4417, Accuracy = 0.3600 Test Loss = 3.4938, Test Accuracy = 0.3123\n",
      "Iteration 1547: Loss = 1.4245, Accuracy = 0.5000 Test Loss = 3.4938, Test Accuracy = 0.3127\n",
      "Iteration 1548: Loss = 1.3826, Accuracy = 0.3800 Test Loss = 3.4894, Test Accuracy = 0.3146\n",
      "Iteration 1549: Loss = 1.3081, Accuracy = 0.4500 Test Loss = 3.4861, Test Accuracy = 0.3137\n",
      "Iteration 1550: Loss = 1.4413, Accuracy = 0.4800 Test Loss = 3.4864, Test Accuracy = 0.3138\n",
      "Iteration 1551: Loss = 1.3191, Accuracy = 0.5300 Test Loss = 3.4880, Test Accuracy = 0.3128\n",
      "Iteration 1552: Loss = 1.4617, Accuracy = 0.4500 Test Loss = 3.4851, Test Accuracy = 0.3123\n",
      "Iteration 1553: Loss = 1.3498, Accuracy = 0.5300 Test Loss = 3.4790, Test Accuracy = 0.3144\n",
      "Iteration 1554: Loss = 1.2310, Accuracy = 0.4800 Test Loss = 3.4781, Test Accuracy = 0.3132\n",
      "Iteration 1555: Loss = 1.4106, Accuracy = 0.4400 Test Loss = 3.4771, Test Accuracy = 0.3154\n",
      "Iteration 1556: Loss = 1.2754, Accuracy = 0.4600 Test Loss = 3.4751, Test Accuracy = 0.3143\n",
      "Iteration 1557: Loss = 1.2942, Accuracy = 0.4100 Test Loss = 3.4752, Test Accuracy = 0.3156\n",
      "Iteration 1558: Loss = 1.4437, Accuracy = 0.4500 Test Loss = 3.4709, Test Accuracy = 0.3156\n",
      "Iteration 1559: Loss = 1.3253, Accuracy = 0.5600 Test Loss = 3.4726, Test Accuracy = 0.3138\n",
      "Iteration 1560: Loss = 1.3882, Accuracy = 0.4800 Test Loss = 3.4696, Test Accuracy = 0.3138\n",
      "Iteration 1561: Loss = 1.3727, Accuracy = 0.4500 Test Loss = 3.4659, Test Accuracy = 0.3139\n",
      "Iteration 1562: Loss = 1.3478, Accuracy = 0.5300 Test Loss = 3.4683, Test Accuracy = 0.3133\n",
      "Iteration 1563: Loss = 1.4237, Accuracy = 0.4100 Test Loss = 3.4649, Test Accuracy = 0.3135\n",
      "Iteration 1564: Loss = 1.3122, Accuracy = 0.5300 Test Loss = 3.4629, Test Accuracy = 0.3143\n",
      "Iteration 1565: Loss = 1.3994, Accuracy = 0.4100 Test Loss = 3.4576, Test Accuracy = 0.3158\n",
      "Iteration 1566: Loss = 1.3385, Accuracy = 0.5500 Test Loss = 3.4566, Test Accuracy = 0.3163\n",
      "Iteration 1567: Loss = 1.2172, Accuracy = 0.5800 Test Loss = 3.4589, Test Accuracy = 0.3146\n",
      "Iteration 1568: Loss = 1.4241, Accuracy = 0.4800 Test Loss = 3.4552, Test Accuracy = 0.3155\n",
      "Iteration 1569: Loss = 1.3756, Accuracy = 0.4200 Test Loss = 3.4561, Test Accuracy = 0.3147\n",
      "Iteration 1570: Loss = 1.3738, Accuracy = 0.4300 Test Loss = 3.4518, Test Accuracy = 0.3143\n",
      "Iteration 1571: Loss = 1.3933, Accuracy = 0.4400 Test Loss = 3.4469, Test Accuracy = 0.3157\n",
      "Iteration 1572: Loss = 1.3808, Accuracy = 0.4600 Test Loss = 3.4488, Test Accuracy = 0.3150\n",
      "Iteration 1573: Loss = 1.3183, Accuracy = 0.4500 Test Loss = 3.4464, Test Accuracy = 0.3179\n",
      "Iteration 1574: Loss = 1.3011, Accuracy = 0.5100 Test Loss = 3.4450, Test Accuracy = 0.3156\n",
      "Iteration 1575: Loss = 1.3234, Accuracy = 0.4900 Test Loss = 3.4438, Test Accuracy = 0.3160\n",
      "Iteration 1576: Loss = 1.3539, Accuracy = 0.5100 Test Loss = 3.4429, Test Accuracy = 0.3157\n",
      "Iteration 1577: Loss = 1.3478, Accuracy = 0.4800 Test Loss = 3.4396, Test Accuracy = 0.3140\n",
      "Iteration 1578: Loss = 1.4266, Accuracy = 0.4700 Test Loss = 3.4368, Test Accuracy = 0.3153\n",
      "Iteration 1579: Loss = 1.2050, Accuracy = 0.5400 Test Loss = 3.4400, Test Accuracy = 0.3149\n",
      "Iteration 1580: Loss = 1.4016, Accuracy = 0.4900 Test Loss = 3.4358, Test Accuracy = 0.3171\n",
      "Iteration 1581: Loss = 1.3157, Accuracy = 0.4800 Test Loss = 3.4316, Test Accuracy = 0.3151\n",
      "Iteration 1582: Loss = 1.2661, Accuracy = 0.4400 Test Loss = 3.4353, Test Accuracy = 0.3158\n",
      "Iteration 1583: Loss = 1.3258, Accuracy = 0.5200 Test Loss = 3.4331, Test Accuracy = 0.3153\n",
      "Iteration 1584: Loss = 1.2075, Accuracy = 0.4900 Test Loss = 3.4335, Test Accuracy = 0.3162\n",
      "Iteration 1585: Loss = 1.2614, Accuracy = 0.5000 Test Loss = 3.4262, Test Accuracy = 0.3165\n",
      "Iteration 1586: Loss = 1.3296, Accuracy = 0.4300 Test Loss = 3.4276, Test Accuracy = 0.3165\n",
      "Iteration 1587: Loss = 1.4959, Accuracy = 0.4400 Test Loss = 3.4234, Test Accuracy = 0.3173\n",
      "Iteration 1588: Loss = 1.3182, Accuracy = 0.5200 Test Loss = 3.4251, Test Accuracy = 0.3148\n",
      "Iteration 1589: Loss = 1.2763, Accuracy = 0.3800 Test Loss = 3.4175, Test Accuracy = 0.3158\n",
      "Iteration 1590: Loss = 1.4079, Accuracy = 0.4000 Test Loss = 3.4191, Test Accuracy = 0.3174\n",
      "Iteration 1591: Loss = 1.3921, Accuracy = 0.4600 Test Loss = 3.4152, Test Accuracy = 0.3173\n",
      "Iteration 1592: Loss = 1.4529, Accuracy = 0.5300 Test Loss = 3.4128, Test Accuracy = 0.3175\n",
      "Iteration 1593: Loss = 1.2757, Accuracy = 0.5400 Test Loss = 3.4132, Test Accuracy = 0.3168\n",
      "Iteration 1594: Loss = 1.5221, Accuracy = 0.4400 Test Loss = 3.4120, Test Accuracy = 0.3182\n",
      "Iteration 1595: Loss = 1.2439, Accuracy = 0.5100 Test Loss = 3.4098, Test Accuracy = 0.3174\n",
      "Iteration 1596: Loss = 1.2683, Accuracy = 0.5400 Test Loss = 3.4101, Test Accuracy = 0.3171\n",
      "Iteration 1597: Loss = 1.3882, Accuracy = 0.3800 Test Loss = 3.4080, Test Accuracy = 0.3157\n",
      "Iteration 1598: Loss = 1.4393, Accuracy = 0.5300 Test Loss = 3.4048, Test Accuracy = 0.3183\n",
      "Iteration 1599: Loss = 1.2530, Accuracy = 0.4800 Test Loss = 3.4044, Test Accuracy = 0.3191\n",
      "Iteration 1600: Loss = 1.2989, Accuracy = 0.4200 Test Loss = 3.4033, Test Accuracy = 0.3181\n",
      "Iteration 1601: Loss = 1.2652, Accuracy = 0.4400 Test Loss = 3.4011, Test Accuracy = 0.3183\n",
      "Iteration 1602: Loss = 1.2135, Accuracy = 0.5800 Test Loss = 3.3972, Test Accuracy = 0.3184\n",
      "Iteration 1603: Loss = 1.2215, Accuracy = 0.4700 Test Loss = 3.3995, Test Accuracy = 0.3186\n",
      "Iteration 1604: Loss = 1.3572, Accuracy = 0.4700 Test Loss = 3.4000, Test Accuracy = 0.3177\n",
      "Iteration 1605: Loss = 1.3608, Accuracy = 0.5300 Test Loss = 3.3941, Test Accuracy = 0.3168\n",
      "Iteration 1606: Loss = 1.4269, Accuracy = 0.4600 Test Loss = 3.3907, Test Accuracy = 0.3184\n",
      "Iteration 1607: Loss = 1.3245, Accuracy = 0.5400 Test Loss = 3.3917, Test Accuracy = 0.3181\n",
      "Iteration 1608: Loss = 1.3181, Accuracy = 0.4700 Test Loss = 3.3873, Test Accuracy = 0.3188\n",
      "Iteration 1609: Loss = 1.3667, Accuracy = 0.5000 Test Loss = 3.3850, Test Accuracy = 0.3190\n",
      "Iteration 1610: Loss = 1.2972, Accuracy = 0.4600 Test Loss = 3.3866, Test Accuracy = 0.3194\n",
      "Iteration 1611: Loss = 1.3990, Accuracy = 0.3900 Test Loss = 3.3838, Test Accuracy = 0.3178\n",
      "Iteration 1612: Loss = 1.2676, Accuracy = 0.4900 Test Loss = 3.3846, Test Accuracy = 0.3183\n",
      "Iteration 1613: Loss = 1.3160, Accuracy = 0.4700 Test Loss = 3.3836, Test Accuracy = 0.3179\n",
      "Iteration 1614: Loss = 1.3614, Accuracy = 0.4800 Test Loss = 3.3774, Test Accuracy = 0.3202\n",
      "Iteration 1615: Loss = 1.3464, Accuracy = 0.4900 Test Loss = 3.3781, Test Accuracy = 0.3195\n",
      "Iteration 1616: Loss = 1.3837, Accuracy = 0.4900 Test Loss = 3.3755, Test Accuracy = 0.3191\n",
      "Iteration 1617: Loss = 1.2279, Accuracy = 0.4600 Test Loss = 3.3768, Test Accuracy = 0.3189\n",
      "Iteration 1618: Loss = 1.3455, Accuracy = 0.5200 Test Loss = 3.3712, Test Accuracy = 0.3188\n",
      "Iteration 1619: Loss = 1.2727, Accuracy = 0.5400 Test Loss = 3.3737, Test Accuracy = 0.3203\n",
      "Iteration 1620: Loss = 1.2505, Accuracy = 0.4600 Test Loss = 3.3671, Test Accuracy = 0.3188\n",
      "Iteration 1621: Loss = 1.3738, Accuracy = 0.4600 Test Loss = 3.3693, Test Accuracy = 0.3193\n",
      "Iteration 1622: Loss = 1.2871, Accuracy = 0.5500 Test Loss = 3.3636, Test Accuracy = 0.3197\n",
      "Iteration 1623: Loss = 1.2257, Accuracy = 0.4200 Test Loss = 3.3657, Test Accuracy = 0.3206\n",
      "Iteration 1624: Loss = 1.3343, Accuracy = 0.4900 Test Loss = 3.3656, Test Accuracy = 0.3200\n",
      "Iteration 1625: Loss = 1.3004, Accuracy = 0.4200 Test Loss = 3.3647, Test Accuracy = 0.3192\n",
      "Iteration 1626: Loss = 1.2256, Accuracy = 0.5000 Test Loss = 3.3640, Test Accuracy = 0.3207\n",
      "Iteration 1627: Loss = 1.2869, Accuracy = 0.4500 Test Loss = 3.3610, Test Accuracy = 0.3187\n",
      "Iteration 1628: Loss = 1.4489, Accuracy = 0.4800 Test Loss = 3.3580, Test Accuracy = 0.3211\n",
      "Iteration 1629: Loss = 1.3524, Accuracy = 0.4700 Test Loss = 3.3528, Test Accuracy = 0.3203\n",
      "Iteration 1630: Loss = 1.4025, Accuracy = 0.4700 Test Loss = 3.3536, Test Accuracy = 0.3199\n",
      "Iteration 1631: Loss = 1.2974, Accuracy = 0.3900 Test Loss = 3.3508, Test Accuracy = 0.3209\n",
      "Iteration 1632: Loss = 1.3054, Accuracy = 0.5100 Test Loss = 3.3500, Test Accuracy = 0.3213\n",
      "Iteration 1633: Loss = 1.3605, Accuracy = 0.4500 Test Loss = 3.3507, Test Accuracy = 0.3194\n",
      "Iteration 1634: Loss = 1.3010, Accuracy = 0.4800 Test Loss = 3.3465, Test Accuracy = 0.3205\n",
      "Iteration 1635: Loss = 1.2478, Accuracy = 0.5400 Test Loss = 3.3463, Test Accuracy = 0.3198\n",
      "Iteration 1636: Loss = 1.4439, Accuracy = 0.4100 Test Loss = 3.3480, Test Accuracy = 0.3186\n",
      "Iteration 1637: Loss = 1.0809, Accuracy = 0.5900 Test Loss = 3.3447, Test Accuracy = 0.3207\n",
      "Iteration 1638: Loss = 1.1083, Accuracy = 0.5700 Test Loss = 3.3451, Test Accuracy = 0.3216\n",
      "Iteration 1639: Loss = 1.2589, Accuracy = 0.5400 Test Loss = 3.3400, Test Accuracy = 0.3198\n",
      "Iteration 1640: Loss = 1.3436, Accuracy = 0.5400 Test Loss = 3.3371, Test Accuracy = 0.3213\n",
      "Iteration 1641: Loss = 1.2899, Accuracy = 0.5200 Test Loss = 3.3398, Test Accuracy = 0.3212\n",
      "Iteration 1642: Loss = 1.3014, Accuracy = 0.4400 Test Loss = 3.3321, Test Accuracy = 0.3223\n",
      "Iteration 1643: Loss = 1.1935, Accuracy = 0.5600 Test Loss = 3.3331, Test Accuracy = 0.3218\n",
      "Iteration 1644: Loss = 1.1252, Accuracy = 0.5000 Test Loss = 3.3346, Test Accuracy = 0.3206\n",
      "Iteration 1645: Loss = 1.3362, Accuracy = 0.5300 Test Loss = 3.3285, Test Accuracy = 0.3207\n",
      "Iteration 1646: Loss = 1.2445, Accuracy = 0.3800 Test Loss = 3.3290, Test Accuracy = 0.3223\n",
      "Iteration 1647: Loss = 1.2969, Accuracy = 0.4400 Test Loss = 3.3273, Test Accuracy = 0.3210\n",
      "Iteration 1648: Loss = 1.3096, Accuracy = 0.4500 Test Loss = 3.3225, Test Accuracy = 0.3217\n",
      "Iteration 1649: Loss = 1.3764, Accuracy = 0.4400 Test Loss = 3.3214, Test Accuracy = 0.3209\n",
      "Iteration 1650: Loss = 1.2122, Accuracy = 0.5200 Test Loss = 3.3241, Test Accuracy = 0.3215\n",
      "Iteration 1651: Loss = 1.3372, Accuracy = 0.5000 Test Loss = 3.3186, Test Accuracy = 0.3223\n",
      "Iteration 1652: Loss = 1.2405, Accuracy = 0.4800 Test Loss = 3.3187, Test Accuracy = 0.3211\n",
      "Iteration 1653: Loss = 1.3289, Accuracy = 0.4700 Test Loss = 3.3157, Test Accuracy = 0.3216\n",
      "Iteration 1654: Loss = 1.1266, Accuracy = 0.6000 Test Loss = 3.3181, Test Accuracy = 0.3225\n",
      "Iteration 1655: Loss = 1.3162, Accuracy = 0.4600 Test Loss = 3.3171, Test Accuracy = 0.3215\n",
      "Iteration 1656: Loss = 1.2427, Accuracy = 0.4700 Test Loss = 3.3133, Test Accuracy = 0.3232\n",
      "Iteration 1657: Loss = 1.2487, Accuracy = 0.5300 Test Loss = 3.3120, Test Accuracy = 0.3226\n",
      "Iteration 1658: Loss = 1.3723, Accuracy = 0.4800 Test Loss = 3.3111, Test Accuracy = 0.3219\n",
      "Iteration 1659: Loss = 1.1158, Accuracy = 0.5400 Test Loss = 3.3057, Test Accuracy = 0.3213\n",
      "Iteration 1660: Loss = 1.3369, Accuracy = 0.4700 Test Loss = 3.3054, Test Accuracy = 0.3229\n",
      "Iteration 1661: Loss = 1.2590, Accuracy = 0.4300 Test Loss = 3.3086, Test Accuracy = 0.3202\n",
      "Iteration 1662: Loss = 1.2349, Accuracy = 0.4500 Test Loss = 3.3043, Test Accuracy = 0.3234\n",
      "Iteration 1663: Loss = 1.1733, Accuracy = 0.4900 Test Loss = 3.2992, Test Accuracy = 0.3239\n",
      "Iteration 1664: Loss = 1.2086, Accuracy = 0.5300 Test Loss = 3.3014, Test Accuracy = 0.3241\n",
      "Iteration 1665: Loss = 1.1573, Accuracy = 0.5100 Test Loss = 3.3006, Test Accuracy = 0.3219\n",
      "Iteration 1666: Loss = 1.2316, Accuracy = 0.4800 Test Loss = 3.2949, Test Accuracy = 0.3228\n",
      "Iteration 1667: Loss = 1.1698, Accuracy = 0.5200 Test Loss = 3.2969, Test Accuracy = 0.3224\n",
      "Iteration 1668: Loss = 1.3628, Accuracy = 0.5000 Test Loss = 3.2967, Test Accuracy = 0.3226\n",
      "Iteration 1669: Loss = 1.2304, Accuracy = 0.5500 Test Loss = 3.2933, Test Accuracy = 0.3235\n",
      "Iteration 1670: Loss = 1.4321, Accuracy = 0.5000 Test Loss = 3.2913, Test Accuracy = 0.3228\n",
      "Iteration 1671: Loss = 1.2374, Accuracy = 0.5300 Test Loss = 3.2896, Test Accuracy = 0.3237\n",
      "Iteration 1672: Loss = 1.2896, Accuracy = 0.3800 Test Loss = 3.2863, Test Accuracy = 0.3242\n",
      "Iteration 1673: Loss = 1.2735, Accuracy = 0.5300 Test Loss = 3.2855, Test Accuracy = 0.3248\n",
      "Iteration 1674: Loss = 1.2393, Accuracy = 0.5500 Test Loss = 3.2873, Test Accuracy = 0.3242\n",
      "Iteration 1675: Loss = 1.2408, Accuracy = 0.5300 Test Loss = 3.2839, Test Accuracy = 0.3240\n",
      "Iteration 1676: Loss = 1.2220, Accuracy = 0.5500 Test Loss = 3.2829, Test Accuracy = 0.3230\n",
      "Iteration 1677: Loss = 1.3266, Accuracy = 0.4900 Test Loss = 3.2809, Test Accuracy = 0.3249\n",
      "Iteration 1678: Loss = 1.2548, Accuracy = 0.4500 Test Loss = 3.2781, Test Accuracy = 0.3233\n",
      "Iteration 1679: Loss = 1.1754, Accuracy = 0.4400 Test Loss = 3.2757, Test Accuracy = 0.3251\n",
      "Iteration 1680: Loss = 1.2971, Accuracy = 0.4900 Test Loss = 3.2752, Test Accuracy = 0.3237\n",
      "Iteration 1681: Loss = 1.3448, Accuracy = 0.4500 Test Loss = 3.2780, Test Accuracy = 0.3243\n",
      "Iteration 1682: Loss = 1.2583, Accuracy = 0.3200 Test Loss = 3.2722, Test Accuracy = 0.3243\n",
      "Iteration 1683: Loss = 1.3122, Accuracy = 0.5200 Test Loss = 3.2726, Test Accuracy = 0.3251\n",
      "Iteration 1684: Loss = 1.2705, Accuracy = 0.5100 Test Loss = 3.2699, Test Accuracy = 0.3247\n",
      "Iteration 1685: Loss = 1.2173, Accuracy = 0.5300 Test Loss = 3.2683, Test Accuracy = 0.3242\n",
      "Iteration 1686: Loss = 1.2156, Accuracy = 0.5600 Test Loss = 3.2664, Test Accuracy = 0.3247\n",
      "Iteration 1687: Loss = 1.1747, Accuracy = 0.5600 Test Loss = 3.2667, Test Accuracy = 0.3244\n",
      "Iteration 1688: Loss = 1.4710, Accuracy = 0.4600 Test Loss = 3.2646, Test Accuracy = 0.3266\n",
      "Iteration 1689: Loss = 1.1969, Accuracy = 0.5000 Test Loss = 3.2624, Test Accuracy = 0.3249\n",
      "Iteration 1690: Loss = 1.1395, Accuracy = 0.6000 Test Loss = 3.2618, Test Accuracy = 0.3264\n",
      "Iteration 1691: Loss = 1.2019, Accuracy = 0.5700 Test Loss = 3.2598, Test Accuracy = 0.3248\n",
      "Iteration 1692: Loss = 1.2074, Accuracy = 0.4100 Test Loss = 3.2606, Test Accuracy = 0.3236\n",
      "Iteration 1693: Loss = 1.1667, Accuracy = 0.5500 Test Loss = 3.2595, Test Accuracy = 0.3255\n",
      "Iteration 1694: Loss = 1.1451, Accuracy = 0.5000 Test Loss = 3.2569, Test Accuracy = 0.3240\n",
      "Iteration 1695: Loss = 1.2358, Accuracy = 0.4300 Test Loss = 3.2520, Test Accuracy = 0.3263\n",
      "Iteration 1696: Loss = 1.2354, Accuracy = 0.4200 Test Loss = 3.2557, Test Accuracy = 0.3246\n",
      "Iteration 1697: Loss = 1.2021, Accuracy = 0.5000 Test Loss = 3.2499, Test Accuracy = 0.3254\n",
      "Iteration 1698: Loss = 1.1876, Accuracy = 0.5000 Test Loss = 3.2518, Test Accuracy = 0.3252\n",
      "Iteration 1699: Loss = 1.2482, Accuracy = 0.5200 Test Loss = 3.2470, Test Accuracy = 0.3262\n",
      "Iteration 1700: Loss = 1.0921, Accuracy = 0.4400 Test Loss = 3.2481, Test Accuracy = 0.3264\n",
      "Iteration 1701: Loss = 1.3154, Accuracy = 0.5000 Test Loss = 3.2460, Test Accuracy = 0.3247\n",
      "Iteration 1702: Loss = 1.2099, Accuracy = 0.4900 Test Loss = 3.2463, Test Accuracy = 0.3253\n",
      "Iteration 1703: Loss = 1.1925, Accuracy = 0.4600 Test Loss = 3.2435, Test Accuracy = 0.3249\n",
      "Iteration 1704: Loss = 1.2250, Accuracy = 0.4900 Test Loss = 3.2400, Test Accuracy = 0.3247\n",
      "Iteration 1705: Loss = 1.1557, Accuracy = 0.5500 Test Loss = 3.2366, Test Accuracy = 0.3263\n",
      "Iteration 1706: Loss = 1.2553, Accuracy = 0.4900 Test Loss = 3.2413, Test Accuracy = 0.3249\n",
      "Iteration 1707: Loss = 1.1707, Accuracy = 0.5600 Test Loss = 3.2373, Test Accuracy = 0.3248\n",
      "Iteration 1708: Loss = 1.2142, Accuracy = 0.5000 Test Loss = 3.2361, Test Accuracy = 0.3250\n",
      "Iteration 1709: Loss = 1.3439, Accuracy = 0.4900 Test Loss = 3.2365, Test Accuracy = 0.3258\n",
      "Iteration 1710: Loss = 1.1159, Accuracy = 0.4700 Test Loss = 3.2320, Test Accuracy = 0.3266\n",
      "Iteration 1711: Loss = 1.2140, Accuracy = 0.5600 Test Loss = 3.2300, Test Accuracy = 0.3262\n",
      "Iteration 1712: Loss = 1.1905, Accuracy = 0.5700 Test Loss = 3.2314, Test Accuracy = 0.3263\n",
      "Iteration 1713: Loss = 1.1731, Accuracy = 0.5500 Test Loss = 3.2285, Test Accuracy = 0.3276\n",
      "Iteration 1714: Loss = 1.1950, Accuracy = 0.4900 Test Loss = 3.2251, Test Accuracy = 0.3264\n",
      "Iteration 1715: Loss = 1.1347, Accuracy = 0.5800 Test Loss = 3.2284, Test Accuracy = 0.3249\n",
      "Iteration 1716: Loss = 1.2060, Accuracy = 0.5400 Test Loss = 3.2232, Test Accuracy = 0.3272\n",
      "Iteration 1717: Loss = 1.2252, Accuracy = 0.5200 Test Loss = 3.2209, Test Accuracy = 0.3266\n",
      "Iteration 1718: Loss = 1.3097, Accuracy = 0.5100 Test Loss = 3.2251, Test Accuracy = 0.3257\n",
      "Iteration 1719: Loss = 1.3197, Accuracy = 0.4600 Test Loss = 3.2177, Test Accuracy = 0.3272\n",
      "Iteration 1720: Loss = 1.1110, Accuracy = 0.6600 Test Loss = 3.2150, Test Accuracy = 0.3273\n",
      "Iteration 1721: Loss = 1.1709, Accuracy = 0.4600 Test Loss = 3.2171, Test Accuracy = 0.3269\n",
      "Iteration 1722: Loss = 1.1287, Accuracy = 0.4900 Test Loss = 3.2120, Test Accuracy = 0.3272\n",
      "Iteration 1723: Loss = 1.2345, Accuracy = 0.4900 Test Loss = 3.2118, Test Accuracy = 0.3270\n",
      "Iteration 1724: Loss = 1.1880, Accuracy = 0.5400 Test Loss = 3.2131, Test Accuracy = 0.3271\n",
      "Iteration 1725: Loss = 1.1861, Accuracy = 0.5500 Test Loss = 3.2108, Test Accuracy = 0.3269\n",
      "Iteration 1726: Loss = 1.1268, Accuracy = 0.5300 Test Loss = 3.2074, Test Accuracy = 0.3274\n",
      "Iteration 1727: Loss = 1.1374, Accuracy = 0.5200 Test Loss = 3.2075, Test Accuracy = 0.3262\n",
      "Iteration 1728: Loss = 1.3129, Accuracy = 0.4900 Test Loss = 3.2024, Test Accuracy = 0.3298\n",
      "Iteration 1729: Loss = 1.2188, Accuracy = 0.4500 Test Loss = 3.2029, Test Accuracy = 0.3280\n",
      "Iteration 1730: Loss = 1.2354, Accuracy = 0.4600 Test Loss = 3.2013, Test Accuracy = 0.3297\n",
      "Iteration 1731: Loss = 1.2062, Accuracy = 0.4800 Test Loss = 3.2008, Test Accuracy = 0.3280\n",
      "Iteration 1732: Loss = 1.1435, Accuracy = 0.5200 Test Loss = 3.2018, Test Accuracy = 0.3273\n",
      "Iteration 1733: Loss = 1.3043, Accuracy = 0.5300 Test Loss = 3.2003, Test Accuracy = 0.3284\n",
      "Iteration 1734: Loss = 1.2683, Accuracy = 0.4400 Test Loss = 3.1996, Test Accuracy = 0.3274\n",
      "Iteration 1735: Loss = 1.1568, Accuracy = 0.5500 Test Loss = 3.1977, Test Accuracy = 0.3284\n",
      "Iteration 1736: Loss = 1.2527, Accuracy = 0.4000 Test Loss = 3.1946, Test Accuracy = 0.3288\n",
      "Iteration 1737: Loss = 1.0691, Accuracy = 0.5700 Test Loss = 3.1930, Test Accuracy = 0.3293\n",
      "Iteration 1738: Loss = 1.1730, Accuracy = 0.5600 Test Loss = 3.1934, Test Accuracy = 0.3273\n",
      "Iteration 1739: Loss = 1.1645, Accuracy = 0.4700 Test Loss = 3.1910, Test Accuracy = 0.3282\n",
      "Iteration 1740: Loss = 1.1931, Accuracy = 0.5800 Test Loss = 3.1885, Test Accuracy = 0.3280\n",
      "Iteration 1741: Loss = 1.2791, Accuracy = 0.5100 Test Loss = 3.1878, Test Accuracy = 0.3289\n",
      "Iteration 1742: Loss = 1.1984, Accuracy = 0.4600 Test Loss = 3.1863, Test Accuracy = 0.3294\n",
      "Iteration 1743: Loss = 1.2033, Accuracy = 0.4700 Test Loss = 3.1857, Test Accuracy = 0.3287\n",
      "Iteration 1744: Loss = 1.2181, Accuracy = 0.5400 Test Loss = 3.1810, Test Accuracy = 0.3301\n",
      "Iteration 1745: Loss = 1.1829, Accuracy = 0.4300 Test Loss = 3.1814, Test Accuracy = 0.3297\n",
      "Iteration 1746: Loss = 1.1492, Accuracy = 0.5600 Test Loss = 3.1791, Test Accuracy = 0.3299\n",
      "Iteration 1747: Loss = 1.1070, Accuracy = 0.5800 Test Loss = 3.1791, Test Accuracy = 0.3295\n",
      "Iteration 1748: Loss = 1.2751, Accuracy = 0.4000 Test Loss = 3.1768, Test Accuracy = 0.3292\n",
      "Iteration 1749: Loss = 1.2465, Accuracy = 0.4700 Test Loss = 3.1795, Test Accuracy = 0.3269\n",
      "Iteration 1750: Loss = 1.1735, Accuracy = 0.5400 Test Loss = 3.1714, Test Accuracy = 0.3299\n",
      "Iteration 1751: Loss = 1.2742, Accuracy = 0.4700 Test Loss = 3.1732, Test Accuracy = 0.3291\n",
      "Iteration 1752: Loss = 1.1397, Accuracy = 0.6300 Test Loss = 3.1698, Test Accuracy = 0.3287\n",
      "Iteration 1753: Loss = 1.1840, Accuracy = 0.4800 Test Loss = 3.1703, Test Accuracy = 0.3309\n",
      "Iteration 1754: Loss = 1.2077, Accuracy = 0.5200 Test Loss = 3.1704, Test Accuracy = 0.3305\n",
      "Iteration 1755: Loss = 1.2181, Accuracy = 0.4800 Test Loss = 3.1687, Test Accuracy = 0.3294\n",
      "Iteration 1756: Loss = 1.1145, Accuracy = 0.5600 Test Loss = 3.1672, Test Accuracy = 0.3289\n",
      "Iteration 1757: Loss = 1.1650, Accuracy = 0.5800 Test Loss = 3.1674, Test Accuracy = 0.3297\n",
      "Iteration 1758: Loss = 1.1583, Accuracy = 0.5500 Test Loss = 3.1605, Test Accuracy = 0.3318\n",
      "Iteration 1759: Loss = 1.2227, Accuracy = 0.5400 Test Loss = 3.1625, Test Accuracy = 0.3295\n",
      "Iteration 1760: Loss = 1.3737, Accuracy = 0.4800 Test Loss = 3.1599, Test Accuracy = 0.3300\n",
      "Iteration 1761: Loss = 1.1816, Accuracy = 0.5000 Test Loss = 3.1571, Test Accuracy = 0.3311\n",
      "Iteration 1762: Loss = 1.2046, Accuracy = 0.4700 Test Loss = 3.1592, Test Accuracy = 0.3292\n",
      "Iteration 1763: Loss = 1.2435, Accuracy = 0.5100 Test Loss = 3.1597, Test Accuracy = 0.3306\n",
      "Iteration 1764: Loss = 1.0714, Accuracy = 0.5600 Test Loss = 3.1538, Test Accuracy = 0.3319\n",
      "Iteration 1765: Loss = 1.1270, Accuracy = 0.5000 Test Loss = 3.1543, Test Accuracy = 0.3305\n",
      "Iteration 1766: Loss = 1.1429, Accuracy = 0.5500 Test Loss = 3.1514, Test Accuracy = 0.3311\n",
      "Iteration 1767: Loss = 1.2302, Accuracy = 0.4500 Test Loss = 3.1519, Test Accuracy = 0.3318\n",
      "Iteration 1768: Loss = 1.1935, Accuracy = 0.5400 Test Loss = 3.1513, Test Accuracy = 0.3299\n",
      "Iteration 1769: Loss = 1.1603, Accuracy = 0.5700 Test Loss = 3.1521, Test Accuracy = 0.3293\n",
      "Iteration 1770: Loss = 1.1599, Accuracy = 0.5300 Test Loss = 3.1454, Test Accuracy = 0.3310\n",
      "Iteration 1771: Loss = 1.2978, Accuracy = 0.4800 Test Loss = 3.1455, Test Accuracy = 0.3300\n",
      "Iteration 1772: Loss = 1.2211, Accuracy = 0.5800 Test Loss = 3.1416, Test Accuracy = 0.3313\n",
      "Iteration 1773: Loss = 1.1082, Accuracy = 0.5300 Test Loss = 3.1428, Test Accuracy = 0.3311\n",
      "Iteration 1774: Loss = 1.1682, Accuracy = 0.4800 Test Loss = 3.1415, Test Accuracy = 0.3306\n",
      "Iteration 1775: Loss = 1.1769, Accuracy = 0.5100 Test Loss = 3.1395, Test Accuracy = 0.3325\n",
      "Iteration 1776: Loss = 1.2548, Accuracy = 0.4300 Test Loss = 3.1414, Test Accuracy = 0.3301\n",
      "Iteration 1777: Loss = 1.3153, Accuracy = 0.5000 Test Loss = 3.1392, Test Accuracy = 0.3314\n",
      "Iteration 1778: Loss = 1.1625, Accuracy = 0.5700 Test Loss = 3.1379, Test Accuracy = 0.3304\n",
      "Iteration 1779: Loss = 1.1773, Accuracy = 0.5000 Test Loss = 3.1369, Test Accuracy = 0.3314\n",
      "Iteration 1780: Loss = 1.1108, Accuracy = 0.5200 Test Loss = 3.1348, Test Accuracy = 0.3303\n",
      "Iteration 1781: Loss = 1.1469, Accuracy = 0.5400 Test Loss = 3.1313, Test Accuracy = 0.3314\n",
      "Iteration 1782: Loss = 1.1565, Accuracy = 0.5300 Test Loss = 3.1338, Test Accuracy = 0.3299\n",
      "Iteration 1783: Loss = 1.2526, Accuracy = 0.4500 Test Loss = 3.1295, Test Accuracy = 0.3324\n",
      "Iteration 1784: Loss = 1.1231, Accuracy = 0.5700 Test Loss = 3.1296, Test Accuracy = 0.3321\n",
      "Iteration 1785: Loss = 1.1891, Accuracy = 0.5900 Test Loss = 3.1336, Test Accuracy = 0.3294\n",
      "Iteration 1786: Loss = 1.1831, Accuracy = 0.4900 Test Loss = 3.1256, Test Accuracy = 0.3316\n",
      "Iteration 1787: Loss = 1.2752, Accuracy = 0.4100 Test Loss = 3.1235, Test Accuracy = 0.3312\n",
      "Iteration 1788: Loss = 1.1370, Accuracy = 0.5800 Test Loss = 3.1209, Test Accuracy = 0.3322\n",
      "Iteration 1789: Loss = 1.0896, Accuracy = 0.5800 Test Loss = 3.1221, Test Accuracy = 0.3322\n",
      "Iteration 1790: Loss = 1.2295, Accuracy = 0.5200 Test Loss = 3.1188, Test Accuracy = 0.3311\n",
      "Iteration 1791: Loss = 1.0723, Accuracy = 0.5000 Test Loss = 3.1188, Test Accuracy = 0.3322\n",
      "Iteration 1792: Loss = 1.1005, Accuracy = 0.5900 Test Loss = 3.1218, Test Accuracy = 0.3321\n",
      "Iteration 1793: Loss = 1.2309, Accuracy = 0.5500 Test Loss = 3.1181, Test Accuracy = 0.3316\n",
      "Iteration 1794: Loss = 1.1065, Accuracy = 0.6000 Test Loss = 3.1125, Test Accuracy = 0.3315\n",
      "Iteration 1795: Loss = 1.1209, Accuracy = 0.5600 Test Loss = 3.1149, Test Accuracy = 0.3315\n",
      "Iteration 1796: Loss = 1.2134, Accuracy = 0.4500 Test Loss = 3.1103, Test Accuracy = 0.3320\n",
      "Iteration 1797: Loss = 1.1357, Accuracy = 0.5800 Test Loss = 3.1126, Test Accuracy = 0.3325\n",
      "Iteration 1798: Loss = 1.1423, Accuracy = 0.5400 Test Loss = 3.1101, Test Accuracy = 0.3331\n",
      "Iteration 1799: Loss = 1.1875, Accuracy = 0.4200 Test Loss = 3.1101, Test Accuracy = 0.3328\n",
      "Iteration 1800: Loss = 1.2359, Accuracy = 0.4800 Test Loss = 3.1076, Test Accuracy = 0.3323\n",
      "Iteration 1801: Loss = 1.2348, Accuracy = 0.5300 Test Loss = 3.1037, Test Accuracy = 0.3329\n",
      "Iteration 1802: Loss = 1.2536, Accuracy = 0.4900 Test Loss = 3.1042, Test Accuracy = 0.3323\n",
      "Iteration 1803: Loss = 1.1963, Accuracy = 0.5400 Test Loss = 3.1016, Test Accuracy = 0.3329\n",
      "Iteration 1804: Loss = 1.0735, Accuracy = 0.5200 Test Loss = 3.1056, Test Accuracy = 0.3321\n",
      "Iteration 1805: Loss = 1.1368, Accuracy = 0.5800 Test Loss = 3.1001, Test Accuracy = 0.3337\n",
      "Iteration 1806: Loss = 1.2405, Accuracy = 0.4300 Test Loss = 3.0980, Test Accuracy = 0.3323\n",
      "Iteration 1807: Loss = 1.1970, Accuracy = 0.4600 Test Loss = 3.0969, Test Accuracy = 0.3330\n",
      "Iteration 1808: Loss = 1.0144, Accuracy = 0.5500 Test Loss = 3.0988, Test Accuracy = 0.3329\n",
      "Iteration 1809: Loss = 1.1062, Accuracy = 0.5300 Test Loss = 3.0982, Test Accuracy = 0.3333\n",
      "Iteration 1810: Loss = 1.1174, Accuracy = 0.4000 Test Loss = 3.0943, Test Accuracy = 0.3336\n",
      "Iteration 1811: Loss = 1.1263, Accuracy = 0.5400 Test Loss = 3.0917, Test Accuracy = 0.3339\n",
      "Iteration 1812: Loss = 1.1029, Accuracy = 0.5300 Test Loss = 3.0912, Test Accuracy = 0.3333\n",
      "Iteration 1813: Loss = 1.1362, Accuracy = 0.5000 Test Loss = 3.0911, Test Accuracy = 0.3332\n",
      "Iteration 1814: Loss = 1.1172, Accuracy = 0.5500 Test Loss = 3.0869, Test Accuracy = 0.3351\n",
      "Iteration 1815: Loss = 1.2810, Accuracy = 0.5200 Test Loss = 3.0879, Test Accuracy = 0.3331\n",
      "Iteration 1816: Loss = 1.1217, Accuracy = 0.5500 Test Loss = 3.0844, Test Accuracy = 0.3339\n",
      "Iteration 1817: Loss = 1.2377, Accuracy = 0.4600 Test Loss = 3.0824, Test Accuracy = 0.3350\n",
      "Iteration 1818: Loss = 1.0987, Accuracy = 0.5600 Test Loss = 3.0806, Test Accuracy = 0.3341\n",
      "Iteration 1819: Loss = 1.0653, Accuracy = 0.6100 Test Loss = 3.0792, Test Accuracy = 0.3343\n",
      "Iteration 1820: Loss = 1.1513, Accuracy = 0.4800 Test Loss = 3.0813, Test Accuracy = 0.3341\n",
      "Iteration 1821: Loss = 1.1694, Accuracy = 0.5600 Test Loss = 3.0810, Test Accuracy = 0.3335\n",
      "Iteration 1822: Loss = 1.0975, Accuracy = 0.5600 Test Loss = 3.0765, Test Accuracy = 0.3338\n",
      "Iteration 1823: Loss = 1.1444, Accuracy = 0.4500 Test Loss = 3.0753, Test Accuracy = 0.3342\n",
      "Iteration 1824: Loss = 1.2435, Accuracy = 0.4700 Test Loss = 3.0741, Test Accuracy = 0.3342\n",
      "Iteration 1825: Loss = 1.2072, Accuracy = 0.4800 Test Loss = 3.0768, Test Accuracy = 0.3337\n",
      "Iteration 1826: Loss = 1.0923, Accuracy = 0.5300 Test Loss = 3.0704, Test Accuracy = 0.3346\n",
      "Iteration 1827: Loss = 1.0072, Accuracy = 0.5500 Test Loss = 3.0700, Test Accuracy = 0.3353\n",
      "Iteration 1828: Loss = 1.1238, Accuracy = 0.5500 Test Loss = 3.0687, Test Accuracy = 0.3342\n",
      "Iteration 1829: Loss = 1.0313, Accuracy = 0.5400 Test Loss = 3.0662, Test Accuracy = 0.3365\n",
      "Iteration 1830: Loss = 1.1211, Accuracy = 0.4800 Test Loss = 3.0711, Test Accuracy = 0.3362\n",
      "Iteration 1831: Loss = 1.1349, Accuracy = 0.5600 Test Loss = 3.0655, Test Accuracy = 0.3357\n",
      "Iteration 1832: Loss = 1.0634, Accuracy = 0.5400 Test Loss = 3.0666, Test Accuracy = 0.3363\n",
      "Iteration 1833: Loss = 1.1026, Accuracy = 0.5000 Test Loss = 3.0630, Test Accuracy = 0.3335\n",
      "Iteration 1834: Loss = 1.1174, Accuracy = 0.5700 Test Loss = 3.0633, Test Accuracy = 0.3336\n",
      "Iteration 1835: Loss = 1.1554, Accuracy = 0.5100 Test Loss = 3.0599, Test Accuracy = 0.3359\n",
      "Iteration 1836: Loss = 1.1463, Accuracy = 0.5500 Test Loss = 3.0577, Test Accuracy = 0.3355\n",
      "Iteration 1837: Loss = 1.1443, Accuracy = 0.5100 Test Loss = 3.0567, Test Accuracy = 0.3355\n",
      "Iteration 1838: Loss = 1.1849, Accuracy = 0.4700 Test Loss = 3.0568, Test Accuracy = 0.3366\n",
      "Iteration 1839: Loss = 1.0424, Accuracy = 0.5600 Test Loss = 3.0604, Test Accuracy = 0.3344\n",
      "Iteration 1840: Loss = 1.0892, Accuracy = 0.4300 Test Loss = 3.0512, Test Accuracy = 0.3364\n",
      "Iteration 1841: Loss = 1.0379, Accuracy = 0.5100 Test Loss = 3.0495, Test Accuracy = 0.3349\n",
      "Iteration 1842: Loss = 1.1016, Accuracy = 0.5600 Test Loss = 3.0519, Test Accuracy = 0.3372\n",
      "Iteration 1843: Loss = 1.1693, Accuracy = 0.5100 Test Loss = 3.0504, Test Accuracy = 0.3360\n",
      "Iteration 1844: Loss = 1.0806, Accuracy = 0.5600 Test Loss = 3.0495, Test Accuracy = 0.3361\n",
      "Iteration 1845: Loss = 1.1947, Accuracy = 0.5600 Test Loss = 3.0483, Test Accuracy = 0.3362\n",
      "Iteration 1846: Loss = 1.0642, Accuracy = 0.5300 Test Loss = 3.0522, Test Accuracy = 0.3346\n",
      "Iteration 1847: Loss = 1.0081, Accuracy = 0.6600 Test Loss = 3.0464, Test Accuracy = 0.3353\n",
      "Iteration 1848: Loss = 1.0487, Accuracy = 0.5600 Test Loss = 3.0410, Test Accuracy = 0.3372\n",
      "Iteration 1849: Loss = 1.3015, Accuracy = 0.4400 Test Loss = 3.0398, Test Accuracy = 0.3368\n",
      "Iteration 1850: Loss = 1.1361, Accuracy = 0.4700 Test Loss = 3.0425, Test Accuracy = 0.3356\n",
      "Iteration 1851: Loss = 1.0239, Accuracy = 0.5500 Test Loss = 3.0394, Test Accuracy = 0.3356\n",
      "Iteration 1852: Loss = 1.1333, Accuracy = 0.5700 Test Loss = 3.0369, Test Accuracy = 0.3373\n",
      "Iteration 1853: Loss = 1.0702, Accuracy = 0.5200 Test Loss = 3.0382, Test Accuracy = 0.3371\n",
      "Iteration 1854: Loss = 1.1540, Accuracy = 0.5400 Test Loss = 3.0363, Test Accuracy = 0.3367\n",
      "Iteration 1855: Loss = 1.1820, Accuracy = 0.6300 Test Loss = 3.0385, Test Accuracy = 0.3360\n",
      "Iteration 1856: Loss = 1.0444, Accuracy = 0.5500 Test Loss = 3.0316, Test Accuracy = 0.3373\n",
      "Iteration 1857: Loss = 1.1619, Accuracy = 0.4700 Test Loss = 3.0331, Test Accuracy = 0.3364\n",
      "Iteration 1858: Loss = 1.2186, Accuracy = 0.5500 Test Loss = 3.0323, Test Accuracy = 0.3365\n",
      "Iteration 1859: Loss = 1.1225, Accuracy = 0.4700 Test Loss = 3.0305, Test Accuracy = 0.3376\n",
      "Iteration 1860: Loss = 1.1104, Accuracy = 0.5500 Test Loss = 3.0306, Test Accuracy = 0.3371\n",
      "Iteration 1861: Loss = 1.1443, Accuracy = 0.4400 Test Loss = 3.0291, Test Accuracy = 0.3355\n",
      "Iteration 1862: Loss = 1.2151, Accuracy = 0.4100 Test Loss = 3.0280, Test Accuracy = 0.3354\n",
      "Iteration 1863: Loss = 1.1869, Accuracy = 0.4300 Test Loss = 3.0242, Test Accuracy = 0.3377\n",
      "Iteration 1864: Loss = 1.2366, Accuracy = 0.5200 Test Loss = 3.0234, Test Accuracy = 0.3387\n",
      "Iteration 1865: Loss = 1.0583, Accuracy = 0.5500 Test Loss = 3.0233, Test Accuracy = 0.3383\n",
      "Iteration 1866: Loss = 1.1392, Accuracy = 0.5500 Test Loss = 3.0227, Test Accuracy = 0.3371\n",
      "Iteration 1867: Loss = 1.0922, Accuracy = 0.5400 Test Loss = 3.0222, Test Accuracy = 0.3366\n",
      "Iteration 1868: Loss = 1.0613, Accuracy = 0.5600 Test Loss = 3.0178, Test Accuracy = 0.3388\n",
      "Iteration 1869: Loss = 1.0642, Accuracy = 0.5700 Test Loss = 3.0180, Test Accuracy = 0.3390\n",
      "Iteration 1870: Loss = 1.0994, Accuracy = 0.5500 Test Loss = 3.0181, Test Accuracy = 0.3378\n",
      "Iteration 1871: Loss = 1.2183, Accuracy = 0.4800 Test Loss = 3.0148, Test Accuracy = 0.3383\n",
      "Iteration 1872: Loss = 1.1590, Accuracy = 0.5000 Test Loss = 3.0160, Test Accuracy = 0.3391\n",
      "Iteration 1873: Loss = 1.2256, Accuracy = 0.4800 Test Loss = 3.0146, Test Accuracy = 0.3385\n",
      "Iteration 1874: Loss = 1.1206, Accuracy = 0.4700 Test Loss = 3.0099, Test Accuracy = 0.3383\n",
      "Iteration 1875: Loss = 1.1169, Accuracy = 0.5900 Test Loss = 3.0116, Test Accuracy = 0.3386\n",
      "Iteration 1876: Loss = 1.1076, Accuracy = 0.4800 Test Loss = 3.0090, Test Accuracy = 0.3387\n",
      "Iteration 1877: Loss = 1.0755, Accuracy = 0.6000 Test Loss = 3.0102, Test Accuracy = 0.3393\n",
      "Iteration 1878: Loss = 1.1215, Accuracy = 0.5400 Test Loss = 3.0068, Test Accuracy = 0.3401\n",
      "Iteration 1879: Loss = 1.0153, Accuracy = 0.5500 Test Loss = 3.0039, Test Accuracy = 0.3397\n",
      "Iteration 1880: Loss = 1.0511, Accuracy = 0.6000 Test Loss = 3.0036, Test Accuracy = 0.3389\n",
      "Iteration 1881: Loss = 1.0567, Accuracy = 0.5100 Test Loss = 3.0035, Test Accuracy = 0.3385\n",
      "Iteration 1882: Loss = 1.1584, Accuracy = 0.5600 Test Loss = 3.0016, Test Accuracy = 0.3397\n",
      "Iteration 1883: Loss = 0.9862, Accuracy = 0.5600 Test Loss = 2.9991, Test Accuracy = 0.3388\n",
      "Iteration 1884: Loss = 0.9747, Accuracy = 0.6300 Test Loss = 2.9985, Test Accuracy = 0.3389\n",
      "Iteration 1885: Loss = 1.2010, Accuracy = 0.4700 Test Loss = 2.9961, Test Accuracy = 0.3390\n",
      "Iteration 1886: Loss = 1.0146, Accuracy = 0.5700 Test Loss = 3.0016, Test Accuracy = 0.3386\n",
      "Iteration 1887: Loss = 1.1942, Accuracy = 0.5300 Test Loss = 2.9960, Test Accuracy = 0.3392\n",
      "Iteration 1888: Loss = 1.0575, Accuracy = 0.6000 Test Loss = 2.9951, Test Accuracy = 0.3381\n",
      "Iteration 1889: Loss = 0.9738, Accuracy = 0.5800 Test Loss = 2.9949, Test Accuracy = 0.3400\n",
      "Iteration 1890: Loss = 1.1593, Accuracy = 0.5300 Test Loss = 2.9909, Test Accuracy = 0.3387\n",
      "Iteration 1891: Loss = 1.0947, Accuracy = 0.5400 Test Loss = 2.9888, Test Accuracy = 0.3392\n",
      "Iteration 1892: Loss = 0.9943, Accuracy = 0.5400 Test Loss = 2.9880, Test Accuracy = 0.3405\n",
      "Iteration 1893: Loss = 1.0445, Accuracy = 0.5200 Test Loss = 2.9868, Test Accuracy = 0.3403\n",
      "Iteration 1894: Loss = 0.9623, Accuracy = 0.7000 Test Loss = 2.9878, Test Accuracy = 0.3383\n",
      "Iteration 1895: Loss = 1.0775, Accuracy = 0.5100 Test Loss = 2.9858, Test Accuracy = 0.3396\n",
      "Iteration 1896: Loss = 1.0137, Accuracy = 0.5900 Test Loss = 2.9851, Test Accuracy = 0.3404\n",
      "Iteration 1897: Loss = 1.1068, Accuracy = 0.5500 Test Loss = 2.9837, Test Accuracy = 0.3404\n",
      "Iteration 1898: Loss = 1.1595, Accuracy = 0.5700 Test Loss = 2.9827, Test Accuracy = 0.3389\n",
      "Iteration 1899: Loss = 1.1114, Accuracy = 0.5100 Test Loss = 2.9811, Test Accuracy = 0.3400\n",
      "Iteration 1900: Loss = 1.0770, Accuracy = 0.5500 Test Loss = 2.9777, Test Accuracy = 0.3399\n",
      "Iteration 1901: Loss = 1.0574, Accuracy = 0.5400 Test Loss = 2.9784, Test Accuracy = 0.3416\n",
      "Iteration 1902: Loss = 1.0627, Accuracy = 0.5100 Test Loss = 2.9752, Test Accuracy = 0.3411\n",
      "Iteration 1903: Loss = 1.1807, Accuracy = 0.4900 Test Loss = 2.9739, Test Accuracy = 0.3401\n",
      "Iteration 1904: Loss = 1.1758, Accuracy = 0.5000 Test Loss = 2.9779, Test Accuracy = 0.3401\n",
      "Iteration 1905: Loss = 1.0386, Accuracy = 0.5400 Test Loss = 2.9737, Test Accuracy = 0.3402\n",
      "Iteration 1906: Loss = 1.1028, Accuracy = 0.5200 Test Loss = 2.9716, Test Accuracy = 0.3403\n",
      "Iteration 1907: Loss = 1.1193, Accuracy = 0.5800 Test Loss = 2.9726, Test Accuracy = 0.3419\n",
      "Iteration 1908: Loss = 1.0059, Accuracy = 0.5500 Test Loss = 2.9720, Test Accuracy = 0.3424\n",
      "Iteration 1909: Loss = 1.1110, Accuracy = 0.5400 Test Loss = 2.9706, Test Accuracy = 0.3396\n",
      "Iteration 1910: Loss = 1.0666, Accuracy = 0.5700 Test Loss = 2.9692, Test Accuracy = 0.3417\n",
      "Iteration 1911: Loss = 1.0999, Accuracy = 0.5300 Test Loss = 2.9638, Test Accuracy = 0.3426\n",
      "Iteration 1912: Loss = 1.1477, Accuracy = 0.5000 Test Loss = 2.9649, Test Accuracy = 0.3416\n",
      "Iteration 1913: Loss = 1.0670, Accuracy = 0.4900 Test Loss = 2.9643, Test Accuracy = 0.3427\n",
      "Iteration 1914: Loss = 1.1273, Accuracy = 0.5200 Test Loss = 2.9636, Test Accuracy = 0.3410\n",
      "Iteration 1915: Loss = 1.0772, Accuracy = 0.5000 Test Loss = 2.9598, Test Accuracy = 0.3426\n",
      "Iteration 1916: Loss = 0.9818, Accuracy = 0.6000 Test Loss = 2.9603, Test Accuracy = 0.3409\n",
      "Iteration 1917: Loss = 1.0748, Accuracy = 0.4900 Test Loss = 2.9603, Test Accuracy = 0.3413\n",
      "Iteration 1918: Loss = 1.0026, Accuracy = 0.5800 Test Loss = 2.9560, Test Accuracy = 0.3411\n",
      "Iteration 1919: Loss = 1.0940, Accuracy = 0.5800 Test Loss = 2.9552, Test Accuracy = 0.3411\n",
      "Iteration 1920: Loss = 1.1198, Accuracy = 0.5000 Test Loss = 2.9573, Test Accuracy = 0.3402\n",
      "Iteration 1921: Loss = 1.0110, Accuracy = 0.4900 Test Loss = 2.9530, Test Accuracy = 0.3411\n",
      "Iteration 1922: Loss = 1.0284, Accuracy = 0.6000 Test Loss = 2.9550, Test Accuracy = 0.3417\n",
      "Iteration 1923: Loss = 1.1711, Accuracy = 0.4700 Test Loss = 2.9545, Test Accuracy = 0.3423\n",
      "Iteration 1924: Loss = 1.1382, Accuracy = 0.5500 Test Loss = 2.9523, Test Accuracy = 0.3412\n",
      "Iteration 1925: Loss = 1.0147, Accuracy = 0.4800 Test Loss = 2.9468, Test Accuracy = 0.3418\n",
      "Iteration 1926: Loss = 0.9843, Accuracy = 0.6300 Test Loss = 2.9483, Test Accuracy = 0.3412\n",
      "Iteration 1927: Loss = 1.0395, Accuracy = 0.5300 Test Loss = 2.9459, Test Accuracy = 0.3432\n",
      "Iteration 1928: Loss = 1.0616, Accuracy = 0.5900 Test Loss = 2.9442, Test Accuracy = 0.3433\n",
      "Iteration 1929: Loss = 1.1388, Accuracy = 0.4400 Test Loss = 2.9446, Test Accuracy = 0.3438\n",
      "Iteration 1930: Loss = 1.0264, Accuracy = 0.6000 Test Loss = 2.9421, Test Accuracy = 0.3413\n",
      "Iteration 1931: Loss = 1.0532, Accuracy = 0.5800 Test Loss = 2.9439, Test Accuracy = 0.3419\n",
      "Iteration 1932: Loss = 1.1209, Accuracy = 0.5400 Test Loss = 2.9405, Test Accuracy = 0.3428\n",
      "Iteration 1933: Loss = 1.1109, Accuracy = 0.5000 Test Loss = 2.9405, Test Accuracy = 0.3423\n",
      "Iteration 1934: Loss = 0.9541, Accuracy = 0.6200 Test Loss = 2.9421, Test Accuracy = 0.3426\n",
      "Iteration 1935: Loss = 1.1455, Accuracy = 0.5700 Test Loss = 2.9374, Test Accuracy = 0.3438\n",
      "Iteration 1936: Loss = 1.0272, Accuracy = 0.5600 Test Loss = 2.9364, Test Accuracy = 0.3432\n",
      "Iteration 1937: Loss = 1.0483, Accuracy = 0.5300 Test Loss = 2.9333, Test Accuracy = 0.3439\n",
      "Iteration 1938: Loss = 1.0592, Accuracy = 0.5800 Test Loss = 2.9333, Test Accuracy = 0.3441\n",
      "Iteration 1939: Loss = 1.0189, Accuracy = 0.5600 Test Loss = 2.9340, Test Accuracy = 0.3434\n",
      "Iteration 1940: Loss = 1.0773, Accuracy = 0.5800 Test Loss = 2.9321, Test Accuracy = 0.3429\n",
      "Iteration 1941: Loss = 0.9636, Accuracy = 0.6500 Test Loss = 2.9295, Test Accuracy = 0.3436\n",
      "Iteration 1942: Loss = 1.0035, Accuracy = 0.6400 Test Loss = 2.9273, Test Accuracy = 0.3450\n",
      "Iteration 1943: Loss = 1.0393, Accuracy = 0.5600 Test Loss = 2.9268, Test Accuracy = 0.3437\n",
      "Iteration 1944: Loss = 1.0791, Accuracy = 0.5600 Test Loss = 2.9253, Test Accuracy = 0.3428\n",
      "Iteration 1945: Loss = 1.1073, Accuracy = 0.5500 Test Loss = 2.9316, Test Accuracy = 0.3401\n",
      "Iteration 1946: Loss = 1.0882, Accuracy = 0.5800 Test Loss = 2.9275, Test Accuracy = 0.3428\n",
      "Iteration 1947: Loss = 1.0717, Accuracy = 0.5700 Test Loss = 2.9245, Test Accuracy = 0.3431\n",
      "Iteration 1948: Loss = 1.0392, Accuracy = 0.5900 Test Loss = 2.9212, Test Accuracy = 0.3436\n",
      "Iteration 1949: Loss = 1.0566, Accuracy = 0.4900 Test Loss = 2.9242, Test Accuracy = 0.3436\n",
      "Iteration 1950: Loss = 1.0243, Accuracy = 0.6000 Test Loss = 2.9233, Test Accuracy = 0.3454\n",
      "Iteration 1951: Loss = 1.1591, Accuracy = 0.5000 Test Loss = 2.9168, Test Accuracy = 0.3454\n",
      "Iteration 1952: Loss = 0.9063, Accuracy = 0.6400 Test Loss = 2.9158, Test Accuracy = 0.3444\n",
      "Iteration 1953: Loss = 1.0623, Accuracy = 0.5100 Test Loss = 2.9172, Test Accuracy = 0.3449\n",
      "Iteration 1954: Loss = 1.0532, Accuracy = 0.5700 Test Loss = 2.9191, Test Accuracy = 0.3428\n",
      "Iteration 1955: Loss = 1.0118, Accuracy = 0.5300 Test Loss = 2.9157, Test Accuracy = 0.3434\n",
      "Iteration 1956: Loss = 1.0446, Accuracy = 0.4900 Test Loss = 2.9132, Test Accuracy = 0.3439\n",
      "Iteration 1957: Loss = 0.9828, Accuracy = 0.5800 Test Loss = 2.9100, Test Accuracy = 0.3449\n",
      "Iteration 1958: Loss = 1.0533, Accuracy = 0.5600 Test Loss = 2.9123, Test Accuracy = 0.3445\n",
      "Iteration 1959: Loss = 0.9807, Accuracy = 0.5800 Test Loss = 2.9102, Test Accuracy = 0.3431\n",
      "Iteration 1960: Loss = 1.0969, Accuracy = 0.5900 Test Loss = 2.9075, Test Accuracy = 0.3449\n",
      "Iteration 1961: Loss = 1.1222, Accuracy = 0.5400 Test Loss = 2.9087, Test Accuracy = 0.3455\n",
      "Iteration 1962: Loss = 1.0704, Accuracy = 0.4700 Test Loss = 2.9065, Test Accuracy = 0.3444\n",
      "Iteration 1963: Loss = 1.0198, Accuracy = 0.5300 Test Loss = 2.9055, Test Accuracy = 0.3451\n",
      "Iteration 1964: Loss = 1.0149, Accuracy = 0.4900 Test Loss = 2.9054, Test Accuracy = 0.3446\n",
      "Iteration 1965: Loss = 0.9523, Accuracy = 0.6100 Test Loss = 2.9001, Test Accuracy = 0.3455\n",
      "Iteration 1966: Loss = 1.0363, Accuracy = 0.5900 Test Loss = 2.8995, Test Accuracy = 0.3444\n",
      "Iteration 1967: Loss = 1.0769, Accuracy = 0.5300 Test Loss = 2.9027, Test Accuracy = 0.3442\n",
      "Iteration 1968: Loss = 1.0512, Accuracy = 0.5500 Test Loss = 2.8986, Test Accuracy = 0.3452\n",
      "Iteration 1969: Loss = 0.9911, Accuracy = 0.5100 Test Loss = 2.8985, Test Accuracy = 0.3449\n",
      "Iteration 1970: Loss = 1.1880, Accuracy = 0.4600 Test Loss = 2.8968, Test Accuracy = 0.3454\n",
      "Iteration 1971: Loss = 1.0315, Accuracy = 0.5200 Test Loss = 2.8951, Test Accuracy = 0.3455\n",
      "Iteration 1972: Loss = 0.9730, Accuracy = 0.5700 Test Loss = 2.8952, Test Accuracy = 0.3440\n",
      "Iteration 1973: Loss = 0.9574, Accuracy = 0.5300 Test Loss = 2.8933, Test Accuracy = 0.3458\n",
      "Iteration 1974: Loss = 0.9946, Accuracy = 0.5500 Test Loss = 2.8948, Test Accuracy = 0.3453\n",
      "Iteration 1975: Loss = 1.1028, Accuracy = 0.5400 Test Loss = 2.8932, Test Accuracy = 0.3460\n",
      "Iteration 1976: Loss = 0.9828, Accuracy = 0.5600 Test Loss = 2.8909, Test Accuracy = 0.3471\n",
      "Iteration 1977: Loss = 1.1490, Accuracy = 0.4700 Test Loss = 2.8895, Test Accuracy = 0.3466\n",
      "Iteration 1978: Loss = 1.0078, Accuracy = 0.5000 Test Loss = 2.8875, Test Accuracy = 0.3469\n",
      "Iteration 1979: Loss = 0.9201, Accuracy = 0.6400 Test Loss = 2.8853, Test Accuracy = 0.3476\n",
      "Iteration 1980: Loss = 1.0551, Accuracy = 0.5300 Test Loss = 2.8863, Test Accuracy = 0.3458\n",
      "Iteration 1981: Loss = 1.0823, Accuracy = 0.5300 Test Loss = 2.8824, Test Accuracy = 0.3465\n",
      "Iteration 1982: Loss = 0.9466, Accuracy = 0.5800 Test Loss = 2.8856, Test Accuracy = 0.3447\n",
      "Iteration 1983: Loss = 1.0659, Accuracy = 0.4900 Test Loss = 2.8828, Test Accuracy = 0.3464\n",
      "Iteration 1984: Loss = 1.0956, Accuracy = 0.5200 Test Loss = 2.8816, Test Accuracy = 0.3458\n",
      "Iteration 1985: Loss = 1.1084, Accuracy = 0.5000 Test Loss = 2.8811, Test Accuracy = 0.3449\n",
      "Iteration 1986: Loss = 1.1154, Accuracy = 0.4900 Test Loss = 2.8822, Test Accuracy = 0.3467\n",
      "Iteration 1987: Loss = 0.9817, Accuracy = 0.6300 Test Loss = 2.8766, Test Accuracy = 0.3460\n",
      "Iteration 1988: Loss = 0.9916, Accuracy = 0.5200 Test Loss = 2.8781, Test Accuracy = 0.3469\n",
      "Iteration 1989: Loss = 0.9565, Accuracy = 0.6100 Test Loss = 2.8784, Test Accuracy = 0.3449\n",
      "Iteration 1990: Loss = 1.1373, Accuracy = 0.5500 Test Loss = 2.8754, Test Accuracy = 0.3476\n",
      "Iteration 1991: Loss = 1.0141, Accuracy = 0.4400 Test Loss = 2.8743, Test Accuracy = 0.3475\n",
      "Iteration 1992: Loss = 1.0172, Accuracy = 0.5700 Test Loss = 2.8700, Test Accuracy = 0.3468\n",
      "Iteration 1993: Loss = 0.9551, Accuracy = 0.6600 Test Loss = 2.8704, Test Accuracy = 0.3459\n",
      "Iteration 1994: Loss = 0.9520, Accuracy = 0.6700 Test Loss = 2.8697, Test Accuracy = 0.3476\n",
      "Iteration 1995: Loss = 1.0343, Accuracy = 0.5900 Test Loss = 2.8678, Test Accuracy = 0.3476\n",
      "Iteration 1996: Loss = 0.9838, Accuracy = 0.5200 Test Loss = 2.8660, Test Accuracy = 0.3472\n",
      "Iteration 1997: Loss = 1.0004, Accuracy = 0.5700 Test Loss = 2.8639, Test Accuracy = 0.3478\n",
      "Iteration 1998: Loss = 1.0535, Accuracy = 0.5500 Test Loss = 2.8702, Test Accuracy = 0.3466\n",
      "Iteration 1999: Loss = 0.9998, Accuracy = 0.5200 Test Loss = 2.8640, Test Accuracy = 0.3471\n",
      "Total training time: 5.83s\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAAE9CAYAAACyU3u7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAB9C0lEQVR4nO3dd3xb1fnH8c+RLG/H2TshgwTIICEJYYSwKWHPsktboGkpFEpnoEALLYXS/iilhdJAKaWUPUrYe5MACSRkT7L39rYlnd8fGpZsSZZsDcv6vl8vE917zz330cC6j88y1lpERERERESkY3FkOgARERERERFJPiV7IiIiIiIiHZCSPRERERERkQ5IyZ6IiIiIiEgHpGRPRERERESkA1KyJyIiIiIi0gHlZTqAtujevbsdNGhQpsMQEZE0mDNnznZrbY9Mx5Et9B0pIpIbYn0/ZnWyN2jQIGbPnp3pMEREJA2MMWsyHUM20XekiEhuiPX9qG6cIiIiIiIiHZCSPRERERERkQ5IyZ6IiIiIiEgHlNVj9kREsklDQwPr16+ntrY206G0a4WFhfTv3x+Xy5XpUDocfQbjo8+giHQUSvZERNJk/fr1lJWVMWjQIIwxmQ6nXbLWsmPHDtavX8/gwYMzHU6Ho89gy/QZFJGORN04RUTSpLa2lm7duukmOwZjDN26dVPLU4roM9gyfQZFpCNRsicikka6yW6ZXqPU0uvbMr1GItJRKNkTEckRu3fv5r777kv4vJNPPpndu3fHLHPzzTfz1ltvtTKy3GaMmWKMWWqMWWGMmRbh+J+NMXP9P8uMMbszEGZS6DMoIpJeSvZERHJEtBttt9sd87xXXnmFzp07xyxz6623cvzxx7clvJxkjHEC9wInASOAC40xI0LLWGuvs9aOtdaOBf4KPJf2QJNEn0ERkfTK6WRv855aHvt0LVv3ql++iHR806ZNY+XKlYwdO5aDDz6YyZMnc/rppzNihC+3OPPMMxk/fjwjR45k+vTpwfMGDRrE9u3bWb16NQcccADf+973GDlyJN/4xjeoqakB4Dvf+Q7PPPNMsPyvf/1rxo0bx+jRo1myZAkA27Zt44QTTmDkyJFcccUV7LPPPmzfvj3Nr0K7MxFYYa1dZa2tB54AzohR/kLg8bRElgL6DIpIR/Dl2l3srW3IdBhxyelkb+W2Sm54fj5fb6/KdCgiIil3xx13MHToUObOncsf//hHvvjiC/7yl7+wbNkyAB566CHmzJnD7Nmzueeee9ixY0ezOpYvX85VV13FwoUL6dy5M88++2zEa3Xv3p0vvviCK6+8kj/96U8A3HLLLRx77LEsXLiQc889l7Vr16buyWaPfsC6kO31/n3NGGP2AQYD70SrzBgz1Rgz2xgze9u2bUkNNBn0GRSRbNfg8XLWfZ9w2b8+z3QoccnppRcCw69tRqMQkVx0y4sLWbRxb1LrHNG3E78+bWTc5SdOnBg2tfw999zD888/D8C6detYvnw53bp1Cztn8ODBjB07FoDx48ezevXqiHWfffbZwTLPPefrdfjRRx8F658yZQpdunSJO1YB4ALgGWutJ1oBa+10YDrAhAkTYn696TOoz6CIJM7j9f1q/Wr9ngxHEp+cTvYC2Z5VticiOaikpCT4+L333uOtt95i5syZFBcXc/TRR0ecer6goCD42Ol0BrvQRSvndDpbHI+V4zYAA0K2+/v3RXIBcFXKI0ojfQZFRFIrp5M948/2rNr2RCTNEmn9SJaysjIqKioiHtuzZw9dunShuLiYJUuWMGvWrKRff9KkSTz11FP88pe/5I033mDXrl1Jv0YW+hwYZowZjC/JuwC4qGkhY8z+QBdgZrIurM+gPoMikrhsW5klt5M99eMUkRzSrVs3Jk2axKhRoygqKqJXr17BY1OmTOH+++/ngAMOYL/99uPQQw9N+vV//etfc+GFF/Kf//yHww47jN69e1NWVpb062QTa63bGHM18DrgBB6y1i40xtwKzLbWzvAXvQB4wtrs7ouiz6CISHqZbP7emDBhgp09e3arz/901Q7Onz6L/15xCJP27Z7EyEREmlu8eDEHHHBApsPImLq6OpxOJ3l5ecycOZMrr7ySuXPnRiwb6bUyxsyx1k5IQ6gdQqTvSH0G2/YZFBGpc3vY78bXyHc6WHbbSZkOB4j9/ZjTLXsOh78bZ/bmuyIiWWPt2rWcd955eL1e8vPzeeCBBzIdkuQYfQZFpK2yLW/I6WQv0IvTm23vmohIFho2bBhffvllpsOQHKbPoIjkmpxeZ69wz0p+l/dPCipWZzoUERERERGRpMrpZC+/eguX5L1NfvWWTIciIiIiIiKSVClL9owxA4wx7xpjFhljFhpjrvXv72qMedMYs9z/bxf/fmOMuccYs8IY85UxZlyqYgtyaDpOERERERGJT7aN/kply54b+Km1dgRwKHCVMWYEMA1421o7DHjbvw1wEjDM/zMV+HsKYwMa19nDm2XvmoiIiIiIpF2y1udeta2SJZv3JqWuWFKW7FlrN1lrv/A/rgAWA/2AM4B/+4v9GzjT//gM4BHrMwvobIzpk6r4ADCBp+9N6WVERNqD3bt3c99997Xq3Lvvvpvq6uokRyS5Rp9BERGfY//vfabc/WHKr5OWMXvGmEHAQcCnQC9r7Sb/oc1AYEXVfsC6kNPW+/elLi4CSy+oZU9EOj7daEum6TMoItku29KGlC+9YIwpBZ4Ffmyt3WuMCR6z1lpjTEIvmTFmKr5ungwcOLBtwQXG7GXbuyYi0grTpk1j5cqVjB07lhNOOIGePXvy1FNPUVdXx1lnncUtt9xCVVUV5513HuvXr8fj8XDTTTexZcsWNm7cyDHHHEP37t159913M/1UJEvpMygikl4pTfaMMS58id5/rbXP+XdvMcb0sdZu8nfT3OrfvwEYEHJ6f/++MNba6cB0gAkTJrQpS2ts2WtLLSIi2eGOO+5gwYIFzJ07lzfeeINnnnmGzz77DGstp59+Oh988AHbtm2jb9++vPzyywDs2bOH8vJy7rrrLt599126d++e4Wch2UyfQRFJprcWbWHSvt0pyncmtd7XF27mqOE9KHQ1rzfb0oaUJXvG14T3T2CxtfaukEMzgG8Dd/j/fSFk/9XGmCeAQ4A9Id09U8Ph78VqNWZPRNLs1WmweX5y6+w9Gk66I66ib7zxBm+88QYHHXQQAJWVlSxfvpzJkyfz05/+lF/+8peceuqpTJ48ObkxSvuhz6CIZLHFm/ZyxSOzOXtcP+46b2zS6v1i7S6+/585XHLoQH535uhmx7Nt+FcqW/YmAd8C5htj5vr33YAvyXvKGHM5sAY4z3/sFeBkYAVQDXw3hbEBEOhSapXsiUiOsdZy/fXX8/3vf7/ZsS+++IJXXnmFG2+8keOOO46bb745AxFKR6fPoIi0RUWtG4B1O5M7lndPTYO/3pqk1pspKUv2rLUfASbK4eMilLfAVamKJxITmJ8myzJ0EekA4mz9SKaysjIqKioAOPHEE7npppu4+OKLKS0tZcOGDbhcLtxuN127duWSSy6hc+fOPPjgg2HnqgtdB6LPoIhIwrIta0j5BC3tmtEELSKSO7p168akSZMYNWoUJ510EhdddBGHHXYYAKWlpTz66KOsWLGCn//85zgcDlwuF3//u2/J06lTpzJlyhT69u2ryTGk1fQZFJFsF0/aMHv1TnqWFTKwW3HqA2pBTid7wVwv63J0EZHWeeyxx8K2r7322rDtoUOHcuKJJzY770c/+hE/+tGPUhqb5AZ9BkWkozv3/pkArL7jlAxHkqZ19tot459hRy17IiIiIiLiFzU7yLK0IaeTPRNcZ08TtIiIiIiI5LpoE45kq9xO9oLr7GVZii4iIiIiImmXyPCvD5ZtY8ve2uB2vdvLC3M3pDX3yOkxe8FBe9nWHisiWctaG1z2RSLTH+BSS5/BlukzKCLRJPLr4dKHPqNPeSEzr/ctRPDXd5bz13dWUJCXvva2nG7Z02ycIpJOhYWF7NixQzeSMVhr2bFjB4WFhZkOpUPSZ7Bl+gyKSDJt2tPYshdo5Qus5ZcOOd2yZ9SyJyJp1L9/f9avX8+2bdsyHUq7VlhYSP/+/TMdRoekz2B89BkUyR7p/ttVtmUNOZ7saTZOEUkfl8vF4MGDMx2G5DB9BkWko1u3s5o1O6o5Ylj3NtWzYMMeFmzYw6h+5WH7dlTVRyy/vbKOL9fu5oQRvVqs+6MVO9oUWyJyuhtnoGXPajZOEREREZGs03QI8uQ73+WSf37a5np3VtVz6l8/Ctt36l8/4tsPfRax/Lf++Rnfe2Q21fXu6LH6J4d8cd7GNscXLyV7aCC2iIiIiIi03todVQB421lakdPJniZoERERERGRgLbOVtzeGpFyOtkLvpnqxikiIiIiIq0UyCtmpLGLZjxyOtkjsKh6hqMQEREREZEsYiJv/ur5BWkPJZacTvaMw/f0TTtrbhURERERkY6ljT1EWyWnkz2M/+lbT2bjEBERERERSbIcX2cvA+m1iIiIiIgkRVs76L22YDMH9i+nb+eiBC8cf9F563bj9nrVspduWnpBREQyzRgzxRiz1BizwhgzLUqZ84wxi4wxC40xj6U7RhGRjuoHj87h7Ps+aXtFMRK5M+79mHP+PrPt12iF3G7ZQ0sviIhI5hhjnMC9wAnAeuBzY8wMa+2ikDLDgOuBSdbaXcaYnpmJVkSkY9q8tzb4OO7GtyzpIJjbLXv+CVrUsiciIhkyEVhhrV1lra0HngDOaFLme8C91tpdANbarWmOUUSkQ0p/DpD+DDGnkz0cgRdc6+yJiEhG9APWhWyv9+8LNRwYboz52BgzyxgzJW3RiYik0bqd1by2YHOz/bUNHv4zczVeb/PkLJFxcLUNHv4za00wyYtQXVSPf7Y24n6v1/KfmaupqHXHX1ka5Xg3zsDSC0r2RESk3coDhgFHA/2BD4wxo621u5sWNMZMBaYCDBw4MI0hioi03ZS7P6Cq3sPqO04J2//nt5bxj/dX0aUkn1MP7Nvq+v/vjaU88OHXdC/J56TRfRJq2bv+ufnhO/ynzpi3kZteWNjqmFItp1v2ghO0ZDgOERHJWRuAASHb/f37Qq0HZlhrG6y1XwPL8CV/zVhrp1trJ1hrJ/To0SMlAYuIpEpVfeTl0PZUNwC0ufVsZ5Wvnso6Xz2JtOxFU1Hb0PZKUkjJHmiCFhERyZTPgWHGmMHGmHzgAmBGkzL/w9eqhzGmO75unavSGKOISEY5/EOvvBHu2dtyG2/b0uTTiuF3Wnoh3YKLqqsbp4iIpJ+11g1cDbwOLAaestYuNMbcaow53V/sdWCHMWYR8C7wc2vtjsxELCKSXJv21PD8l+tjlglMsxFpzF683l2ylef81wnUEm+iWNvQvMWx3p0d+UNuj9nTouoiIpJh1tpXgFea7Ls55LEFfuL/ERHpUC558FNWbqviGyN6Ry3j8N+ze9qQ7H334c8bN/zVxJvs/eXt5a2+bqbldMteYzfO7MjMRUREREQ6ku2V9UDslrJAspeMMXbQ2H0zUjfOSG1Bu6vb97i8WHI82Qt049SYPRERERGRdHM5fffjDd7oyZ4zxpi9tkhW8tie5XSyF0jdtai6iIiIiEjbLdtSwWsLNjXbv3p7FTPmbWy2P9/pux9v8ES/Hw+M2QvtxjljXvjExfPX7+HJzxvXwvt4xXastTwyczW7q+vDyr65aCv//XRNm3OAmSt38NnqXXGXz8QAspwesxeY2cdo8QURERERkTb7xp8/AGi2Vt6Uv3xAbYOX08eEr5PnyvO37MXqxum/Z/eEJGePzvIldoFul6f97aOwcy5+8FNeuGoSN7+wkA+Xbw879tbiLby1eAsj+nQKqyNRFz4wq3UnhrDWpnQekRxv2XMCatkTEREREUml2obIyVyeI9CyF6MbZ7A3XvNjsW7j6/117qyqj3g80JqYySkbU52G5HSypwlaREREREQyJzhmL0Y3zsCYvURn4wwkcS2dl8kZ+lPd5KRkD0j9yywiIiIiIk3lB7pxxmjZMyZ8gpa1O6rDjkdbf2/hxr0AzF23u8U4dlbV86+Pv27W0lZR28Djn62NfFKCnvtiQ7N9VfXupNQdTY4ne5qNU0REREQkUyJ142w6xCrQPBPI6c687+Ow4+8s2Rqx7l/PWBjz2oHrGOAnT83llhcXsWjT3rAyv31pUcw6ElETYXH2P762NGn1R5LjyZ5a9kREREREMiXQjbM+RsteQODOPdoYvESFZgC7/GvpNZ0oZleK19jbXZPa+nM62Qt+YtSyJyIiIiKSdo3dOBvvx5vemrd0p16U72xTDMY0bz1sjCW1eYInxvqCyZDTyZ5xBJ6+kj0RERERyU4er+W+91awYmsFj85ak7br1rk93PvuCur9rWFPz16XcB2Bbpz//Ojr4L6md+ZvLdoC+JKypmvmQduTvQaPDY7r+/Nby8KOpXrhdXeMiWmSIafX2TOBXFezcYqIiIhIlnrpq43c+dpS7vSP/zr1wD50Ls5P+XUf/PBr/vj6UgryHFwxeQg/f+arhOsIdOP8YNm24D5fa1rjDJmh4+imPTu/WR35ztS1X3lT3rKX2vpzvGUvsPSCWvZEREREJDvV1IdP/JHq1qiAav9MkrURJh6Jpmm3yMCi6mFlYpy/tzZ8jFtbVk2IJwVIecuekr3UMRldQlFEREREJLc0TbBcjsTux5smd21ps7FxDOVK9Zi9VLcc5nSy53Bo6QURERERSY1HZ61hzY6qTIeRdHtqGrj33RXBVq9EbqUDRf/50dds3lMb7MYZVsbCM3PWM+mOd3giZI27T1ftZObKHWFlZ6/Z1Wy5hHhd9d8vWizz4fLtrao7XqnuxpnbY/b8fxpIdcYuIiIiIrml3u3lxv8toHtpAbNvPD6l10r3neytLy7i2S/Ws3/vsoTPtdaydkcNv31pES/M3cCofuXNy2D52dPzAJj2XOMYvZmrdjQrC/CLVowVhNQvqxAPdeNMIeMIzNyjZE9EREREkifQRXBPTXLWhEvo2iluyKis869JF8faeE1ZwO1fbqCi1h1xcpVcaofRBC0p5WvZM5qNU0RERESSKJNzQ6Q6V2qajCUySUqzMXvO3J5DQy17qRT8ZObQnw9EREREJKbPV+/klfmb2lRH6Lpx7dULczfwxdpdYfv21DRw91vLYrY4BY44gkOimrcmrthayaOz1mCt5ZrHvwzuf3XBJuZv2BPcfmvx1mb1v7qgba99Nkn1ouo5PWYvuH5HLrUVi4iIiEhM37x/JgCr7zilVedvq6jjD68tSWZIMbX2VvbaJ+YC4c8zMB7vgD6dOHFk75jnh7boNY3h1L9+SG2Dl4MGdmbGvI3Nrhnw9fbmE9hc9+S8+J5AB9CKnrAJUcseoJY9EREREUmW0FaudLQpNF1CoC3XrGnwrZ3n9sRo2YtwqOmu2gZfFlNZ645aT2534PRJdcuekj1Qy56IiIiIJE3Hv7P0PcPQcYnRJoWpjrXgurI9jdlLNa81GDRBi4iIiIgk5j8zV7N0c0XMMplI/KItFj5j3kY+X70z9rlxBBwYZxdoN9lRVc+YW96IWLa6LkayJ1pnL9UsatgTERERkcTd9MJCoPnYvow3WEW5tw1MlNLasYjRPPzJ6qjH6txK9mLJ2qUXjDEPGWO2GmMWhOz7jTFmgzFmrv/n5JBj1xtjVhhjlhpjTkxVXE1ZDKhlT0RERESyVNOGi7akD4ksoxCPWMlMxpPiFPn9WaPjLuvN1mQPeBiYEmH/n621Y/0/rwAYY0YAFwAj/efcZ4xxRjg36SwmFzpWi4iIiEiahN5apnqB84jXT9MlTRyZYapbrtqjaN1oI8naMXvW2g+A2J2CG50BPGGtrbPWfg2sACamKrZQFkCLqouIiIhIB/H7VxZTG2tilCZWbG0cd/jK/M3Bx395aznf+ddnURPWeFrmpj03P+44OopE8res7cYZw9XGmK/83Ty7+Pf1A9aFlFnv35dyVnPUiIiIiEgSpbt7YtN0Yca8jQkt6n7mvZ8AUFXXuEyCMfDnt5bx3tJtYYugh2prl894WgazUSKtuSeOir2WYVulO9P5OzAUGAtsAv4v0QqMMVONMbONMbO3bdvW5oAsYNSyJyIiIiIJiHVD3x46LibSYlRd70vywrufNj6OVlWbk722nd5uxTsOb+qRQxIa39caaU32rLVbrLUea60XeIDGrpobgAEhRfv790WqY7q1doK1dkKPHj3aHhOG9vG/pIiIiIhki3hzqbTcZUZIPB0JZFKtjdF02HStbdrTMMW0JnvGmD4hm2cBgZk6ZwAXGGMKjDGDgWHAZ+mIScmeiIiIiCQqmROvfL29ir+9szzq8WfnrOeTFdsjHnt94WbeWLSl2f5YXSSvf+4rHvt0bbP9oc/pj68vCT7+1fPzWbRxb9T6WmtnVX3S62wP2lNmkcqlFx4HZgL7GWPWG2MuB+40xsw3xnwFHANcB2CtXQg8BSwCXgOustamZ1EOgxbaExGRjDHGTPEvO7TCGDMtwvHvGGO2hSxbdEUm4hSRcMlsvbn4gVn86Y1lUZOfnz49j4se/DTise//Zw4fLo+cCEbz+GfruOH5xolTArfCoc9p9Y7q4OOFG/fy+1cWN6unrd04d2RpsnfJoQNjHs/EDKzRpGxRdWvthRF2/zNG+duA21IVTzReHJh2lX+LiEiu8C8zdC9wAr7JyT43xsyw1i5qUvRJa+3VaQ9QRKLyxnlDH0+xmgRmzoyXoxWZWKyxZrtrmidmudqJ83dnjuazr3eybEtlxOPxfjbSIeenotTSCyIikkETgRXW2lXW2nrgCXzLEYmItEkiY/YCYiUprUkeO7JYr0fOjtlrn/TBFRGRjIl36aFz/MsWPWOMGRDhuIikWdPE6J63l4etV9fU5j213P7q4pitZ4/OWsPnq6MvU/3SVxt5feFm3l2ylee/XB8zPmNgd3U9v31pEfXu+Bo2YiUpDmN4Zf4mZszbGNw3b33kJRlyQawxke2pZS9l3TizhcVozJ6IiLRnLwKPW2vrjDHfB/4NHBupoDFmKjAVYODA2GNKRKRtQm8f99Q0cNeby3hk5hpm33h8xPI/eWoun6zcwfEH9OLgQV3D6/L/e9eby+BNWH3HKRHruPqxL8O2zzqof9T4HMZwx6tLeOLzdYzs24mzx0Uv2/icYrXswQ//+0WLdeSKWK/VBQcP5M7XlqYxmuhyvmVPyZ6IiGRQi0sPWWt3WGvr/JsPAuOjVZbs5YlEJLrQ1pvAmnZub/QWtAaP71ik285U3YrWuaNfMxJPjIIddQH01orVWtq1JD+NkcSmZC/kvyIiImn2OTDMGDPYGJMPXIBvOaKgJssWnQ40nxJPRNIu9O4xkPg5/QlRpJwpsCZdumZqNMY0xhXnAL7Y3TiTEVXHUe/Jjjk/lOzhaFfTo4qISO6w1rqBq4HX8SVxT1lrFxpjbjXGnO4vdo0xZqExZh5wDfCdzEQrIqFC5/cLjMOL1vr11qItwWkiAned//zoa2ZHGZ+3u7qeX7+wgDp362fp3FFZxwtzN/rj8o0ZbMmr8zdFPaaWvXDxjoPMtJxP9gDNxikiIhljrX3FWjvcWjvUvwwR1tqbrbUz/I+vt9aOtNaOsdYeY61dErtGEUmHsG6cwRY037Zt0mvsikdmNzv/ty8t4tz7Z0as+w+vLeHfM9fw4rzoyVdL7ntvZfCx02H4+TPzWjzndy9H7ziglr1wD1w6gbMP6setZ4yMePyJqYdy5PDMd6fP+WTPiwOjZE9EREREEhCazgXG7MXqxhk8L+KYvfCddQ3JvTd1GhMcv9fqOpTthRkzoDN3nT+WSw8bxIrbTmp2/NAh3Xjkson8+PhhzY5df9L+6QgRULKH1zjUsiciIiIiCQlt2QvMy+LwJ0SRcr1YqVLT8oGWwrwkJVgOh4m55EM8jJYry0o5n+z5ZuNUsiciIiKSK7xey29fWsS6ndWtriO0Mc7TZCKUSGPxahNoWQu0FG7YXcNvX1oUtdxbi7bEVd/6XTXMXrMr7utH8tGK7W06vyNrz+MZc36dPS9OdeMUERERySGLNu0NTpDywtVHtKoOG2HphUA3zmufmNus/Lx1u33nxTELfKDV8I+vx16rLdJYwEhiJYzSdu031VPLnr9lr/UzHYmIiIhIdgnkabHWlWuxjpDHgeTM0dpul03CcHs0U3y6nTK6T8uFomjHDXtK9rzGgdE6eyIiIiI5py2rb0VaVD1Zc5h4tSxY2rmcrX/z2nM3zpxP9iwOjFcteyIiIiK5YEdlHTc8P7/Z/oraBqY9+xWVde6I5931xlK+Wr87uB0638n/veHrbumI56bfwlOz1zXdFcbTxslUWuO+91ak/ZrticvZMdOijvmsEuA1DkBj9kRERERywZ2vLWX+hj3N9k//YBVPfL6Of330dcTz7nlnBaf/7ePgduiYvbcWbwXiX57gF898FfN4Jnpx3vla7PGB7U2XYlfUY2UFefz8xP0Sqi8/L3padNtZo/jO4YP4z+UTufqYfSOWufyIwRH3f3fSYE4b0ze4nc5lF0DJnq9lTxO0iIiIiOSE0AlSwmbU9EYfd9d0Hbym5wYkay26ti6TAO17HFlb9S0vZMqo6GPszj94AN8/ckhCdbqcDk4e3TvisTH9O/Ob00cyeVgPfhYlibzp1BER95cXufjrhQcFt79/1NCE4morJXtGyZ6IiIhIrojW1TJWfhV5IfT46w47L2L94XuT0Y3T2YGzPWNMzGTWmMTH0RXkOdo0hrO9UrKHUbInIiIikiOe+HxdxP2BhCtSwhY6a+fNLyxg5bbKiJOoxNOyt3jT3hbLzFy1o8UyLXFnYNxfOsV6qY1JfAl4lzN6spfsvDmd74zW2TNONGZPREREJPdEXD4hwo19aGL3yMw1zFy5g/u/Nb5ZuXha03738uKYcUjL/vXdg+lRWsCjs9ZGPG5IPEFzOR1R10CMa+KdFtx4ygEM7l7S5noSlfMte2BwqGVPREREJKcF8rlIN/aRWnwijavrwD0n0ybauLlQw3uV0aUkn9V3nBK5QALdOC+b5JtYxZUXvXwy3tcrJg/huAN6tb2iBOV8sqeWPREREREJ5G6RbuwjddmM1E2ytRO0dMSxYpmUSCdOt9eXB+TH6saZcKfQ+KTjbwM5343T17KndfZERERE2oute2v53cuLWbmtkk6FLh694pCkzXQZKnRilEBCF6lFqGleZ0zkSVQ+WbmDl77amFAMFz0wi5oG3YsmUyItcYH3PT/PEbU7bQo+emmjlj3j1J9TRERERNqR215ZzIx5G1m4cS8zV+3g6+2VKb9mIPFztqFlD+Dqx75M6LqfrGz7ZCy57KnvH9ZsX+AtvObYyGvihbr2uOGcP2EA3xw/IG0TtKRTzid7GAcOdeMUERERyTmhrXiN3TgjjNlrcqtoMElZHqEj69e5qFXnJfq6ThzcNeqxn3xjv2aTovTvEh5X15J8/nDugRTlO4k+VU72Zns5n+xpnT0RERGR3BTajTMwE2NLs3EGKNmLLT+vdWlGTUPb78tDJ9lpuoZhLOlu2UvHJ0jJHg6MWvZERKSNjDGnGWNy/ntVJBlaure21vKr5+dz5r0fMyuONelOuOt9zrrv42b7l2yuCD6O1LI35PqX8XptlG6cun+MxRWpP2wcquvcbb52IslZaNHoY/aSm+0F/qCQjvbCnP9SssahCVpERCQZzgeWG2PuNMbsn+lgRDqy2gYv//10LXPX7eaC6bNaLL98ayVfrt0ds0ykRdW9FrZV1jWboAXUsteSgjwnea2Y2WRIj9hr0fUtL2yxjlhXbZq3R8rjThrVm/svGRdXfaF+fuJ+PPfDw1ssd8mh+3DhxIFcFceYwrZSsmccGC1lKSIibWStvQQ4CFgJPGyMmWmMmWqMKctwaCISh0BDXdObf6+1EbsCKtmLrcjl5AdHDU34vJZe1u8dOaTZvmP37xm+I4GWOBOhy+e54/szZVSfhKu76ph9GTewS4vlivPzuP3s0XQqdMUdZ2vlfLKHcWhRdRERSQpr7V7gGeAJoA9wFvCFMeZHGQ1MJMvEuyB2MkUbs+fx2riXXpBGBS5Hq5aUiLRYfahUTqIfqLrpxy9V6+ylQ84ne9Y4NWZPRETazBhzujHmeeA9wAVMtNaeBIwBfprJ2ETag7cXb+HWFxdlOoxmZq7cwQ3Pz8fjvx186KPVYceve3Iu89bvbnbePe+sSH1wWazI5WxVQtxSoh9PjaE15DnD051YE7YEup02jUFLL2Qxa4ySPRERSYZzgD9ba0dba/9ord0KYK2tBi7PbGgimXf5v2fz0MdfZzqMZi58YBaPfbo2mAQs3VIRdvzz1bv4/n/mNDtv3rrd6QgvY/JDkiSX0/B/3xyT0PlF+U5+fPywhK97w8n78+3D9mFA18hLN8Qzu2ZocvbgpRPCupPGyj9/f9ZovnP4ICbv2z1svzOLV1XP+WQP41Q3ThERSYbfAJ8FNowxRcaYQQDW2rczFJNIh2RTMN9CpBk3c5nTYfj1aSMAuPiQfThnfP+Ezi/Mc9K5OD/h63YrLeCWM0bhckROU2K9TSP6dALCJ9kZ1L2EaSc1zpkV67PTs1Mhvzl9ZLPWQJcze1Om7I08SSxaVF1ERJLiaQj7QvH494lIkqUiL/Mo1wvjdJg2vc6+RcqTL1ayFhxzF+v8Vjyn1i4j0R7kfLKHw6nZOEVEJBnyrLX1gQ3/48T/rC2SZdweL997ZDbz1+9JSn2PzFzN819uiFmm6Z3bW4u2cP1zX3HXm8sYNO1l7n13BZc//DkNnvA/6J/+t4+i1tnSxCC5pq3j1EoL8pITSBOx1ryLp4tnaxZ7V8teVjNq2RMRkWTYZow5PbBhjDkD2J7BeETSYvWOKt5ctIUfP/llUuq7+YWFLZZpelN/xSOzefyzddzz9nIA/vj6Ut5espVlTcbffRUjIdXsmuEiJVWJLKVw5dHNy15zXOMYvnPGJdYtNOCSQ/dpsUysRPWRyyaGxRGPPLXsZS9rnBiN2RMRkbb7AXCDMWatMWYd8Evg+xmOSSTlnP6xVelMluK9UiJT5nsS6N+XiaUh0s3paN737fIjBsd9fkmElr3Dh3YLPv6/8xKb8CWg0BW9e2jgLYz1/gzpUcpPThie0DWjjR/MBqlpX80mDo3ZExGRtrPWrgQONcaU+rcrMxySSFo4/TfW7nQme3FeKpGcTN04w4VOQBl4Hds6MU6qU+TAJDvJzsUdWTwbZ1zJnjGmBKix1nqNMcOB/YFXrbUNKY0uDaxx4NCYPRERSQJjzCnASKAw8Jdla+2tGQ1KJEEPfriKyjo3Pz4+euvH0s0V3PrSQv757YMJNHpES5aenr2OpZsrIh4LqG3wcNnDn/Pr00ZGKeH7/6ne7eWyhz9n9pqdLT4P8HVFvOvNZXGVfXfp1rjKASzetDfustnKGBNcdy4wZs3dxllsUpU0BWptnKAle5OzZIu3TfIDfF9c/YA3gG8BD6cqqHQyRi17IiLSdsaY+4HzgR/hu/f4JtDy4BLfuVOMMUuNMSuMMdNilDvHGGONMROSErRIBL97eTF3v7U8ZpmbXljAxyt28OXa3cE1yKJ1g/z5M1/x4Eex19ebvXoXn6zcwS0vRhuv56t72ZYKPlqxndqG+O7djCE4jq8l2d6wd/jQbkw9ckjC5w3pXhJxv8PA+QcP4IojBgfHuPUpLwwrs1+vMgpCJjy5cOJAHAae+v5hUeuM5M5zDmwxzptOHcFLPzoi4rF43rqXrzmCG085II6SjV68+ghuPnVEQue0N/Eme8a/KOzZwH3W2m/i+8tl1rPGqWRPRESS4XBr7aXALmvtLcBhQIsDQ4wxTuBe4CRgBHChMabZ3YUxpgy4Fvg0qVGLtEKgFc/pMMFWlGSM2Ut297tcat/pWpLPDScnlswAPPzdiRH3O4yh0OXkxlNHBGfWbDoWbmC3Yq4NWTj99rNHs+r2U5g4uGuUq0V+R86NYw2/y48YzKh+5THL2BjdOEf2LeeKyYklw6P7l3NZAuMU26O4kz1jzGHAxcDL/n2pWTwj3fwte/FM1SoiIhJDrf/famNMX6AB6BPHeROBFdbaVf7lGp4AzohQ7rfAH0KuI5IxgbFRTkfjOK62JHstjwVrXdqWA/OoBLV20phop8Va4iB4boLXitay19b3KdiN04ZvS/zJ3o+B64HnrbULjTFDgHdTFlU6OZw48Wq6XRERaasXjTGdgT8CXwCrgcfiOK8fsC5ke71/X5AxZhwwwFr7MiIpdN2Tc8O2691eLpg+kzlrdoXt90SY9TDeCVoue/hz/vDaEr71z0+D91+NN+nRb9PX7qjmjHs/jusaATX1udN7q7UJTlvG0SWapEVLINs6u2mBy5fSBGbqzOZ18ZItrglarLXvA+8DGGMcwHZr7TWpDCxtTJ4v2bNWU5OKiEir+L8b37bW7gaeNca8BBRaa9u8yrS/7ruA78RRdiowFWDgwIFtvbTkoKaLma/ZUcWsVTv55bNf8dZPjgruD/SIchoTTNTi/cP5O0u28s4S32QoO6vq6VFWENd59767IuE/zs9clTtLXbY2Z3NGSbRSsdpAqlpaf3fmaAZ1K+HKo4fyt3dWcPGhLf/+e+lHRzT7I0ZHFNfbaIx5zBjTyT8r5wJgkTHm56kNLT2sIw8XHry584cfERFJMmutF9+4u8B2XQKJ3gZgQMh2f/++gDJgFPCeMWY1cCgwI9IkLdba6dbaCdbaCT169EjwWYg0F5xyv8lwl0DS5TCNa7G1ZumFxin9w7cjaU0LlDOL10dLVKRWs28f1vIcUVG7VsbRVtheZr3sWpLPL6bsT1mhi+tPPoCCvJZHm43qV863Dx+U+uAyLN7/A0ZYa/cCZwKvAoPxzciZ9awjDyeeYN9zERGRVnrbP1tmonc/nwPDjDGDjTH5wAXAjMBBa+0ea213a+0ga+0gYBZwurV2dtIiF4nKv4RIk73BZM/RmAi2Zp26RP5naU3PPGf7yEXSo7XPtQ3j6IxJLOFrL8lhLon3fxuXMcaFL9mb4V9fr2NkR4488owXj5r2RESkbb4PPA3UGWP2GmMqjDEtLsZlrXUDVwOvA4uBp/zj4281xpye2pAl13m8lvP/MZMPl29rduzr7VUhLXvhx4KLVxPSjbMVfzgP/G3k4Y99SzN8uDxyt8sVWyt4dNbahOvP5sWwExUpkcrPa/lWP9o4up5xdK8NjJFLVOBtycuh9ydT4k32/oFvoHkJ8IExZh+gQ6wmaR2+kXped32GIxERkWxmrS2z1jqstfnW2k7+7U5xnvuKtXa4tXaotfY2/76brbUzIpQ9Wq16kix7ahr49OudXPP4l82O3f/eypBZDsMTuUAjXugsmq3pJBWo/92lzZPNUC2t+xe1/hyajjPSU/3x8cO5/5Jxwe2DB3Vpfl6Eur47aRC3nD4q5vV+dOy+/Pq0xNags1huOX0kr157JACvXDuZ3yRYhyQm3gla7gHuCdm1xhhzTGpCSi/rcAHgaVCyJyIirWeMOTLSfmvtB+mORSRegck5ok18EkiWmh71hsyi2ZaRMPHmYm1tQcoFkZ5rSUEeU0Y1rgDzkxP248IHZoWViZQQ//q0lpfT/uk39vOfn1icoePkhvcqY3ivssQqkITElewZY8qBXwOBL7L3gVuBNs8ylnFOX7Ln9TRkOBAREclyoROXFeJbP28OcGxmwhGJg/9GPdpwu6brlwUEunF6rY1jjby2K3S1bqKVeNaK6yjiGQ8XaV3pdL5CGrOXfvGuNvAQvlk4z/Nvfwv4F3B2KoJKq0A3To87w4GIiEg2s9aeFrptjBkA3J2ZaETi1MKyCY995hsnt3Znddj+QPG2LlO8vbKes//+SYvlvly7u1X1X//c/Fadl43imXg00tvV1oQ4kbMTmRy1tFCLoiVDvK/iUGvtOSHbtxhj5sY6wRjzEHAqsNVaO8q/ryvwJDAI3xjA86y1u/wzl/0FOBmoBr5jrf0igefResFkTy17IiKSVOuBAzIdhEgsoS10kUz/YFXE/YHk0Gttm7pxvjp/E6u2VbVYrs6tifRaFj3tuvPcAxnRpxO7qyPc7yapsS3SeECABy+dwN7aBjbtqWVEn+jDmP947oEcEHL8H98azwtzN3LHq0uSE2COijfZqzHGHGGt/QjAGDMJqGnhnIeBvwGPhOybhm/R2TuMMdP8278ETgKG+X8OAf7u/zflAhO0WE3QIiIibWCM+SuNfzh3AGOB9PzhUqSVAklepIQtVvfMxvPS0YlT4hFrfOJ5E3xLeUaadTVZPV0PGhg52Tt+RK+4zv/mhAFh233Ki/jBUUOV7LVRvMneD4BH/GP3AHYB3451grX2A2PMoCa7zwCO9j/+N/AevmTvDOAR6+tIPMsY09kY08dauynO+FrNBMbsudWyJyIibRI6Q6YbeNxa+3GmghGJR6AbZqLLJnjCJmhRutcexJO0RXqrNIquY4t3Ns55wBhjTCf/9l5jzI+BrxK8Xq+QBG4zEEj1+wHrQsqt9+9rluwZY6YCUwEGDhyY4OUj8Cd7Vt04RUSkbZ4Baq21HgBjjNMYU2ytrW7hPOkgtlXUcea9H/Pvyyayb8/STIfTouP+7z1W+rtQRuvGGU3omL1IZw6a9nIbo5NExTVBS4R9yZrERkl/+5TQ1EbW2r3W2sD6ej9py4X9rXgJfyqstdOttROstRN69OjRlhB89TkCyZ66cYqISJu8DRSFbBcBb2UoFsmA1xduZsPuGv750deZDiUuK0PGyiV6nx42G2cb7vE7UnoQbcxaqnz4i2P4+Yn7ce1xw4B4W/YizMbZ5LwZV0+KWcd/rziEh74zIer50r60bh5bn9a8tVuMMX0A/P9u9e/fAIR21O3v35dyJjhBiycdlxMRkY6r0FpbGdjwPy7OYDySIR3l5jdWEhc+sUvrU7YO8lIBcNmkwWm93oCuxVx1zL50LvY1XMTzWkZ6p5q2CB7Yv3PMOibt251j949vHJ5kXluSvdb8nz2DxrF+3wZeCNl/qfE5FNiTjvF6AMbpT/Y0QYuIiLRNlTFmXGDDGDOeliczkw4kcGPUkRKYaDxpXlQ9G2SqlTLQpTbS4uhNxdOy11rqxdk+xRyzZ4ypINofAcK7qkQ693F8k7F0N8asx7co+x3AU8aYy4E1NK7b9wq+ZRdW4Ft64bvxP4U28nfjRGP2RESkbX4MPG2M2Yjve7I3cH5GI5L08t/tdqQEJpqKWt/6xBc/+GnY/kTH6nWkBCHf2ZY2lNYLJHDxjL2LOEFLGz+vRfm+dKI439m2iiQlYiZ71tqy1lZsrb0wyqHjIpS1wFWtvVZbBGfjVLInIiJtYK393BizP7Cff9dSa62+XHJIB8pbgI73fFLt2P17JnzOiSN78frCLW26rg227MVfdvKw7ny4fLvvvJC26L9cMDbh619w8AD2VNdzxeQhCZ8rqZeZP0G0J3majVNERNrOGHMVUGKtXWCtXQCUGmN+mOm4JH2CN9050ZFTmnI4DKUF8a5qBpP27cYRw3yTDfbuVNjq6wZWOoznUxcYa1mQ15gChCaJZ4ztl/D1XU4HVx87jEKXWvbao5xP9gITtFiPO8ORiIhIlvuetXZ3YMNauwv4XubCkUzJhW6c0nbWJmd8Z+CPDI5Yq6oHygYfmQiPpCNSsqd19kREJDmcJmSGBGOME8jPYDySZoGxU7Funn/9wgJ+8uRclm6uYMwtb7Blby1er+WYP73HC3PDJyK/8tE53P7q4havW1PvYeJtb/Hh8m1h+2/63wJ+9vS84PagaS8zaNrLVNdH/gP3Ff/+PGz7mTnrw7ZP/PMHwTqS5fHP1iatrnTIiyOhSkQy/jBQ5B8rV5LfcqtioEWvvMgV3JesdfakFbzelF8i/rbmDkrJnoiIJMlrwJPGmH/4t78PvJrBeCTNgrNxxrh5/vfMNQDk5znYU9PAO0u2cva4fny9vYqfP/1VWDe6VxdsBuD6kw6Ied3lWyvYWlHHH15bwuRhjWsQ/2eW71p/+uaYsPKrtlUxql95s3reWry12b5QS7dUxDzeGhv31Ca9zlTKz3Pgro++XFe0hcUvOXQgj85qntgGuvxG+sg89J0JXPbw7LB9Bw3szJdrd4ftu3DiQKrqPHx30iAAXrlmMve+u4Krj923WZ1HDe/BDSfvz4UTB/KDo4awaNNetUSnUkMtuAqhvgqME569HJa8FF7mgNPh/P+kLIScT/YCs3Ear5I9ERFpk18CU4Ef+Le/wjcjp0gzDR5fUuB0mDbPSOn2BuqKr8OWtyNNgdlK3Ury2VGV+LJbBXkOqmMke9HceMqIyMmeP9GKlG8dPbz5hC/P/3BSs5ZVl9PBlUcPDW6P6NuJey8e1/RU//UMU4/0lS0rdDGsV6vnYpSmrIVlr8GWBfDO76BTf9i7vuXzBkxMaVg5n+w5NEGLiIgkgbXWa4z5FBiKb2mh7sCzmY1K0imRHMrj774V1i2wlS0sgTXv4u1i6FWu1+rWrPy81o2Aina9wFsWcZ0ztbi1X3WVsOIt+PxBWP1h5DLREr1R58CCZ2HyT30/+SWpixMleziDyZ4maBERkcQZY4YDF/p/tgNPAlhrj8lkXJJ+jd04Wy7rb9jD2coxYBt313D4He8A8Nj3DgFgzppdrNpWyZAepWFlD7jpNT6edmxjnNZy/XNfteq6HUfrXvc+5UVs2VsX9Xj3sgKqdlQ32x9tXFyxf5xdWWEem/Y0iVDZXuZZC/Ofgc/+AduXQ+3u+M7rexBs/BIGHwkHXgBDjoLy/o3Hz30oJeFGkvPJnivfN3be4068KV9ERARYAnwInGqtXQFgjLkusyFJJjRO0NLyTXpjy54jZMmG+L25qHFtNk9IU92Xa3c3S/ZqGjx8vnpnY5zA45+tS+Bq2e+Ifbvz0Yrtwe3WzrMy/dLx/OP9VXQtyeePry9tdvzx7x3KRyu284tnwpPpaJc7ZXQftuytZZ9uJXzvkdnNjj8x9VAACl1OdlX77lXvv2Qcg7uXNisrbeBpgFd/AZVbm4+pi6W4O/QaCYdfAw1VMHyKf4iYhdkPwdiLIb84ZWHHQ8meqwAAd4OSPRERaZWzgQuAd40xrwFPoNnMc1pcLXvBcXaN66QlInTcnTsk2Yt27dAuptEmEenIfvqN4WHJXujrNKBrEet21sRVT8+yQm46dQQAd725LCzRBujbuYjzJgxoluxFa9lzOAxXTB7CJyGxga+lD+DQId2anTNlVJ+4YpUoPA1QsQkWvwSvXx//ed//EMp6w7alUNIdug6FvBgTLk9sHyvvKNnzt+zN+GItY8/JcDAiIpJ1rLX/A/5njCkBzgB+DPQ0xvwdeN5a+0YGw5M0SmzMXuOkKq3JvUJzDI8nngoay+TimL2mXSJDW1/Tkfu29AcAddlMIq/H1/Xynd/BnlYu7dFzBBz5c+g1Cqq2waBJjcdKm0+c054p2Svwtey50Jg9ERFpPWttFfAY8JgxpgvwTXwzdCrZyyK1DR7G//ZN7jp/LCeOTGwy1UALnQGO+dN7XHzIQK6YPASAl7/axK/+Nz9YNpDs/fuT1Rw2tHnrTajrnpxLg8fL3y4axwtzN3DzCwvDZl8M7U4YLWf4waNfBB9/8/6ZCT2vjqDpy1LsX5sOoHtpAet3xdeyF6vOmGVbSOaU67XBs9+D+U9B54GwO8Hk7vhbYOgxUD4ACjpB3V4o7hpepsfw5MWaATmf7OW5fP1oC9BsnCIikhzW2l3AdP+PZJH1u6qpqvdw52tLEk72AoyBr7dX8buXFweTvd+/spjd1Y33GoHWtY9WbA92yYx2w//8l77F1v92EfxmxkL21DSwp6axrlSsf9fRNO1GecSw7qzaXsXIvp2Yful4Jt72drNzvjd5MK/M38yG3YkngpG8+7OjeXPRZlZureLJ2eFjJjOd6/3o2H3pWhKjS2KGHeZYCPffDvtMgpIesOELWBq+BEVcid6pd8O4b0O0ZUqaJnodQM4ne11KC6m3TvqU5GCfBhEREYmoNXcFwYlWImRtBa7oU/Y3TtAS/y1/tK6HidTRkvIiV1hSmc2aviWBzXPH96dnWWHEc351yojgwvYAJSGtga0xuHsJU48cyscrtjdL9hyOpt1M0+un39gvzVeMYefXsHYmbJoHn97P6sDbsxnYPD/WmXDGvbDyHZj0Y+hzYIoDzQ45n+wZY2gw+fQsUrInIiIiMRY+a0Fw6YUIx4pcMRKF1lwrSraXzO6Abo83eZW1M4GEvKXxeqGvZyrH1WW6ZS/trIXaPTDvcd9kKR//JbHze46AA06D3gfCfieHt9QddElyY81yOZ/sAdSbApxezcYpIiKS62Ldz2+vrGPC797iyamHckiEWRKjJQ5frt3Fwo17o9Y75lbfsM6aBg9/fnMZL8/fxFs/OapZuW8/9FkwL0zHn6ir6j1puEp6RJsNs6XXMbSltFengqTEUuhP/LuVFjTb12F4veB1N85WuXcjfHwPVO/wja+L15n3c8lTa/jIO5rVvzvet6xBtC6YEpGSPaDe5OPyRl8gU0RERHJLpCRgtn+tuoc+/jpyskewP2aYR2auiat+gL+8vTxqTO8v20bnYhcA3jRNqTl+ny7MWbMrLdcKVZDn4B/fGs93/vV5i2XvPOdAfvFs7EXim3XjDDTg+jP0x753CGUFLpZs3svPQ5ZNCJT78fHDuODggfE/gRjGDezM788azaljGpdQGNWvnD+cM5pCl5Nrn5ibnbNzej2wfRnUVcJ/z/G13GGI+08TZz8AAw/1rV239BUYdQ4Ywy+67+aHdW7IS06ynWuU7OFr2XNZJXsiIiK5LtYttjfOsXXxjJtrbbIWaD1M1+CTzkWuNF0p3ORhPTh6v/imuD9rXL+Ek72mLX2HD+0OwOj+5eHJnv/f08f0pXd55LF9iTLGcNEhzRPH8w8eyO7qLOpp1lAD7jqYfhTsWh2lUJNPal4R7HM4HHEdDDrC98Z4PWC94Az5rI0+N/jwwP6dkx15TlGyBzSYfPLUsiciIiJ+kcbEBXZF60XWmnX2Wiva+cluEfJkwQLs0bpoxioT2PK2s+fXzsKBjV+Cxw0DDvbNgDnjGtjSwiQpTY29BA6+3Le0Qfd9mx93OIEO1o21HVGyh79lT8meiIhIzrnrzWU8O2c9H087FmhMllbvqG5WtnEdvdjJhQ1pzRg07WWOP6B5C1VLSdSgaS9H3B9IQh/+ZHXE48nu/NfWpLS1EslZ4ynatEwX/zIDZYWtb7ns16WINRE+J8mQkV6cXi9YD2xdDFsWwju/hb0bWj6vfAD0GwcNtTDldnDkQZd9Uh+vxEXJHr6WPZfNomZzERHpUIwxU4C/4Pvz9oPW2juaHP8BcBXgASqBqdbaRWkPtAO6J8YYuaaC+VmUG/FoM2Su3FbVbF+qxtwlO0mI1vL14KUTuOKR2cm9GDCqXycWbNgbVwL3zfH96dO5CIfD8MJVk3B7vSzdXMmB/cu5/dXFfLxiR7Bs09dl6pFDKC9ycd6EATGvEZy1M8KxJ6cexpw1u7jqsS8iHG2nPP6lND75q68b5rAT4MVrYWsCv06GHA2Dj4LBR4KrCHocoElT2jEle8DWGkNPk5q/zIiIiMRijHEC9wInAOuBz40xM5okc49Za+/3lz8duAuYkvZgc1xw8fMox4N5kW26v3mqkKrukcmuNlrL3vEjeiX3QsA3RvRi/z6+ZC8eZ4/rz2FDfRPljBnQGYDx+/gWxZ48rEeTZC/8XXM5HVxyaMutT4GzIr2uvcsLOeXAPlz1WFzhpp+18OovfGPkZt4L6yNMdvPBnS3Xc8MmX1fLvAJfndk4eUwOU7IH1OKikI6xaKiIiGSdicAKa+0qAGPME8AZQDDZs9aG3v2WkL75OXJOPLexLY0Ra/rmRBpH19qGvZZOS/YHw5vGpfacDoMjke6bSe7qGfvEdvy/nLseGqphzSewcyXsXgcr3vI9BvhsemL13bQDnHlQXw3GAa6QiWmU6GUdJXtALfkUom6cIiKSEf2AdSHb64FDmhYyxlwF/ATIB45NT2gd12l//YhhvUoTOifYshetG6f/3+kfrArb//X25t04o3X5bElFrTvm8Wse/5KfPz2Pn5wwvFX1N/WZf7mJdOjVqTA4Bm7+hj0tlo+VdpQ3mUW0tRPXxGrZSwWn03fFfp2LIheo3ApLXoJtS+HT+2HMhb6FyeNVPhAO/QHMfQy++wpgIK/Qtx5ecFZMf3qQX9y2JyPtgpI9IC+/mEK3kj0REWm/rLX3AvcaYy4CbgS+3bSMMWYqMBVg4MDkrAnWUc3fsCdiQhErJwjc8LfYjTMOqZz4pM7t5fZXl6Ss/mS796Jx/G/uBqadtD8Tb3sLgE17attU53kTBmCAac/5Zo4Mfc+6l+bHPPfla46gxr+gfGuTxBeumoTXWs6675OEzutU6OL+C0Yyfkhv3weqocY3vq5yi2/dugXPhJ/QUqLXaxSc9hfofWDjAucAh13VvKxmxeyQlOwBA3p2pWBjPdba7FzEUkREstkGIHSWiP7+fdE8Afw90gFr7XRgOsCECRPacb+z9itWwhZceiHKvYJNoKtfpma5bI9OObAPpxzYp+WCfiP6dGLRpr0x79mcDsMFEwcGk73Q96ylpHxk3/Jm+xJ9twJjCOOy8UvfxCnlA2DTPKb87/wErwbsdzKccCt0H5b4udKhKdkDvM5CCmjAa8GpXE9ERNLrc2CYMWYwviTvAuCi0ALGmGHW2sC0kacA8U8hKQmJdVPvbalpLwHtbX23bJTQmL1WvmdJ7cbp9ULdXt/i4e46WPQ/eONmqK+Iv47eB8KlL0Bx1yQEJLlAyR7gcRZQYNw0eNw4Ha1fb0VERCRR1lq3MeZq4HV8fagestYuNMbcCsy21s4ArjbGHA80ALuI0IVTmhtzyxucf/AAbjj5AHZX1zP21je5/5JxTBnVvBVp0LSX+c1pIzhyeI+o9QXu95/7YgPrdlbz9A8ODx5btqWCu9+KPwcvcmVvd7lMd4Jq6/X7d41/LNqArsUs31pJQV7spQWcoTPLeL3BpQg6Uck4x3L4bCO88rP4LnrSH6HPGF8rXd1eKOsb3gVTJAFK9gCPowAAb0MNuJTsiYhIellrXwFeabLv5pDH16Y9qA5gT00D0z9YxQ0nH8CKrZUAPPDh1xGTPYDbX13C5BjJXmiz3+erd4UdemPh5oRiG9mvnHnrW56EpD165ZrJCZ/zr+8ezHf/FWHq/yaads08Z1x/nv1ifdi+1jSwOhyG/15xCIs27uXscf3iPu/P54/lw+XbGNS9JGqZRy6byODuJbBlEXz1BHz8F3AWwMBD+arwfV+hV6KeDgXlcOB5vgXJnU3uQ9WCJ22kZA/wOH1Tynrra6G4U4ajERERkUyoc3tjj9mL0cnTk+ASBa2djbM96BttpsgYjtmvJ2eO7cv/5m5M6LyBEVrhWvPKGWDSvt2ZtG/3hM4rL3Jx6oF9G3dU74QtC6C4G3zyN9ixgiP7jIHHHgg/0VMHX78fvs+RBz/8FLYuhBFntOJZiCROyR7gzfO17NmGmgxHIiIiIpkUKwmLNadKooukp3P9umRrbTfK1iRpkRJs28ISGJG0qetn5Tbf+LpN8+DL/zQ/vv6zyOeNvZhvfHogy2x/Vv9iJJT28i1n0H3fNgQjkhgle4DX6fsLlbe++To4IiIikh3+8NoSpn+wipW/P7nVdYSmFo/MXM2lhw0KbjedVOXXLyzgljNG+c5LMNl7cva6lgu1U63Nm1rTmNmttKD59YOZW/yRRJtBNSgwzs7rhYXPwbOXJxAlsO/xMOgIOPB86NTYErhs1su+B10HJ1afSJIo2QMa8nz9sK2SPRERkaz19/dWtrmO0ITkz28uC0v2miYr/565Jpjs5dLsmokuUzXEP96t6Wt07P49ueX0kU3qDj/3ookDeWb2Ouat38OpB/bhrIP68dd3ViQec9Mda2ZC54FQ1AU+uQfeuz3+yqb8AQ6+AhqqoLAc6iqgoCzhmETSQcke4Mnz9wevTWDqWxEREelwQrsNNk3fYqVzscbs5Tsd1Cc6qK8dS7Rl75Ah3YDmyfJd542hc3HsWSadDsNZB/Vj3vo9dC3J57gDenGPP9mLN+c8x/EBhV+thxEnwGPnw/Zl8Z34rf+BccDnD8Dkn0K3YVBQGhKcfz0+JXrSjinZA1bt9U2P+/mytRx7QIaDERERkYwJTUi8TQfpxRzP17pj2ajFLpFRNH0d4m0hDJRr+jJGPbt2L6z+ELoN44X8GxnjWAVv4fuJ5cInodu+YL3QY3jj/iFHxRWnSHukZA9YuMP317alazZwbIZjERERyRWDpr3M1cfsy89O3C+h8/7x/kpuf3UJvz1jJN8K6WYZau663WHbgTxhzppdPPHZ2qh1hyYUe2vdDJr2MgtvOZGRv349YvlB03xjsiLNGhngjjWzSxZq9QQtTZO1CPXs07WY3dXhS1J0LfG1/vUsK4hckdcLO1fBl4/AZw9AQ3Xw0JhIy+MddzMcdjXkFUB9FXg9UKjZ2KVjir1CZI6ocfh+QRd6NRuniIhIOv3t3cTHX93+6hIA/vDa0qhlXl2wKeqx+2KM7Ys0++PandURSiZepr35+8Xjoh777qRBra63V6fmk6pA85a9SC2Ef/zmmGb7Tj2wD3+5YCxXTh7gS/SspYhayjbPgt+Uw61d4G/jfevbNYS/D4+6j+PQ2r+ye+oXcP0G+M0eX5dM/0zs5Jco0ZMOTS17QF0w2dMELSIiItnOWtsskQjd8sRoaYvU47K63pOkyNqXI2MsID+sZ/RxaLFa9kb168S2irqIx5q+tJGq6VToarbPWMsZgy38vhcALwAUEn2h8sLOcOUn0KkvN17vL9R5ABTEHh8o0hEp2QMaTAFu66DQm31/lRMREZFwXht7EpGGBCdLqapzty2gdirPGf1VcsR4AU2MVzfWS9t0eYpILXuB6/Y32+CNm2DF275FyGPpvh+cdjf0PjB8ApU4YxbpyJTsAcbhoJIiJXsiIiIZMGjay/z2jJGcOKo3E297m3svGscpB/Zp8bzQ2/f56xvHeXmtjdn6tDVKy1Pg3KYufSjKotlZzuVw0L00n+2V9c2OOWJlezHEWm+wxTF77jq6PnwEqwuX+7Y/iVDJyX/i3FmD+XJjNf/7wURGD+odX2DK9SRHKdnD9/9/JUUUWSV7IiIimfDAh1/T3z/JyZOz18WV7IV6e8mW4ONY3TRb0sEmzozJ4TC89KPJrNlRxfnTZ4Udc0bJlv9z+UTy83xTPrzz06OoqvPQpcTFh8u3c/1z8/F4bdTX0JdIW8qpYg+lmD3rYObdMOdfwTIRb0yHHgdn3AudfJ+J2k8/xEMdNq8w7ufa2kll2urdnx1NRW1DZi4ugpI9AFxOBxW2iPrKXZkORUREJCdZLLX+sXFFrsTnjwvtpmdt65cHyKFcD4De5YX0Lm+eNEV7+SYPaxznN6RHY5fJgwd1AcBjI01x42OBbzrf54+u6b4df4se16fe/TnkFy/BrtUw4ODwevwXSKRrZms/D2012L+gvEimKNkDbj97NOv+XEZnU5npUERERHJCpO5+NQ2BZM+ZcH0eb+NgMa+1re61F6sbokTnCFkLr7fdyjjHUspNFT/Oe5a+X+2E+U4eth5oPv8KlA+E/hNgyu3syevGmFveAGB1aQ8obT6JTDDZS+BNVi9OyVVK9oD+XYqYRxn7sy7ToYiIiHRI9723gjtfW8ry207C5XQ06+pnLdQ2+BK2wibJ3s+ensczc9az+o5TwvZX1PnWwXv7p0dxzzuNSzjc885y/vH+qrCy594/M644z7ov0kCx3JNoQ1jZ8v9xc96LHFO1kMF2HTSd+NI2zmg6w3MY4x3L6H3N2zi7Dgq7mCOOLo9DepSwaNNeSgriv43NVDdOkUxTsgcYYyjv1psuuxZlOhQREZEO6b53fWvb1TR4fMlek+PW+roAQvPJQZ6Zsz5m3Z+u2hm23TTRy4R+nYvYsDt16/f+csr+/OG1JWH7Hrx0ApV1bn785NwWz//g58fEPB7oIjnQbOG+q87is9W7OXRIN9/BzfOhciu8fgOU9oLqHfTYsoDL8ojeD3bYiTy+dQDXbzmGQDvb100SPWie6Edy57kHcs74/gl1kcxUN06RTFOy5/fFdgeTnJV8tnIbE4dGX3dGREREWi9wyx2ru2Sit+WhXTjbi56dClKa7H1zQv9myd7xI3zr0MWT7A3sVhzzuDGwj9nM+wU/gSXrGOUqhum/a15w25Lm+8ZcxMlrLmDR5kpevuYIRvYtB+ClB2fBlh0h12j+TrucLY/XLM7P45j9erZYTkQg8RHQHdRO2wmHsWzesjnToYiIiHQ4TZO7iKleK8fLtTT7ZibG4UWbzTJZUle7b8bMfVY/7Uv0AD66C96NkOgFHHA6W777KUNr/8ORrifgrL/jjRBhJnNyNexJrlLLnt8uWwaAq35nCyVFREQklk17ajjs9ne458KDOH1M37BjT89ez60vLeLTG44L279hdw3bYqx/F8tvXow9DCMTc658FbLuXypEahVrlQXPwqvTWFGwnTwTko3NjVJ+v5N9C51/ewb0HAH5peBwUFBdj4eV7NO7a3icobOkJjDXabKTM3XjlFylZM9vJ75kr6Bud2YDERERyXJLNlcA8Oyc9cFkL3Cb/9hnawFYvb2q2XkrI+xLhkgLpadavSe1zVhNU5dfnXxAxHJ/Pn8M1z05D4Ae7Oax/NvYbsvhNxeFlcuLlQtd+gL0nwj50bt+di7O57HvHcKofr4um5FmzIx3+cMXrz6CbqVNZ3hpG6V6kquU7PkFW/bq1LInIiKSKoEulbHu+5PdCJMLiykM6RE+WUkp1RRTx6l9K3G57uFIxzw6Gd8YwmFsiFjH9Q2Xs9A7iCLq+ekx/TjvnU6cMroP9w4ZF1cMhw/tHnwcaMULey/jfCNG9y+Pr2ACktYSKpJlMpLsGWNWAxWAB3BbaycYY7oCTwKDgNXAedbatK1yvtOf7OU37E7XJUVERDqmCK06gZYe22Q74nlJbofJRMteqjXNXRzGQEMN3Nab1aFrpP8dTo00weWYC8HrgaOnQVEX9r31Q9wht4Vbex8EfJlQ18uIcbayG2eyOZTrSY7KZMveMdba7SHb04C3rbV3GGOm+bd/ma5gdlEKQEFd2vJLERGRrDbl7g/YVlHHnJtOYE9NA2NueYNfnzaCffwzPYY36vhu9FdtqwrbJkKZaM79+ycs2rQ34Tj3u/G1hM9p7wwGJx4shgddf+KYJ+ZGLfuOZyxL7EB22xKW2/686x3L6rNODSsTSPTKi1zsqWkIJmmtzZOH9ypj2ZZKSgoaM814u3Em06h+nViwYa9a9iRntadunGcAR/sf/xt4jzQme7UUUGkLKajb3nJhERERCY7NA9iytxaA/366lhtO3r/Fc1uTRMxe07H+IPvr00ZwSwuTy0RypuMjSv/5G1YWLotZrrrHWIq/9QSX/f6LuOt+8ydHsnlPLet3+bp8tjbZu/PcA7lo4kD6d2kc55eJWVEfvfwQVm6rTPt1RdqLTCV7FnjDGGOBf1hrpwO9rLWb/Mc3A73SHdRm25WiGi29ICIikqiW1s9rursjdq1MVLfSghbLlFDDj/Ke5wTHHIY6NjUe2BHlhNP+AgddCg4HgTSrW0k+O6rq44qpZ1khPcsK2RBI9lrZ9bI4P4/D9+0eti8TLXudi/MZv0/XlguKdFCZSvaOsNZuMMb0BN40xoStyGmttf5EsBljzFRgKsDAgQOTGtRG240hlRuTWqeIiEguCPSSi/d+PlauZ0xj0tiRu99FW4uvmFqOcczl964HKTfVUc9f7e3Fs57J/NVzFv+9bAKTOu+Gns1bVVuTY6XiZVd6L5J+GUn2rLUb/P9uNcY8D0wEthhj+lhrNxlj+gBbo5w7HZgOMGHChKT93nA5DZtsN8bUfZWsKkVERHJIY7YXSOTeXboteLTpF/alD33WrIZX5m8O1vSr/y3gsU/XpiDO9sPp8P17pXMGpzhn0UAeBzlWxDyn3jqZ2vBT7r7x5xx965vB/caZFzHRg9Z1n+zub3Uc3L004XOjGd6zlHnrdietPhFpWdqTPWNMCeCw1lb4H38DuBWYAXwbuMP/7wvpjKu8KJ9NtV0p8+wCdz3kJXd9FxERkY4s0Za9lnTkRK8re3HjpPe6V1ldeF2L5R91H8dn3gOY4T0cgP9cPrFZy2isRcPjeU/evO5IigsabwsnDOrKf684hImDk9cF8rdnjuKc8f25YPqspNUpIrFlomWvF/C8v1tGHvCYtfY1Y8znwFPGmMuBNcB56QzqmR8cxn1/fg0HFio2QpdB6by8iIhIVgsdsxdrWYXcYTFYLA7AMtEsYX/HWs52fshYxypfkU8jnznDcxjPeI7kU+8B1JPnr6NRl+Lmf5COmezF8doP61XWbN+kJmPu2qrQ5eTQId2SWqeIxJb2ZM9auwoYE2H/DuC4dMcTMKh7Cf0GDoNNwO51SvZERESa8HobF0R3Nlm4LDC2zmvDJ1+x1mKMyegaa5kw3XUX33DOiVmmtrAnP997Hnsp4VDHIu50n98ssYskUl4Xax25TMyCKSLtQ3taeiHjHN2Hwiao3LSM0sGTMx2OiIhIuzLkhleCj1f+/uSwY4FcY+3Oaqb+pzHJuf/9VVx59NCErvPIrDWtjjHdurOH8Y6lXOJ8i8nOBS2W/8QzgseH/oEXl1Rw/7njefFR32v1vrfZ38GjchiDKy88KYw1kU0g1XM6DB6vJT+v5YRSRDoGJXshNtGNeuvkrY9ncubhl2c6HBERyQHGmCnAXwAn8KC19o4mx38CXAG4gW3AZdbajGdDbq83bDtarvGvj7/myqOHJrReW3tsiHLhppfZhcc6sMCNhzg5dd4PY55TbQt4ynMUH3tHsci7Dwc7lvKi9zCOcxQDFTTt23ry6N7BSWpiKXI5KS3I4/kfHs5Pn57Hqm1VMVv2Apd587ojmb9hD4cNzWxXypnXH0tVnSejMYjkCiV7IazJY53tSafqjjsoXERE2g9jjBO4FzgBWA98boyZYa0NXWn7S2CCtbbaGHMlcCdwfvqjDWcwMbeD+7Nw5YQC6jne8QVjHCsZ51jONlvOSc7PwwvNi3zuJ54R/Nb9LYoLnMyp6wchr8sGbw8g+msyqFtJXPEV5zsBOGhgF8oKWr6VC6SU3csKOGNsv7iukUp9yosyHYJIzlCyF6LI5eRr25sB3k0tFxYREWm7icAK/3h2jDFPAGcAwWTPWvtuSPlZwCVpjTCKpmPwoiUwNfUeGjxe3JlYUTsOxdTyHefrXJr3Br3NLtzWwQI7mLGOlXHXcV39lTzvPYLQxK7cuICG5AcMFPmTPSCubDq4ZmFKohGR9kzJXgiX07DS9mUyC7T8goiIpEM/YF3I9nrgkBjlLwdeTWlEcWra1TJa18u9tW6G/apdhAxAD3ZTbir5cd5znOpsvgRAnvEy1kRP9B5wn4wXw8n96xlw0V+5b04lz7++rFm5mN0qo+haEt99R5GrMdkb2bcT89btpjBkXzQdeYF6EYlMyV6IHx6zL7/6aAgFeQ2wdRH0HZvpkERERAAwxlwCTACOilFmKjAVYODAgSmNp1my1w5n28zDzUTHEr7hmM14xzJGO1YndP5eZ1f+MPB+/rvY3exY5/GjOb9TH35wlOXv76+ioja8TKylEEIZ0/haDupWwrNXHs45f/8kavmXfnQEec7GCVamnbQ/xx/Qk/17N186ISDwzijVE8k9SvZClBe5mGeHAGA3fIFRsiciIqm1ARgQst3fvy+MMeZ44FfAUdbaumiVWWunA9MBJkyYkNLsq2ly154mVenLdvqa7TxTcGvMcpW2kCn1d7De9qAnu9lKF5x4ONPxMf/zTuJ3Z48lf0sFsLrZuYHn63AYJg7qyttLtgaPFeQ5wlrRenUqYMve5m+btbBfrzKWbK4AfInf+H26xIx5VL/ysO1OhS6O3b9XzHMCS2GoYU8k9yjZa2Kd7clOW0rJ2tkUHHxZpsMREZGO7XNgmDFmML4k7wLgotACxpiDgH8AU6y1W5tXkRmhyV1tg4eq+uatX+lSTC0XO99ismM+RzrnRy33gWc01zX8kCJTz3rbI+zYVnxJlgcnz3qPDO6Pt4UulDGxu3FGm8wm1TJ1XRHJHCV7zRi+8g5l/xWf0jvToYiISIdmrXUbY64GXse39MJD1tqFxphbgdnW2hnAH4FS4Gl/a9Faa+3pGQvaL3Th9LPv+4RFm/ZmJI7b8v7JxXlvRzz2gWc0d7vPYa7dFy+GYEfGBFoh9+1ZGnF/aBVN80GDidmK1lKX16E9Sli5rSrOCFt28KCufLh8Ow4tryeSc5TsNXHXeWOY99wQJlf/D+qrID++aZBFRERaw1r7CvBKk303hzw+Pu1BxSE0XUl3oldELY/m3854x/Jmx+5sOI9HPcdTSEOwtS5gRJ9OCcVqgPMPHsCwnqWce/9MACbt242PV+wIS3YL8nyTo/z4+GHc/dZyf8tey61o0Yo8d+UktlTU4vFatlfW8a1/fhZ3zJHcf8l4Vu+oCsYpIrlDyV4To/uV87J3CM48C5vmwT6HZzokERGRdifdY/QceDnG8SX/zP+/iMePqruLNbYXhw3pzt5VO4iU0h27f8/Ekj3jm8FywqCuwX0Du5bwMTvCyhW4fE1mobNphiZ70V6raPvLi12UF7vijrMlJQV5jOxb3nJBEelwlOw1kZ/nYLZ3PzzW4Fz1npI9ERHJeVV17uBC3gG1DZ60XPte192c4mzesrXbltDZVLHS24cT6/+A239Lk+eM3qKWzAlKQhO1wLIHNfWNr0msa3WkBehFpH1TsteEwbCHUubafRm//E045oZMhyQiIpIxm/bUcNjt79Cvc1HY/kN+H3mcXLJc63yW61zPRjw2reEKnvQcjaX5ILRYa8klI5cKLHHQv0vj6zHK32o2oGsxABMHd6VzkYv1u2oi1jGibydeW7iZXuWFCa19V1ao2zYRSYx+azTRpcTXbeJdz1jGb3yaqp0bKenaN8NRiYiIZEYgYdmwO3Likmxd2Mv7BdfRyTRe79/uE7jbfQ41FFBLQcTzzjqoHz86dl9ufWlRq6/9xnVH8o0/fxDcjrRQ+aWH7cOB/cs5aGDjeMALJw5g/z5ljBvYhdd+PJmBXYtxGMPpY/ty2cOzw86fef2x9Cwr5KjhPRgzoHPYsWgtfu/89Cgqat3BZFJEJF5K9pooK/Qle297x/EznuaNZ//JWd+7KcNRiYiIZEasJQSSqZhaFhWGL3n0iPsE/uC+gCqKopzV6KjhPRjSoxRnzP6TsZ/M8F7hC5MXRUj2jDFhiV5g3zj/vv17dwruH9Gn+Ti5PuW+59I00YtlSI/IM4KKiLREyV4Ui+1AVnr7sN+OdwAleyIikpsiLQaeXJbr8p7l2rzngnt22VIOqpueUC2BPC6Z3TiL8lM/e6WJuiEi0nZacSWCWdcfBxhe9h7CfrVzYe/GTIckIiKSds/MWc8P//tFimq3XO58mdWFF4clesfV/ZGD6v7R6loP7B951sk8h4m6Zl40fTu33KIYS6ITrvQqK2zT9UREmlLLXgS9y32/bJ/2HMXVzhdgzr/hmOszHJWIiEh6vbd0a0rq7cFuPi/8Ydi+5d5+3O6+kJW2X6vqDMyOedUx+7JPt2KufWJu2PFPbziOriX5vLNkK89/uSFqPbOuPw6PteyurmdoErtPfjLtWFzOSBPK+P79wzmjGdG3U7PjIiJtoZa9GNbZXrznHYN3zr/AnepuLCIiIu1LspfSc+JhmFnfLNE7vu5OTqj/I+94x7X9Gg7DGWP70bMsfCKXbqUFGGMY1S/2enO9ywvp17ko6evS9e1cRI+yyJPLAFoHT0RSQsleFP/6zsEAPOg5GUflFvi09V1KREREso31t24ly+mOT1hZ+C3eLPhF2P7htf9mhe2ftOtkq3QvUi8iuUHJXhTH7N8TgE+8o/iAg+CDP0LV9gxHJSIikh7/+ng1H6/Y0eZ6TnHMYnXhRdyT/7fgvu22E5fUX8+RdX+mHlfCde7XZNbMlnQvbWxRCwyja80so7Fa5mKJlcdpIXURSSWN2YvhT98cw8+ensctdRfxtpkG794Gp/4502GJiIik3DtL2jZer5RqFhRe0Wz/7xsuZLrntFbXe2D/cv73w0ks3ryXU+75KGq5QBL1zA8OY1jP5snhtw7dh6P378kBvTtx6O0tLxD/4S+OoVNhYomp8jgRyTS17MVw7nhft5KVth9rhl4Ecx6GLa1frFVERCRbtKXFqZzKZoneYu8ALqz/VZsSPYARfTrhcJgWx7gFFijv16WI8uLGJC10iYZj9usZnJStJQO6FofVEw/1zBSRTFOy14KzDvLNCnbGgiOwBZ1gxtXQUJPhqERERNqXYmr5kfM5VhdexLzCqcH9L3oO5eDaezmp/g/M9I7MYIQiIrlHyV4LDhvSDYDdlHG9eypsmAMvXK2R1CIiIiEWFV7GT13PBLe/8g5mbO0/+FHDNWyjS9Ku09YxboHlFA7ok9i4v9Yo9i/KPmlotxbLWrUDikgKaMxeC9zexl++T1SO5faTb8a8cyv02A+O+kWMM0VERDo2g5fb8v7JRXnvBvfd7T6bu93npvSqiWj6t9kjh/fg9R8fyfBejWvofXHTCbi93mQEF6as0MU7Pz2Kfl2iL85uNLJPRFJIyV4LSgqcYdvj3h3FG0POose7t0GXQXDgeZkJTEREJMM+KbiGPmZncPs3DZfysGdKs3LDe5WybEtlOkOL2QK4X+/wVr2uJfkpi2NIEhdmFxFJlJK9Fpx2YF/yHA6ueuwLAHbVuJm06EyW7bcNnpsK1Tvh0B9kOEoREZH0OsvxYTDR+6/7OP7pOYlVtm/Esskc+dBRlyrQ6BARSQWN2WuBw2E45cA+YfvqccElz8D+p8Brv4TXrgdPQ4YiFBERSZ9e7OQ4xxxudT0MwC0N3+JX7sujJnrJdmC/yLNwDuxWHHF/e8+hDh3SFYBupalrXRSR3KWWvVa6/5ONfPPkB+hWfivMug/Wz4ZzH4LOAzIdmoiISJuZKE1onxZeHXx8et1v+coObbGuaAnXy9ccEXOtvKbG9C/n/IMbv2dnXX8cxQVOtu6tY9+e4d0ls6UB8JdT9ueiQ/ahf5fIyaqISFuoZS9OS347hdvOGhXcvuPVJYz//bs80/NqOPdfsHUx3HcYfDodUjDIW0REJJPycPNG/s+D2194940r0YulpbXympo8rEdYEtq7vJBOha5miV4o2877R+Y5HQzuXpLpMESkg1KyF6dCl5MLDh7Io5cfErb/Z0/PY3mPE+AHH8CAg+HVn8P0o2DlOxmKVEREpO1Wbm2cUOX/XPexovBShjs2ALDG25ML6m/KVGhxidYyKSKSS5TsJcDpMBwxrHuz/Sf8+QPe3lKC56Jn4ewHoXY3/Ocs+PfpsHaWRl2LiEjW2bC7BoB/uO7iHGdjV8sH3SdxVP3dvvHrSTI6yji8gM7FvmuN7Nsp7jqPHO77vi4t0IgVEcldSvaS5PJ/z+ZPby6jev+z4OrZcOLtsGUBPHSir6Vv3hNQX53pMEVEROJ2tuMDTnTOBuAh9xT2rX2E37m/1eJ5s288Pmw7VlfKWdcfx5PfPzRmfR/+4hje/dnRnDS6T8xyoW49YxQf/uIYOhdr4hMRyV1K9lrhw18cw7NXHsYHPz8mbP/f31vJiJtfxzrz4bAfwrVfwSl3QUMNPP99+L/9YMaP1NonIiJZ4cq8F6m2BYyrvZ9b3ZfijnNet+6lBWHbsb7xepcXUpwfu94ilzPhcW0up4MBXTXpiYjkNvVtaIUBXYtjfoEMvv4VLjpkIL8/azQcfDmM/y6s+QjmPg7zn4EvHoHyATD0WNj3OBh8FBR1Tt8TEBERiUNfs53HPceyk/i7T6aCxt+JiLSOWvba6NHLD+HEkb2a7X/s07UMmvYyCzbsYdbqXTD4SDjr7/CzZXDGfdBnDCx4Dp66FO4cDA+eAO/dAes+A487A89ERESk0SCziRJTx9e2d5vrmjioa9xljz+gZ7N9SvVERFpHLXttdMSw7hwxrDun/fUj5m/Y0+z4qX/1DWq/4eT9Wbypgj99cwzOgy6Ggy72LcS+fjasfNs3e+d7d8B7t0NhOQw52vfTfyL02B+ceqtERCR9+pvtACzxJrZ+7Lybv9Fs37cPH8QTn6+Led7sG49nT00D/bsUsd+NrwEw9+YTqG3w4nAo3RMRaQ1lEEny1wsP4p8ffc17y7aybmdNs+O/f2UJ4JtJbNw+XRg3sAs4XbDPYb6fY2+E6p2w6l1f4rfiHVj0gu9kVzH0PtDXGthnDPQeBd33A1dhOp+iiIjkkCFmIwDbSWwtvPLi5rN0xtMLs3tpQbOxfppcRUSkbZTsJcmg7iX89szGRdettQy+/pVm5X738mIA9u1Zyl8vPIgD+oSMgyjuCqPO8f1YCztXwYY5vp+NX8KXj8Jn//CVNU7oPgx6HgA9R/ged9vX9+MqSulzFRGRjm+4Wc8eW8zqJHTjFBGRzFCylyLGGP531SRmr97J1oo6pn+wKuz4iq2VnPSXD8P2LfntFApdzkAF7CwcQNnIwbgOPM+3z+vxJYBbFsDmBbBlIWz4AhY+H3pl3+QvXQf7froMhi6DoMs+UD7Ql1BqoLuIiLSgi6lgm+1MPCPmenUqYMveuqjHu5Y0b6FraXbNltbeExGRlplYa9+0dxMmTLCzZ8/OdBgJ8Xotp9/7EQs27I1Z7vtHDuEfH6zisCHduP+S8RG7xQTVVfqSwB3LYdsy2LkSdn4Nu76G6h3hZV3FvmSw8wDfv536Qac+UNYHOvX1/VtYroRQRNodY8wca+2ETMeRbMaYKcBfACfwoLX2jibHjwTuBg4ELrDWPhNPvW39jvzvjWdTbqoYde1zHP2n9wAY0LUo4lCFhbeciNtrMQY6Ffq+r7ZV1FFakMfumnr6lBexu7qePKeDPTUNFLmcFLocUZdc2FFZR0lBXuMfQEVEJKpY349q2Uszh8Pw0o8ms2DDHm56YQFfrt0dsdw//C2BM1ftYMytbzCqXyeWbq7goAFd+PMFY9lT3cCIvv4uoAWl0OdA309TtXtg1xrYvQb2rIfd62DPWti91tcqWLOz+TmuYijrDSU9obQHlPQIedzTt13aE4q7KTEUEWkDY4wTuBc4AVgPfG6MmWGtXRRSbC3wHeBn6YztV+7LAVgd0gLXs6wwYrJXUtD8dqJHmW/8XVG+b2hBYPxdaYSyTXVrMnZPRERaR8lehozqV87zP5wEwKptlfQoK2D0b96IWj7QEvjZ6p1MuuMdACbs04XlWysZv08XHrh0As5Is5UVlkdPBAEaaqFik+9n70bfT+UW33blVti+HFZ/HDkpBHDkQVFXX/fQoq5Q1MX/09n/0yXyT34ZOLTyh4jkvInACmvtKgBjzBPAGUAw2bPWrvYf82YiwFDZ3BtIRCQXKdlrB4b0KAVg9R2nAL4v07vfWs5f3l4OQN/yQjbuqW123uw1uwB4Z8lWht4QPhnMTaeO4PHP1tKnvJDTDuzLOeP7s3lvLWWFeZTm5zVOY+0qbBzfF4vHDdXbfQlg1Vao3ObrIlqz0/dv9Q6o2e1rMdw0D2p2QUNVjAoNFHbyJaMF5b7HBZ2goCzy4/wS309BmX+71Nei6SoGh7r5iEjW6geErkmwHjiktZUZY6YCUwEGDhzYpsCOHN6DD5Zta1MdIiKSWUr22iFjDNedMJzrThgetn/GvI1c8/iXcdXx25d8fxResbWSD5dv5xfPfhW17NM/OIyDB3Xl+S/XM7pfOXtr3Xi8lvEDuzQmhc48X9fOsgRmZXPX+RLAml3Nf2r3QO1uqN0LdXt9/+5dH75tPfFdJ6/InwwW+5LAQGKY708G84vBVeKbpdRVFLKvOHxf8KfQV2fgX61xKCJZwlo7HZgOvjF7banrgUvHU1UX+ffwr04+gCmjejP5znfbcgkREUkx3cVmkdPH9OX0MX0jHqt3e/ly7S6ueeLLmDOiRfLN+2cmVH7qkUOYNmV/9tY2UJyfx7bKOtweL/27FON0GKy1GGMgrwDKevl+EmUtuGv9yV8F1Ff6fuoqfBPS1Af+rfK1INZX+x7XVzb+W7nNf6wKGmqgoRpsK3pBOfLCkz9XIeQFfgrC/3UVgrMAnPm+JNGZ7/txBB67fD8OV/i2M9+/zxWlXJS6HHkaMymS3TYAoauW9/fvy7iCPCcFeZF7TgzoWsSArsVpjkhERBKlZK+DyM9zcMiQbnx6w/F4vZZd1fXBAe5bK2pZta2KIpeT215ezC9P2p8X523k4U9Wt+pa0z9Y1WwpidA46t2+hKpbST47quoB2KdbMQV5Do7Zvyc9ywqDLY+/OvkAenYq4MSRvalt8OC1UOf20LtTIZWePFyF3XGV9Iw8HjFR1oKn3pf0NdQ0JoCh/wYSQ3dt5H8Dj911jf9W7/A/rvWNgfTU+bq9eup9P/G2ULZWxMQxL0YyGVK+aTLZmoQzrEycdTmcSlJFfD4HhhljBuNL8i4ALspsSNHVNvh+vzv0/6+ISFZQstcBORwmbCaznmWF9CwrBOCpHxwGwPh9uvCb00fi9njZXdNA1+J8jIFd1Q2UFuTx8YrtfL29ig27azh4UFf++dEqNu2pZf/eZby1eGvUawcSPSCY6AGs2VENwLItlWHlb3tlcdzP65DBXflq/R4m7dud95Zuxe1t7KF09H49KMhzMH6fLri9lgFdiunfpYiSgjxWbq2kT+ciOhe5KHQ5KcovpbxTF8C3FMbSLRUcMKBTtMu2ndcL3gbwNPgTwAb/dn1jUtj0eKQynnrwuqOUCTk/al0NvuS0riK+GFKdpEZsqXT6Wyv9/zqc0fcFt/N8k/2ElYm0L1JdoWWcjf8GHhtH+P5m24F9juZ1GGfj/qj1OML3Rfppdkw32R2JtdZtjLkaeB3f0gsPWWsXGmNuBWZba2cYYw4Gnge6AKcZY26x1o7MRLwnjuzNok17w9bIG9Enhb8/RUSkTbTOniTMWktNgye4PlJlnRuDr1XP5fTNsLl1by0zV+3g9YWbMRi+O2kQt7+6hAsnDuS2lxexq7ohrM7R/cqZv2FPup9Kiw4b0o2Zq3xrFQ7qVkxtg5fNe8MnyzmgTye6leSzZmcV63bW0K0knzPG9uO9pVs5Y2w/Plm5nbPH9aPBY2nwePly7W4OH9qNLiX5TB7Wna+3V9GtpIDKOjf9Ohexdmc1XUvysVjKi1w4jMHjtTiMIT+vcQZTay3V9R6K852+brMh+00yEoJgkhotmWxokoAmI3l1+5JMrxu8Hv9PhH3Bbbc/zpbOa1rG3fbXJ2NMjGTQNCaXzY6bxuSy2fHQOhM93jRBjXL8uF/7Zu1tyzPvoOvspUoyvyMHTXsZgK9vP5ntlfXBZRX21DRQkOfQengiIhkU6/ux3SV7LS0uG0rJXsdU7/bitZZClxNrLV4LHyzfRmlBHlV1brZX1jOqXyfW7qjmmTnr+WjFdk4a1QeP14sxhue/9A13KchzUOduPkYv2qLAHYnLaSgtyGNXdQN5DsPQHqUs3VIRPH78AT2Zu243dQ1eKurcTNq3G4V5TrZU1LJ1bx29OhUyrGcp/bsU8dnqnXQrLeDlrzYBcPjQblTVuTl83+4s21zB8N5l1DZ46FqcT1G+k51V9XQtyad3eSGbdteyekcVvToV4nI6qKl307k4n721DQzvVUZpQR6LN+1lwqAuVNd7WL+rhgUb9nDk8B7sqKxnYNdihvQoocHjJT/PQYPbUl7sYt3OavbWNICBfbqV4HKY4Hudn+egR2kB1Q0equvcwQS50OUk3+nA7bXk5zmw/oTQWC/W04CxXjwe3z4HvoTRYP3JpTckyQz91xt2zPrrw+sNLxss442wz18Owuu03sZy1uvrhhz1uA2/RkLHbZPn4Y3+05bj3/8gsQmeIlCyl5hUJHuBWaNFRKT9yJpkz7+47DJCFpcFLmyyuGyQkj1pSU29h6L8lv/iXFnnJs9hcDkdwfGB2yvrKM53Upyfx/bKOmrqPSzdXMFxgUTJ7WXTnho6FbrYU9PA7uoGivOdPPflBvbrVcb4fbpQUefm3SVb6du5kO0V9SzatJe1O6s5cngP6ho8lBe5KC9yMX/DHnZXN3Dw4K68OG8j+/YsZcXWypgx9ykvZFOEJTmkZaUFeVTWhbfu5Tsd1HuiT+ATOga10OWgtsHL4O4lfL29CqfD1/oK0L00n9KCPKrrPWytqKNzsQu3xwY/Y0UuJxX+awfqHN6rFINh5bZKJg/rzrtLtzGkewnbKuuYOKgr63ZV43Q4KC/Ko3enQrZX1lNS4GRrRR11DV56lxfS4PHS4PFSWefGYQz79y6jqt5DVZ2bDbtqGNKjhJoGL0O6l1BV52btzmr21ropLXDSs1Mhe2sa6NWpkE6FLh79dA39Oxdx1H49qKx1s6u6gb6dCykrzGNPTQPbK+pxey2j+5WztaKW5Vt8ce+paWBnVT1rd1bTp3MR5UV5DOhSTFG+k7PH9Y9rMe1YlOwlRsmeiEhuyKZk7zDgN9baE/3b1wNYa2+PVF7JnkjLvF4bXELD67UYAw0ei8tp2Fvrpt7tpbzIRa3bg8MY6t1equrcFOQ5qK73BMd05uc5+PTrHZQV5rF5Tx2njunD19uqKM53kud0UFHbwJ6aBgyGr3dUMaR7CdX1HipqG6h3+2Zr3bi7hveWbcVhDGeM7Yfb42XWqh2UF+czY+4Gph45lLU7q9mwuwa3x8sXa3cxsGsxhS4nxflOXl+4hWP268GcNbvoUpJPr7JCClwOdlTWM3FwV95bupUBXYtxOR28u3Qrhw7uRqHLwfKtlRy9Xw+2VdTh8Vq6FOcHu+P2KC3g/WXbGN2/nLoGL8u3VrC9snG8aZHLyZAeJQzpUcrHK7azs6qefboV4/ZYBnQtYsXWKurcHipqfQnc6H7l9CwrYE9NA1sr6jDGl0guj5G89+9ShDGwbmdNxES0Z1kBtQ0e8vOc/kTTg7Wwt7aBBo+le2kBFbUNlBe52FFVj8drKSvICyaVTRnja9BrKtK1k2Xm9cfSp7yoTXUo2UtMspO9gjwHS393UlLqExGR5MmmZO9cYIq19gr/9reAQ6y1V0cqr2RPRCS2Bo83OJa2weMlL2Rm20DSb0zjkinW+lohjTHkOx24nCZYrqbBQ0GeMzhu1+uFwnwHe6obKMhzUu/x4nQYahs8GIOvpdwYPNaXYLd1Vl0le4lJ5ndkdb0bg4mrp4SIiKRXrO/HrJuN0xgzFZgKMHDgwAxHIyLSvgUSvaaPAfLzGpOvwKQ+xhjKCl0RywUmZQJDWUhdPTspAejoGt97ERHJJo6Wi6RVi4vLWmunW2snWGsn9OjRI63BiYiIiIiIZIv2luwFF5c1xuTjW1x2RoZjEhERERERyTrtql9GtMVlMxyWiIiIiIhI1mlXyR6AtfYV4JVMxyEiIiIiIpLN2ls3ThEREREREUkCJXsiIiIiIiIdkJI9ERERERGRDkjJnoiIiIiISAekZE9ERERERKQDUrInIiIiIiLSARlrbaZjaDVjzDZgTRur6Q5sT0I46ZJN8SrW1MmmeBVramRTrJCcePex1vZIRjC5IAe/I7MpVsiueBVramRTrJBd8eZarFG/H7M62UsGY8xsa+2ETMcRr2yKV7GmTjbFq1hTI5tiheyLV3yy6X3Lplghu+JVrKmRTbFCdsWrWBupG6eIiIiIiEgHpGRPRERERESkA1KyB9MzHUCCsilexZo62RSvYk2NbIoVsi9e8cmm9y2bYoXsilexpkY2xQrZFa9i9cv5MXsiIiIiIiIdkVr2REREREREOqCcTvaMMVOMMUuNMSuMMdPaQTwDjDHvGmMWGWMWGmOu9e//jTFmgzFmrv/n5JBzrvfHv9QYc2Ka411tjJnvj2m2f19XY8ybxpjl/n+7+PcbY8w9/li/MsaMS3Os+4W8fnONMXuNMT9uL6+tMeYhY8xWY8yCkH0Jv5bGmG/7yy83xnw7jbH+0RizxB/P88aYzv79g4wxNSGv7/0h54z3f35W+J+PSWO8Cb/v6fh9ESXWJ0PiXG2Mmevfn9HXNsbvq3b5uZXEpeMzn2A8+o5MTZzt+vvRfz19R6bm97i+H1Pzurav70drbU7+AE5gJTAEyAfmASMyHFMfYJz/cRmwDBgB/Ab4WYTyI/xxFwCD/c/HmcZ4VwPdm+y7E5jmfzwN+IP/8cnAq4ABDgU+zfB7vxnYp728tsCRwDhgQWtfS6ArsMr/bxf/4y5pivUbQJ7/8R9CYh0UWq5JPZ/54zf+53NSGl/bhN73dP2+iBRrk+P/B9zcHl7bGL+v2uXnVj8Jv7/6jmx7vKvJsu9I2uH3o/+a+o5Mze9xfT/mwPdjLrfsTQRWWGtXWWvrgSeAMzIZkLV2k7X2C//jCmAx0C/GKWcAT1hr66y1XwMr8D2vTDoD+Lf/8b+BM0P2P2J9ZgGdjTF9MhAfwHHASmttrMWG0/raWms/AHZGiCGR1/JE4E1r7U5r7S7gTWBKOmK11r5hrXX7N2cB/WPV4Y+3k7V2lvX9RnuExueXVFFe22iive9p+X0RK1b/Xx/PAx6PVUe6XtsYv6/a5edWEqbvyNRo79+R7e77EfQdSep+j+v7MQe+H3M52esHrAvZXk/sL420MsYMAg4CPvXvutrftPtQoNmXzD8HC7xhjJljjJnq39fLWrvJ/3gz0Mv/ONOxhrqA8F8I7fG1hcRfy/YQM8Bl+P5CFTDYGPOlMeZ9Y8xk/75++OILyESsibzv7eG1nQxssdYuD9nXLl7bJr+vsvVzK+Ha9fui78iUyZbvR8je3zXZ8B2p78ckaQ/fj7mc7LVbxphS4Fngx9bavcDfgaHAWGATvqbq9uAIa+044CTgKmPMkaEH/X81aVfTvRpj8oHTgaf9u9rraxumPb6WkRhjfgW4gf/6d20CBlprDwJ+AjxmjOmUqfhCZMX73sSFhN+EtYvXNsLvq6Bs+dxKdtF3ZGpk6/cjtL/XMpos+Y7Mmvc9hL4fY8jlZG8DMCBku79/X0YZY1z4Phj/tdY+B2Ct3WKt9VhrvcADNHaXyOhzsNZu8P+7FXjeH9eWQNcT/79b20OsIU4CvrDWboH2+9r6JfpaZjRmY8x3gFOBi/2/xPB399jhfzwHX7/+4f64QruxpPuzm+j7nunXNg84G3gysK89vLaRfl+RZZ9biapdvi/6jkypbPp+hCz7XZMt35H6fkxaXO3m+zGXk73PgWHGmMH+v2ZdAMzIZED+Psf/BBZba+8K2R/ab/8sIDAT0QzgAmNMgTFmMDAM38DTdMRaYowpCzzGN/h4gT+mwGxB3wZeCIn1Uv+MQ4cCe0KastMp7K8/7fG1DZHoa/k68A1jTBd/t4tv+PelnDFmCvAL4HRrbXXI/h7GGKf/8RB8r+Mqf7x7jTGH+j/3l4Y8v3TEm+j7nunfF8cDS6y1we4nmX5to/2+Ios+txJTpj/zzeg7MuWy6fsxEEdW/K7Jpu9IfT+2Xbv7frRJnoEmm37wzX6zDF/G/6t2EM8R+Jp0vwLm+n9OBv4DzPfvnwH0CTnnV/74l5Ki2QyjxDoE34xL84CFgdcP6Aa8DSwH3gK6+vcb4F5/rPOBCRl4fUuAHUB5yL528dri+4LdBDTg65N9eWteS3xjAVb4f76bxlhX4OtXHvjc3u8ve47/8zEX+AI4LaSeCfi+RFYCfwNMGuNN+H1Px++LSLH69z8M/KBJ2Yy+tkT/fdUuP7f6adV7rO/I1seaVd+RtOPvR//19B2Zmt/j+n7Mge9H469IREREREREOpBc7sYpIiIiIiLSYSnZExERERER6YCU7ImIiIiIiHRASvZEREREREQ6ICV7IiIiIiIiHZCSPZEUM8ZU+v8dZIy5KMl139Bk+5Nk1i8iIpJK+o4USS0leyLpMwhI6IvMGJPXQpGwLzJr7eEJxiQiItIeDELfkSJJp2RPJH3uACYbY+YaY64zxjiNMX80xnxujPnKGPN9AGPM0caYD40xM4BF/n3/M8bMMcYsNMZM9e+7Ayjy1/df/77AX0iNv+4Fxpj5xpjzQ+p+zxjzjDFmiTHmv8YYk4HXQkREJJS+I0VSoKW/iIhI8kwDfmatPRXA/4W0x1p7sDGmAPjYGPOGv+w4YJS19mv/9mXW2p3GmCLgc2PMs9baacaYq621YyNc62xgLDAG6O4/5wP/sYOAkcBG4GNgEvBRsp+siIhIAvQdKZICatkTyZxvAJcaY+YCnwLdgGH+Y5+FfIkBXGOMmQfMAgaElIvmCOBxa63HWrsFeB84OKTu9dZaLzAXX9cZERGR9kTfkSJJoJY9kcwxwI+sta+H7TTmaKCqyfbxwGHW2mpjzHtAYRuuWxfy2IN+D4iISPuj70iRJFDLnkj6VABlIduvA1caY1wAxpjhxpiSCOeVA7v8X2L7A4eGHGsInN/Eh8D5/jEPPYAjgc+S8ixERESST9+RIimgv1aIpM9XgMff1eRh4C/4uod84R8Avg04M8J5rwE/MMYsBpbi66YSMB34yhjzhbX24pD9zwOHAfMAC/zCWrvZ/0UoIiLS3ug7UiQFjLU20zGIiIiIiIhIkqkbp4iIiIiISAekZE9ERERERKQDUrInIiIiIiLSASnZExERERER6YCU7ImIiIiIiHRASvZEREREREQ6ICV7IiIiIiIiHZCSPRERERERkQ7o/wEg7/l5aNYFjwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = make_train_test_data(train_dataset, test_dataset, n=1000)\n",
    "print(X_tr.shape, X_ts.shape)\n",
    "history7 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=2000)\n",
    "plot_history(history7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Training Data = 10000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "torch.Size([10000, 28, 28]) torch.Size([10000, 28, 28])\n",
      "Iteration 0: Loss = 78.7406, Accuracy = 0.1400 Test Loss = 75.2497, Test Accuracy = 0.1272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data = torch.tensor(train_dataset.data, dtype=torch.float32) / 255\n",
      "/var/folders/bg/yqgwsftd079fpjycqm6w_4_40000gp/T/ipykernel_2670/1392350790.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data = torch.tensor(test_dataset.data, dtype=torch.float32) / 255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Loss = 49.7004, Accuracy = 0.1400 Test Loss = 49.8086, Test Accuracy = 0.1263\n",
      "Iteration 2: Loss = 41.2468, Accuracy = 0.1300 Test Loss = 38.6273, Test Accuracy = 0.1301\n",
      "Iteration 3: Loss = 31.2275, Accuracy = 0.1100 Test Loss = 32.2685, Test Accuracy = 0.1335\n",
      "Iteration 4: Loss = 23.4190, Accuracy = 0.1600 Test Loss = 28.1362, Test Accuracy = 0.1370\n",
      "Iteration 5: Loss = 25.1672, Accuracy = 0.0800 Test Loss = 25.1044, Test Accuracy = 0.1398\n",
      "Iteration 6: Loss = 21.9486, Accuracy = 0.1700 Test Loss = 22.7665, Test Accuracy = 0.1462\n",
      "Iteration 7: Loss = 21.4685, Accuracy = 0.1400 Test Loss = 20.9165, Test Accuracy = 0.1501\n",
      "Iteration 8: Loss = 19.4022, Accuracy = 0.1300 Test Loss = 19.4030, Test Accuracy = 0.1516\n",
      "Iteration 9: Loss = 18.2619, Accuracy = 0.2000 Test Loss = 18.1541, Test Accuracy = 0.1543\n",
      "Iteration 10: Loss = 17.0207, Accuracy = 0.1500 Test Loss = 17.0448, Test Accuracy = 0.1586\n",
      "Iteration 11: Loss = 17.1912, Accuracy = 0.1200 Test Loss = 16.1404, Test Accuracy = 0.1627\n",
      "Iteration 12: Loss = 15.0736, Accuracy = 0.1400 Test Loss = 15.2965, Test Accuracy = 0.1653\n",
      "Iteration 13: Loss = 14.4867, Accuracy = 0.1500 Test Loss = 14.5351, Test Accuracy = 0.1661\n",
      "Iteration 14: Loss = 13.5302, Accuracy = 0.2300 Test Loss = 13.8928, Test Accuracy = 0.1716\n",
      "Iteration 15: Loss = 13.3503, Accuracy = 0.1500 Test Loss = 13.2823, Test Accuracy = 0.1749\n",
      "Iteration 16: Loss = 12.5390, Accuracy = 0.1400 Test Loss = 12.7183, Test Accuracy = 0.1732\n",
      "Iteration 17: Loss = 12.5302, Accuracy = 0.1300 Test Loss = 12.2416, Test Accuracy = 0.1786\n",
      "Iteration 18: Loss = 11.5150, Accuracy = 0.1700 Test Loss = 11.7736, Test Accuracy = 0.1786\n",
      "Iteration 19: Loss = 10.5794, Accuracy = 0.1900 Test Loss = 11.3700, Test Accuracy = 0.1791\n",
      "Iteration 20: Loss = 11.2495, Accuracy = 0.1700 Test Loss = 10.9820, Test Accuracy = 0.1810\n",
      "Iteration 21: Loss = 9.7370, Accuracy = 0.1700 Test Loss = 10.6045, Test Accuracy = 0.1894\n",
      "Iteration 22: Loss = 10.5615, Accuracy = 0.1500 Test Loss = 10.2638, Test Accuracy = 0.1848\n",
      "Iteration 23: Loss = 9.8220, Accuracy = 0.1900 Test Loss = 9.9941, Test Accuracy = 0.1868\n",
      "Iteration 24: Loss = 9.2860, Accuracy = 0.1600 Test Loss = 9.6830, Test Accuracy = 0.1890\n",
      "Iteration 25: Loss = 9.7697, Accuracy = 0.1800 Test Loss = 9.3804, Test Accuracy = 0.1909\n",
      "Iteration 26: Loss = 9.3902, Accuracy = 0.1800 Test Loss = 9.1298, Test Accuracy = 0.1960\n",
      "Iteration 27: Loss = 8.7046, Accuracy = 0.1700 Test Loss = 8.8904, Test Accuracy = 0.1944\n",
      "Iteration 28: Loss = 8.8737, Accuracy = 0.2400 Test Loss = 8.6274, Test Accuracy = 0.1976\n",
      "Iteration 29: Loss = 7.7716, Accuracy = 0.2800 Test Loss = 8.4189, Test Accuracy = 0.2006\n",
      "Iteration 30: Loss = 7.4464, Accuracy = 0.2300 Test Loss = 8.1864, Test Accuracy = 0.2006\n",
      "Iteration 31: Loss = 7.8706, Accuracy = 0.1400 Test Loss = 8.0045, Test Accuracy = 0.2077\n",
      "Iteration 32: Loss = 7.1756, Accuracy = 0.2300 Test Loss = 7.8014, Test Accuracy = 0.2061\n",
      "Iteration 33: Loss = 8.6910, Accuracy = 0.2100 Test Loss = 7.6218, Test Accuracy = 0.2056\n",
      "Iteration 34: Loss = 7.3965, Accuracy = 0.2100 Test Loss = 7.4385, Test Accuracy = 0.2113\n",
      "Iteration 35: Loss = 6.6292, Accuracy = 0.2200 Test Loss = 7.2638, Test Accuracy = 0.2130\n",
      "Iteration 36: Loss = 7.2794, Accuracy = 0.1600 Test Loss = 7.1024, Test Accuracy = 0.2119\n",
      "Iteration 37: Loss = 7.5049, Accuracy = 0.2000 Test Loss = 6.9543, Test Accuracy = 0.2137\n",
      "Iteration 38: Loss = 6.6069, Accuracy = 0.1600 Test Loss = 6.7940, Test Accuracy = 0.2192\n",
      "Iteration 39: Loss = 5.9557, Accuracy = 0.3000 Test Loss = 6.6602, Test Accuracy = 0.2209\n",
      "Iteration 40: Loss = 7.1534, Accuracy = 0.1700 Test Loss = 6.5258, Test Accuracy = 0.2244\n",
      "Iteration 41: Loss = 6.0463, Accuracy = 0.3000 Test Loss = 6.3796, Test Accuracy = 0.2226\n",
      "Iteration 42: Loss = 6.0620, Accuracy = 0.2900 Test Loss = 6.2612, Test Accuracy = 0.2272\n",
      "Iteration 43: Loss = 5.3527, Accuracy = 0.2400 Test Loss = 6.1320, Test Accuracy = 0.2276\n",
      "Iteration 44: Loss = 6.1812, Accuracy = 0.2000 Test Loss = 6.0087, Test Accuracy = 0.2293\n",
      "Iteration 45: Loss = 4.8722, Accuracy = 0.2400 Test Loss = 5.9024, Test Accuracy = 0.2296\n",
      "Iteration 46: Loss = 6.1987, Accuracy = 0.2400 Test Loss = 5.7892, Test Accuracy = 0.2333\n",
      "Iteration 47: Loss = 5.9097, Accuracy = 0.1600 Test Loss = 5.7031, Test Accuracy = 0.2340\n",
      "Iteration 48: Loss = 5.6905, Accuracy = 0.2200 Test Loss = 5.5676, Test Accuracy = 0.2374\n",
      "Iteration 49: Loss = 5.6127, Accuracy = 0.2200 Test Loss = 5.4753, Test Accuracy = 0.2401\n",
      "Iteration 50: Loss = 5.4853, Accuracy = 0.2600 Test Loss = 5.3807, Test Accuracy = 0.2377\n",
      "Iteration 51: Loss = 5.3436, Accuracy = 0.2000 Test Loss = 5.2912, Test Accuracy = 0.2444\n",
      "Iteration 52: Loss = 4.9463, Accuracy = 0.2400 Test Loss = 5.1900, Test Accuracy = 0.2410\n",
      "Iteration 53: Loss = 4.5849, Accuracy = 0.1500 Test Loss = 5.0972, Test Accuracy = 0.2461\n",
      "Iteration 54: Loss = 4.5163, Accuracy = 0.2500 Test Loss = 5.0188, Test Accuracy = 0.2470\n",
      "Iteration 55: Loss = 4.8224, Accuracy = 0.3000 Test Loss = 4.9270, Test Accuracy = 0.2500\n",
      "Iteration 56: Loss = 4.8420, Accuracy = 0.2500 Test Loss = 4.8502, Test Accuracy = 0.2489\n",
      "Iteration 57: Loss = 4.5203, Accuracy = 0.2700 Test Loss = 4.7771, Test Accuracy = 0.2508\n",
      "Iteration 58: Loss = 4.9990, Accuracy = 0.2200 Test Loss = 4.6968, Test Accuracy = 0.2555\n",
      "Iteration 59: Loss = 3.8237, Accuracy = 0.2500 Test Loss = 4.6170, Test Accuracy = 0.2529\n",
      "Iteration 60: Loss = 4.3971, Accuracy = 0.2200 Test Loss = 4.5522, Test Accuracy = 0.2559\n",
      "Iteration 61: Loss = 4.4881, Accuracy = 0.2200 Test Loss = 4.4755, Test Accuracy = 0.2592\n",
      "Iteration 62: Loss = 4.5290, Accuracy = 0.2000 Test Loss = 4.4191, Test Accuracy = 0.2594\n",
      "Iteration 63: Loss = 4.1478, Accuracy = 0.2700 Test Loss = 4.3475, Test Accuracy = 0.2631\n",
      "Iteration 64: Loss = 3.9433, Accuracy = 0.1900 Test Loss = 4.2837, Test Accuracy = 0.2637\n",
      "Iteration 65: Loss = 4.2253, Accuracy = 0.1600 Test Loss = 4.2172, Test Accuracy = 0.2705\n",
      "Iteration 66: Loss = 3.9607, Accuracy = 0.2700 Test Loss = 4.1576, Test Accuracy = 0.2685\n",
      "Iteration 67: Loss = 3.6216, Accuracy = 0.2400 Test Loss = 4.0965, Test Accuracy = 0.2658\n",
      "Iteration 68: Loss = 3.6611, Accuracy = 0.3100 Test Loss = 4.0331, Test Accuracy = 0.2711\n",
      "Iteration 69: Loss = 3.8516, Accuracy = 0.2500 Test Loss = 3.9786, Test Accuracy = 0.2740\n",
      "Iteration 70: Loss = 3.4726, Accuracy = 0.2600 Test Loss = 3.9331, Test Accuracy = 0.2738\n",
      "Iteration 71: Loss = 3.8679, Accuracy = 0.2200 Test Loss = 3.8743, Test Accuracy = 0.2770\n",
      "Iteration 72: Loss = 3.8894, Accuracy = 0.2500 Test Loss = 3.8145, Test Accuracy = 0.2812\n",
      "Iteration 73: Loss = 3.3707, Accuracy = 0.2000 Test Loss = 3.7700, Test Accuracy = 0.2808\n",
      "Iteration 74: Loss = 3.6181, Accuracy = 0.3500 Test Loss = 3.7175, Test Accuracy = 0.2815\n",
      "Iteration 75: Loss = 4.1226, Accuracy = 0.2800 Test Loss = 3.6841, Test Accuracy = 0.2778\n",
      "Iteration 76: Loss = 3.3247, Accuracy = 0.3100 Test Loss = 3.6174, Test Accuracy = 0.2848\n",
      "Iteration 77: Loss = 3.8466, Accuracy = 0.2200 Test Loss = 3.5705, Test Accuracy = 0.2838\n",
      "Iteration 78: Loss = 3.5139, Accuracy = 0.2400 Test Loss = 3.5207, Test Accuracy = 0.2869\n",
      "Iteration 79: Loss = 3.2151, Accuracy = 0.3500 Test Loss = 3.4727, Test Accuracy = 0.2914\n",
      "Iteration 80: Loss = 3.0890, Accuracy = 0.2500 Test Loss = 3.4315, Test Accuracy = 0.2897\n",
      "Iteration 81: Loss = 3.1765, Accuracy = 0.2800 Test Loss = 3.3899, Test Accuracy = 0.2916\n",
      "Iteration 82: Loss = 3.1344, Accuracy = 0.2800 Test Loss = 3.3458, Test Accuracy = 0.2922\n",
      "Iteration 83: Loss = 3.1312, Accuracy = 0.3400 Test Loss = 3.3109, Test Accuracy = 0.2976\n",
      "Iteration 84: Loss = 3.4198, Accuracy = 0.3000 Test Loss = 3.2674, Test Accuracy = 0.3005\n",
      "Iteration 85: Loss = 2.7238, Accuracy = 0.3100 Test Loss = 3.2254, Test Accuracy = 0.3016\n",
      "Iteration 86: Loss = 2.8451, Accuracy = 0.2800 Test Loss = 3.1940, Test Accuracy = 0.3021\n",
      "Iteration 87: Loss = 3.5898, Accuracy = 0.3200 Test Loss = 3.1538, Test Accuracy = 0.3024\n",
      "Iteration 88: Loss = 2.8803, Accuracy = 0.3900 Test Loss = 3.1132, Test Accuracy = 0.3047\n",
      "Iteration 89: Loss = 3.0844, Accuracy = 0.3100 Test Loss = 3.0727, Test Accuracy = 0.3098\n",
      "Iteration 90: Loss = 2.6548, Accuracy = 0.1700 Test Loss = 3.0381, Test Accuracy = 0.3115\n",
      "Iteration 91: Loss = 2.8024, Accuracy = 0.3300 Test Loss = 3.0134, Test Accuracy = 0.3112\n",
      "Iteration 92: Loss = 3.0917, Accuracy = 0.2900 Test Loss = 2.9797, Test Accuracy = 0.3088\n",
      "Iteration 93: Loss = 3.2208, Accuracy = 0.2800 Test Loss = 2.9401, Test Accuracy = 0.3158\n",
      "Iteration 94: Loss = 2.5075, Accuracy = 0.3500 Test Loss = 2.9172, Test Accuracy = 0.3158\n",
      "Iteration 95: Loss = 2.4671, Accuracy = 0.3800 Test Loss = 2.8736, Test Accuracy = 0.3184\n",
      "Iteration 96: Loss = 2.7423, Accuracy = 0.2100 Test Loss = 2.8426, Test Accuracy = 0.3210\n",
      "Iteration 97: Loss = 2.6628, Accuracy = 0.2500 Test Loss = 2.8136, Test Accuracy = 0.3212\n",
      "Iteration 98: Loss = 2.6564, Accuracy = 0.3100 Test Loss = 2.7793, Test Accuracy = 0.3236\n",
      "Iteration 99: Loss = 2.5307, Accuracy = 0.3500 Test Loss = 2.7528, Test Accuracy = 0.3244\n",
      "Iteration 100: Loss = 2.5893, Accuracy = 0.3400 Test Loss = 2.7287, Test Accuracy = 0.3254\n",
      "Iteration 101: Loss = 2.7113, Accuracy = 0.3200 Test Loss = 2.6957, Test Accuracy = 0.3296\n",
      "Iteration 102: Loss = 2.4290, Accuracy = 0.3300 Test Loss = 2.6672, Test Accuracy = 0.3313\n",
      "Iteration 103: Loss = 2.5104, Accuracy = 0.4300 Test Loss = 2.6395, Test Accuracy = 0.3340\n",
      "Iteration 104: Loss = 2.2291, Accuracy = 0.3200 Test Loss = 2.6102, Test Accuracy = 0.3316\n",
      "Iteration 105: Loss = 2.6293, Accuracy = 0.3000 Test Loss = 2.5913, Test Accuracy = 0.3374\n",
      "Iteration 106: Loss = 2.4011, Accuracy = 0.3400 Test Loss = 2.5572, Test Accuracy = 0.3392\n",
      "Iteration 107: Loss = 2.2710, Accuracy = 0.3100 Test Loss = 2.5411, Test Accuracy = 0.3366\n",
      "Iteration 108: Loss = 2.3865, Accuracy = 0.3400 Test Loss = 2.5081, Test Accuracy = 0.3407\n",
      "Iteration 109: Loss = 2.6061, Accuracy = 0.3000 Test Loss = 2.4827, Test Accuracy = 0.3435\n",
      "Iteration 110: Loss = 2.0451, Accuracy = 0.4300 Test Loss = 2.4568, Test Accuracy = 0.3495\n",
      "Iteration 111: Loss = 2.3256, Accuracy = 0.2700 Test Loss = 2.4368, Test Accuracy = 0.3492\n",
      "Iteration 112: Loss = 1.9852, Accuracy = 0.3900 Test Loss = 2.4101, Test Accuracy = 0.3495\n",
      "Iteration 113: Loss = 2.3762, Accuracy = 0.3500 Test Loss = 2.3885, Test Accuracy = 0.3486\n",
      "Iteration 114: Loss = 2.0025, Accuracy = 0.3800 Test Loss = 2.3640, Test Accuracy = 0.3519\n",
      "Iteration 115: Loss = 2.2692, Accuracy = 0.3400 Test Loss = 2.3475, Test Accuracy = 0.3522\n",
      "Iteration 116: Loss = 2.7530, Accuracy = 0.2800 Test Loss = 2.3255, Test Accuracy = 0.3590\n",
      "Iteration 117: Loss = 2.6085, Accuracy = 0.3000 Test Loss = 2.2987, Test Accuracy = 0.3580\n",
      "Iteration 118: Loss = 1.9378, Accuracy = 0.3400 Test Loss = 2.2768, Test Accuracy = 0.3636\n",
      "Iteration 119: Loss = 2.6295, Accuracy = 0.3600 Test Loss = 2.2564, Test Accuracy = 0.3597\n",
      "Iteration 120: Loss = 2.1791, Accuracy = 0.3500 Test Loss = 2.2397, Test Accuracy = 0.3663\n",
      "Iteration 121: Loss = 2.0744, Accuracy = 0.3400 Test Loss = 2.2169, Test Accuracy = 0.3677\n",
      "Iteration 122: Loss = 2.0283, Accuracy = 0.3200 Test Loss = 2.1974, Test Accuracy = 0.3657\n",
      "Iteration 123: Loss = 1.9101, Accuracy = 0.3300 Test Loss = 2.1787, Test Accuracy = 0.3700\n",
      "Iteration 124: Loss = 1.8352, Accuracy = 0.4200 Test Loss = 2.1580, Test Accuracy = 0.3704\n",
      "Iteration 125: Loss = 2.0700, Accuracy = 0.3500 Test Loss = 2.1410, Test Accuracy = 0.3728\n",
      "Iteration 126: Loss = 1.8054, Accuracy = 0.3500 Test Loss = 2.1186, Test Accuracy = 0.3743\n",
      "Iteration 127: Loss = 1.9181, Accuracy = 0.3600 Test Loss = 2.1000, Test Accuracy = 0.3724\n",
      "Iteration 128: Loss = 1.7592, Accuracy = 0.4300 Test Loss = 2.0826, Test Accuracy = 0.3778\n",
      "Iteration 129: Loss = 1.8140, Accuracy = 0.4900 Test Loss = 2.0643, Test Accuracy = 0.3766\n",
      "Iteration 130: Loss = 2.1631, Accuracy = 0.3600 Test Loss = 2.0473, Test Accuracy = 0.3792\n",
      "Iteration 131: Loss = 1.6000, Accuracy = 0.4400 Test Loss = 2.0324, Test Accuracy = 0.3817\n",
      "Iteration 132: Loss = 2.0338, Accuracy = 0.4500 Test Loss = 2.0145, Test Accuracy = 0.3821\n",
      "Iteration 133: Loss = 1.8355, Accuracy = 0.4200 Test Loss = 1.9982, Test Accuracy = 0.3840\n",
      "Iteration 134: Loss = 1.7145, Accuracy = 0.3300 Test Loss = 1.9808, Test Accuracy = 0.3846\n",
      "Iteration 135: Loss = 1.9579, Accuracy = 0.3900 Test Loss = 1.9653, Test Accuracy = 0.3862\n",
      "Iteration 136: Loss = 1.8269, Accuracy = 0.4300 Test Loss = 1.9515, Test Accuracy = 0.3887\n",
      "Iteration 137: Loss = 1.7709, Accuracy = 0.4000 Test Loss = 1.9370, Test Accuracy = 0.3892\n",
      "Iteration 138: Loss = 1.6044, Accuracy = 0.4100 Test Loss = 1.9212, Test Accuracy = 0.3904\n",
      "Iteration 139: Loss = 1.6235, Accuracy = 0.3200 Test Loss = 1.9033, Test Accuracy = 0.3872\n",
      "Iteration 140: Loss = 1.7587, Accuracy = 0.4400 Test Loss = 1.8897, Test Accuracy = 0.3978\n",
      "Iteration 141: Loss = 1.8702, Accuracy = 0.3200 Test Loss = 1.8709, Test Accuracy = 0.3967\n",
      "Iteration 142: Loss = 1.7821, Accuracy = 0.3500 Test Loss = 1.8640, Test Accuracy = 0.3990\n",
      "Iteration 143: Loss = 1.7566, Accuracy = 0.4700 Test Loss = 1.8447, Test Accuracy = 0.3986\n",
      "Iteration 144: Loss = 1.9857, Accuracy = 0.3300 Test Loss = 1.8288, Test Accuracy = 0.4021\n",
      "Iteration 145: Loss = 1.7635, Accuracy = 0.3800 Test Loss = 1.8151, Test Accuracy = 0.4031\n",
      "Iteration 146: Loss = 1.8786, Accuracy = 0.4000 Test Loss = 1.8039, Test Accuracy = 0.4013\n",
      "Iteration 147: Loss = 1.6359, Accuracy = 0.4200 Test Loss = 1.7875, Test Accuracy = 0.4072\n",
      "Iteration 148: Loss = 1.5200, Accuracy = 0.4700 Test Loss = 1.7736, Test Accuracy = 0.4060\n",
      "Iteration 149: Loss = 1.5210, Accuracy = 0.4300 Test Loss = 1.7612, Test Accuracy = 0.4071\n",
      "Iteration 150: Loss = 1.6089, Accuracy = 0.3700 Test Loss = 1.7485, Test Accuracy = 0.4129\n",
      "Iteration 151: Loss = 1.4338, Accuracy = 0.4100 Test Loss = 1.7350, Test Accuracy = 0.4122\n",
      "Iteration 152: Loss = 1.7351, Accuracy = 0.4600 Test Loss = 1.7258, Test Accuracy = 0.4110\n",
      "Iteration 153: Loss = 1.5364, Accuracy = 0.4800 Test Loss = 1.7148, Test Accuracy = 0.4162\n",
      "Iteration 154: Loss = 1.6196, Accuracy = 0.3300 Test Loss = 1.6981, Test Accuracy = 0.4182\n",
      "Iteration 155: Loss = 1.7060, Accuracy = 0.4100 Test Loss = 1.6876, Test Accuracy = 0.4168\n",
      "Iteration 156: Loss = 1.4872, Accuracy = 0.4200 Test Loss = 1.6758, Test Accuracy = 0.4196\n",
      "Iteration 157: Loss = 1.3824, Accuracy = 0.4400 Test Loss = 1.6604, Test Accuracy = 0.4169\n",
      "Iteration 158: Loss = 1.7973, Accuracy = 0.4600 Test Loss = 1.6518, Test Accuracy = 0.4235\n",
      "Iteration 159: Loss = 1.5605, Accuracy = 0.3700 Test Loss = 1.6426, Test Accuracy = 0.4189\n",
      "Iteration 160: Loss = 1.4792, Accuracy = 0.5200 Test Loss = 1.6249, Test Accuracy = 0.4265\n",
      "Iteration 161: Loss = 1.5204, Accuracy = 0.4000 Test Loss = 1.6152, Test Accuracy = 0.4247\n",
      "Iteration 162: Loss = 1.5194, Accuracy = 0.4900 Test Loss = 1.6056, Test Accuracy = 0.4311\n",
      "Iteration 163: Loss = 1.6843, Accuracy = 0.4700 Test Loss = 1.5967, Test Accuracy = 0.4288\n",
      "Iteration 164: Loss = 1.7243, Accuracy = 0.3900 Test Loss = 1.5830, Test Accuracy = 0.4290\n",
      "Iteration 165: Loss = 1.3473, Accuracy = 0.3600 Test Loss = 1.5731, Test Accuracy = 0.4315\n",
      "Iteration 166: Loss = 1.5251, Accuracy = 0.4600 Test Loss = 1.5616, Test Accuracy = 0.4362\n",
      "Iteration 167: Loss = 1.7625, Accuracy = 0.4200 Test Loss = 1.5520, Test Accuracy = 0.4337\n",
      "Iteration 168: Loss = 1.2394, Accuracy = 0.4600 Test Loss = 1.5398, Test Accuracy = 0.4372\n",
      "Iteration 169: Loss = 1.4818, Accuracy = 0.3700 Test Loss = 1.5301, Test Accuracy = 0.4382\n",
      "Iteration 170: Loss = 1.1490, Accuracy = 0.5100 Test Loss = 1.5262, Test Accuracy = 0.4393\n",
      "Iteration 171: Loss = 1.3805, Accuracy = 0.3800 Test Loss = 1.5137, Test Accuracy = 0.4403\n",
      "Iteration 172: Loss = 1.8381, Accuracy = 0.3600 Test Loss = 1.5042, Test Accuracy = 0.4452\n",
      "Iteration 173: Loss = 1.3759, Accuracy = 0.4100 Test Loss = 1.4914, Test Accuracy = 0.4445\n",
      "Iteration 174: Loss = 1.2933, Accuracy = 0.4300 Test Loss = 1.4837, Test Accuracy = 0.4417\n",
      "Iteration 175: Loss = 1.5553, Accuracy = 0.4100 Test Loss = 1.4714, Test Accuracy = 0.4475\n",
      "Iteration 176: Loss = 1.3282, Accuracy = 0.4100 Test Loss = 1.4635, Test Accuracy = 0.4506\n",
      "Iteration 177: Loss = 1.5105, Accuracy = 0.5500 Test Loss = 1.4536, Test Accuracy = 0.4519\n",
      "Iteration 178: Loss = 1.4408, Accuracy = 0.4300 Test Loss = 1.4448, Test Accuracy = 0.4542\n",
      "Iteration 179: Loss = 1.2427, Accuracy = 0.5000 Test Loss = 1.4374, Test Accuracy = 0.4536\n",
      "Iteration 180: Loss = 1.2443, Accuracy = 0.5100 Test Loss = 1.4302, Test Accuracy = 0.4562\n",
      "Iteration 181: Loss = 1.4934, Accuracy = 0.4700 Test Loss = 1.4210, Test Accuracy = 0.4605\n",
      "Iteration 182: Loss = 1.8226, Accuracy = 0.4400 Test Loss = 1.4099, Test Accuracy = 0.4585\n",
      "Iteration 183: Loss = 1.4551, Accuracy = 0.4400 Test Loss = 1.4048, Test Accuracy = 0.4590\n",
      "Iteration 184: Loss = 1.2163, Accuracy = 0.5100 Test Loss = 1.3930, Test Accuracy = 0.4627\n",
      "Iteration 185: Loss = 1.2070, Accuracy = 0.3700 Test Loss = 1.3843, Test Accuracy = 0.4614\n",
      "Iteration 186: Loss = 1.2651, Accuracy = 0.5200 Test Loss = 1.3754, Test Accuracy = 0.4625\n",
      "Iteration 187: Loss = 1.4061, Accuracy = 0.4000 Test Loss = 1.3706, Test Accuracy = 0.4674\n",
      "Iteration 188: Loss = 1.3638, Accuracy = 0.4800 Test Loss = 1.3611, Test Accuracy = 0.4689\n",
      "Iteration 189: Loss = 1.1502, Accuracy = 0.4600 Test Loss = 1.3521, Test Accuracy = 0.4705\n",
      "Iteration 190: Loss = 1.3174, Accuracy = 0.4500 Test Loss = 1.3463, Test Accuracy = 0.4724\n",
      "Iteration 191: Loss = 1.2031, Accuracy = 0.5300 Test Loss = 1.3382, Test Accuracy = 0.4704\n",
      "Iteration 192: Loss = 1.2722, Accuracy = 0.5000 Test Loss = 1.3297, Test Accuracy = 0.4719\n",
      "Iteration 193: Loss = 1.2836, Accuracy = 0.4100 Test Loss = 1.3224, Test Accuracy = 0.4736\n",
      "Iteration 194: Loss = 1.2667, Accuracy = 0.5100 Test Loss = 1.3128, Test Accuracy = 0.4754\n",
      "Iteration 195: Loss = 1.1695, Accuracy = 0.4600 Test Loss = 1.3077, Test Accuracy = 0.4782\n",
      "Iteration 196: Loss = 1.1171, Accuracy = 0.5200 Test Loss = 1.2997, Test Accuracy = 0.4841\n",
      "Iteration 197: Loss = 1.1400, Accuracy = 0.4900 Test Loss = 1.2927, Test Accuracy = 0.4779\n",
      "Iteration 198: Loss = 1.2194, Accuracy = 0.5100 Test Loss = 1.2821, Test Accuracy = 0.4826\n",
      "Iteration 199: Loss = 1.1412, Accuracy = 0.4800 Test Loss = 1.2808, Test Accuracy = 0.4816\n",
      "Iteration 200: Loss = 1.1467, Accuracy = 0.4500 Test Loss = 1.2701, Test Accuracy = 0.4847\n",
      "Iteration 201: Loss = 1.2595, Accuracy = 0.4400 Test Loss = 1.2641, Test Accuracy = 0.4843\n",
      "Iteration 202: Loss = 1.1710, Accuracy = 0.4000 Test Loss = 1.2582, Test Accuracy = 0.4865\n",
      "Iteration 203: Loss = 1.1085, Accuracy = 0.4400 Test Loss = 1.2498, Test Accuracy = 0.4912\n",
      "Iteration 204: Loss = 1.1691, Accuracy = 0.4100 Test Loss = 1.2426, Test Accuracy = 0.4872\n",
      "Iteration 205: Loss = 1.2694, Accuracy = 0.4700 Test Loss = 1.2367, Test Accuracy = 0.4920\n",
      "Iteration 206: Loss = 1.0538, Accuracy = 0.5200 Test Loss = 1.2278, Test Accuracy = 0.4938\n",
      "Iteration 207: Loss = 1.1865, Accuracy = 0.5000 Test Loss = 1.2242, Test Accuracy = 0.4941\n",
      "Iteration 208: Loss = 1.1453, Accuracy = 0.5100 Test Loss = 1.2195, Test Accuracy = 0.4931\n",
      "Iteration 209: Loss = 1.1838, Accuracy = 0.5600 Test Loss = 1.2125, Test Accuracy = 0.4898\n",
      "Iteration 210: Loss = 1.1187, Accuracy = 0.5500 Test Loss = 1.2042, Test Accuracy = 0.5013\n",
      "Iteration 211: Loss = 0.8543, Accuracy = 0.6000 Test Loss = 1.1984, Test Accuracy = 0.5003\n",
      "Iteration 212: Loss = 1.0727, Accuracy = 0.5400 Test Loss = 1.1906, Test Accuracy = 0.5005\n",
      "Iteration 213: Loss = 1.1154, Accuracy = 0.4500 Test Loss = 1.1875, Test Accuracy = 0.5030\n",
      "Iteration 214: Loss = 1.0524, Accuracy = 0.5400 Test Loss = 1.1766, Test Accuracy = 0.5044\n",
      "Iteration 215: Loss = 1.1749, Accuracy = 0.5700 Test Loss = 1.1754, Test Accuracy = 0.5047\n",
      "Iteration 216: Loss = 1.1137, Accuracy = 0.5400 Test Loss = 1.1685, Test Accuracy = 0.5086\n",
      "Iteration 217: Loss = 1.0379, Accuracy = 0.4700 Test Loss = 1.1624, Test Accuracy = 0.5036\n",
      "Iteration 218: Loss = 0.8962, Accuracy = 0.5900 Test Loss = 1.1559, Test Accuracy = 0.5080\n",
      "Iteration 219: Loss = 1.1612, Accuracy = 0.4600 Test Loss = 1.1495, Test Accuracy = 0.5079\n",
      "Iteration 220: Loss = 1.0727, Accuracy = 0.5300 Test Loss = 1.1448, Test Accuracy = 0.5149\n",
      "Iteration 221: Loss = 1.0110, Accuracy = 0.5400 Test Loss = 1.1392, Test Accuracy = 0.5116\n",
      "Iteration 222: Loss = 0.9618, Accuracy = 0.5500 Test Loss = 1.1344, Test Accuracy = 0.5156\n",
      "Iteration 223: Loss = 1.0767, Accuracy = 0.5400 Test Loss = 1.1279, Test Accuracy = 0.5167\n",
      "Iteration 224: Loss = 1.0393, Accuracy = 0.5400 Test Loss = 1.1216, Test Accuracy = 0.5124\n",
      "Iteration 225: Loss = 1.1122, Accuracy = 0.5500 Test Loss = 1.1169, Test Accuracy = 0.5184\n",
      "Iteration 226: Loss = 0.9851, Accuracy = 0.5400 Test Loss = 1.1107, Test Accuracy = 0.5238\n",
      "Iteration 227: Loss = 1.0361, Accuracy = 0.5900 Test Loss = 1.1064, Test Accuracy = 0.5214\n",
      "Iteration 228: Loss = 1.0259, Accuracy = 0.5200 Test Loss = 1.0995, Test Accuracy = 0.5215\n",
      "Iteration 229: Loss = 0.8411, Accuracy = 0.6900 Test Loss = 1.0946, Test Accuracy = 0.5265\n",
      "Iteration 230: Loss = 0.8260, Accuracy = 0.5500 Test Loss = 1.0907, Test Accuracy = 0.5257\n",
      "Iteration 231: Loss = 0.9403, Accuracy = 0.6000 Test Loss = 1.0842, Test Accuracy = 0.5255\n",
      "Iteration 232: Loss = 1.0600, Accuracy = 0.5400 Test Loss = 1.0804, Test Accuracy = 0.5233\n",
      "Iteration 233: Loss = 0.9244, Accuracy = 0.5500 Test Loss = 1.0737, Test Accuracy = 0.5309\n",
      "Iteration 234: Loss = 1.0072, Accuracy = 0.5800 Test Loss = 1.0705, Test Accuracy = 0.5330\n",
      "Iteration 235: Loss = 1.1084, Accuracy = 0.6100 Test Loss = 1.0663, Test Accuracy = 0.5298\n",
      "Iteration 236: Loss = 0.9244, Accuracy = 0.5500 Test Loss = 1.0632, Test Accuracy = 0.5295\n",
      "Iteration 237: Loss = 0.9548, Accuracy = 0.4800 Test Loss = 1.0550, Test Accuracy = 0.5330\n",
      "Iteration 238: Loss = 0.9800, Accuracy = 0.5700 Test Loss = 1.0519, Test Accuracy = 0.5312\n",
      "Iteration 239: Loss = 1.0027, Accuracy = 0.5200 Test Loss = 1.0464, Test Accuracy = 0.5303\n",
      "Iteration 240: Loss = 0.8813, Accuracy = 0.5100 Test Loss = 1.0449, Test Accuracy = 0.5317\n",
      "Iteration 241: Loss = 1.0097, Accuracy = 0.4800 Test Loss = 1.0372, Test Accuracy = 0.5357\n",
      "Iteration 242: Loss = 0.9845, Accuracy = 0.4600 Test Loss = 1.0349, Test Accuracy = 0.5399\n",
      "Iteration 243: Loss = 0.9998, Accuracy = 0.5600 Test Loss = 1.0288, Test Accuracy = 0.5370\n",
      "Iteration 244: Loss = 0.9302, Accuracy = 0.5400 Test Loss = 1.0237, Test Accuracy = 0.5382\n",
      "Iteration 245: Loss = 1.1193, Accuracy = 0.4800 Test Loss = 1.0220, Test Accuracy = 0.5437\n",
      "Iteration 246: Loss = 0.9647, Accuracy = 0.5900 Test Loss = 1.0141, Test Accuracy = 0.5413\n",
      "Iteration 247: Loss = 0.9519, Accuracy = 0.6200 Test Loss = 1.0118, Test Accuracy = 0.5412\n",
      "Iteration 248: Loss = 1.0474, Accuracy = 0.5600 Test Loss = 1.0052, Test Accuracy = 0.5488\n",
      "Iteration 249: Loss = 0.8194, Accuracy = 0.5600 Test Loss = 1.0010, Test Accuracy = 0.5485\n",
      "Iteration 250: Loss = 0.9337, Accuracy = 0.6100 Test Loss = 1.0000, Test Accuracy = 0.5475\n",
      "Iteration 251: Loss = 0.8551, Accuracy = 0.5500 Test Loss = 0.9925, Test Accuracy = 0.5483\n",
      "Iteration 252: Loss = 0.8590, Accuracy = 0.5800 Test Loss = 0.9882, Test Accuracy = 0.5496\n",
      "Iteration 253: Loss = 0.8059, Accuracy = 0.6000 Test Loss = 0.9841, Test Accuracy = 0.5525\n",
      "Iteration 254: Loss = 0.8450, Accuracy = 0.6200 Test Loss = 0.9798, Test Accuracy = 0.5495\n",
      "Iteration 255: Loss = 0.8659, Accuracy = 0.5700 Test Loss = 0.9770, Test Accuracy = 0.5512\n",
      "Iteration 256: Loss = 0.9017, Accuracy = 0.5600 Test Loss = 0.9720, Test Accuracy = 0.5528\n",
      "Iteration 257: Loss = 0.8431, Accuracy = 0.5200 Test Loss = 0.9713, Test Accuracy = 0.5521\n",
      "Iteration 258: Loss = 0.7374, Accuracy = 0.6100 Test Loss = 0.9642, Test Accuracy = 0.5570\n",
      "Iteration 259: Loss = 0.8576, Accuracy = 0.5300 Test Loss = 0.9610, Test Accuracy = 0.5574\n",
      "Iteration 260: Loss = 1.0240, Accuracy = 0.5600 Test Loss = 0.9571, Test Accuracy = 0.5567\n",
      "Iteration 261: Loss = 0.9098, Accuracy = 0.5800 Test Loss = 0.9525, Test Accuracy = 0.5595\n",
      "Iteration 262: Loss = 1.0199, Accuracy = 0.5500 Test Loss = 0.9481, Test Accuracy = 0.5605\n",
      "Iteration 263: Loss = 0.9275, Accuracy = 0.5300 Test Loss = 0.9490, Test Accuracy = 0.5611\n",
      "Iteration 264: Loss = 1.0239, Accuracy = 0.5700 Test Loss = 0.9402, Test Accuracy = 0.5622\n",
      "Iteration 265: Loss = 0.8147, Accuracy = 0.6500 Test Loss = 0.9377, Test Accuracy = 0.5651\n",
      "Iteration 266: Loss = 0.7654, Accuracy = 0.6000 Test Loss = 0.9340, Test Accuracy = 0.5694\n",
      "Iteration 267: Loss = 0.8544, Accuracy = 0.5800 Test Loss = 0.9306, Test Accuracy = 0.5663\n",
      "Iteration 268: Loss = 0.9765, Accuracy = 0.5300 Test Loss = 0.9270, Test Accuracy = 0.5678\n",
      "Iteration 269: Loss = 0.9951, Accuracy = 0.6100 Test Loss = 0.9249, Test Accuracy = 0.5681\n",
      "Iteration 270: Loss = 0.9698, Accuracy = 0.5500 Test Loss = 0.9185, Test Accuracy = 0.5690\n",
      "Iteration 271: Loss = 0.7893, Accuracy = 0.5400 Test Loss = 0.9159, Test Accuracy = 0.5703\n",
      "Iteration 272: Loss = 1.1001, Accuracy = 0.5900 Test Loss = 0.9164, Test Accuracy = 0.5678\n",
      "Iteration 273: Loss = 0.7860, Accuracy = 0.5800 Test Loss = 0.9090, Test Accuracy = 0.5739\n",
      "Iteration 274: Loss = 0.8447, Accuracy = 0.5600 Test Loss = 0.9073, Test Accuracy = 0.5752\n",
      "Iteration 275: Loss = 1.0064, Accuracy = 0.5700 Test Loss = 0.9035, Test Accuracy = 0.5761\n",
      "Iteration 276: Loss = 0.8158, Accuracy = 0.6400 Test Loss = 0.8999, Test Accuracy = 0.5759\n",
      "Iteration 277: Loss = 0.7493, Accuracy = 0.7200 Test Loss = 0.8962, Test Accuracy = 0.5735\n",
      "Iteration 278: Loss = 0.7795, Accuracy = 0.7000 Test Loss = 0.8917, Test Accuracy = 0.5787\n",
      "Iteration 279: Loss = 0.7553, Accuracy = 0.6600 Test Loss = 0.8884, Test Accuracy = 0.5753\n",
      "Iteration 280: Loss = 0.7582, Accuracy = 0.6700 Test Loss = 0.8856, Test Accuracy = 0.5753\n",
      "Iteration 281: Loss = 0.9134, Accuracy = 0.6200 Test Loss = 0.8824, Test Accuracy = 0.5787\n",
      "Iteration 282: Loss = 0.8161, Accuracy = 0.5900 Test Loss = 0.8799, Test Accuracy = 0.5846\n",
      "Iteration 283: Loss = 0.6925, Accuracy = 0.6200 Test Loss = 0.8760, Test Accuracy = 0.5850\n",
      "Iteration 284: Loss = 0.7074, Accuracy = 0.6400 Test Loss = 0.8732, Test Accuracy = 0.5831\n",
      "Iteration 285: Loss = 0.8429, Accuracy = 0.5700 Test Loss = 0.8705, Test Accuracy = 0.5824\n",
      "Iteration 286: Loss = 0.8656, Accuracy = 0.5500 Test Loss = 0.8656, Test Accuracy = 0.5842\n",
      "Iteration 287: Loss = 0.7875, Accuracy = 0.5500 Test Loss = 0.8640, Test Accuracy = 0.5834\n",
      "Iteration 288: Loss = 0.7340, Accuracy = 0.6300 Test Loss = 0.8645, Test Accuracy = 0.5864\n",
      "Iteration 289: Loss = 0.8830, Accuracy = 0.5000 Test Loss = 0.8584, Test Accuracy = 0.5870\n",
      "Iteration 290: Loss = 0.6401, Accuracy = 0.6700 Test Loss = 0.8539, Test Accuracy = 0.5889\n",
      "Iteration 291: Loss = 0.8588, Accuracy = 0.5800 Test Loss = 0.8519, Test Accuracy = 0.5877\n",
      "Iteration 292: Loss = 0.7148, Accuracy = 0.6300 Test Loss = 0.8481, Test Accuracy = 0.5907\n",
      "Iteration 293: Loss = 0.6742, Accuracy = 0.6800 Test Loss = 0.8454, Test Accuracy = 0.5916\n",
      "Iteration 294: Loss = 0.7920, Accuracy = 0.7000 Test Loss = 0.8417, Test Accuracy = 0.5938\n",
      "Iteration 295: Loss = 0.7211, Accuracy = 0.6200 Test Loss = 0.8391, Test Accuracy = 0.5924\n",
      "Iteration 296: Loss = 0.8272, Accuracy = 0.6700 Test Loss = 0.8375, Test Accuracy = 0.5939\n",
      "Iteration 297: Loss = 0.6781, Accuracy = 0.6300 Test Loss = 0.8332, Test Accuracy = 0.5956\n",
      "Iteration 298: Loss = 0.6289, Accuracy = 0.6100 Test Loss = 0.8323, Test Accuracy = 0.5967\n",
      "Iteration 299: Loss = 0.8539, Accuracy = 0.6400 Test Loss = 0.8294, Test Accuracy = 0.6005\n",
      "Iteration 300: Loss = 0.7543, Accuracy = 0.6200 Test Loss = 0.8255, Test Accuracy = 0.6016\n",
      "Iteration 301: Loss = 0.8494, Accuracy = 0.5400 Test Loss = 0.8231, Test Accuracy = 0.6002\n",
      "Iteration 302: Loss = 0.7900, Accuracy = 0.6700 Test Loss = 0.8220, Test Accuracy = 0.5974\n",
      "Iteration 303: Loss = 0.8557, Accuracy = 0.5700 Test Loss = 0.8196, Test Accuracy = 0.6016\n",
      "Iteration 304: Loss = 0.7881, Accuracy = 0.5700 Test Loss = 0.8141, Test Accuracy = 0.6039\n",
      "Iteration 305: Loss = 0.7105, Accuracy = 0.6900 Test Loss = 0.8127, Test Accuracy = 0.6078\n",
      "Iteration 306: Loss = 0.7977, Accuracy = 0.5700 Test Loss = 0.8096, Test Accuracy = 0.6032\n",
      "Iteration 307: Loss = 0.6942, Accuracy = 0.6100 Test Loss = 0.8065, Test Accuracy = 0.6058\n",
      "Iteration 308: Loss = 0.8251, Accuracy = 0.6700 Test Loss = 0.8031, Test Accuracy = 0.6058\n",
      "Iteration 309: Loss = 0.7823, Accuracy = 0.6200 Test Loss = 0.8045, Test Accuracy = 0.6010\n",
      "Iteration 310: Loss = 0.7378, Accuracy = 0.6600 Test Loss = 0.7982, Test Accuracy = 0.6062\n",
      "Iteration 311: Loss = 0.7212, Accuracy = 0.6400 Test Loss = 0.7958, Test Accuracy = 0.6089\n",
      "Iteration 312: Loss = 0.7075, Accuracy = 0.6200 Test Loss = 0.7945, Test Accuracy = 0.6085\n",
      "Iteration 313: Loss = 0.5547, Accuracy = 0.6100 Test Loss = 0.7913, Test Accuracy = 0.6080\n",
      "Iteration 314: Loss = 0.6821, Accuracy = 0.6900 Test Loss = 0.7895, Test Accuracy = 0.6124\n",
      "Iteration 315: Loss = 0.6354, Accuracy = 0.6600 Test Loss = 0.7862, Test Accuracy = 0.6116\n",
      "Iteration 316: Loss = 0.7538, Accuracy = 0.5900 Test Loss = 0.7847, Test Accuracy = 0.6139\n",
      "Iteration 317: Loss = 0.7220, Accuracy = 0.5700 Test Loss = 0.7820, Test Accuracy = 0.6100\n",
      "Iteration 318: Loss = 0.6289, Accuracy = 0.6400 Test Loss = 0.7784, Test Accuracy = 0.6133\n",
      "Iteration 319: Loss = 0.6552, Accuracy = 0.6300 Test Loss = 0.7761, Test Accuracy = 0.6160\n",
      "Iteration 320: Loss = 0.6079, Accuracy = 0.6500 Test Loss = 0.7747, Test Accuracy = 0.6160\n",
      "Iteration 321: Loss = 0.7703, Accuracy = 0.6500 Test Loss = 0.7713, Test Accuracy = 0.6171\n",
      "Iteration 322: Loss = 0.8324, Accuracy = 0.6500 Test Loss = 0.7699, Test Accuracy = 0.6167\n",
      "Iteration 323: Loss = 0.6455, Accuracy = 0.6700 Test Loss = 0.7672, Test Accuracy = 0.6183\n",
      "Iteration 324: Loss = 0.6499, Accuracy = 0.6400 Test Loss = 0.7652, Test Accuracy = 0.6204\n",
      "Iteration 325: Loss = 0.6472, Accuracy = 0.6500 Test Loss = 0.7633, Test Accuracy = 0.6208\n",
      "Iteration 326: Loss = 0.8061, Accuracy = 0.5900 Test Loss = 0.7610, Test Accuracy = 0.6229\n",
      "Iteration 327: Loss = 0.8624, Accuracy = 0.6400 Test Loss = 0.7595, Test Accuracy = 0.6211\n",
      "Iteration 328: Loss = 0.7306, Accuracy = 0.6700 Test Loss = 0.7560, Test Accuracy = 0.6186\n",
      "Iteration 329: Loss = 0.7122, Accuracy = 0.5900 Test Loss = 0.7536, Test Accuracy = 0.6207\n",
      "Iteration 330: Loss = 0.7745, Accuracy = 0.5700 Test Loss = 0.7518, Test Accuracy = 0.6226\n",
      "Iteration 331: Loss = 0.7135, Accuracy = 0.6600 Test Loss = 0.7485, Test Accuracy = 0.6291\n",
      "Iteration 332: Loss = 0.6521, Accuracy = 0.7200 Test Loss = 0.7467, Test Accuracy = 0.6257\n",
      "Iteration 333: Loss = 0.6729, Accuracy = 0.6300 Test Loss = 0.7451, Test Accuracy = 0.6279\n",
      "Iteration 334: Loss = 0.8691, Accuracy = 0.5700 Test Loss = 0.7443, Test Accuracy = 0.6238\n",
      "Iteration 335: Loss = 0.6738, Accuracy = 0.6600 Test Loss = 0.7417, Test Accuracy = 0.6249\n",
      "Iteration 336: Loss = 0.6752, Accuracy = 0.6400 Test Loss = 0.7388, Test Accuracy = 0.6310\n",
      "Iteration 337: Loss = 0.5726, Accuracy = 0.6700 Test Loss = 0.7389, Test Accuracy = 0.6262\n",
      "Iteration 338: Loss = 0.6081, Accuracy = 0.6200 Test Loss = 0.7340, Test Accuracy = 0.6302\n",
      "Iteration 339: Loss = 0.5378, Accuracy = 0.7400 Test Loss = 0.7329, Test Accuracy = 0.6279\n",
      "Iteration 340: Loss = 0.5212, Accuracy = 0.7100 Test Loss = 0.7307, Test Accuracy = 0.6337\n",
      "Iteration 341: Loss = 0.6479, Accuracy = 0.6900 Test Loss = 0.7290, Test Accuracy = 0.6346\n",
      "Iteration 342: Loss = 0.7614, Accuracy = 0.6600 Test Loss = 0.7258, Test Accuracy = 0.6357\n",
      "Iteration 343: Loss = 0.5880, Accuracy = 0.7200 Test Loss = 0.7244, Test Accuracy = 0.6363\n",
      "Iteration 344: Loss = 0.6570, Accuracy = 0.6900 Test Loss = 0.7239, Test Accuracy = 0.6347\n",
      "Iteration 345: Loss = 0.9010, Accuracy = 0.6200 Test Loss = 0.7208, Test Accuracy = 0.6349\n",
      "Iteration 346: Loss = 0.5943, Accuracy = 0.7100 Test Loss = 0.7175, Test Accuracy = 0.6370\n",
      "Iteration 347: Loss = 0.8296, Accuracy = 0.7100 Test Loss = 0.7182, Test Accuracy = 0.6370\n",
      "Iteration 348: Loss = 0.5693, Accuracy = 0.6400 Test Loss = 0.7134, Test Accuracy = 0.6364\n",
      "Iteration 349: Loss = 0.5910, Accuracy = 0.6900 Test Loss = 0.7129, Test Accuracy = 0.6375\n",
      "Iteration 350: Loss = 0.6334, Accuracy = 0.7000 Test Loss = 0.7110, Test Accuracy = 0.6390\n",
      "Iteration 351: Loss = 0.5490, Accuracy = 0.7400 Test Loss = 0.7094, Test Accuracy = 0.6404\n",
      "Iteration 352: Loss = 0.7151, Accuracy = 0.6300 Test Loss = 0.7073, Test Accuracy = 0.6439\n",
      "Iteration 353: Loss = 0.6364, Accuracy = 0.5900 Test Loss = 0.7045, Test Accuracy = 0.6453\n",
      "Iteration 354: Loss = 0.5487, Accuracy = 0.6300 Test Loss = 0.7022, Test Accuracy = 0.6398\n",
      "Iteration 355: Loss = 0.5697, Accuracy = 0.7000 Test Loss = 0.7022, Test Accuracy = 0.6447\n",
      "Iteration 356: Loss = 0.6691, Accuracy = 0.6800 Test Loss = 0.6991, Test Accuracy = 0.6449\n",
      "Iteration 357: Loss = 0.6299, Accuracy = 0.6600 Test Loss = 0.6986, Test Accuracy = 0.6425\n",
      "Iteration 358: Loss = 0.6530, Accuracy = 0.7200 Test Loss = 0.6974, Test Accuracy = 0.6422\n",
      "Iteration 359: Loss = 0.5282, Accuracy = 0.7100 Test Loss = 0.6937, Test Accuracy = 0.6453\n",
      "Iteration 360: Loss = 0.6282, Accuracy = 0.6700 Test Loss = 0.6941, Test Accuracy = 0.6447\n",
      "Iteration 361: Loss = 0.5026, Accuracy = 0.7400 Test Loss = 0.6891, Test Accuracy = 0.6514\n",
      "Iteration 362: Loss = 0.6404, Accuracy = 0.7100 Test Loss = 0.6901, Test Accuracy = 0.6489\n",
      "Iteration 363: Loss = 0.7016, Accuracy = 0.6900 Test Loss = 0.6864, Test Accuracy = 0.6486\n",
      "Iteration 364: Loss = 0.5941, Accuracy = 0.7400 Test Loss = 0.6853, Test Accuracy = 0.6534\n",
      "Iteration 365: Loss = 0.7628, Accuracy = 0.6900 Test Loss = 0.6834, Test Accuracy = 0.6526\n",
      "Iteration 366: Loss = 0.6509, Accuracy = 0.7300 Test Loss = 0.6814, Test Accuracy = 0.6511\n",
      "Iteration 367: Loss = 0.5774, Accuracy = 0.6900 Test Loss = 0.6795, Test Accuracy = 0.6511\n",
      "Iteration 368: Loss = 0.6001, Accuracy = 0.6300 Test Loss = 0.6770, Test Accuracy = 0.6545\n",
      "Iteration 369: Loss = 0.8303, Accuracy = 0.6500 Test Loss = 0.6786, Test Accuracy = 0.6559\n",
      "Iteration 370: Loss = 0.5518, Accuracy = 0.7000 Test Loss = 0.6739, Test Accuracy = 0.6553\n",
      "Iteration 371: Loss = 0.7016, Accuracy = 0.5900 Test Loss = 0.6724, Test Accuracy = 0.6576\n",
      "Iteration 372: Loss = 0.6551, Accuracy = 0.6400 Test Loss = 0.6703, Test Accuracy = 0.6539\n",
      "Iteration 373: Loss = 0.5292, Accuracy = 0.6900 Test Loss = 0.6696, Test Accuracy = 0.6539\n",
      "Iteration 374: Loss = 0.4635, Accuracy = 0.7300 Test Loss = 0.6673, Test Accuracy = 0.6560\n",
      "Iteration 375: Loss = 0.8097, Accuracy = 0.6500 Test Loss = 0.6664, Test Accuracy = 0.6574\n",
      "Iteration 376: Loss = 0.6548, Accuracy = 0.6300 Test Loss = 0.6653, Test Accuracy = 0.6572\n",
      "Iteration 377: Loss = 0.6895, Accuracy = 0.7000 Test Loss = 0.6625, Test Accuracy = 0.6593\n",
      "Iteration 378: Loss = 0.5785, Accuracy = 0.6100 Test Loss = 0.6618, Test Accuracy = 0.6516\n",
      "Iteration 379: Loss = 0.6550, Accuracy = 0.6500 Test Loss = 0.6607, Test Accuracy = 0.6573\n",
      "Iteration 380: Loss = 0.5983, Accuracy = 0.7400 Test Loss = 0.6587, Test Accuracy = 0.6613\n",
      "Iteration 381: Loss = 0.7724, Accuracy = 0.6700 Test Loss = 0.6567, Test Accuracy = 0.6611\n",
      "Iteration 382: Loss = 0.5216, Accuracy = 0.6800 Test Loss = 0.6550, Test Accuracy = 0.6615\n",
      "Iteration 383: Loss = 0.5552, Accuracy = 0.6500 Test Loss = 0.6526, Test Accuracy = 0.6630\n",
      "Iteration 384: Loss = 0.5172, Accuracy = 0.7000 Test Loss = 0.6515, Test Accuracy = 0.6635\n",
      "Iteration 385: Loss = 0.5547, Accuracy = 0.7200 Test Loss = 0.6515, Test Accuracy = 0.6634\n",
      "Iteration 386: Loss = 0.6026, Accuracy = 0.5800 Test Loss = 0.6480, Test Accuracy = 0.6648\n",
      "Iteration 387: Loss = 0.5535, Accuracy = 0.6900 Test Loss = 0.6469, Test Accuracy = 0.6666\n",
      "Iteration 388: Loss = 0.5425, Accuracy = 0.6600 Test Loss = 0.6457, Test Accuracy = 0.6659\n",
      "Iteration 389: Loss = 0.5924, Accuracy = 0.7400 Test Loss = 0.6439, Test Accuracy = 0.6673\n",
      "Iteration 390: Loss = 0.5469, Accuracy = 0.7400 Test Loss = 0.6434, Test Accuracy = 0.6684\n",
      "Iteration 391: Loss = 0.4840, Accuracy = 0.7000 Test Loss = 0.6407, Test Accuracy = 0.6665\n",
      "Iteration 392: Loss = 0.6245, Accuracy = 0.6500 Test Loss = 0.6408, Test Accuracy = 0.6681\n",
      "Iteration 393: Loss = 0.6247, Accuracy = 0.7300 Test Loss = 0.6379, Test Accuracy = 0.6695\n",
      "Iteration 394: Loss = 0.5904, Accuracy = 0.7000 Test Loss = 0.6380, Test Accuracy = 0.6707\n",
      "Iteration 395: Loss = 0.6026, Accuracy = 0.5700 Test Loss = 0.6351, Test Accuracy = 0.6685\n",
      "Iteration 396: Loss = 0.5527, Accuracy = 0.6700 Test Loss = 0.6357, Test Accuracy = 0.6612\n",
      "Iteration 397: Loss = 0.4480, Accuracy = 0.6200 Test Loss = 0.6335, Test Accuracy = 0.6718\n",
      "Iteration 398: Loss = 0.6784, Accuracy = 0.6700 Test Loss = 0.6318, Test Accuracy = 0.6720\n",
      "Iteration 399: Loss = 0.7075, Accuracy = 0.7000 Test Loss = 0.6292, Test Accuracy = 0.6728\n",
      "Iteration 400: Loss = 0.5706, Accuracy = 0.7100 Test Loss = 0.6288, Test Accuracy = 0.6723\n",
      "Iteration 401: Loss = 0.4407, Accuracy = 0.7300 Test Loss = 0.6269, Test Accuracy = 0.6769\n",
      "Iteration 402: Loss = 0.5777, Accuracy = 0.7200 Test Loss = 0.6266, Test Accuracy = 0.6714\n",
      "Iteration 403: Loss = 0.5883, Accuracy = 0.6700 Test Loss = 0.6239, Test Accuracy = 0.6738\n",
      "Iteration 404: Loss = 0.5670, Accuracy = 0.6700 Test Loss = 0.6225, Test Accuracy = 0.6786\n",
      "Iteration 405: Loss = 0.6072, Accuracy = 0.6300 Test Loss = 0.6209, Test Accuracy = 0.6769\n",
      "Iteration 406: Loss = 0.5464, Accuracy = 0.6800 Test Loss = 0.6216, Test Accuracy = 0.6772\n",
      "Iteration 407: Loss = 0.5634, Accuracy = 0.6700 Test Loss = 0.6183, Test Accuracy = 0.6745\n",
      "Iteration 408: Loss = 0.6011, Accuracy = 0.6800 Test Loss = 0.6167, Test Accuracy = 0.6766\n",
      "Iteration 409: Loss = 0.5669, Accuracy = 0.6900 Test Loss = 0.6169, Test Accuracy = 0.6778\n",
      "Iteration 410: Loss = 0.5836, Accuracy = 0.7000 Test Loss = 0.6157, Test Accuracy = 0.6750\n",
      "Iteration 411: Loss = 0.5250, Accuracy = 0.7200 Test Loss = 0.6130, Test Accuracy = 0.6798\n",
      "Iteration 412: Loss = 0.5432, Accuracy = 0.6100 Test Loss = 0.6126, Test Accuracy = 0.6786\n",
      "Iteration 413: Loss = 0.5539, Accuracy = 0.6900 Test Loss = 0.6120, Test Accuracy = 0.6793\n",
      "Iteration 414: Loss = 0.5490, Accuracy = 0.7000 Test Loss = 0.6106, Test Accuracy = 0.6798\n",
      "Iteration 415: Loss = 0.5398, Accuracy = 0.6400 Test Loss = 0.6098, Test Accuracy = 0.6822\n",
      "Iteration 416: Loss = 0.4895, Accuracy = 0.7200 Test Loss = 0.6075, Test Accuracy = 0.6837\n",
      "Iteration 417: Loss = 0.6480, Accuracy = 0.6100 Test Loss = 0.6053, Test Accuracy = 0.6842\n",
      "Iteration 418: Loss = 0.6353, Accuracy = 0.7100 Test Loss = 0.6048, Test Accuracy = 0.6869\n",
      "Iteration 419: Loss = 0.4896, Accuracy = 0.6900 Test Loss = 0.6047, Test Accuracy = 0.6809\n",
      "Iteration 420: Loss = 0.5080, Accuracy = 0.7400 Test Loss = 0.6030, Test Accuracy = 0.6805\n",
      "Iteration 421: Loss = 0.5245, Accuracy = 0.7400 Test Loss = 0.6017, Test Accuracy = 0.6807\n",
      "Iteration 422: Loss = 0.6211, Accuracy = 0.7300 Test Loss = 0.6004, Test Accuracy = 0.6818\n",
      "Iteration 423: Loss = 0.7095, Accuracy = 0.7200 Test Loss = 0.5988, Test Accuracy = 0.6840\n",
      "Iteration 424: Loss = 0.5670, Accuracy = 0.6600 Test Loss = 0.5973, Test Accuracy = 0.6860\n",
      "Iteration 425: Loss = 0.5561, Accuracy = 0.7400 Test Loss = 0.5961, Test Accuracy = 0.6816\n",
      "Iteration 426: Loss = 0.6267, Accuracy = 0.6200 Test Loss = 0.5951, Test Accuracy = 0.6879\n",
      "Iteration 427: Loss = 0.5511, Accuracy = 0.6600 Test Loss = 0.5936, Test Accuracy = 0.6843\n",
      "Iteration 428: Loss = 0.7063, Accuracy = 0.6700 Test Loss = 0.5929, Test Accuracy = 0.6902\n",
      "Iteration 429: Loss = 0.6660, Accuracy = 0.6400 Test Loss = 0.5919, Test Accuracy = 0.6898\n",
      "Iteration 430: Loss = 0.4718, Accuracy = 0.7400 Test Loss = 0.5898, Test Accuracy = 0.6873\n",
      "Iteration 431: Loss = 0.5222, Accuracy = 0.7400 Test Loss = 0.5887, Test Accuracy = 0.6864\n",
      "Iteration 432: Loss = 0.5341, Accuracy = 0.7500 Test Loss = 0.5878, Test Accuracy = 0.6917\n",
      "Iteration 433: Loss = 0.5081, Accuracy = 0.7100 Test Loss = 0.5877, Test Accuracy = 0.6880\n",
      "Iteration 434: Loss = 0.4256, Accuracy = 0.7600 Test Loss = 0.5851, Test Accuracy = 0.6932\n",
      "Iteration 435: Loss = 0.5470, Accuracy = 0.6700 Test Loss = 0.5856, Test Accuracy = 0.6928\n",
      "Iteration 436: Loss = 0.4340, Accuracy = 0.7800 Test Loss = 0.5837, Test Accuracy = 0.6930\n",
      "Iteration 437: Loss = 0.5558, Accuracy = 0.7200 Test Loss = 0.5844, Test Accuracy = 0.6892\n",
      "Iteration 438: Loss = 0.5311, Accuracy = 0.6200 Test Loss = 0.5836, Test Accuracy = 0.6919\n",
      "Iteration 439: Loss = 0.6240, Accuracy = 0.7300 Test Loss = 0.5798, Test Accuracy = 0.6923\n",
      "Iteration 440: Loss = 0.5692, Accuracy = 0.6700 Test Loss = 0.5814, Test Accuracy = 0.6942\n",
      "Iteration 441: Loss = 0.4608, Accuracy = 0.7300 Test Loss = 0.5783, Test Accuracy = 0.6933\n",
      "Iteration 442: Loss = 0.4874, Accuracy = 0.6900 Test Loss = 0.5768, Test Accuracy = 0.6951\n",
      "Iteration 443: Loss = 0.4921, Accuracy = 0.6700 Test Loss = 0.5753, Test Accuracy = 0.7003\n",
      "Iteration 444: Loss = 0.6439, Accuracy = 0.6300 Test Loss = 0.5751, Test Accuracy = 0.6942\n",
      "Iteration 445: Loss = 0.4491, Accuracy = 0.7000 Test Loss = 0.5745, Test Accuracy = 0.6940\n",
      "Iteration 446: Loss = 0.5389, Accuracy = 0.7100 Test Loss = 0.5725, Test Accuracy = 0.6970\n",
      "Iteration 447: Loss = 0.5254, Accuracy = 0.6600 Test Loss = 0.5722, Test Accuracy = 0.6931\n",
      "Iteration 448: Loss = 0.6219, Accuracy = 0.6400 Test Loss = 0.5704, Test Accuracy = 0.7028\n",
      "Iteration 449: Loss = 0.4786, Accuracy = 0.6700 Test Loss = 0.5685, Test Accuracy = 0.6958\n",
      "Iteration 450: Loss = 0.5348, Accuracy = 0.6700 Test Loss = 0.5672, Test Accuracy = 0.6980\n",
      "Iteration 451: Loss = 0.5249, Accuracy = 0.7700 Test Loss = 0.5681, Test Accuracy = 0.6997\n",
      "Iteration 452: Loss = 0.4900, Accuracy = 0.7100 Test Loss = 0.5658, Test Accuracy = 0.6988\n",
      "Iteration 453: Loss = 0.4980, Accuracy = 0.6700 Test Loss = 0.5654, Test Accuracy = 0.6972\n",
      "Iteration 454: Loss = 0.5225, Accuracy = 0.6900 Test Loss = 0.5637, Test Accuracy = 0.7043\n",
      "Iteration 455: Loss = 0.5299, Accuracy = 0.7000 Test Loss = 0.5629, Test Accuracy = 0.7025\n",
      "Iteration 456: Loss = 0.4708, Accuracy = 0.7100 Test Loss = 0.5622, Test Accuracy = 0.7000\n",
      "Iteration 457: Loss = 0.5660, Accuracy = 0.6700 Test Loss = 0.5607, Test Accuracy = 0.7022\n",
      "Iteration 458: Loss = 0.6030, Accuracy = 0.7200 Test Loss = 0.5618, Test Accuracy = 0.7006\n",
      "Iteration 459: Loss = 0.3964, Accuracy = 0.7500 Test Loss = 0.5582, Test Accuracy = 0.7025\n",
      "Iteration 460: Loss = 0.5302, Accuracy = 0.7400 Test Loss = 0.5577, Test Accuracy = 0.7039\n",
      "Iteration 461: Loss = 0.4194, Accuracy = 0.7200 Test Loss = 0.5565, Test Accuracy = 0.7041\n",
      "Iteration 462: Loss = 0.4691, Accuracy = 0.8200 Test Loss = 0.5562, Test Accuracy = 0.7049\n",
      "Iteration 463: Loss = 0.6349, Accuracy = 0.6900 Test Loss = 0.5548, Test Accuracy = 0.7047\n",
      "Iteration 464: Loss = 0.5026, Accuracy = 0.7300 Test Loss = 0.5541, Test Accuracy = 0.7023\n",
      "Iteration 465: Loss = 0.5538, Accuracy = 0.6700 Test Loss = 0.5541, Test Accuracy = 0.7034\n",
      "Iteration 466: Loss = 0.5170, Accuracy = 0.6900 Test Loss = 0.5519, Test Accuracy = 0.7083\n",
      "Iteration 467: Loss = 0.4258, Accuracy = 0.6700 Test Loss = 0.5521, Test Accuracy = 0.7061\n",
      "Iteration 468: Loss = 0.5951, Accuracy = 0.7400 Test Loss = 0.5533, Test Accuracy = 0.7024\n",
      "Iteration 469: Loss = 0.5479, Accuracy = 0.6400 Test Loss = 0.5494, Test Accuracy = 0.7047\n",
      "Iteration 470: Loss = 0.4588, Accuracy = 0.7600 Test Loss = 0.5487, Test Accuracy = 0.7096\n",
      "Iteration 471: Loss = 0.4912, Accuracy = 0.7300 Test Loss = 0.5476, Test Accuracy = 0.7042\n",
      "Iteration 472: Loss = 0.4569, Accuracy = 0.7000 Test Loss = 0.5463, Test Accuracy = 0.7099\n",
      "Iteration 473: Loss = 0.4936, Accuracy = 0.7300 Test Loss = 0.5448, Test Accuracy = 0.7109\n",
      "Iteration 474: Loss = 0.4559, Accuracy = 0.7400 Test Loss = 0.5436, Test Accuracy = 0.7092\n",
      "Iteration 475: Loss = 0.5299, Accuracy = 0.6900 Test Loss = 0.5435, Test Accuracy = 0.7086\n",
      "Iteration 476: Loss = 0.4570, Accuracy = 0.7200 Test Loss = 0.5424, Test Accuracy = 0.7097\n",
      "Iteration 477: Loss = 0.4807, Accuracy = 0.7100 Test Loss = 0.5423, Test Accuracy = 0.7077\n",
      "Iteration 478: Loss = 0.4651, Accuracy = 0.7200 Test Loss = 0.5409, Test Accuracy = 0.7114\n",
      "Iteration 479: Loss = 0.7314, Accuracy = 0.7100 Test Loss = 0.5430, Test Accuracy = 0.7118\n",
      "Iteration 480: Loss = 0.5329, Accuracy = 0.7300 Test Loss = 0.5396, Test Accuracy = 0.7100\n",
      "Iteration 481: Loss = 0.4812, Accuracy = 0.7100 Test Loss = 0.5378, Test Accuracy = 0.7107\n",
      "Iteration 482: Loss = 0.4246, Accuracy = 0.7700 Test Loss = 0.5378, Test Accuracy = 0.7091\n",
      "Iteration 483: Loss = 0.4891, Accuracy = 0.7500 Test Loss = 0.5362, Test Accuracy = 0.7157\n",
      "Iteration 484: Loss = 0.4620, Accuracy = 0.7300 Test Loss = 0.5352, Test Accuracy = 0.7145\n",
      "Iteration 485: Loss = 0.5483, Accuracy = 0.6500 Test Loss = 0.5346, Test Accuracy = 0.7159\n",
      "Iteration 486: Loss = 0.4812, Accuracy = 0.7600 Test Loss = 0.5339, Test Accuracy = 0.7136\n",
      "Iteration 487: Loss = 0.4302, Accuracy = 0.7400 Test Loss = 0.5333, Test Accuracy = 0.7126\n",
      "Iteration 488: Loss = 0.5391, Accuracy = 0.6700 Test Loss = 0.5329, Test Accuracy = 0.7126\n",
      "Iteration 489: Loss = 0.5205, Accuracy = 0.7200 Test Loss = 0.5311, Test Accuracy = 0.7128\n",
      "Iteration 490: Loss = 0.4776, Accuracy = 0.6100 Test Loss = 0.5306, Test Accuracy = 0.7139\n",
      "Iteration 491: Loss = 0.5605, Accuracy = 0.7000 Test Loss = 0.5295, Test Accuracy = 0.7149\n",
      "Iteration 492: Loss = 0.3980, Accuracy = 0.8000 Test Loss = 0.5282, Test Accuracy = 0.7172\n",
      "Iteration 493: Loss = 0.4185, Accuracy = 0.7100 Test Loss = 0.5273, Test Accuracy = 0.7163\n",
      "Iteration 494: Loss = 0.6347, Accuracy = 0.7500 Test Loss = 0.5276, Test Accuracy = 0.7127\n",
      "Iteration 495: Loss = 0.4940, Accuracy = 0.7600 Test Loss = 0.5257, Test Accuracy = 0.7178\n",
      "Iteration 496: Loss = 0.4514, Accuracy = 0.7000 Test Loss = 0.5260, Test Accuracy = 0.7157\n",
      "Iteration 497: Loss = 0.5815, Accuracy = 0.6600 Test Loss = 0.5251, Test Accuracy = 0.7150\n",
      "Iteration 498: Loss = 0.5463, Accuracy = 0.6500 Test Loss = 0.5255, Test Accuracy = 0.7173\n",
      "Iteration 499: Loss = 0.4747, Accuracy = 0.7300 Test Loss = 0.5229, Test Accuracy = 0.7149\n",
      "Iteration 500: Loss = 0.4379, Accuracy = 0.7400 Test Loss = 0.5216, Test Accuracy = 0.7178\n",
      "Iteration 501: Loss = 0.5706, Accuracy = 0.7600 Test Loss = 0.5222, Test Accuracy = 0.7183\n",
      "Iteration 502: Loss = 0.4209, Accuracy = 0.7600 Test Loss = 0.5199, Test Accuracy = 0.7220\n",
      "Iteration 503: Loss = 0.6316, Accuracy = 0.7200 Test Loss = 0.5195, Test Accuracy = 0.7192\n",
      "Iteration 504: Loss = 0.3919, Accuracy = 0.8000 Test Loss = 0.5185, Test Accuracy = 0.7208\n",
      "Iteration 505: Loss = 0.5924, Accuracy = 0.6800 Test Loss = 0.5199, Test Accuracy = 0.7130\n",
      "Iteration 506: Loss = 0.4583, Accuracy = 0.7400 Test Loss = 0.5169, Test Accuracy = 0.7218\n",
      "Iteration 507: Loss = 0.4356, Accuracy = 0.7600 Test Loss = 0.5172, Test Accuracy = 0.7208\n",
      "Iteration 508: Loss = 0.3958, Accuracy = 0.7600 Test Loss = 0.5159, Test Accuracy = 0.7211\n",
      "Iteration 509: Loss = 0.4273, Accuracy = 0.7300 Test Loss = 0.5148, Test Accuracy = 0.7227\n",
      "Iteration 510: Loss = 0.5197, Accuracy = 0.6500 Test Loss = 0.5136, Test Accuracy = 0.7238\n",
      "Iteration 511: Loss = 0.6654, Accuracy = 0.7100 Test Loss = 0.5133, Test Accuracy = 0.7227\n",
      "Iteration 512: Loss = 0.4719, Accuracy = 0.7500 Test Loss = 0.5132, Test Accuracy = 0.7213\n",
      "Iteration 513: Loss = 0.4254, Accuracy = 0.7300 Test Loss = 0.5125, Test Accuracy = 0.7233\n",
      "Iteration 514: Loss = 0.4901, Accuracy = 0.6900 Test Loss = 0.5110, Test Accuracy = 0.7236\n",
      "Iteration 515: Loss = 0.3653, Accuracy = 0.7800 Test Loss = 0.5103, Test Accuracy = 0.7229\n",
      "Iteration 516: Loss = 0.4663, Accuracy = 0.7400 Test Loss = 0.5112, Test Accuracy = 0.7201\n",
      "Iteration 517: Loss = 0.4843, Accuracy = 0.7200 Test Loss = 0.5083, Test Accuracy = 0.7231\n",
      "Iteration 518: Loss = 0.4208, Accuracy = 0.8300 Test Loss = 0.5077, Test Accuracy = 0.7251\n",
      "Iteration 519: Loss = 0.4306, Accuracy = 0.7700 Test Loss = 0.5078, Test Accuracy = 0.7229\n",
      "Iteration 520: Loss = 0.4248, Accuracy = 0.7200 Test Loss = 0.5063, Test Accuracy = 0.7248\n",
      "Iteration 521: Loss = 0.4425, Accuracy = 0.7700 Test Loss = 0.5058, Test Accuracy = 0.7241\n",
      "Iteration 522: Loss = 0.3701, Accuracy = 0.7700 Test Loss = 0.5052, Test Accuracy = 0.7254\n",
      "Iteration 523: Loss = 0.4438, Accuracy = 0.7400 Test Loss = 0.5039, Test Accuracy = 0.7278\n",
      "Iteration 524: Loss = 0.4349, Accuracy = 0.7300 Test Loss = 0.5035, Test Accuracy = 0.7281\n",
      "Iteration 525: Loss = 0.4860, Accuracy = 0.6700 Test Loss = 0.5024, Test Accuracy = 0.7271\n",
      "Iteration 526: Loss = 0.3932, Accuracy = 0.7300 Test Loss = 0.5022, Test Accuracy = 0.7286\n",
      "Iteration 527: Loss = 0.3958, Accuracy = 0.7200 Test Loss = 0.5016, Test Accuracy = 0.7273\n",
      "Iteration 528: Loss = 0.5904, Accuracy = 0.7300 Test Loss = 0.5008, Test Accuracy = 0.7295\n",
      "Iteration 529: Loss = 0.4208, Accuracy = 0.7900 Test Loss = 0.5007, Test Accuracy = 0.7275\n",
      "Iteration 530: Loss = 0.4130, Accuracy = 0.7500 Test Loss = 0.4998, Test Accuracy = 0.7286\n",
      "Iteration 531: Loss = 0.5393, Accuracy = 0.6900 Test Loss = 0.4992, Test Accuracy = 0.7325\n",
      "Iteration 532: Loss = 0.6607, Accuracy = 0.7100 Test Loss = 0.4975, Test Accuracy = 0.7303\n",
      "Iteration 533: Loss = 0.3542, Accuracy = 0.8200 Test Loss = 0.4976, Test Accuracy = 0.7288\n",
      "Iteration 534: Loss = 0.3738, Accuracy = 0.7000 Test Loss = 0.4956, Test Accuracy = 0.7292\n",
      "Iteration 535: Loss = 0.4867, Accuracy = 0.7000 Test Loss = 0.4965, Test Accuracy = 0.7285\n",
      "Iteration 536: Loss = 0.4046, Accuracy = 0.7900 Test Loss = 0.4947, Test Accuracy = 0.7302\n",
      "Iteration 537: Loss = 0.4392, Accuracy = 0.7600 Test Loss = 0.4940, Test Accuracy = 0.7301\n",
      "Iteration 538: Loss = 0.3707, Accuracy = 0.8400 Test Loss = 0.4942, Test Accuracy = 0.7302\n",
      "Iteration 539: Loss = 0.5171, Accuracy = 0.7100 Test Loss = 0.4939, Test Accuracy = 0.7292\n",
      "Iteration 540: Loss = 0.4603, Accuracy = 0.6500 Test Loss = 0.4923, Test Accuracy = 0.7318\n",
      "Iteration 541: Loss = 0.4814, Accuracy = 0.7000 Test Loss = 0.4917, Test Accuracy = 0.7307\n",
      "Iteration 542: Loss = 0.4292, Accuracy = 0.7200 Test Loss = 0.4909, Test Accuracy = 0.7320\n",
      "Iteration 543: Loss = 0.4854, Accuracy = 0.7200 Test Loss = 0.4904, Test Accuracy = 0.7308\n",
      "Iteration 544: Loss = 0.3470, Accuracy = 0.8600 Test Loss = 0.4896, Test Accuracy = 0.7326\n",
      "Iteration 545: Loss = 0.5026, Accuracy = 0.7500 Test Loss = 0.4892, Test Accuracy = 0.7318\n",
      "Iteration 546: Loss = 0.3931, Accuracy = 0.8300 Test Loss = 0.4889, Test Accuracy = 0.7307\n",
      "Iteration 547: Loss = 0.4382, Accuracy = 0.7300 Test Loss = 0.4874, Test Accuracy = 0.7357\n",
      "Iteration 548: Loss = 0.4788, Accuracy = 0.7700 Test Loss = 0.4870, Test Accuracy = 0.7353\n",
      "Iteration 549: Loss = 0.3880, Accuracy = 0.7400 Test Loss = 0.4865, Test Accuracy = 0.7356\n",
      "Iteration 550: Loss = 0.4220, Accuracy = 0.7300 Test Loss = 0.4856, Test Accuracy = 0.7339\n",
      "Iteration 551: Loss = 0.3908, Accuracy = 0.7300 Test Loss = 0.4860, Test Accuracy = 0.7365\n",
      "Iteration 552: Loss = 0.3710, Accuracy = 0.7900 Test Loss = 0.4843, Test Accuracy = 0.7388\n",
      "Iteration 553: Loss = 0.4224, Accuracy = 0.7600 Test Loss = 0.4842, Test Accuracy = 0.7370\n",
      "Iteration 554: Loss = 0.5053, Accuracy = 0.7600 Test Loss = 0.4833, Test Accuracy = 0.7352\n",
      "Iteration 555: Loss = 0.4354, Accuracy = 0.7100 Test Loss = 0.4824, Test Accuracy = 0.7382\n",
      "Iteration 556: Loss = 0.3286, Accuracy = 0.8100 Test Loss = 0.4814, Test Accuracy = 0.7373\n",
      "Iteration 557: Loss = 0.4059, Accuracy = 0.7800 Test Loss = 0.4823, Test Accuracy = 0.7359\n",
      "Iteration 558: Loss = 0.3810, Accuracy = 0.7000 Test Loss = 0.4803, Test Accuracy = 0.7372\n",
      "Iteration 559: Loss = 0.3634, Accuracy = 0.8100 Test Loss = 0.4801, Test Accuracy = 0.7389\n",
      "Iteration 560: Loss = 0.5537, Accuracy = 0.6500 Test Loss = 0.4798, Test Accuracy = 0.7422\n",
      "Iteration 561: Loss = 0.4784, Accuracy = 0.6900 Test Loss = 0.4793, Test Accuracy = 0.7391\n",
      "Iteration 562: Loss = 0.3936, Accuracy = 0.7700 Test Loss = 0.4782, Test Accuracy = 0.7383\n",
      "Iteration 563: Loss = 0.3593, Accuracy = 0.7500 Test Loss = 0.4777, Test Accuracy = 0.7402\n",
      "Iteration 564: Loss = 0.4646, Accuracy = 0.6700 Test Loss = 0.4770, Test Accuracy = 0.7358\n",
      "Iteration 565: Loss = 0.4165, Accuracy = 0.7400 Test Loss = 0.4766, Test Accuracy = 0.7414\n",
      "Iteration 566: Loss = 0.3709, Accuracy = 0.7700 Test Loss = 0.4758, Test Accuracy = 0.7383\n",
      "Iteration 567: Loss = 0.3982, Accuracy = 0.8200 Test Loss = 0.4750, Test Accuracy = 0.7400\n",
      "Iteration 568: Loss = 0.4667, Accuracy = 0.7800 Test Loss = 0.4772, Test Accuracy = 0.7383\n",
      "Iteration 569: Loss = 0.4716, Accuracy = 0.7300 Test Loss = 0.4737, Test Accuracy = 0.7417\n",
      "Iteration 570: Loss = 0.4862, Accuracy = 0.7300 Test Loss = 0.4746, Test Accuracy = 0.7396\n",
      "Iteration 571: Loss = 0.4952, Accuracy = 0.7500 Test Loss = 0.4741, Test Accuracy = 0.7385\n",
      "Iteration 572: Loss = 0.5286, Accuracy = 0.7500 Test Loss = 0.4731, Test Accuracy = 0.7402\n",
      "Iteration 573: Loss = 0.4708, Accuracy = 0.7600 Test Loss = 0.4716, Test Accuracy = 0.7396\n",
      "Iteration 574: Loss = 0.6346, Accuracy = 0.6900 Test Loss = 0.4724, Test Accuracy = 0.7414\n",
      "Iteration 575: Loss = 0.3933, Accuracy = 0.7400 Test Loss = 0.4711, Test Accuracy = 0.7428\n",
      "Iteration 576: Loss = 0.3934, Accuracy = 0.7600 Test Loss = 0.4697, Test Accuracy = 0.7470\n",
      "Iteration 577: Loss = 0.3984, Accuracy = 0.7700 Test Loss = 0.4695, Test Accuracy = 0.7443\n",
      "Iteration 578: Loss = 0.4404, Accuracy = 0.6900 Test Loss = 0.4685, Test Accuracy = 0.7461\n",
      "Iteration 579: Loss = 0.4085, Accuracy = 0.7600 Test Loss = 0.4678, Test Accuracy = 0.7417\n",
      "Iteration 580: Loss = 0.3707, Accuracy = 0.7800 Test Loss = 0.4673, Test Accuracy = 0.7448\n",
      "Iteration 581: Loss = 0.4302, Accuracy = 0.8600 Test Loss = 0.4667, Test Accuracy = 0.7437\n",
      "Iteration 582: Loss = 0.3719, Accuracy = 0.8100 Test Loss = 0.4662, Test Accuracy = 0.7439\n",
      "Iteration 583: Loss = 0.4675, Accuracy = 0.7100 Test Loss = 0.4655, Test Accuracy = 0.7436\n",
      "Iteration 584: Loss = 0.3807, Accuracy = 0.7400 Test Loss = 0.4658, Test Accuracy = 0.7445\n",
      "Iteration 585: Loss = 0.4314, Accuracy = 0.7000 Test Loss = 0.4651, Test Accuracy = 0.7434\n",
      "Iteration 586: Loss = 0.4547, Accuracy = 0.6900 Test Loss = 0.4658, Test Accuracy = 0.7454\n",
      "Iteration 587: Loss = 0.3655, Accuracy = 0.7700 Test Loss = 0.4637, Test Accuracy = 0.7430\n",
      "Iteration 588: Loss = 0.4967, Accuracy = 0.7900 Test Loss = 0.4621, Test Accuracy = 0.7452\n",
      "Iteration 589: Loss = 0.3583, Accuracy = 0.7700 Test Loss = 0.4628, Test Accuracy = 0.7439\n",
      "Iteration 590: Loss = 0.3250, Accuracy = 0.8000 Test Loss = 0.4624, Test Accuracy = 0.7456\n",
      "Iteration 591: Loss = 0.3770, Accuracy = 0.8400 Test Loss = 0.4612, Test Accuracy = 0.7481\n",
      "Iteration 592: Loss = 0.5281, Accuracy = 0.7700 Test Loss = 0.4610, Test Accuracy = 0.7439\n",
      "Iteration 593: Loss = 0.3817, Accuracy = 0.7200 Test Loss = 0.4604, Test Accuracy = 0.7464\n",
      "Iteration 594: Loss = 0.3779, Accuracy = 0.7400 Test Loss = 0.4602, Test Accuracy = 0.7487\n",
      "Iteration 595: Loss = 0.3891, Accuracy = 0.7900 Test Loss = 0.4591, Test Accuracy = 0.7464\n",
      "Iteration 596: Loss = 0.4461, Accuracy = 0.7800 Test Loss = 0.4583, Test Accuracy = 0.7475\n",
      "Iteration 597: Loss = 0.4030, Accuracy = 0.7600 Test Loss = 0.4589, Test Accuracy = 0.7442\n",
      "Iteration 598: Loss = 0.3700, Accuracy = 0.8100 Test Loss = 0.4574, Test Accuracy = 0.7471\n",
      "Iteration 599: Loss = 0.3786, Accuracy = 0.7600 Test Loss = 0.4574, Test Accuracy = 0.7475\n",
      "Iteration 600: Loss = 0.3531, Accuracy = 0.7700 Test Loss = 0.4566, Test Accuracy = 0.7486\n",
      "Iteration 601: Loss = 0.3767, Accuracy = 0.7500 Test Loss = 0.4562, Test Accuracy = 0.7474\n",
      "Iteration 602: Loss = 0.3619, Accuracy = 0.7800 Test Loss = 0.4560, Test Accuracy = 0.7492\n",
      "Iteration 603: Loss = 0.4454, Accuracy = 0.7200 Test Loss = 0.4564, Test Accuracy = 0.7489\n",
      "Iteration 604: Loss = 0.3834, Accuracy = 0.7300 Test Loss = 0.4555, Test Accuracy = 0.7502\n",
      "Iteration 605: Loss = 0.4488, Accuracy = 0.7800 Test Loss = 0.4536, Test Accuracy = 0.7516\n",
      "Iteration 606: Loss = 0.3814, Accuracy = 0.7800 Test Loss = 0.4534, Test Accuracy = 0.7513\n",
      "Iteration 607: Loss = 0.3066, Accuracy = 0.8400 Test Loss = 0.4529, Test Accuracy = 0.7481\n",
      "Iteration 608: Loss = 0.3586, Accuracy = 0.8000 Test Loss = 0.4528, Test Accuracy = 0.7491\n",
      "Iteration 609: Loss = 0.3897, Accuracy = 0.7800 Test Loss = 0.4527, Test Accuracy = 0.7489\n",
      "Iteration 610: Loss = 0.3689, Accuracy = 0.7600 Test Loss = 0.4512, Test Accuracy = 0.7515\n",
      "Iteration 611: Loss = 0.4132, Accuracy = 0.7900 Test Loss = 0.4511, Test Accuracy = 0.7509\n",
      "Iteration 612: Loss = 0.3971, Accuracy = 0.7600 Test Loss = 0.4519, Test Accuracy = 0.7492\n",
      "Iteration 613: Loss = 0.3812, Accuracy = 0.7500 Test Loss = 0.4506, Test Accuracy = 0.7535\n",
      "Iteration 614: Loss = 0.3296, Accuracy = 0.7900 Test Loss = 0.4489, Test Accuracy = 0.7523\n",
      "Iteration 615: Loss = 0.3254, Accuracy = 0.7700 Test Loss = 0.4489, Test Accuracy = 0.7505\n",
      "Iteration 616: Loss = 0.4238, Accuracy = 0.8000 Test Loss = 0.4486, Test Accuracy = 0.7518\n",
      "Iteration 617: Loss = 0.3602, Accuracy = 0.7700 Test Loss = 0.4507, Test Accuracy = 0.7496\n",
      "Iteration 618: Loss = 0.4203, Accuracy = 0.8300 Test Loss = 0.4485, Test Accuracy = 0.7489\n",
      "Iteration 619: Loss = 0.3737, Accuracy = 0.8300 Test Loss = 0.4477, Test Accuracy = 0.7507\n",
      "Iteration 620: Loss = 0.3651, Accuracy = 0.8600 Test Loss = 0.4473, Test Accuracy = 0.7519\n",
      "Iteration 621: Loss = 0.3696, Accuracy = 0.7600 Test Loss = 0.4473, Test Accuracy = 0.7497\n",
      "Iteration 622: Loss = 0.4054, Accuracy = 0.7500 Test Loss = 0.4461, Test Accuracy = 0.7496\n",
      "Iteration 623: Loss = 0.5115, Accuracy = 0.7500 Test Loss = 0.4447, Test Accuracy = 0.7532\n",
      "Iteration 624: Loss = 0.4042, Accuracy = 0.7600 Test Loss = 0.4445, Test Accuracy = 0.7559\n",
      "Iteration 625: Loss = 0.4330, Accuracy = 0.8000 Test Loss = 0.4443, Test Accuracy = 0.7516\n",
      "Iteration 626: Loss = 0.3936, Accuracy = 0.6800 Test Loss = 0.4435, Test Accuracy = 0.7548\n",
      "Iteration 627: Loss = 0.4010, Accuracy = 0.7200 Test Loss = 0.4446, Test Accuracy = 0.7548\n",
      "Iteration 628: Loss = 0.3928, Accuracy = 0.7900 Test Loss = 0.4423, Test Accuracy = 0.7542\n",
      "Iteration 629: Loss = 0.3681, Accuracy = 0.8000 Test Loss = 0.4421, Test Accuracy = 0.7528\n",
      "Iteration 630: Loss = 0.4208, Accuracy = 0.7100 Test Loss = 0.4412, Test Accuracy = 0.7537\n",
      "Iteration 631: Loss = 0.4020, Accuracy = 0.7600 Test Loss = 0.4413, Test Accuracy = 0.7536\n",
      "Iteration 632: Loss = 0.4655, Accuracy = 0.7300 Test Loss = 0.4416, Test Accuracy = 0.7505\n",
      "Iteration 633: Loss = 0.4309, Accuracy = 0.7700 Test Loss = 0.4400, Test Accuracy = 0.7548\n",
      "Iteration 634: Loss = 0.3775, Accuracy = 0.7800 Test Loss = 0.4411, Test Accuracy = 0.7529\n",
      "Iteration 635: Loss = 0.4530, Accuracy = 0.7500 Test Loss = 0.4403, Test Accuracy = 0.7533\n",
      "Iteration 636: Loss = 0.3267, Accuracy = 0.7800 Test Loss = 0.4389, Test Accuracy = 0.7536\n",
      "Iteration 637: Loss = 0.3477, Accuracy = 0.7000 Test Loss = 0.4385, Test Accuracy = 0.7566\n",
      "Iteration 638: Loss = 0.4182, Accuracy = 0.7400 Test Loss = 0.4381, Test Accuracy = 0.7543\n",
      "Iteration 639: Loss = 0.4441, Accuracy = 0.8000 Test Loss = 0.4378, Test Accuracy = 0.7570\n",
      "Iteration 640: Loss = 0.3755, Accuracy = 0.7700 Test Loss = 0.4378, Test Accuracy = 0.7561\n",
      "Iteration 641: Loss = 0.4044, Accuracy = 0.7400 Test Loss = 0.4376, Test Accuracy = 0.7553\n",
      "Iteration 642: Loss = 0.3879, Accuracy = 0.7500 Test Loss = 0.4372, Test Accuracy = 0.7576\n",
      "Iteration 643: Loss = 0.4045, Accuracy = 0.7700 Test Loss = 0.4357, Test Accuracy = 0.7566\n",
      "Iteration 644: Loss = 0.3557, Accuracy = 0.7700 Test Loss = 0.4351, Test Accuracy = 0.7595\n",
      "Iteration 645: Loss = 0.3653, Accuracy = 0.7400 Test Loss = 0.4359, Test Accuracy = 0.7557\n",
      "Iteration 646: Loss = 0.3723, Accuracy = 0.7800 Test Loss = 0.4356, Test Accuracy = 0.7598\n",
      "Iteration 647: Loss = 0.3739, Accuracy = 0.7700 Test Loss = 0.4337, Test Accuracy = 0.7587\n",
      "Iteration 648: Loss = 0.3463, Accuracy = 0.7900 Test Loss = 0.4340, Test Accuracy = 0.7556\n",
      "Iteration 649: Loss = 0.3688, Accuracy = 0.7700 Test Loss = 0.4331, Test Accuracy = 0.7548\n",
      "Iteration 650: Loss = 0.3779, Accuracy = 0.8700 Test Loss = 0.4330, Test Accuracy = 0.7594\n",
      "Iteration 651: Loss = 0.3476, Accuracy = 0.7900 Test Loss = 0.4322, Test Accuracy = 0.7597\n",
      "Iteration 652: Loss = 0.3274, Accuracy = 0.7900 Test Loss = 0.4320, Test Accuracy = 0.7588\n",
      "Iteration 653: Loss = 0.3702, Accuracy = 0.8100 Test Loss = 0.4329, Test Accuracy = 0.7619\n",
      "Iteration 654: Loss = 0.3616, Accuracy = 0.7700 Test Loss = 0.4310, Test Accuracy = 0.7603\n",
      "Iteration 655: Loss = 0.3560, Accuracy = 0.7700 Test Loss = 0.4304, Test Accuracy = 0.7610\n",
      "Iteration 656: Loss = 0.4042, Accuracy = 0.7800 Test Loss = 0.4310, Test Accuracy = 0.7581\n",
      "Iteration 657: Loss = 0.3993, Accuracy = 0.7200 Test Loss = 0.4297, Test Accuracy = 0.7627\n",
      "Iteration 658: Loss = 0.3669, Accuracy = 0.7800 Test Loss = 0.4295, Test Accuracy = 0.7605\n",
      "Iteration 659: Loss = 0.3334, Accuracy = 0.7600 Test Loss = 0.4295, Test Accuracy = 0.7582\n",
      "Iteration 660: Loss = 0.4176, Accuracy = 0.7900 Test Loss = 0.4298, Test Accuracy = 0.7591\n",
      "Iteration 661: Loss = 0.3218, Accuracy = 0.8400 Test Loss = 0.4286, Test Accuracy = 0.7603\n",
      "Iteration 662: Loss = 0.3624, Accuracy = 0.7700 Test Loss = 0.4280, Test Accuracy = 0.7620\n",
      "Iteration 663: Loss = 0.3728, Accuracy = 0.7400 Test Loss = 0.4273, Test Accuracy = 0.7616\n",
      "Iteration 664: Loss = 0.3820, Accuracy = 0.7700 Test Loss = 0.4274, Test Accuracy = 0.7595\n",
      "Iteration 665: Loss = 0.3673, Accuracy = 0.8300 Test Loss = 0.4272, Test Accuracy = 0.7612\n",
      "Iteration 666: Loss = 0.4478, Accuracy = 0.8000 Test Loss = 0.4258, Test Accuracy = 0.7620\n",
      "Iteration 667: Loss = 0.4108, Accuracy = 0.7700 Test Loss = 0.4252, Test Accuracy = 0.7596\n",
      "Iteration 668: Loss = 0.3915, Accuracy = 0.8200 Test Loss = 0.4249, Test Accuracy = 0.7591\n",
      "Iteration 669: Loss = 0.3336, Accuracy = 0.8100 Test Loss = 0.4245, Test Accuracy = 0.7656\n",
      "Iteration 670: Loss = 0.4080, Accuracy = 0.8100 Test Loss = 0.4261, Test Accuracy = 0.7605\n",
      "Iteration 671: Loss = 0.3731, Accuracy = 0.8200 Test Loss = 0.4238, Test Accuracy = 0.7635\n",
      "Iteration 672: Loss = 0.3697, Accuracy = 0.7200 Test Loss = 0.4241, Test Accuracy = 0.7647\n",
      "Iteration 673: Loss = 0.3803, Accuracy = 0.7800 Test Loss = 0.4230, Test Accuracy = 0.7642\n",
      "Iteration 674: Loss = 0.3676, Accuracy = 0.8500 Test Loss = 0.4226, Test Accuracy = 0.7643\n",
      "Iteration 675: Loss = 0.4227, Accuracy = 0.8600 Test Loss = 0.4225, Test Accuracy = 0.7621\n",
      "Iteration 676: Loss = 0.3346, Accuracy = 0.8000 Test Loss = 0.4222, Test Accuracy = 0.7651\n",
      "Iteration 677: Loss = 0.3381, Accuracy = 0.8200 Test Loss = 0.4219, Test Accuracy = 0.7617\n",
      "Iteration 678: Loss = 0.5175, Accuracy = 0.7500 Test Loss = 0.4207, Test Accuracy = 0.7640\n",
      "Iteration 679: Loss = 0.4086, Accuracy = 0.7900 Test Loss = 0.4207, Test Accuracy = 0.7667\n",
      "Iteration 680: Loss = 0.3546, Accuracy = 0.7500 Test Loss = 0.4221, Test Accuracy = 0.7591\n",
      "Iteration 681: Loss = 0.4302, Accuracy = 0.7600 Test Loss = 0.4202, Test Accuracy = 0.7619\n",
      "Iteration 682: Loss = 0.4109, Accuracy = 0.7600 Test Loss = 0.4194, Test Accuracy = 0.7649\n",
      "Iteration 683: Loss = 0.3264, Accuracy = 0.8600 Test Loss = 0.4190, Test Accuracy = 0.7642\n",
      "Iteration 684: Loss = 0.3897, Accuracy = 0.7200 Test Loss = 0.4189, Test Accuracy = 0.7637\n",
      "Iteration 685: Loss = 0.4138, Accuracy = 0.8700 Test Loss = 0.4188, Test Accuracy = 0.7662\n",
      "Iteration 686: Loss = 0.3714, Accuracy = 0.7900 Test Loss = 0.4184, Test Accuracy = 0.7649\n",
      "Iteration 687: Loss = 0.3394, Accuracy = 0.8700 Test Loss = 0.4182, Test Accuracy = 0.7610\n",
      "Iteration 688: Loss = 0.3461, Accuracy = 0.8400 Test Loss = 0.4181, Test Accuracy = 0.7643\n",
      "Iteration 689: Loss = 0.4080, Accuracy = 0.7700 Test Loss = 0.4168, Test Accuracy = 0.7680\n",
      "Iteration 690: Loss = 0.3323, Accuracy = 0.8000 Test Loss = 0.4166, Test Accuracy = 0.7642\n",
      "Iteration 691: Loss = 0.3840, Accuracy = 0.8000 Test Loss = 0.4157, Test Accuracy = 0.7655\n",
      "Iteration 692: Loss = 0.3281, Accuracy = 0.8000 Test Loss = 0.4162, Test Accuracy = 0.7675\n",
      "Iteration 693: Loss = 0.4567, Accuracy = 0.7500 Test Loss = 0.4153, Test Accuracy = 0.7691\n",
      "Iteration 694: Loss = 0.3058, Accuracy = 0.8100 Test Loss = 0.4151, Test Accuracy = 0.7667\n",
      "Iteration 695: Loss = 0.2994, Accuracy = 0.8000 Test Loss = 0.4147, Test Accuracy = 0.7682\n",
      "Iteration 696: Loss = 0.3459, Accuracy = 0.7400 Test Loss = 0.4144, Test Accuracy = 0.7688\n",
      "Iteration 697: Loss = 0.2988, Accuracy = 0.7900 Test Loss = 0.4138, Test Accuracy = 0.7692\n",
      "Iteration 698: Loss = 0.3091, Accuracy = 0.8300 Test Loss = 0.4135, Test Accuracy = 0.7686\n",
      "Iteration 699: Loss = 0.3889, Accuracy = 0.8000 Test Loss = 0.4138, Test Accuracy = 0.7653\n",
      "Iteration 700: Loss = 0.3499, Accuracy = 0.8200 Test Loss = 0.4128, Test Accuracy = 0.7705\n",
      "Iteration 701: Loss = 0.3747, Accuracy = 0.7400 Test Loss = 0.4127, Test Accuracy = 0.7658\n",
      "Iteration 702: Loss = 0.2819, Accuracy = 0.8400 Test Loss = 0.4124, Test Accuracy = 0.7650\n",
      "Iteration 703: Loss = 0.3437, Accuracy = 0.7400 Test Loss = 0.4121, Test Accuracy = 0.7724\n",
      "Iteration 704: Loss = 0.4172, Accuracy = 0.7700 Test Loss = 0.4114, Test Accuracy = 0.7671\n",
      "Iteration 705: Loss = 0.3538, Accuracy = 0.7800 Test Loss = 0.4121, Test Accuracy = 0.7707\n",
      "Iteration 706: Loss = 0.3551, Accuracy = 0.7700 Test Loss = 0.4116, Test Accuracy = 0.7690\n",
      "Iteration 707: Loss = 0.3372, Accuracy = 0.8400 Test Loss = 0.4103, Test Accuracy = 0.7676\n",
      "Iteration 708: Loss = 0.3291, Accuracy = 0.7900 Test Loss = 0.4105, Test Accuracy = 0.7709\n",
      "Iteration 709: Loss = 0.3030, Accuracy = 0.8400 Test Loss = 0.4092, Test Accuracy = 0.7683\n",
      "Iteration 710: Loss = 0.3235, Accuracy = 0.7900 Test Loss = 0.4100, Test Accuracy = 0.7683\n",
      "Iteration 711: Loss = 0.3724, Accuracy = 0.7700 Test Loss = 0.4091, Test Accuracy = 0.7667\n",
      "Iteration 712: Loss = 0.4331, Accuracy = 0.7900 Test Loss = 0.4087, Test Accuracy = 0.7693\n",
      "Iteration 713: Loss = 0.3670, Accuracy = 0.8300 Test Loss = 0.4084, Test Accuracy = 0.7709\n",
      "Iteration 714: Loss = 0.4097, Accuracy = 0.7600 Test Loss = 0.4084, Test Accuracy = 0.7724\n",
      "Iteration 715: Loss = 0.3437, Accuracy = 0.7800 Test Loss = 0.4080, Test Accuracy = 0.7751\n",
      "Iteration 716: Loss = 0.3849, Accuracy = 0.8200 Test Loss = 0.4073, Test Accuracy = 0.7704\n",
      "Iteration 717: Loss = 0.3437, Accuracy = 0.7900 Test Loss = 0.4068, Test Accuracy = 0.7693\n",
      "Iteration 718: Loss = 0.3716, Accuracy = 0.7800 Test Loss = 0.4063, Test Accuracy = 0.7676\n",
      "Iteration 719: Loss = 0.4059, Accuracy = 0.7700 Test Loss = 0.4066, Test Accuracy = 0.7702\n",
      "Iteration 720: Loss = 0.3461, Accuracy = 0.7200 Test Loss = 0.4058, Test Accuracy = 0.7701\n",
      "Iteration 721: Loss = 0.4652, Accuracy = 0.8000 Test Loss = 0.4063, Test Accuracy = 0.7694\n",
      "Iteration 722: Loss = 0.3511, Accuracy = 0.8300 Test Loss = 0.4050, Test Accuracy = 0.7693\n",
      "Iteration 723: Loss = 0.3778, Accuracy = 0.7900 Test Loss = 0.4048, Test Accuracy = 0.7692\n",
      "Iteration 724: Loss = 0.3279, Accuracy = 0.7100 Test Loss = 0.4050, Test Accuracy = 0.7717\n",
      "Iteration 725: Loss = 0.3408, Accuracy = 0.7600 Test Loss = 0.4041, Test Accuracy = 0.7730\n",
      "Iteration 726: Loss = 0.4246, Accuracy = 0.8700 Test Loss = 0.4059, Test Accuracy = 0.7683\n",
      "Iteration 727: Loss = 0.3914, Accuracy = 0.8500 Test Loss = 0.4031, Test Accuracy = 0.7718\n",
      "Iteration 728: Loss = 0.3653, Accuracy = 0.7700 Test Loss = 0.4037, Test Accuracy = 0.7708\n",
      "Iteration 729: Loss = 0.3380, Accuracy = 0.8200 Test Loss = 0.4029, Test Accuracy = 0.7727\n",
      "Iteration 730: Loss = 0.2806, Accuracy = 0.8300 Test Loss = 0.4020, Test Accuracy = 0.7750\n",
      "Iteration 731: Loss = 0.3358, Accuracy = 0.8100 Test Loss = 0.4020, Test Accuracy = 0.7697\n",
      "Iteration 732: Loss = 0.3837, Accuracy = 0.7300 Test Loss = 0.4016, Test Accuracy = 0.7715\n",
      "Iteration 733: Loss = 0.4036, Accuracy = 0.8000 Test Loss = 0.4026, Test Accuracy = 0.7731\n",
      "Iteration 734: Loss = 0.3364, Accuracy = 0.7800 Test Loss = 0.4022, Test Accuracy = 0.7739\n",
      "Iteration 735: Loss = 0.3067, Accuracy = 0.8700 Test Loss = 0.4012, Test Accuracy = 0.7729\n",
      "Iteration 736: Loss = 0.3441, Accuracy = 0.8200 Test Loss = 0.4007, Test Accuracy = 0.7716\n",
      "Iteration 737: Loss = 0.3145, Accuracy = 0.8400 Test Loss = 0.4011, Test Accuracy = 0.7733\n",
      "Iteration 738: Loss = 0.4042, Accuracy = 0.8300 Test Loss = 0.4002, Test Accuracy = 0.7739\n",
      "Iteration 739: Loss = 0.3037, Accuracy = 0.8300 Test Loss = 0.3998, Test Accuracy = 0.7718\n",
      "Iteration 740: Loss = 0.4281, Accuracy = 0.7900 Test Loss = 0.4007, Test Accuracy = 0.7746\n",
      "Iteration 741: Loss = 0.3564, Accuracy = 0.8500 Test Loss = 0.3989, Test Accuracy = 0.7719\n",
      "Iteration 742: Loss = 0.3210, Accuracy = 0.8000 Test Loss = 0.3986, Test Accuracy = 0.7753\n",
      "Iteration 743: Loss = 0.3719, Accuracy = 0.8200 Test Loss = 0.3986, Test Accuracy = 0.7760\n",
      "Iteration 744: Loss = 0.3669, Accuracy = 0.7500 Test Loss = 0.3983, Test Accuracy = 0.7717\n",
      "Iteration 745: Loss = 0.3900, Accuracy = 0.8000 Test Loss = 0.3991, Test Accuracy = 0.7713\n",
      "Iteration 746: Loss = 0.3642, Accuracy = 0.7300 Test Loss = 0.3972, Test Accuracy = 0.7750\n",
      "Iteration 747: Loss = 0.3271, Accuracy = 0.8100 Test Loss = 0.3973, Test Accuracy = 0.7743\n",
      "Iteration 748: Loss = 0.2785, Accuracy = 0.8300 Test Loss = 0.3965, Test Accuracy = 0.7758\n",
      "Iteration 749: Loss = 0.4524, Accuracy = 0.7800 Test Loss = 0.3964, Test Accuracy = 0.7736\n",
      "Iteration 750: Loss = 0.3277, Accuracy = 0.8100 Test Loss = 0.3964, Test Accuracy = 0.7726\n",
      "Iteration 751: Loss = 0.3249, Accuracy = 0.8200 Test Loss = 0.3966, Test Accuracy = 0.7729\n",
      "Iteration 752: Loss = 0.4418, Accuracy = 0.8000 Test Loss = 0.3962, Test Accuracy = 0.7720\n",
      "Iteration 753: Loss = 0.3406, Accuracy = 0.7900 Test Loss = 0.3955, Test Accuracy = 0.7769\n",
      "Iteration 754: Loss = 0.3669, Accuracy = 0.7900 Test Loss = 0.3951, Test Accuracy = 0.7731\n",
      "Iteration 755: Loss = 0.3806, Accuracy = 0.8600 Test Loss = 0.3945, Test Accuracy = 0.7739\n",
      "Iteration 756: Loss = 0.3268, Accuracy = 0.8100 Test Loss = 0.3946, Test Accuracy = 0.7748\n",
      "Iteration 757: Loss = 0.3821, Accuracy = 0.7900 Test Loss = 0.3940, Test Accuracy = 0.7755\n",
      "Iteration 758: Loss = 0.3350, Accuracy = 0.8200 Test Loss = 0.3939, Test Accuracy = 0.7772\n",
      "Iteration 759: Loss = 0.3827, Accuracy = 0.8200 Test Loss = 0.3929, Test Accuracy = 0.7759\n",
      "Iteration 760: Loss = 0.3542, Accuracy = 0.7500 Test Loss = 0.3936, Test Accuracy = 0.7759\n",
      "Iteration 761: Loss = 0.3414, Accuracy = 0.8100 Test Loss = 0.3931, Test Accuracy = 0.7760\n",
      "Iteration 762: Loss = 0.3606, Accuracy = 0.7500 Test Loss = 0.3923, Test Accuracy = 0.7774\n",
      "Iteration 763: Loss = 0.4014, Accuracy = 0.7600 Test Loss = 0.3927, Test Accuracy = 0.7750\n",
      "Iteration 764: Loss = 0.3464, Accuracy = 0.8300 Test Loss = 0.3917, Test Accuracy = 0.7750\n",
      "Iteration 765: Loss = 0.4302, Accuracy = 0.7800 Test Loss = 0.3917, Test Accuracy = 0.7755\n",
      "Iteration 766: Loss = 0.3120, Accuracy = 0.8200 Test Loss = 0.3922, Test Accuracy = 0.7769\n",
      "Iteration 767: Loss = 0.3882, Accuracy = 0.7300 Test Loss = 0.3916, Test Accuracy = 0.7749\n",
      "Iteration 768: Loss = 0.3235, Accuracy = 0.8100 Test Loss = 0.3908, Test Accuracy = 0.7756\n",
      "Iteration 769: Loss = 0.3379, Accuracy = 0.7400 Test Loss = 0.3908, Test Accuracy = 0.7812\n",
      "Iteration 770: Loss = 0.3001, Accuracy = 0.8500 Test Loss = 0.3899, Test Accuracy = 0.7780\n",
      "Iteration 771: Loss = 0.3545, Accuracy = 0.7700 Test Loss = 0.3899, Test Accuracy = 0.7798\n",
      "Iteration 772: Loss = 0.3349, Accuracy = 0.8100 Test Loss = 0.3898, Test Accuracy = 0.7767\n",
      "Iteration 773: Loss = 0.3683, Accuracy = 0.7900 Test Loss = 0.3900, Test Accuracy = 0.7757\n",
      "Iteration 774: Loss = 0.3370, Accuracy = 0.7800 Test Loss = 0.3889, Test Accuracy = 0.7789\n",
      "Iteration 775: Loss = 0.3863, Accuracy = 0.8100 Test Loss = 0.3892, Test Accuracy = 0.7784\n",
      "Iteration 776: Loss = 0.3226, Accuracy = 0.7600 Test Loss = 0.3882, Test Accuracy = 0.7781\n",
      "Iteration 777: Loss = 0.3185, Accuracy = 0.7800 Test Loss = 0.3876, Test Accuracy = 0.7758\n",
      "Iteration 778: Loss = 0.4155, Accuracy = 0.7100 Test Loss = 0.3875, Test Accuracy = 0.7785\n",
      "Iteration 779: Loss = 0.2925, Accuracy = 0.8200 Test Loss = 0.3882, Test Accuracy = 0.7747\n",
      "Iteration 780: Loss = 0.3365, Accuracy = 0.7700 Test Loss = 0.3885, Test Accuracy = 0.7757\n",
      "Iteration 781: Loss = 0.3836, Accuracy = 0.7900 Test Loss = 0.3872, Test Accuracy = 0.7784\n",
      "Iteration 782: Loss = 0.3571, Accuracy = 0.7900 Test Loss = 0.3866, Test Accuracy = 0.7793\n",
      "Iteration 783: Loss = 0.2784, Accuracy = 0.8800 Test Loss = 0.3869, Test Accuracy = 0.7760\n",
      "Iteration 784: Loss = 0.2755, Accuracy = 0.8400 Test Loss = 0.3873, Test Accuracy = 0.7799\n",
      "Iteration 785: Loss = 0.3271, Accuracy = 0.7500 Test Loss = 0.3861, Test Accuracy = 0.7785\n",
      "Iteration 786: Loss = 0.3527, Accuracy = 0.8000 Test Loss = 0.3859, Test Accuracy = 0.7779\n",
      "Iteration 787: Loss = 0.3565, Accuracy = 0.7900 Test Loss = 0.3857, Test Accuracy = 0.7772\n",
      "Iteration 788: Loss = 0.3305, Accuracy = 0.8300 Test Loss = 0.3855, Test Accuracy = 0.7778\n",
      "Iteration 789: Loss = 0.3572, Accuracy = 0.7500 Test Loss = 0.3850, Test Accuracy = 0.7783\n",
      "Iteration 790: Loss = 0.3222, Accuracy = 0.8600 Test Loss = 0.3847, Test Accuracy = 0.7827\n",
      "Iteration 791: Loss = 0.3467, Accuracy = 0.7600 Test Loss = 0.3848, Test Accuracy = 0.7799\n",
      "Iteration 792: Loss = 0.4878, Accuracy = 0.8200 Test Loss = 0.3851, Test Accuracy = 0.7784\n",
      "Iteration 793: Loss = 0.3879, Accuracy = 0.8700 Test Loss = 0.3836, Test Accuracy = 0.7795\n",
      "Iteration 794: Loss = 0.3150, Accuracy = 0.7800 Test Loss = 0.3839, Test Accuracy = 0.7759\n",
      "Iteration 795: Loss = 0.3446, Accuracy = 0.7800 Test Loss = 0.3838, Test Accuracy = 0.7813\n",
      "Iteration 796: Loss = 0.3037, Accuracy = 0.8400 Test Loss = 0.3833, Test Accuracy = 0.7806\n",
      "Iteration 797: Loss = 0.3099, Accuracy = 0.7800 Test Loss = 0.3826, Test Accuracy = 0.7790\n",
      "Iteration 798: Loss = 0.3171, Accuracy = 0.8200 Test Loss = 0.3822, Test Accuracy = 0.7813\n",
      "Iteration 799: Loss = 0.3558, Accuracy = 0.7600 Test Loss = 0.3819, Test Accuracy = 0.7817\n",
      "Iteration 800: Loss = 0.2761, Accuracy = 0.8200 Test Loss = 0.3820, Test Accuracy = 0.7821\n",
      "Iteration 801: Loss = 0.3529, Accuracy = 0.8300 Test Loss = 0.3816, Test Accuracy = 0.7810\n",
      "Iteration 802: Loss = 0.2952, Accuracy = 0.7900 Test Loss = 0.3825, Test Accuracy = 0.7818\n",
      "Iteration 803: Loss = 0.3302, Accuracy = 0.7700 Test Loss = 0.3811, Test Accuracy = 0.7813\n",
      "Iteration 804: Loss = 0.3144, Accuracy = 0.8200 Test Loss = 0.3806, Test Accuracy = 0.7838\n",
      "Iteration 805: Loss = 0.3593, Accuracy = 0.8200 Test Loss = 0.3810, Test Accuracy = 0.7823\n",
      "Iteration 806: Loss = 0.3115, Accuracy = 0.7700 Test Loss = 0.3811, Test Accuracy = 0.7836\n",
      "Iteration 807: Loss = 0.2984, Accuracy = 0.8600 Test Loss = 0.3805, Test Accuracy = 0.7803\n",
      "Iteration 808: Loss = 0.3134, Accuracy = 0.8100 Test Loss = 0.3802, Test Accuracy = 0.7842\n",
      "Iteration 809: Loss = 0.3925, Accuracy = 0.8100 Test Loss = 0.3798, Test Accuracy = 0.7847\n",
      "Iteration 810: Loss = 0.3137, Accuracy = 0.8000 Test Loss = 0.3794, Test Accuracy = 0.7821\n",
      "Iteration 811: Loss = 0.3142, Accuracy = 0.8100 Test Loss = 0.3791, Test Accuracy = 0.7796\n",
      "Iteration 812: Loss = 0.3580, Accuracy = 0.7600 Test Loss = 0.3798, Test Accuracy = 0.7861\n",
      "Iteration 813: Loss = 0.2988, Accuracy = 0.8100 Test Loss = 0.3784, Test Accuracy = 0.7846\n",
      "Iteration 814: Loss = 0.3529, Accuracy = 0.8100 Test Loss = 0.3793, Test Accuracy = 0.7866\n",
      "Iteration 815: Loss = 0.2699, Accuracy = 0.8000 Test Loss = 0.3781, Test Accuracy = 0.7827\n",
      "Iteration 816: Loss = 0.3356, Accuracy = 0.8100 Test Loss = 0.3770, Test Accuracy = 0.7823\n",
      "Iteration 817: Loss = 0.2935, Accuracy = 0.8000 Test Loss = 0.3776, Test Accuracy = 0.7812\n",
      "Iteration 818: Loss = 0.3346, Accuracy = 0.8200 Test Loss = 0.3778, Test Accuracy = 0.7810\n",
      "Iteration 819: Loss = 0.3081, Accuracy = 0.7600 Test Loss = 0.3771, Test Accuracy = 0.7830\n",
      "Iteration 820: Loss = 0.3231, Accuracy = 0.7900 Test Loss = 0.3773, Test Accuracy = 0.7826\n",
      "Iteration 821: Loss = 0.3636, Accuracy = 0.8300 Test Loss = 0.3767, Test Accuracy = 0.7835\n",
      "Iteration 822: Loss = 0.2979, Accuracy = 0.7900 Test Loss = 0.3763, Test Accuracy = 0.7859\n",
      "Iteration 823: Loss = 0.3285, Accuracy = 0.7900 Test Loss = 0.3770, Test Accuracy = 0.7848\n",
      "Iteration 824: Loss = 0.2553, Accuracy = 0.8300 Test Loss = 0.3781, Test Accuracy = 0.7778\n",
      "Iteration 825: Loss = 0.3563, Accuracy = 0.8100 Test Loss = 0.3770, Test Accuracy = 0.7829\n",
      "Iteration 826: Loss = 0.3512, Accuracy = 0.8000 Test Loss = 0.3751, Test Accuracy = 0.7835\n",
      "Iteration 827: Loss = 0.3336, Accuracy = 0.8000 Test Loss = 0.3753, Test Accuracy = 0.7848\n",
      "Iteration 828: Loss = 0.2884, Accuracy = 0.8400 Test Loss = 0.3750, Test Accuracy = 0.7843\n",
      "Iteration 829: Loss = 0.3476, Accuracy = 0.8500 Test Loss = 0.3745, Test Accuracy = 0.7807\n",
      "Iteration 830: Loss = 0.3835, Accuracy = 0.7200 Test Loss = 0.3740, Test Accuracy = 0.7844\n",
      "Iteration 831: Loss = 0.3063, Accuracy = 0.7800 Test Loss = 0.3747, Test Accuracy = 0.7848\n",
      "Iteration 832: Loss = 0.2982, Accuracy = 0.8300 Test Loss = 0.3743, Test Accuracy = 0.7828\n",
      "Iteration 833: Loss = 0.3605, Accuracy = 0.7800 Test Loss = 0.3736, Test Accuracy = 0.7850\n",
      "Iteration 834: Loss = 0.3082, Accuracy = 0.8000 Test Loss = 0.3735, Test Accuracy = 0.7840\n",
      "Iteration 835: Loss = 0.3099, Accuracy = 0.8500 Test Loss = 0.3734, Test Accuracy = 0.7808\n",
      "Iteration 836: Loss = 0.3804, Accuracy = 0.7900 Test Loss = 0.3728, Test Accuracy = 0.7843\n",
      "Iteration 837: Loss = 0.3098, Accuracy = 0.7800 Test Loss = 0.3729, Test Accuracy = 0.7831\n",
      "Iteration 838: Loss = 0.4086, Accuracy = 0.6900 Test Loss = 0.3733, Test Accuracy = 0.7879\n",
      "Iteration 839: Loss = 0.2900, Accuracy = 0.8500 Test Loss = 0.3729, Test Accuracy = 0.7831\n",
      "Iteration 840: Loss = 0.3284, Accuracy = 0.8800 Test Loss = 0.3718, Test Accuracy = 0.7840\n",
      "Iteration 841: Loss = 0.3127, Accuracy = 0.8600 Test Loss = 0.3718, Test Accuracy = 0.7844\n",
      "Iteration 842: Loss = 0.3001, Accuracy = 0.8400 Test Loss = 0.3716, Test Accuracy = 0.7836\n",
      "Iteration 843: Loss = 0.2895, Accuracy = 0.8300 Test Loss = 0.3717, Test Accuracy = 0.7859\n",
      "Iteration 844: Loss = 0.3300, Accuracy = 0.9100 Test Loss = 0.3715, Test Accuracy = 0.7818\n",
      "Iteration 845: Loss = 0.3460, Accuracy = 0.7900 Test Loss = 0.3706, Test Accuracy = 0.7847\n",
      "Iteration 846: Loss = 0.3359, Accuracy = 0.8300 Test Loss = 0.3705, Test Accuracy = 0.7842\n",
      "Iteration 847: Loss = 0.2838, Accuracy = 0.9000 Test Loss = 0.3706, Test Accuracy = 0.7860\n",
      "Iteration 848: Loss = 0.3689, Accuracy = 0.8100 Test Loss = 0.3699, Test Accuracy = 0.7828\n",
      "Iteration 849: Loss = 0.2916, Accuracy = 0.8400 Test Loss = 0.3702, Test Accuracy = 0.7833\n",
      "Iteration 850: Loss = 0.4426, Accuracy = 0.7800 Test Loss = 0.3700, Test Accuracy = 0.7879\n",
      "Iteration 851: Loss = 0.3106, Accuracy = 0.7900 Test Loss = 0.3696, Test Accuracy = 0.7839\n",
      "Iteration 852: Loss = 0.3342, Accuracy = 0.7800 Test Loss = 0.3700, Test Accuracy = 0.7829\n",
      "Iteration 853: Loss = 0.2941, Accuracy = 0.7900 Test Loss = 0.3688, Test Accuracy = 0.7864\n",
      "Iteration 854: Loss = 0.2812, Accuracy = 0.8900 Test Loss = 0.3688, Test Accuracy = 0.7885\n",
      "Iteration 855: Loss = 0.4985, Accuracy = 0.7000 Test Loss = 0.3692, Test Accuracy = 0.7870\n",
      "Iteration 856: Loss = 0.3223, Accuracy = 0.8100 Test Loss = 0.3681, Test Accuracy = 0.7867\n",
      "Iteration 857: Loss = 0.2997, Accuracy = 0.8100 Test Loss = 0.3682, Test Accuracy = 0.7846\n",
      "Iteration 858: Loss = 0.3181, Accuracy = 0.8100 Test Loss = 0.3688, Test Accuracy = 0.7883\n",
      "Iteration 859: Loss = 0.3447, Accuracy = 0.7200 Test Loss = 0.3676, Test Accuracy = 0.7872\n",
      "Iteration 860: Loss = 0.3622, Accuracy = 0.7300 Test Loss = 0.3676, Test Accuracy = 0.7866\n",
      "Iteration 861: Loss = 0.3812, Accuracy = 0.7500 Test Loss = 0.3673, Test Accuracy = 0.7892\n",
      "Iteration 862: Loss = 0.3394, Accuracy = 0.8300 Test Loss = 0.3675, Test Accuracy = 0.7881\n",
      "Iteration 863: Loss = 0.3650, Accuracy = 0.7700 Test Loss = 0.3668, Test Accuracy = 0.7862\n",
      "Iteration 864: Loss = 0.3538, Accuracy = 0.7900 Test Loss = 0.3670, Test Accuracy = 0.7858\n",
      "Iteration 865: Loss = 0.2787, Accuracy = 0.8500 Test Loss = 0.3661, Test Accuracy = 0.7872\n",
      "Iteration 866: Loss = 0.3535, Accuracy = 0.7700 Test Loss = 0.3665, Test Accuracy = 0.7850\n",
      "Iteration 867: Loss = 0.2912, Accuracy = 0.8200 Test Loss = 0.3662, Test Accuracy = 0.7884\n",
      "Iteration 868: Loss = 0.2803, Accuracy = 0.8500 Test Loss = 0.3667, Test Accuracy = 0.7834\n",
      "Iteration 869: Loss = 0.3666, Accuracy = 0.8300 Test Loss = 0.3652, Test Accuracy = 0.7907\n",
      "Iteration 870: Loss = 0.4080, Accuracy = 0.8200 Test Loss = 0.3652, Test Accuracy = 0.7865\n",
      "Iteration 871: Loss = 0.3232, Accuracy = 0.7900 Test Loss = 0.3646, Test Accuracy = 0.7890\n",
      "Iteration 872: Loss = 0.3120, Accuracy = 0.8400 Test Loss = 0.3649, Test Accuracy = 0.7897\n",
      "Iteration 873: Loss = 0.3143, Accuracy = 0.8200 Test Loss = 0.3642, Test Accuracy = 0.7877\n",
      "Iteration 874: Loss = 0.3006, Accuracy = 0.7800 Test Loss = 0.3639, Test Accuracy = 0.7891\n",
      "Iteration 875: Loss = 0.3307, Accuracy = 0.8000 Test Loss = 0.3634, Test Accuracy = 0.7907\n",
      "Iteration 876: Loss = 0.3472, Accuracy = 0.8100 Test Loss = 0.3640, Test Accuracy = 0.7851\n",
      "Iteration 877: Loss = 0.3642, Accuracy = 0.8000 Test Loss = 0.3640, Test Accuracy = 0.7880\n",
      "Iteration 878: Loss = 0.3116, Accuracy = 0.8500 Test Loss = 0.3638, Test Accuracy = 0.7887\n",
      "Iteration 879: Loss = 0.2787, Accuracy = 0.8700 Test Loss = 0.3636, Test Accuracy = 0.7831\n",
      "Iteration 880: Loss = 0.3210, Accuracy = 0.7600 Test Loss = 0.3631, Test Accuracy = 0.7886\n",
      "Iteration 881: Loss = 0.3461, Accuracy = 0.7800 Test Loss = 0.3634, Test Accuracy = 0.7865\n",
      "Iteration 882: Loss = 0.3386, Accuracy = 0.8500 Test Loss = 0.3634, Test Accuracy = 0.7843\n",
      "Iteration 883: Loss = 0.3251, Accuracy = 0.8100 Test Loss = 0.3623, Test Accuracy = 0.7881\n",
      "Iteration 884: Loss = 0.3280, Accuracy = 0.8100 Test Loss = 0.3618, Test Accuracy = 0.7885\n",
      "Iteration 885: Loss = 0.3400, Accuracy = 0.8000 Test Loss = 0.3620, Test Accuracy = 0.7867\n",
      "Iteration 886: Loss = 0.3422, Accuracy = 0.8400 Test Loss = 0.3616, Test Accuracy = 0.7877\n",
      "Iteration 887: Loss = 0.3494, Accuracy = 0.8400 Test Loss = 0.3617, Test Accuracy = 0.7889\n",
      "Iteration 888: Loss = 0.3557, Accuracy = 0.7700 Test Loss = 0.3617, Test Accuracy = 0.7910\n",
      "Iteration 889: Loss = 0.3043, Accuracy = 0.7800 Test Loss = 0.3610, Test Accuracy = 0.7905\n",
      "Iteration 890: Loss = 0.2665, Accuracy = 0.8500 Test Loss = 0.3611, Test Accuracy = 0.7886\n",
      "Iteration 891: Loss = 0.3091, Accuracy = 0.7800 Test Loss = 0.3605, Test Accuracy = 0.7904\n",
      "Iteration 892: Loss = 0.3377, Accuracy = 0.8200 Test Loss = 0.3609, Test Accuracy = 0.7886\n",
      "Iteration 893: Loss = 0.3398, Accuracy = 0.8000 Test Loss = 0.3598, Test Accuracy = 0.7911\n",
      "Iteration 894: Loss = 0.3904, Accuracy = 0.8100 Test Loss = 0.3609, Test Accuracy = 0.7875\n",
      "Iteration 895: Loss = 0.2460, Accuracy = 0.8700 Test Loss = 0.3597, Test Accuracy = 0.7888\n",
      "Iteration 896: Loss = 0.2897, Accuracy = 0.7600 Test Loss = 0.3603, Test Accuracy = 0.7877\n",
      "Iteration 897: Loss = 0.2745, Accuracy = 0.8400 Test Loss = 0.3595, Test Accuracy = 0.7907\n",
      "Iteration 898: Loss = 0.2940, Accuracy = 0.8400 Test Loss = 0.3593, Test Accuracy = 0.7886\n",
      "Iteration 899: Loss = 0.3406, Accuracy = 0.7700 Test Loss = 0.3588, Test Accuracy = 0.7929\n",
      "Iteration 900: Loss = 0.3245, Accuracy = 0.7800 Test Loss = 0.3584, Test Accuracy = 0.7932\n",
      "Iteration 901: Loss = 0.3059, Accuracy = 0.8400 Test Loss = 0.3592, Test Accuracy = 0.7903\n",
      "Iteration 902: Loss = 0.3251, Accuracy = 0.8400 Test Loss = 0.3585, Test Accuracy = 0.7951\n",
      "Iteration 903: Loss = 0.4003, Accuracy = 0.8700 Test Loss = 0.3583, Test Accuracy = 0.7923\n",
      "Iteration 904: Loss = 0.3149, Accuracy = 0.8400 Test Loss = 0.3585, Test Accuracy = 0.7907\n",
      "Iteration 905: Loss = 0.3019, Accuracy = 0.8600 Test Loss = 0.3582, Test Accuracy = 0.7904\n",
      "Iteration 906: Loss = 0.2816, Accuracy = 0.8300 Test Loss = 0.3575, Test Accuracy = 0.7897\n",
      "Iteration 907: Loss = 0.3558, Accuracy = 0.8000 Test Loss = 0.3581, Test Accuracy = 0.7931\n",
      "Iteration 908: Loss = 0.3033, Accuracy = 0.8600 Test Loss = 0.3573, Test Accuracy = 0.7938\n",
      "Iteration 909: Loss = 0.3053, Accuracy = 0.8500 Test Loss = 0.3570, Test Accuracy = 0.7868\n",
      "Iteration 910: Loss = 0.2795, Accuracy = 0.8600 Test Loss = 0.3571, Test Accuracy = 0.7939\n",
      "Iteration 911: Loss = 0.3351, Accuracy = 0.7800 Test Loss = 0.3572, Test Accuracy = 0.7924\n",
      "Iteration 912: Loss = 0.3162, Accuracy = 0.8100 Test Loss = 0.3578, Test Accuracy = 0.7902\n",
      "Iteration 913: Loss = 0.3108, Accuracy = 0.8300 Test Loss = 0.3563, Test Accuracy = 0.7892\n",
      "Iteration 914: Loss = 0.3416, Accuracy = 0.7700 Test Loss = 0.3566, Test Accuracy = 0.7890\n",
      "Iteration 915: Loss = 0.3315, Accuracy = 0.8000 Test Loss = 0.3563, Test Accuracy = 0.7937\n",
      "Iteration 916: Loss = 0.3423, Accuracy = 0.8000 Test Loss = 0.3562, Test Accuracy = 0.7940\n",
      "Iteration 917: Loss = 0.2873, Accuracy = 0.8400 Test Loss = 0.3554, Test Accuracy = 0.7904\n",
      "Iteration 918: Loss = 0.3740, Accuracy = 0.8200 Test Loss = 0.3553, Test Accuracy = 0.7892\n",
      "Iteration 919: Loss = 0.3628, Accuracy = 0.7700 Test Loss = 0.3555, Test Accuracy = 0.7933\n",
      "Iteration 920: Loss = 0.2978, Accuracy = 0.8100 Test Loss = 0.3551, Test Accuracy = 0.7903\n",
      "Iteration 921: Loss = 0.3825, Accuracy = 0.7300 Test Loss = 0.3556, Test Accuracy = 0.7921\n",
      "Iteration 922: Loss = 0.2971, Accuracy = 0.8500 Test Loss = 0.3550, Test Accuracy = 0.7931\n",
      "Iteration 923: Loss = 0.2874, Accuracy = 0.8200 Test Loss = 0.3546, Test Accuracy = 0.7932\n",
      "Iteration 924: Loss = 0.3214, Accuracy = 0.8300 Test Loss = 0.3546, Test Accuracy = 0.7924\n",
      "Iteration 925: Loss = 0.2746, Accuracy = 0.8200 Test Loss = 0.3539, Test Accuracy = 0.7922\n",
      "Iteration 926: Loss = 0.3297, Accuracy = 0.8600 Test Loss = 0.3535, Test Accuracy = 0.7946\n",
      "Iteration 927: Loss = 0.2722, Accuracy = 0.8400 Test Loss = 0.3533, Test Accuracy = 0.7946\n",
      "Iteration 928: Loss = 0.2860, Accuracy = 0.8100 Test Loss = 0.3539, Test Accuracy = 0.7918\n",
      "Iteration 929: Loss = 0.3087, Accuracy = 0.8600 Test Loss = 0.3537, Test Accuracy = 0.7905\n",
      "Iteration 930: Loss = 0.2799, Accuracy = 0.8100 Test Loss = 0.3534, Test Accuracy = 0.7968\n",
      "Iteration 931: Loss = 0.3276, Accuracy = 0.7800 Test Loss = 0.3532, Test Accuracy = 0.7950\n",
      "Iteration 932: Loss = 0.3723, Accuracy = 0.7300 Test Loss = 0.3528, Test Accuracy = 0.7958\n",
      "Iteration 933: Loss = 0.2963, Accuracy = 0.7800 Test Loss = 0.3531, Test Accuracy = 0.7907\n",
      "Iteration 934: Loss = 0.4364, Accuracy = 0.8100 Test Loss = 0.3523, Test Accuracy = 0.7930\n",
      "Iteration 935: Loss = 0.3401, Accuracy = 0.7900 Test Loss = 0.3520, Test Accuracy = 0.7928\n",
      "Iteration 936: Loss = 0.3043, Accuracy = 0.8400 Test Loss = 0.3523, Test Accuracy = 0.7937\n",
      "Iteration 937: Loss = 0.3444, Accuracy = 0.7700 Test Loss = 0.3525, Test Accuracy = 0.7905\n",
      "Iteration 938: Loss = 0.3206, Accuracy = 0.7500 Test Loss = 0.3522, Test Accuracy = 0.7955\n",
      "Iteration 939: Loss = 0.2695, Accuracy = 0.8600 Test Loss = 0.3515, Test Accuracy = 0.7923\n",
      "Iteration 940: Loss = 0.2973, Accuracy = 0.8000 Test Loss = 0.3514, Test Accuracy = 0.7959\n",
      "Iteration 941: Loss = 0.2971, Accuracy = 0.7600 Test Loss = 0.3514, Test Accuracy = 0.7937\n",
      "Iteration 942: Loss = 0.2797, Accuracy = 0.8100 Test Loss = 0.3512, Test Accuracy = 0.7954\n",
      "Iteration 943: Loss = 0.3310, Accuracy = 0.8500 Test Loss = 0.3515, Test Accuracy = 0.7937\n",
      "Iteration 944: Loss = 0.2917, Accuracy = 0.8300 Test Loss = 0.3506, Test Accuracy = 0.7965\n",
      "Iteration 945: Loss = 0.2352, Accuracy = 0.8700 Test Loss = 0.3508, Test Accuracy = 0.7932\n",
      "Iteration 946: Loss = 0.2548, Accuracy = 0.8200 Test Loss = 0.3500, Test Accuracy = 0.7964\n",
      "Iteration 947: Loss = 0.4235, Accuracy = 0.7700 Test Loss = 0.3503, Test Accuracy = 0.7923\n",
      "Iteration 948: Loss = 0.2564, Accuracy = 0.8600 Test Loss = 0.3494, Test Accuracy = 0.7937\n",
      "Iteration 949: Loss = 0.2598, Accuracy = 0.8300 Test Loss = 0.3497, Test Accuracy = 0.7983\n",
      "Iteration 950: Loss = 0.3650, Accuracy = 0.8100 Test Loss = 0.3500, Test Accuracy = 0.7915\n",
      "Iteration 951: Loss = 0.3264, Accuracy = 0.8200 Test Loss = 0.3492, Test Accuracy = 0.7944\n",
      "Iteration 952: Loss = 0.3068, Accuracy = 0.8200 Test Loss = 0.3495, Test Accuracy = 0.7948\n",
      "Iteration 953: Loss = 0.3058, Accuracy = 0.8500 Test Loss = 0.3492, Test Accuracy = 0.7970\n",
      "Iteration 954: Loss = 0.3024, Accuracy = 0.7800 Test Loss = 0.3486, Test Accuracy = 0.7977\n",
      "Iteration 955: Loss = 0.2995, Accuracy = 0.7900 Test Loss = 0.3485, Test Accuracy = 0.7964\n",
      "Iteration 956: Loss = 0.2981, Accuracy = 0.8400 Test Loss = 0.3482, Test Accuracy = 0.7980\n",
      "Iteration 957: Loss = 0.3187, Accuracy = 0.7900 Test Loss = 0.3479, Test Accuracy = 0.7959\n",
      "Iteration 958: Loss = 0.2855, Accuracy = 0.8100 Test Loss = 0.3480, Test Accuracy = 0.7996\n",
      "Iteration 959: Loss = 0.3284, Accuracy = 0.7800 Test Loss = 0.3476, Test Accuracy = 0.7981\n",
      "Iteration 960: Loss = 0.3926, Accuracy = 0.8400 Test Loss = 0.3480, Test Accuracy = 0.7931\n",
      "Iteration 961: Loss = 0.3356, Accuracy = 0.8000 Test Loss = 0.3475, Test Accuracy = 0.7940\n",
      "Iteration 962: Loss = 0.2541, Accuracy = 0.8800 Test Loss = 0.3476, Test Accuracy = 0.7963\n",
      "Iteration 963: Loss = 0.2709, Accuracy = 0.8600 Test Loss = 0.3477, Test Accuracy = 0.7916\n",
      "Iteration 964: Loss = 0.2643, Accuracy = 0.8500 Test Loss = 0.3477, Test Accuracy = 0.7903\n",
      "Iteration 965: Loss = 0.2411, Accuracy = 0.8600 Test Loss = 0.3472, Test Accuracy = 0.7977\n",
      "Iteration 966: Loss = 0.2671, Accuracy = 0.8800 Test Loss = 0.3466, Test Accuracy = 0.7973\n",
      "Iteration 967: Loss = 0.2674, Accuracy = 0.8400 Test Loss = 0.3465, Test Accuracy = 0.7970\n",
      "Iteration 968: Loss = 0.2964, Accuracy = 0.8400 Test Loss = 0.3465, Test Accuracy = 0.7951\n",
      "Iteration 969: Loss = 0.2799, Accuracy = 0.8200 Test Loss = 0.3465, Test Accuracy = 0.7949\n",
      "Iteration 970: Loss = 0.3321, Accuracy = 0.8100 Test Loss = 0.3465, Test Accuracy = 0.7971\n",
      "Iteration 971: Loss = 0.2596, Accuracy = 0.9100 Test Loss = 0.3460, Test Accuracy = 0.7947\n",
      "Iteration 972: Loss = 0.2695, Accuracy = 0.8400 Test Loss = 0.3457, Test Accuracy = 0.7957\n",
      "Iteration 973: Loss = 0.3161, Accuracy = 0.7800 Test Loss = 0.3452, Test Accuracy = 0.7960\n",
      "Iteration 974: Loss = 0.2928, Accuracy = 0.8400 Test Loss = 0.3456, Test Accuracy = 0.7988\n",
      "Iteration 975: Loss = 0.3054, Accuracy = 0.8000 Test Loss = 0.3457, Test Accuracy = 0.7963\n",
      "Iteration 976: Loss = 0.3180, Accuracy = 0.8300 Test Loss = 0.3453, Test Accuracy = 0.7983\n",
      "Iteration 977: Loss = 0.2901, Accuracy = 0.8700 Test Loss = 0.3451, Test Accuracy = 0.7958\n",
      "Iteration 978: Loss = 0.3134, Accuracy = 0.8000 Test Loss = 0.3452, Test Accuracy = 0.7945\n",
      "Iteration 979: Loss = 0.2376, Accuracy = 0.8100 Test Loss = 0.3456, Test Accuracy = 0.7975\n",
      "Iteration 980: Loss = 0.2574, Accuracy = 0.8300 Test Loss = 0.3439, Test Accuracy = 0.7963\n",
      "Iteration 981: Loss = 0.3433, Accuracy = 0.7600 Test Loss = 0.3455, Test Accuracy = 0.7970\n",
      "Iteration 982: Loss = 0.2985, Accuracy = 0.8200 Test Loss = 0.3440, Test Accuracy = 0.7988\n",
      "Iteration 983: Loss = 0.3704, Accuracy = 0.8600 Test Loss = 0.3442, Test Accuracy = 0.7954\n",
      "Iteration 984: Loss = 0.2581, Accuracy = 0.8200 Test Loss = 0.3434, Test Accuracy = 0.7999\n",
      "Iteration 985: Loss = 0.3476, Accuracy = 0.8200 Test Loss = 0.3435, Test Accuracy = 0.7965\n",
      "Iteration 986: Loss = 0.2848, Accuracy = 0.8300 Test Loss = 0.3433, Test Accuracy = 0.7994\n",
      "Iteration 987: Loss = 0.3098, Accuracy = 0.8400 Test Loss = 0.3436, Test Accuracy = 0.7967\n",
      "Iteration 988: Loss = 0.3106, Accuracy = 0.7400 Test Loss = 0.3434, Test Accuracy = 0.7968\n",
      "Iteration 989: Loss = 0.2562, Accuracy = 0.8700 Test Loss = 0.3436, Test Accuracy = 0.8006\n",
      "Iteration 990: Loss = 0.3289, Accuracy = 0.8300 Test Loss = 0.3431, Test Accuracy = 0.8004\n",
      "Iteration 991: Loss = 0.2643, Accuracy = 0.9000 Test Loss = 0.3428, Test Accuracy = 0.7992\n",
      "Iteration 992: Loss = 0.2732, Accuracy = 0.8200 Test Loss = 0.3425, Test Accuracy = 0.8003\n",
      "Iteration 993: Loss = 0.2801, Accuracy = 0.8200 Test Loss = 0.3430, Test Accuracy = 0.7965\n",
      "Iteration 994: Loss = 0.2774, Accuracy = 0.7800 Test Loss = 0.3421, Test Accuracy = 0.7986\n",
      "Iteration 995: Loss = 0.2653, Accuracy = 0.8500 Test Loss = 0.3418, Test Accuracy = 0.7999\n",
      "Iteration 996: Loss = 0.2592, Accuracy = 0.8400 Test Loss = 0.3416, Test Accuracy = 0.7971\n",
      "Iteration 997: Loss = 0.2893, Accuracy = 0.8000 Test Loss = 0.3416, Test Accuracy = 0.7998\n",
      "Iteration 998: Loss = 0.2650, Accuracy = 0.8200 Test Loss = 0.3419, Test Accuracy = 0.7983\n",
      "Iteration 999: Loss = 0.3322, Accuracy = 0.7900 Test Loss = 0.3413, Test Accuracy = 0.7972\n",
      "Iteration 1000: Loss = 0.3320, Accuracy = 0.7400 Test Loss = 0.3411, Test Accuracy = 0.8012\n",
      "Iteration 1001: Loss = 0.3107, Accuracy = 0.8800 Test Loss = 0.3421, Test Accuracy = 0.7936\n",
      "Iteration 1002: Loss = 0.3010, Accuracy = 0.7900 Test Loss = 0.3410, Test Accuracy = 0.7967\n",
      "Iteration 1003: Loss = 0.3713, Accuracy = 0.7500 Test Loss = 0.3412, Test Accuracy = 0.7990\n",
      "Iteration 1004: Loss = 0.2588, Accuracy = 0.8200 Test Loss = 0.3411, Test Accuracy = 0.8021\n",
      "Iteration 1005: Loss = 0.2772, Accuracy = 0.8500 Test Loss = 0.3403, Test Accuracy = 0.7988\n",
      "Iteration 1006: Loss = 0.3509, Accuracy = 0.7200 Test Loss = 0.3405, Test Accuracy = 0.7992\n",
      "Iteration 1007: Loss = 0.2528, Accuracy = 0.8000 Test Loss = 0.3402, Test Accuracy = 0.7984\n",
      "Iteration 1008: Loss = 0.3274, Accuracy = 0.8500 Test Loss = 0.3409, Test Accuracy = 0.7982\n",
      "Iteration 1009: Loss = 0.3300, Accuracy = 0.7700 Test Loss = 0.3397, Test Accuracy = 0.7987\n",
      "Iteration 1010: Loss = 0.2968, Accuracy = 0.9300 Test Loss = 0.3399, Test Accuracy = 0.7979\n",
      "Iteration 1011: Loss = 0.2769, Accuracy = 0.9200 Test Loss = 0.3396, Test Accuracy = 0.8004\n",
      "Iteration 1012: Loss = 0.2975, Accuracy = 0.8400 Test Loss = 0.3402, Test Accuracy = 0.7991\n",
      "Iteration 1013: Loss = 0.2807, Accuracy = 0.8600 Test Loss = 0.3390, Test Accuracy = 0.8023\n",
      "Iteration 1014: Loss = 0.3521, Accuracy = 0.7800 Test Loss = 0.3392, Test Accuracy = 0.7994\n",
      "Iteration 1015: Loss = 0.3160, Accuracy = 0.8600 Test Loss = 0.3390, Test Accuracy = 0.7994\n",
      "Iteration 1016: Loss = 0.2727, Accuracy = 0.8500 Test Loss = 0.3385, Test Accuracy = 0.7997\n",
      "Iteration 1017: Loss = 0.4263, Accuracy = 0.7400 Test Loss = 0.3396, Test Accuracy = 0.7993\n",
      "Iteration 1018: Loss = 0.2613, Accuracy = 0.7900 Test Loss = 0.3384, Test Accuracy = 0.8019\n",
      "Iteration 1019: Loss = 0.2982, Accuracy = 0.7900 Test Loss = 0.3382, Test Accuracy = 0.8020\n",
      "Iteration 1020: Loss = 0.2670, Accuracy = 0.8800 Test Loss = 0.3382, Test Accuracy = 0.7989\n",
      "Iteration 1021: Loss = 0.2875, Accuracy = 0.8700 Test Loss = 0.3379, Test Accuracy = 0.8002\n",
      "Iteration 1022: Loss = 0.3261, Accuracy = 0.7800 Test Loss = 0.3380, Test Accuracy = 0.8001\n",
      "Iteration 1023: Loss = 0.2828, Accuracy = 0.8700 Test Loss = 0.3377, Test Accuracy = 0.7993\n",
      "Iteration 1024: Loss = 0.2673, Accuracy = 0.8200 Test Loss = 0.3380, Test Accuracy = 0.7987\n",
      "Iteration 1025: Loss = 0.2891, Accuracy = 0.7900 Test Loss = 0.3383, Test Accuracy = 0.7983\n",
      "Iteration 1026: Loss = 0.3630, Accuracy = 0.8000 Test Loss = 0.3368, Test Accuracy = 0.8029\n",
      "Iteration 1027: Loss = 0.2779, Accuracy = 0.8700 Test Loss = 0.3373, Test Accuracy = 0.8000\n",
      "Iteration 1028: Loss = 0.2682, Accuracy = 0.8200 Test Loss = 0.3377, Test Accuracy = 0.8001\n",
      "Iteration 1029: Loss = 0.3201, Accuracy = 0.8100 Test Loss = 0.3371, Test Accuracy = 0.7990\n",
      "Iteration 1030: Loss = 0.2838, Accuracy = 0.8100 Test Loss = 0.3368, Test Accuracy = 0.8030\n",
      "Iteration 1031: Loss = 0.2946, Accuracy = 0.8200 Test Loss = 0.3368, Test Accuracy = 0.8010\n",
      "Iteration 1032: Loss = 0.2761, Accuracy = 0.8000 Test Loss = 0.3362, Test Accuracy = 0.8017\n",
      "Iteration 1033: Loss = 0.2648, Accuracy = 0.8800 Test Loss = 0.3369, Test Accuracy = 0.8008\n",
      "Iteration 1034: Loss = 0.3111, Accuracy = 0.8200 Test Loss = 0.3362, Test Accuracy = 0.7994\n",
      "Iteration 1035: Loss = 0.2716, Accuracy = 0.8600 Test Loss = 0.3364, Test Accuracy = 0.8028\n",
      "Iteration 1036: Loss = 0.2597, Accuracy = 0.8900 Test Loss = 0.3358, Test Accuracy = 0.8026\n",
      "Iteration 1037: Loss = 0.2725, Accuracy = 0.8000 Test Loss = 0.3356, Test Accuracy = 0.8029\n",
      "Iteration 1038: Loss = 0.2656, Accuracy = 0.8300 Test Loss = 0.3362, Test Accuracy = 0.7992\n",
      "Iteration 1039: Loss = 0.2886, Accuracy = 0.8300 Test Loss = 0.3357, Test Accuracy = 0.8010\n",
      "Iteration 1040: Loss = 0.2936, Accuracy = 0.8100 Test Loss = 0.3351, Test Accuracy = 0.8027\n",
      "Iteration 1041: Loss = 0.2898, Accuracy = 0.8100 Test Loss = 0.3350, Test Accuracy = 0.8022\n",
      "Iteration 1042: Loss = 0.2746, Accuracy = 0.8200 Test Loss = 0.3363, Test Accuracy = 0.8003\n",
      "Iteration 1043: Loss = 0.2996, Accuracy = 0.8700 Test Loss = 0.3353, Test Accuracy = 0.7992\n",
      "Iteration 1044: Loss = 0.4157, Accuracy = 0.8400 Test Loss = 0.3352, Test Accuracy = 0.8024\n",
      "Iteration 1045: Loss = 0.2692, Accuracy = 0.8600 Test Loss = 0.3344, Test Accuracy = 0.7999\n",
      "Iteration 1046: Loss = 0.2682, Accuracy = 0.8600 Test Loss = 0.3343, Test Accuracy = 0.8013\n",
      "Iteration 1047: Loss = 0.2820, Accuracy = 0.8000 Test Loss = 0.3348, Test Accuracy = 0.7980\n",
      "Iteration 1048: Loss = 0.3637, Accuracy = 0.8000 Test Loss = 0.3341, Test Accuracy = 0.8024\n",
      "Iteration 1049: Loss = 0.3251, Accuracy = 0.7500 Test Loss = 0.3340, Test Accuracy = 0.8028\n",
      "Iteration 1050: Loss = 0.3323, Accuracy = 0.8500 Test Loss = 0.3347, Test Accuracy = 0.7999\n",
      "Iteration 1051: Loss = 0.3096, Accuracy = 0.8300 Test Loss = 0.3343, Test Accuracy = 0.8012\n",
      "Iteration 1052: Loss = 0.2678, Accuracy = 0.8400 Test Loss = 0.3340, Test Accuracy = 0.7971\n",
      "Iteration 1053: Loss = 0.3078, Accuracy = 0.8100 Test Loss = 0.3332, Test Accuracy = 0.8030\n",
      "Iteration 1054: Loss = 0.2765, Accuracy = 0.8500 Test Loss = 0.3335, Test Accuracy = 0.8016\n",
      "Iteration 1055: Loss = 0.2582, Accuracy = 0.8800 Test Loss = 0.3337, Test Accuracy = 0.8011\n",
      "Iteration 1056: Loss = 0.2957, Accuracy = 0.8400 Test Loss = 0.3333, Test Accuracy = 0.8039\n",
      "Iteration 1057: Loss = 0.2775, Accuracy = 0.8100 Test Loss = 0.3335, Test Accuracy = 0.8019\n",
      "Iteration 1058: Loss = 0.2352, Accuracy = 0.9000 Test Loss = 0.3324, Test Accuracy = 0.8038\n",
      "Iteration 1059: Loss = 0.2968, Accuracy = 0.7700 Test Loss = 0.3329, Test Accuracy = 0.8021\n",
      "Iteration 1060: Loss = 0.2849, Accuracy = 0.8400 Test Loss = 0.3324, Test Accuracy = 0.8011\n",
      "Iteration 1061: Loss = 0.3016, Accuracy = 0.9000 Test Loss = 0.3323, Test Accuracy = 0.8037\n",
      "Iteration 1062: Loss = 0.2634, Accuracy = 0.8000 Test Loss = 0.3327, Test Accuracy = 0.8012\n",
      "Iteration 1063: Loss = 0.2990, Accuracy = 0.8600 Test Loss = 0.3324, Test Accuracy = 0.8040\n",
      "Iteration 1064: Loss = 0.3405, Accuracy = 0.8000 Test Loss = 0.3328, Test Accuracy = 0.8040\n",
      "Iteration 1065: Loss = 0.2766, Accuracy = 0.8200 Test Loss = 0.3319, Test Accuracy = 0.8037\n",
      "Iteration 1066: Loss = 0.2628, Accuracy = 0.8200 Test Loss = 0.3324, Test Accuracy = 0.7986\n",
      "Iteration 1067: Loss = 0.2399, Accuracy = 0.8500 Test Loss = 0.3316, Test Accuracy = 0.8035\n",
      "Iteration 1068: Loss = 0.2816, Accuracy = 0.8200 Test Loss = 0.3319, Test Accuracy = 0.8024\n",
      "Iteration 1069: Loss = 0.3605, Accuracy = 0.7300 Test Loss = 0.3312, Test Accuracy = 0.8013\n",
      "Iteration 1070: Loss = 0.3062, Accuracy = 0.8200 Test Loss = 0.3318, Test Accuracy = 0.8050\n",
      "Iteration 1071: Loss = 0.2669, Accuracy = 0.7700 Test Loss = 0.3314, Test Accuracy = 0.8019\n",
      "Iteration 1072: Loss = 0.3296, Accuracy = 0.7300 Test Loss = 0.3305, Test Accuracy = 0.8041\n",
      "Iteration 1073: Loss = 0.2657, Accuracy = 0.8200 Test Loss = 0.3310, Test Accuracy = 0.8005\n",
      "Iteration 1074: Loss = 0.3148, Accuracy = 0.8600 Test Loss = 0.3311, Test Accuracy = 0.8006\n",
      "Iteration 1075: Loss = 0.2587, Accuracy = 0.8500 Test Loss = 0.3308, Test Accuracy = 0.8009\n",
      "Iteration 1076: Loss = 0.2769, Accuracy = 0.8000 Test Loss = 0.3303, Test Accuracy = 0.8048\n",
      "Iteration 1077: Loss = 0.2809, Accuracy = 0.8900 Test Loss = 0.3303, Test Accuracy = 0.8042\n",
      "Iteration 1078: Loss = 0.3022, Accuracy = 0.8900 Test Loss = 0.3300, Test Accuracy = 0.8032\n",
      "Iteration 1079: Loss = 0.2970, Accuracy = 0.8000 Test Loss = 0.3304, Test Accuracy = 0.8038\n",
      "Iteration 1080: Loss = 0.2763, Accuracy = 0.8400 Test Loss = 0.3300, Test Accuracy = 0.8060\n",
      "Iteration 1081: Loss = 0.2646, Accuracy = 0.8400 Test Loss = 0.3297, Test Accuracy = 0.8059\n",
      "Iteration 1082: Loss = 0.2892, Accuracy = 0.8300 Test Loss = 0.3300, Test Accuracy = 0.8063\n",
      "Iteration 1083: Loss = 0.3240, Accuracy = 0.8400 Test Loss = 0.3291, Test Accuracy = 0.8042\n",
      "Iteration 1084: Loss = 0.2586, Accuracy = 0.8100 Test Loss = 0.3293, Test Accuracy = 0.8073\n",
      "Iteration 1085: Loss = 0.3412, Accuracy = 0.8400 Test Loss = 0.3296, Test Accuracy = 0.8037\n",
      "Iteration 1086: Loss = 0.2772, Accuracy = 0.7800 Test Loss = 0.3290, Test Accuracy = 0.8016\n",
      "Iteration 1087: Loss = 0.2552, Accuracy = 0.8300 Test Loss = 0.3288, Test Accuracy = 0.8020\n",
      "Iteration 1088: Loss = 0.3305, Accuracy = 0.8100 Test Loss = 0.3294, Test Accuracy = 0.8009\n",
      "Iteration 1089: Loss = 0.2909, Accuracy = 0.8000 Test Loss = 0.3287, Test Accuracy = 0.8028\n",
      "Iteration 1090: Loss = 0.3107, Accuracy = 0.8400 Test Loss = 0.3281, Test Accuracy = 0.8053\n",
      "Iteration 1091: Loss = 0.3296, Accuracy = 0.7100 Test Loss = 0.3287, Test Accuracy = 0.8035\n",
      "Iteration 1092: Loss = 0.2939, Accuracy = 0.7700 Test Loss = 0.3283, Test Accuracy = 0.8034\n",
      "Iteration 1093: Loss = 0.2431, Accuracy = 0.8800 Test Loss = 0.3282, Test Accuracy = 0.8048\n",
      "Iteration 1094: Loss = 0.2966, Accuracy = 0.8100 Test Loss = 0.3282, Test Accuracy = 0.8066\n",
      "Iteration 1095: Loss = 0.2597, Accuracy = 0.8200 Test Loss = 0.3287, Test Accuracy = 0.8047\n",
      "Iteration 1096: Loss = 0.2401, Accuracy = 0.8700 Test Loss = 0.3278, Test Accuracy = 0.8043\n",
      "Iteration 1097: Loss = 0.2516, Accuracy = 0.8200 Test Loss = 0.3277, Test Accuracy = 0.8014\n",
      "Iteration 1098: Loss = 0.2755, Accuracy = 0.8300 Test Loss = 0.3279, Test Accuracy = 0.8037\n",
      "Iteration 1099: Loss = 0.2143, Accuracy = 0.8800 Test Loss = 0.3271, Test Accuracy = 0.8051\n",
      "Iteration 1100: Loss = 0.2927, Accuracy = 0.8700 Test Loss = 0.3268, Test Accuracy = 0.8039\n",
      "Iteration 1101: Loss = 0.3286, Accuracy = 0.8300 Test Loss = 0.3279, Test Accuracy = 0.8058\n",
      "Iteration 1102: Loss = 0.3343, Accuracy = 0.8600 Test Loss = 0.3276, Test Accuracy = 0.8044\n",
      "Iteration 1103: Loss = 0.3095, Accuracy = 0.7900 Test Loss = 0.3268, Test Accuracy = 0.8033\n",
      "Iteration 1104: Loss = 0.2965, Accuracy = 0.8200 Test Loss = 0.3269, Test Accuracy = 0.8053\n",
      "Iteration 1105: Loss = 0.2913, Accuracy = 0.8000 Test Loss = 0.3274, Test Accuracy = 0.8044\n",
      "Iteration 1106: Loss = 0.3196, Accuracy = 0.8400 Test Loss = 0.3260, Test Accuracy = 0.8052\n",
      "Iteration 1107: Loss = 0.2758, Accuracy = 0.8400 Test Loss = 0.3261, Test Accuracy = 0.8062\n",
      "Iteration 1108: Loss = 0.3000, Accuracy = 0.8300 Test Loss = 0.3267, Test Accuracy = 0.8076\n",
      "Iteration 1109: Loss = 0.2929, Accuracy = 0.8600 Test Loss = 0.3264, Test Accuracy = 0.8021\n",
      "Iteration 1110: Loss = 0.2365, Accuracy = 0.8300 Test Loss = 0.3259, Test Accuracy = 0.8053\n",
      "Iteration 1111: Loss = 0.2605, Accuracy = 0.8400 Test Loss = 0.3262, Test Accuracy = 0.8050\n",
      "Iteration 1112: Loss = 0.2921, Accuracy = 0.8300 Test Loss = 0.3261, Test Accuracy = 0.8012\n",
      "Iteration 1113: Loss = 0.3621, Accuracy = 0.8400 Test Loss = 0.3257, Test Accuracy = 0.8024\n",
      "Iteration 1114: Loss = 0.2733, Accuracy = 0.8400 Test Loss = 0.3255, Test Accuracy = 0.8034\n",
      "Iteration 1115: Loss = 0.2484, Accuracy = 0.8700 Test Loss = 0.3261, Test Accuracy = 0.8038\n",
      "Iteration 1116: Loss = 0.2482, Accuracy = 0.8900 Test Loss = 0.3255, Test Accuracy = 0.8074\n",
      "Iteration 1117: Loss = 0.2665, Accuracy = 0.8600 Test Loss = 0.3256, Test Accuracy = 0.8065\n",
      "Iteration 1118: Loss = 0.3811, Accuracy = 0.7700 Test Loss = 0.3254, Test Accuracy = 0.8081\n",
      "Iteration 1119: Loss = 0.2741, Accuracy = 0.9100 Test Loss = 0.3250, Test Accuracy = 0.8015\n",
      "Iteration 1120: Loss = 0.2817, Accuracy = 0.8600 Test Loss = 0.3245, Test Accuracy = 0.8053\n",
      "Iteration 1121: Loss = 0.2964, Accuracy = 0.8600 Test Loss = 0.3246, Test Accuracy = 0.8059\n",
      "Iteration 1122: Loss = 0.3371, Accuracy = 0.8200 Test Loss = 0.3249, Test Accuracy = 0.8035\n",
      "Iteration 1123: Loss = 0.2618, Accuracy = 0.8900 Test Loss = 0.3244, Test Accuracy = 0.8064\n",
      "Iteration 1124: Loss = 0.2972, Accuracy = 0.7900 Test Loss = 0.3251, Test Accuracy = 0.8080\n",
      "Iteration 1125: Loss = 0.2872, Accuracy = 0.8400 Test Loss = 0.3245, Test Accuracy = 0.8061\n",
      "Iteration 1126: Loss = 0.2847, Accuracy = 0.8600 Test Loss = 0.3245, Test Accuracy = 0.8038\n",
      "Iteration 1127: Loss = 0.2856, Accuracy = 0.7900 Test Loss = 0.3242, Test Accuracy = 0.8062\n",
      "Iteration 1128: Loss = 0.2856, Accuracy = 0.8300 Test Loss = 0.3242, Test Accuracy = 0.8040\n",
      "Iteration 1129: Loss = 0.2790, Accuracy = 0.7700 Test Loss = 0.3236, Test Accuracy = 0.8058\n",
      "Iteration 1130: Loss = 0.2496, Accuracy = 0.8300 Test Loss = 0.3239, Test Accuracy = 0.8051\n",
      "Iteration 1131: Loss = 0.3394, Accuracy = 0.8400 Test Loss = 0.3238, Test Accuracy = 0.8037\n",
      "Iteration 1132: Loss = 0.2973, Accuracy = 0.7800 Test Loss = 0.3230, Test Accuracy = 0.8065\n",
      "Iteration 1133: Loss = 0.2306, Accuracy = 0.8600 Test Loss = 0.3229, Test Accuracy = 0.8057\n",
      "Iteration 1134: Loss = 0.2997, Accuracy = 0.7700 Test Loss = 0.3234, Test Accuracy = 0.8048\n",
      "Iteration 1135: Loss = 0.2781, Accuracy = 0.8500 Test Loss = 0.3235, Test Accuracy = 0.8044\n",
      "Iteration 1136: Loss = 0.3329, Accuracy = 0.8300 Test Loss = 0.3236, Test Accuracy = 0.8016\n",
      "Iteration 1137: Loss = 0.2442, Accuracy = 0.8100 Test Loss = 0.3227, Test Accuracy = 0.8075\n",
      "Iteration 1138: Loss = 0.3057, Accuracy = 0.8300 Test Loss = 0.3223, Test Accuracy = 0.8059\n",
      "Iteration 1139: Loss = 0.2477, Accuracy = 0.8000 Test Loss = 0.3230, Test Accuracy = 0.8043\n",
      "Iteration 1140: Loss = 0.2781, Accuracy = 0.8700 Test Loss = 0.3232, Test Accuracy = 0.8060\n",
      "Iteration 1141: Loss = 0.2736, Accuracy = 0.8600 Test Loss = 0.3223, Test Accuracy = 0.8069\n",
      "Iteration 1142: Loss = 0.3085, Accuracy = 0.8200 Test Loss = 0.3220, Test Accuracy = 0.8082\n",
      "Iteration 1143: Loss = 0.2310, Accuracy = 0.8800 Test Loss = 0.3220, Test Accuracy = 0.8057\n",
      "Iteration 1144: Loss = 0.2195, Accuracy = 0.9300 Test Loss = 0.3225, Test Accuracy = 0.8078\n",
      "Iteration 1145: Loss = 0.3521, Accuracy = 0.7500 Test Loss = 0.3221, Test Accuracy = 0.8055\n",
      "Iteration 1146: Loss = 0.3307, Accuracy = 0.8000 Test Loss = 0.3221, Test Accuracy = 0.8051\n",
      "Iteration 1147: Loss = 0.2742, Accuracy = 0.8000 Test Loss = 0.3218, Test Accuracy = 0.8072\n",
      "Iteration 1148: Loss = 0.2454, Accuracy = 0.8600 Test Loss = 0.3217, Test Accuracy = 0.8067\n",
      "Iteration 1149: Loss = 0.2978, Accuracy = 0.8500 Test Loss = 0.3214, Test Accuracy = 0.8079\n",
      "Iteration 1150: Loss = 0.2452, Accuracy = 0.8000 Test Loss = 0.3216, Test Accuracy = 0.8058\n",
      "Iteration 1151: Loss = 0.2552, Accuracy = 0.8100 Test Loss = 0.3213, Test Accuracy = 0.8079\n",
      "Iteration 1152: Loss = 0.2736, Accuracy = 0.9000 Test Loss = 0.3214, Test Accuracy = 0.8057\n",
      "Iteration 1153: Loss = 0.2992, Accuracy = 0.8200 Test Loss = 0.3208, Test Accuracy = 0.8071\n",
      "Iteration 1154: Loss = 0.3133, Accuracy = 0.8200 Test Loss = 0.3213, Test Accuracy = 0.8081\n",
      "Iteration 1155: Loss = 0.2788, Accuracy = 0.8500 Test Loss = 0.3211, Test Accuracy = 0.8053\n",
      "Iteration 1156: Loss = 0.2524, Accuracy = 0.8700 Test Loss = 0.3218, Test Accuracy = 0.8064\n",
      "Iteration 1157: Loss = 0.2697, Accuracy = 0.8500 Test Loss = 0.3211, Test Accuracy = 0.8091\n",
      "Iteration 1158: Loss = 0.2748, Accuracy = 0.7900 Test Loss = 0.3207, Test Accuracy = 0.8078\n",
      "Iteration 1159: Loss = 0.2642, Accuracy = 0.8000 Test Loss = 0.3204, Test Accuracy = 0.8052\n",
      "Iteration 1160: Loss = 0.2316, Accuracy = 0.8500 Test Loss = 0.3199, Test Accuracy = 0.8081\n",
      "Iteration 1161: Loss = 0.2519, Accuracy = 0.8300 Test Loss = 0.3201, Test Accuracy = 0.8076\n",
      "Iteration 1162: Loss = 0.2482, Accuracy = 0.8700 Test Loss = 0.3197, Test Accuracy = 0.8053\n",
      "Iteration 1163: Loss = 0.2993, Accuracy = 0.8200 Test Loss = 0.3201, Test Accuracy = 0.8065\n",
      "Iteration 1164: Loss = 0.2835, Accuracy = 0.8500 Test Loss = 0.3200, Test Accuracy = 0.8058\n",
      "Iteration 1165: Loss = 0.2671, Accuracy = 0.8300 Test Loss = 0.3196, Test Accuracy = 0.8092\n",
      "Iteration 1166: Loss = 0.2905, Accuracy = 0.8300 Test Loss = 0.3204, Test Accuracy = 0.8057\n",
      "Iteration 1167: Loss = 0.3457, Accuracy = 0.7800 Test Loss = 0.3195, Test Accuracy = 0.8093\n",
      "Iteration 1168: Loss = 0.2740, Accuracy = 0.8000 Test Loss = 0.3196, Test Accuracy = 0.8068\n",
      "Iteration 1169: Loss = 0.3013, Accuracy = 0.7700 Test Loss = 0.3196, Test Accuracy = 0.8065\n",
      "Iteration 1170: Loss = 0.2334, Accuracy = 0.9000 Test Loss = 0.3191, Test Accuracy = 0.8078\n",
      "Iteration 1171: Loss = 0.2149, Accuracy = 0.8800 Test Loss = 0.3196, Test Accuracy = 0.8055\n",
      "Iteration 1172: Loss = 0.2630, Accuracy = 0.8500 Test Loss = 0.3189, Test Accuracy = 0.8085\n",
      "Iteration 1173: Loss = 0.2717, Accuracy = 0.8500 Test Loss = 0.3190, Test Accuracy = 0.8091\n",
      "Iteration 1174: Loss = 0.2876, Accuracy = 0.8300 Test Loss = 0.3204, Test Accuracy = 0.8080\n",
      "Iteration 1175: Loss = 0.2702, Accuracy = 0.8500 Test Loss = 0.3189, Test Accuracy = 0.8085\n",
      "Iteration 1176: Loss = 0.2577, Accuracy = 0.8300 Test Loss = 0.3187, Test Accuracy = 0.8078\n",
      "Iteration 1177: Loss = 0.2823, Accuracy = 0.8600 Test Loss = 0.3183, Test Accuracy = 0.8099\n",
      "Iteration 1178: Loss = 0.2457, Accuracy = 0.9000 Test Loss = 0.3183, Test Accuracy = 0.8085\n",
      "Iteration 1179: Loss = 0.3394, Accuracy = 0.7200 Test Loss = 0.3183, Test Accuracy = 0.8097\n",
      "Iteration 1180: Loss = 0.2816, Accuracy = 0.7900 Test Loss = 0.3182, Test Accuracy = 0.8102\n",
      "Iteration 1181: Loss = 0.2738, Accuracy = 0.8500 Test Loss = 0.3179, Test Accuracy = 0.8092\n",
      "Iteration 1182: Loss = 0.2620, Accuracy = 0.8500 Test Loss = 0.3177, Test Accuracy = 0.8069\n",
      "Iteration 1183: Loss = 0.3303, Accuracy = 0.7500 Test Loss = 0.3186, Test Accuracy = 0.8100\n",
      "Iteration 1184: Loss = 0.2748, Accuracy = 0.8900 Test Loss = 0.3186, Test Accuracy = 0.8035\n",
      "Iteration 1185: Loss = 0.2345, Accuracy = 0.8500 Test Loss = 0.3176, Test Accuracy = 0.8090\n",
      "Iteration 1186: Loss = 0.3516, Accuracy = 0.8600 Test Loss = 0.3172, Test Accuracy = 0.8101\n",
      "Iteration 1187: Loss = 0.2710, Accuracy = 0.8400 Test Loss = 0.3179, Test Accuracy = 0.8060\n",
      "Iteration 1188: Loss = 0.2524, Accuracy = 0.8300 Test Loss = 0.3170, Test Accuracy = 0.8111\n",
      "Iteration 1189: Loss = 0.2837, Accuracy = 0.8300 Test Loss = 0.3173, Test Accuracy = 0.8070\n",
      "Iteration 1190: Loss = 0.3406, Accuracy = 0.7800 Test Loss = 0.3173, Test Accuracy = 0.8100\n",
      "Iteration 1191: Loss = 0.2732, Accuracy = 0.8700 Test Loss = 0.3173, Test Accuracy = 0.8081\n",
      "Iteration 1192: Loss = 0.3054, Accuracy = 0.8200 Test Loss = 0.3176, Test Accuracy = 0.8052\n",
      "Iteration 1193: Loss = 0.2557, Accuracy = 0.8400 Test Loss = 0.3174, Test Accuracy = 0.8104\n",
      "Iteration 1194: Loss = 0.2887, Accuracy = 0.8200 Test Loss = 0.3164, Test Accuracy = 0.8077\n",
      "Iteration 1195: Loss = 0.2233, Accuracy = 0.9300 Test Loss = 0.3171, Test Accuracy = 0.8043\n",
      "Iteration 1196: Loss = 0.3047, Accuracy = 0.8400 Test Loss = 0.3169, Test Accuracy = 0.8073\n",
      "Iteration 1197: Loss = 0.3679, Accuracy = 0.8300 Test Loss = 0.3165, Test Accuracy = 0.8074\n",
      "Iteration 1198: Loss = 0.2519, Accuracy = 0.8600 Test Loss = 0.3166, Test Accuracy = 0.8090\n",
      "Iteration 1199: Loss = 0.2595, Accuracy = 0.9000 Test Loss = 0.3165, Test Accuracy = 0.8071\n",
      "Iteration 1200: Loss = 0.3017, Accuracy = 0.8600 Test Loss = 0.3161, Test Accuracy = 0.8085\n",
      "Iteration 1201: Loss = 0.2653, Accuracy = 0.8100 Test Loss = 0.3166, Test Accuracy = 0.8102\n",
      "Iteration 1202: Loss = 0.2582, Accuracy = 0.8500 Test Loss = 0.3164, Test Accuracy = 0.8073\n",
      "Iteration 1203: Loss = 0.2296, Accuracy = 0.8200 Test Loss = 0.3155, Test Accuracy = 0.8083\n",
      "Iteration 1204: Loss = 0.2779, Accuracy = 0.8400 Test Loss = 0.3159, Test Accuracy = 0.8074\n",
      "Iteration 1205: Loss = 0.2790, Accuracy = 0.8600 Test Loss = 0.3153, Test Accuracy = 0.8089\n",
      "Iteration 1206: Loss = 0.2928, Accuracy = 0.8900 Test Loss = 0.3157, Test Accuracy = 0.8110\n",
      "Iteration 1207: Loss = 0.2681, Accuracy = 0.8100 Test Loss = 0.3160, Test Accuracy = 0.8065\n",
      "Iteration 1208: Loss = 0.2584, Accuracy = 0.7800 Test Loss = 0.3152, Test Accuracy = 0.8129\n",
      "Iteration 1209: Loss = 0.2833, Accuracy = 0.8500 Test Loss = 0.3152, Test Accuracy = 0.8102\n",
      "Iteration 1210: Loss = 0.2890, Accuracy = 0.8500 Test Loss = 0.3155, Test Accuracy = 0.8069\n",
      "Iteration 1211: Loss = 0.2929, Accuracy = 0.8400 Test Loss = 0.3153, Test Accuracy = 0.8091\n",
      "Iteration 1212: Loss = 0.2784, Accuracy = 0.8000 Test Loss = 0.3149, Test Accuracy = 0.8105\n",
      "Iteration 1213: Loss = 0.2487, Accuracy = 0.8700 Test Loss = 0.3148, Test Accuracy = 0.8110\n",
      "Iteration 1214: Loss = 0.3319, Accuracy = 0.8000 Test Loss = 0.3145, Test Accuracy = 0.8076\n",
      "Iteration 1215: Loss = 0.2731, Accuracy = 0.8200 Test Loss = 0.3146, Test Accuracy = 0.8080\n",
      "Iteration 1216: Loss = 0.2573, Accuracy = 0.8400 Test Loss = 0.3146, Test Accuracy = 0.8097\n",
      "Iteration 1217: Loss = 0.2809, Accuracy = 0.8900 Test Loss = 0.3150, Test Accuracy = 0.8118\n",
      "Iteration 1218: Loss = 0.2357, Accuracy = 0.8400 Test Loss = 0.3142, Test Accuracy = 0.8110\n",
      "Iteration 1219: Loss = 0.2626, Accuracy = 0.8700 Test Loss = 0.3140, Test Accuracy = 0.8099\n",
      "Iteration 1220: Loss = 0.2514, Accuracy = 0.8700 Test Loss = 0.3143, Test Accuracy = 0.8119\n",
      "Iteration 1221: Loss = 0.2602, Accuracy = 0.8900 Test Loss = 0.3148, Test Accuracy = 0.8060\n",
      "Iteration 1222: Loss = 0.2744, Accuracy = 0.8200 Test Loss = 0.3140, Test Accuracy = 0.8119\n",
      "Iteration 1223: Loss = 0.3156, Accuracy = 0.7300 Test Loss = 0.3134, Test Accuracy = 0.8106\n",
      "Iteration 1224: Loss = 0.3230, Accuracy = 0.8100 Test Loss = 0.3132, Test Accuracy = 0.8083\n",
      "Iteration 1225: Loss = 0.2692, Accuracy = 0.8400 Test Loss = 0.3138, Test Accuracy = 0.8104\n",
      "Iteration 1226: Loss = 0.2567, Accuracy = 0.8200 Test Loss = 0.3133, Test Accuracy = 0.8081\n",
      "Iteration 1227: Loss = 0.2829, Accuracy = 0.8300 Test Loss = 0.3136, Test Accuracy = 0.8083\n",
      "Iteration 1228: Loss = 0.3028, Accuracy = 0.8000 Test Loss = 0.3130, Test Accuracy = 0.8097\n",
      "Iteration 1229: Loss = 0.3037, Accuracy = 0.7900 Test Loss = 0.3128, Test Accuracy = 0.8102\n",
      "Iteration 1230: Loss = 0.2754, Accuracy = 0.8400 Test Loss = 0.3132, Test Accuracy = 0.8122\n",
      "Iteration 1231: Loss = 0.2706, Accuracy = 0.8600 Test Loss = 0.3134, Test Accuracy = 0.8059\n",
      "Iteration 1232: Loss = 0.3016, Accuracy = 0.8300 Test Loss = 0.3137, Test Accuracy = 0.8098\n",
      "Iteration 1233: Loss = 0.2379, Accuracy = 0.8600 Test Loss = 0.3125, Test Accuracy = 0.8104\n",
      "Iteration 1234: Loss = 0.2886, Accuracy = 0.8800 Test Loss = 0.3125, Test Accuracy = 0.8114\n",
      "Iteration 1235: Loss = 0.2404, Accuracy = 0.8800 Test Loss = 0.3121, Test Accuracy = 0.8093\n",
      "Iteration 1236: Loss = 0.2857, Accuracy = 0.8300 Test Loss = 0.3125, Test Accuracy = 0.8104\n",
      "Iteration 1237: Loss = 0.2835, Accuracy = 0.8600 Test Loss = 0.3123, Test Accuracy = 0.8120\n",
      "Iteration 1238: Loss = 0.2746, Accuracy = 0.8300 Test Loss = 0.3126, Test Accuracy = 0.8084\n",
      "Iteration 1239: Loss = 0.3102, Accuracy = 0.8300 Test Loss = 0.3127, Test Accuracy = 0.8080\n",
      "Iteration 1240: Loss = 0.2630, Accuracy = 0.7700 Test Loss = 0.3127, Test Accuracy = 0.8072\n",
      "Iteration 1241: Loss = 0.2693, Accuracy = 0.8200 Test Loss = 0.3123, Test Accuracy = 0.8091\n",
      "Iteration 1242: Loss = 0.2831, Accuracy = 0.8100 Test Loss = 0.3127, Test Accuracy = 0.8108\n",
      "Iteration 1243: Loss = 0.2582, Accuracy = 0.9300 Test Loss = 0.3116, Test Accuracy = 0.8095\n",
      "Iteration 1244: Loss = 0.3215, Accuracy = 0.7700 Test Loss = 0.3120, Test Accuracy = 0.8088\n",
      "Iteration 1245: Loss = 0.3073, Accuracy = 0.7700 Test Loss = 0.3116, Test Accuracy = 0.8121\n",
      "Iteration 1246: Loss = 0.2720, Accuracy = 0.7900 Test Loss = 0.3121, Test Accuracy = 0.8129\n",
      "Iteration 1247: Loss = 0.2389, Accuracy = 0.8700 Test Loss = 0.3114, Test Accuracy = 0.8102\n",
      "Iteration 1248: Loss = 0.2487, Accuracy = 0.8800 Test Loss = 0.3114, Test Accuracy = 0.8098\n",
      "Iteration 1249: Loss = 0.2833, Accuracy = 0.8600 Test Loss = 0.3120, Test Accuracy = 0.8088\n",
      "Iteration 1250: Loss = 0.2308, Accuracy = 0.8600 Test Loss = 0.3110, Test Accuracy = 0.8117\n",
      "Iteration 1251: Loss = 0.3080, Accuracy = 0.7700 Test Loss = 0.3107, Test Accuracy = 0.8124\n",
      "Iteration 1252: Loss = 0.2842, Accuracy = 0.7700 Test Loss = 0.3111, Test Accuracy = 0.8130\n",
      "Iteration 1253: Loss = 0.3131, Accuracy = 0.7900 Test Loss = 0.3107, Test Accuracy = 0.8104\n",
      "Iteration 1254: Loss = 0.2451, Accuracy = 0.8400 Test Loss = 0.3106, Test Accuracy = 0.8097\n",
      "Iteration 1255: Loss = 0.3125, Accuracy = 0.8100 Test Loss = 0.3111, Test Accuracy = 0.8096\n",
      "Iteration 1256: Loss = 0.2596, Accuracy = 0.8000 Test Loss = 0.3106, Test Accuracy = 0.8101\n",
      "Iteration 1257: Loss = 0.2899, Accuracy = 0.8200 Test Loss = 0.3105, Test Accuracy = 0.8128\n",
      "Iteration 1258: Loss = 0.3156, Accuracy = 0.8400 Test Loss = 0.3107, Test Accuracy = 0.8104\n",
      "Iteration 1259: Loss = 0.2396, Accuracy = 0.8800 Test Loss = 0.3105, Test Accuracy = 0.8110\n",
      "Iteration 1260: Loss = 0.3087, Accuracy = 0.8000 Test Loss = 0.3101, Test Accuracy = 0.8127\n",
      "Iteration 1261: Loss = 0.2587, Accuracy = 0.8500 Test Loss = 0.3101, Test Accuracy = 0.8122\n",
      "Iteration 1262: Loss = 0.2724, Accuracy = 0.8300 Test Loss = 0.3102, Test Accuracy = 0.8129\n",
      "Iteration 1263: Loss = 0.2536, Accuracy = 0.8600 Test Loss = 0.3099, Test Accuracy = 0.8125\n",
      "Iteration 1264: Loss = 0.2585, Accuracy = 0.8400 Test Loss = 0.3102, Test Accuracy = 0.8095\n",
      "Iteration 1265: Loss = 0.2886, Accuracy = 0.8600 Test Loss = 0.3099, Test Accuracy = 0.8123\n",
      "Iteration 1266: Loss = 0.2934, Accuracy = 0.8400 Test Loss = 0.3097, Test Accuracy = 0.8116\n",
      "Iteration 1267: Loss = 0.2800, Accuracy = 0.8700 Test Loss = 0.3101, Test Accuracy = 0.8078\n",
      "Iteration 1268: Loss = 0.1957, Accuracy = 0.8800 Test Loss = 0.3106, Test Accuracy = 0.8078\n",
      "Iteration 1269: Loss = 0.2920, Accuracy = 0.8400 Test Loss = 0.3093, Test Accuracy = 0.8120\n",
      "Iteration 1270: Loss = 0.2658, Accuracy = 0.8400 Test Loss = 0.3093, Test Accuracy = 0.8102\n",
      "Iteration 1271: Loss = 0.2541, Accuracy = 0.8400 Test Loss = 0.3090, Test Accuracy = 0.8117\n",
      "Iteration 1272: Loss = 0.2514, Accuracy = 0.8500 Test Loss = 0.3096, Test Accuracy = 0.8090\n",
      "Iteration 1273: Loss = 0.2644, Accuracy = 0.8300 Test Loss = 0.3099, Test Accuracy = 0.8078\n",
      "Iteration 1274: Loss = 0.2624, Accuracy = 0.8500 Test Loss = 0.3091, Test Accuracy = 0.8121\n",
      "Iteration 1275: Loss = 0.2717, Accuracy = 0.7800 Test Loss = 0.3092, Test Accuracy = 0.8123\n",
      "Iteration 1276: Loss = 0.2865, Accuracy = 0.8400 Test Loss = 0.3088, Test Accuracy = 0.8132\n",
      "Iteration 1277: Loss = 0.2962, Accuracy = 0.8600 Test Loss = 0.3094, Test Accuracy = 0.8148\n",
      "Iteration 1278: Loss = 0.3150, Accuracy = 0.7500 Test Loss = 0.3085, Test Accuracy = 0.8107\n",
      "Iteration 1279: Loss = 0.2265, Accuracy = 0.8900 Test Loss = 0.3084, Test Accuracy = 0.8131\n",
      "Iteration 1280: Loss = 0.2407, Accuracy = 0.9100 Test Loss = 0.3088, Test Accuracy = 0.8137\n",
      "Iteration 1281: Loss = 0.2860, Accuracy = 0.7800 Test Loss = 0.3085, Test Accuracy = 0.8098\n",
      "Iteration 1282: Loss = 0.2492, Accuracy = 0.8300 Test Loss = 0.3080, Test Accuracy = 0.8117\n",
      "Iteration 1283: Loss = 0.2937, Accuracy = 0.8400 Test Loss = 0.3080, Test Accuracy = 0.8130\n",
      "Iteration 1284: Loss = 0.2649, Accuracy = 0.8400 Test Loss = 0.3085, Test Accuracy = 0.8136\n",
      "Iteration 1285: Loss = 0.2857, Accuracy = 0.8300 Test Loss = 0.3084, Test Accuracy = 0.8130\n",
      "Iteration 1286: Loss = 0.2806, Accuracy = 0.8400 Test Loss = 0.3089, Test Accuracy = 0.8098\n",
      "Iteration 1287: Loss = 0.2240, Accuracy = 0.8700 Test Loss = 0.3077, Test Accuracy = 0.8124\n",
      "Iteration 1288: Loss = 0.2933, Accuracy = 0.8400 Test Loss = 0.3083, Test Accuracy = 0.8145\n",
      "Iteration 1289: Loss = 0.3115, Accuracy = 0.8000 Test Loss = 0.3078, Test Accuracy = 0.8136\n",
      "Iteration 1290: Loss = 0.2560, Accuracy = 0.8600 Test Loss = 0.3081, Test Accuracy = 0.8144\n",
      "Iteration 1291: Loss = 0.2471, Accuracy = 0.8700 Test Loss = 0.3076, Test Accuracy = 0.8089\n",
      "Iteration 1292: Loss = 0.3321, Accuracy = 0.7900 Test Loss = 0.3070, Test Accuracy = 0.8122\n",
      "Iteration 1293: Loss = 0.2509, Accuracy = 0.9200 Test Loss = 0.3073, Test Accuracy = 0.8116\n",
      "Iteration 1294: Loss = 0.2244, Accuracy = 0.8600 Test Loss = 0.3070, Test Accuracy = 0.8117\n",
      "Iteration 1295: Loss = 0.2534, Accuracy = 0.8300 Test Loss = 0.3076, Test Accuracy = 0.8112\n",
      "Iteration 1296: Loss = 0.2373, Accuracy = 0.8700 Test Loss = 0.3074, Test Accuracy = 0.8125\n",
      "Iteration 1297: Loss = 0.2402, Accuracy = 0.8700 Test Loss = 0.3071, Test Accuracy = 0.8111\n",
      "Iteration 1298: Loss = 0.2460, Accuracy = 0.8700 Test Loss = 0.3065, Test Accuracy = 0.8111\n",
      "Iteration 1299: Loss = 0.2589, Accuracy = 0.8800 Test Loss = 0.3064, Test Accuracy = 0.8116\n",
      "Iteration 1300: Loss = 0.2575, Accuracy = 0.8300 Test Loss = 0.3071, Test Accuracy = 0.8099\n",
      "Iteration 1301: Loss = 0.2519, Accuracy = 0.8300 Test Loss = 0.3071, Test Accuracy = 0.8105\n",
      "Iteration 1302: Loss = 0.3107, Accuracy = 0.8700 Test Loss = 0.3072, Test Accuracy = 0.8133\n",
      "Iteration 1303: Loss = 0.2464, Accuracy = 0.8100 Test Loss = 0.3068, Test Accuracy = 0.8132\n",
      "Iteration 1304: Loss = 0.2872, Accuracy = 0.7100 Test Loss = 0.3070, Test Accuracy = 0.8130\n",
      "Iteration 1305: Loss = 0.2399, Accuracy = 0.8800 Test Loss = 0.3068, Test Accuracy = 0.8103\n",
      "Iteration 1306: Loss = 0.2471, Accuracy = 0.8500 Test Loss = 0.3059, Test Accuracy = 0.8120\n",
      "Iteration 1307: Loss = 0.2546, Accuracy = 0.8200 Test Loss = 0.3058, Test Accuracy = 0.8142\n",
      "Iteration 1308: Loss = 0.2320, Accuracy = 0.8400 Test Loss = 0.3058, Test Accuracy = 0.8119\n",
      "Iteration 1309: Loss = 0.3147, Accuracy = 0.8100 Test Loss = 0.3070, Test Accuracy = 0.8100\n",
      "Iteration 1310: Loss = 0.2029, Accuracy = 0.9300 Test Loss = 0.3059, Test Accuracy = 0.8106\n",
      "Iteration 1311: Loss = 0.3400, Accuracy = 0.7400 Test Loss = 0.3059, Test Accuracy = 0.8138\n",
      "Iteration 1312: Loss = 0.2361, Accuracy = 0.8400 Test Loss = 0.3060, Test Accuracy = 0.8115\n",
      "Iteration 1313: Loss = 0.2271, Accuracy = 0.8900 Test Loss = 0.3071, Test Accuracy = 0.8077\n",
      "Iteration 1314: Loss = 0.2802, Accuracy = 0.8600 Test Loss = 0.3061, Test Accuracy = 0.8111\n",
      "Iteration 1315: Loss = 0.2888, Accuracy = 0.8200 Test Loss = 0.3053, Test Accuracy = 0.8104\n",
      "Iteration 1316: Loss = 0.2548, Accuracy = 0.8400 Test Loss = 0.3057, Test Accuracy = 0.8094\n",
      "Iteration 1317: Loss = 0.2168, Accuracy = 0.9200 Test Loss = 0.3051, Test Accuracy = 0.8104\n",
      "Iteration 1318: Loss = 0.2156, Accuracy = 0.9100 Test Loss = 0.3054, Test Accuracy = 0.8124\n",
      "Iteration 1319: Loss = 0.3301, Accuracy = 0.8500 Test Loss = 0.3053, Test Accuracy = 0.8098\n",
      "Iteration 1320: Loss = 0.2751, Accuracy = 0.8100 Test Loss = 0.3060, Test Accuracy = 0.8111\n",
      "Iteration 1321: Loss = 0.2387, Accuracy = 0.8600 Test Loss = 0.3049, Test Accuracy = 0.8109\n",
      "Iteration 1322: Loss = 0.3038, Accuracy = 0.7800 Test Loss = 0.3049, Test Accuracy = 0.8112\n",
      "Iteration 1323: Loss = 0.2692, Accuracy = 0.8600 Test Loss = 0.3044, Test Accuracy = 0.8123\n",
      "Iteration 1324: Loss = 0.2681, Accuracy = 0.8400 Test Loss = 0.3055, Test Accuracy = 0.8116\n",
      "Iteration 1325: Loss = 0.2740, Accuracy = 0.8100 Test Loss = 0.3058, Test Accuracy = 0.8140\n",
      "Iteration 1326: Loss = 0.3077, Accuracy = 0.8100 Test Loss = 0.3046, Test Accuracy = 0.8125\n",
      "Iteration 1327: Loss = 0.2667, Accuracy = 0.8300 Test Loss = 0.3047, Test Accuracy = 0.8124\n",
      "Iteration 1328: Loss = 0.2457, Accuracy = 0.8800 Test Loss = 0.3044, Test Accuracy = 0.8117\n",
      "Iteration 1329: Loss = 0.2532, Accuracy = 0.8300 Test Loss = 0.3050, Test Accuracy = 0.8103\n",
      "Iteration 1330: Loss = 0.2625, Accuracy = 0.8600 Test Loss = 0.3048, Test Accuracy = 0.8121\n",
      "Iteration 1331: Loss = 0.2367, Accuracy = 0.8300 Test Loss = 0.3044, Test Accuracy = 0.8119\n",
      "Iteration 1332: Loss = 0.2159, Accuracy = 0.9000 Test Loss = 0.3051, Test Accuracy = 0.8107\n",
      "Iteration 1333: Loss = 0.3090, Accuracy = 0.8600 Test Loss = 0.3050, Test Accuracy = 0.8146\n",
      "Iteration 1334: Loss = 0.2276, Accuracy = 0.8500 Test Loss = 0.3038, Test Accuracy = 0.8163\n",
      "Iteration 1335: Loss = 0.2446, Accuracy = 0.8200 Test Loss = 0.3039, Test Accuracy = 0.8130\n",
      "Iteration 1336: Loss = 0.2856, Accuracy = 0.8100 Test Loss = 0.3047, Test Accuracy = 0.8135\n",
      "Iteration 1337: Loss = 0.3197, Accuracy = 0.8000 Test Loss = 0.3042, Test Accuracy = 0.8130\n",
      "Iteration 1338: Loss = 0.2473, Accuracy = 0.8300 Test Loss = 0.3037, Test Accuracy = 0.8153\n",
      "Iteration 1339: Loss = 0.2740, Accuracy = 0.8100 Test Loss = 0.3036, Test Accuracy = 0.8149\n",
      "Iteration 1340: Loss = 0.3058, Accuracy = 0.8500 Test Loss = 0.3035, Test Accuracy = 0.8110\n",
      "Iteration 1341: Loss = 0.2166, Accuracy = 0.8600 Test Loss = 0.3030, Test Accuracy = 0.8115\n",
      "Iteration 1342: Loss = 0.2650, Accuracy = 0.7800 Test Loss = 0.3036, Test Accuracy = 0.8132\n",
      "Iteration 1343: Loss = 0.2234, Accuracy = 0.8900 Test Loss = 0.3033, Test Accuracy = 0.8108\n",
      "Iteration 1344: Loss = 0.2431, Accuracy = 0.8700 Test Loss = 0.3031, Test Accuracy = 0.8140\n",
      "Iteration 1345: Loss = 0.2371, Accuracy = 0.8600 Test Loss = 0.3032, Test Accuracy = 0.8124\n",
      "Iteration 1346: Loss = 0.2941, Accuracy = 0.7700 Test Loss = 0.3039, Test Accuracy = 0.8144\n",
      "Iteration 1347: Loss = 0.2603, Accuracy = 0.8300 Test Loss = 0.3037, Test Accuracy = 0.8121\n",
      "Iteration 1348: Loss = 0.2592, Accuracy = 0.8500 Test Loss = 0.3031, Test Accuracy = 0.8149\n",
      "Iteration 1349: Loss = 0.2876, Accuracy = 0.8100 Test Loss = 0.3029, Test Accuracy = 0.8148\n",
      "Iteration 1350: Loss = 0.2503, Accuracy = 0.8600 Test Loss = 0.3031, Test Accuracy = 0.8135\n",
      "Iteration 1351: Loss = 0.2325, Accuracy = 0.8500 Test Loss = 0.3036, Test Accuracy = 0.8115\n",
      "Iteration 1352: Loss = 0.2542, Accuracy = 0.8300 Test Loss = 0.3034, Test Accuracy = 0.8124\n",
      "Iteration 1353: Loss = 0.2309, Accuracy = 0.8800 Test Loss = 0.3030, Test Accuracy = 0.8143\n",
      "Iteration 1354: Loss = 0.2530, Accuracy = 0.8700 Test Loss = 0.3024, Test Accuracy = 0.8143\n",
      "Iteration 1355: Loss = 0.2429, Accuracy = 0.8400 Test Loss = 0.3021, Test Accuracy = 0.8137\n",
      "Iteration 1356: Loss = 0.2557, Accuracy = 0.8500 Test Loss = 0.3019, Test Accuracy = 0.8115\n",
      "Iteration 1357: Loss = 0.2446, Accuracy = 0.8500 Test Loss = 0.3021, Test Accuracy = 0.8145\n",
      "Iteration 1358: Loss = 0.2727, Accuracy = 0.8400 Test Loss = 0.3020, Test Accuracy = 0.8124\n",
      "Iteration 1359: Loss = 0.2864, Accuracy = 0.7700 Test Loss = 0.3022, Test Accuracy = 0.8151\n",
      "Iteration 1360: Loss = 0.2494, Accuracy = 0.9000 Test Loss = 0.3018, Test Accuracy = 0.8142\n",
      "Iteration 1361: Loss = 0.2828, Accuracy = 0.8000 Test Loss = 0.3019, Test Accuracy = 0.8119\n",
      "Iteration 1362: Loss = 0.2748, Accuracy = 0.7800 Test Loss = 0.3022, Test Accuracy = 0.8148\n",
      "Iteration 1363: Loss = 0.2677, Accuracy = 0.8300 Test Loss = 0.3015, Test Accuracy = 0.8142\n",
      "Iteration 1364: Loss = 0.2558, Accuracy = 0.8400 Test Loss = 0.3018, Test Accuracy = 0.8141\n",
      "Iteration 1365: Loss = 0.2546, Accuracy = 0.8800 Test Loss = 0.3018, Test Accuracy = 0.8153\n",
      "Iteration 1366: Loss = 0.2432, Accuracy = 0.8200 Test Loss = 0.3019, Test Accuracy = 0.8141\n",
      "Iteration 1367: Loss = 0.3016, Accuracy = 0.8000 Test Loss = 0.3011, Test Accuracy = 0.8151\n",
      "Iteration 1368: Loss = 0.2470, Accuracy = 0.8700 Test Loss = 0.3011, Test Accuracy = 0.8148\n",
      "Iteration 1369: Loss = 0.2172, Accuracy = 0.8500 Test Loss = 0.3014, Test Accuracy = 0.8151\n",
      "Iteration 1370: Loss = 0.2439, Accuracy = 0.8900 Test Loss = 0.3011, Test Accuracy = 0.8149\n",
      "Iteration 1371: Loss = 0.2115, Accuracy = 0.8700 Test Loss = 0.3018, Test Accuracy = 0.8131\n",
      "Iteration 1372: Loss = 0.2933, Accuracy = 0.8300 Test Loss = 0.3012, Test Accuracy = 0.8163\n",
      "Iteration 1373: Loss = 0.2457, Accuracy = 0.8700 Test Loss = 0.3007, Test Accuracy = 0.8110\n",
      "Iteration 1374: Loss = 0.2541, Accuracy = 0.8600 Test Loss = 0.3009, Test Accuracy = 0.8135\n",
      "Iteration 1375: Loss = 0.2295, Accuracy = 0.8100 Test Loss = 0.3008, Test Accuracy = 0.8148\n",
      "Iteration 1376: Loss = 0.3436, Accuracy = 0.7700 Test Loss = 0.3005, Test Accuracy = 0.8140\n",
      "Iteration 1377: Loss = 0.2603, Accuracy = 0.8300 Test Loss = 0.3008, Test Accuracy = 0.8145\n",
      "Iteration 1378: Loss = 0.2746, Accuracy = 0.8300 Test Loss = 0.3006, Test Accuracy = 0.8166\n",
      "Iteration 1379: Loss = 0.2598, Accuracy = 0.8800 Test Loss = 0.3008, Test Accuracy = 0.8148\n",
      "Iteration 1380: Loss = 0.2800, Accuracy = 0.7700 Test Loss = 0.3005, Test Accuracy = 0.8144\n",
      "Iteration 1381: Loss = 0.2623, Accuracy = 0.8100 Test Loss = 0.3013, Test Accuracy = 0.8151\n",
      "Iteration 1382: Loss = 0.2526, Accuracy = 0.8400 Test Loss = 0.3004, Test Accuracy = 0.8150\n",
      "Iteration 1383: Loss = 0.2341, Accuracy = 0.8700 Test Loss = 0.3001, Test Accuracy = 0.8162\n",
      "Iteration 1384: Loss = 0.2831, Accuracy = 0.7900 Test Loss = 0.2998, Test Accuracy = 0.8152\n",
      "Iteration 1385: Loss = 0.2885, Accuracy = 0.8300 Test Loss = 0.3000, Test Accuracy = 0.8130\n",
      "Iteration 1386: Loss = 0.2397, Accuracy = 0.8900 Test Loss = 0.3005, Test Accuracy = 0.8093\n",
      "Iteration 1387: Loss = 0.2460, Accuracy = 0.8800 Test Loss = 0.3007, Test Accuracy = 0.8146\n",
      "Iteration 1388: Loss = 0.2363, Accuracy = 0.8400 Test Loss = 0.3001, Test Accuracy = 0.8122\n",
      "Iteration 1389: Loss = 0.2237, Accuracy = 0.8500 Test Loss = 0.2999, Test Accuracy = 0.8168\n",
      "Iteration 1390: Loss = 0.2633, Accuracy = 0.8600 Test Loss = 0.2995, Test Accuracy = 0.8127\n",
      "Iteration 1391: Loss = 0.2675, Accuracy = 0.8100 Test Loss = 0.2997, Test Accuracy = 0.8144\n",
      "Iteration 1392: Loss = 0.2649, Accuracy = 0.8400 Test Loss = 0.2998, Test Accuracy = 0.8125\n",
      "Iteration 1393: Loss = 0.2614, Accuracy = 0.8200 Test Loss = 0.3004, Test Accuracy = 0.8164\n",
      "Iteration 1394: Loss = 0.2454, Accuracy = 0.8800 Test Loss = 0.2994, Test Accuracy = 0.8138\n",
      "Iteration 1395: Loss = 0.2213, Accuracy = 0.8500 Test Loss = 0.3001, Test Accuracy = 0.8167\n",
      "Iteration 1396: Loss = 0.2833, Accuracy = 0.8600 Test Loss = 0.2993, Test Accuracy = 0.8118\n",
      "Iteration 1397: Loss = 0.3071, Accuracy = 0.8500 Test Loss = 0.2996, Test Accuracy = 0.8115\n",
      "Iteration 1398: Loss = 0.2217, Accuracy = 0.9100 Test Loss = 0.2989, Test Accuracy = 0.8154\n",
      "Iteration 1399: Loss = 0.2314, Accuracy = 0.9100 Test Loss = 0.2987, Test Accuracy = 0.8144\n",
      "Iteration 1400: Loss = 0.2183, Accuracy = 0.9000 Test Loss = 0.2999, Test Accuracy = 0.8169\n",
      "Iteration 1401: Loss = 0.3128, Accuracy = 0.8100 Test Loss = 0.3013, Test Accuracy = 0.8147\n",
      "Iteration 1402: Loss = 0.2462, Accuracy = 0.8300 Test Loss = 0.2986, Test Accuracy = 0.8156\n",
      "Iteration 1403: Loss = 0.2445, Accuracy = 0.8500 Test Loss = 0.2987, Test Accuracy = 0.8169\n",
      "Iteration 1404: Loss = 0.2835, Accuracy = 0.8100 Test Loss = 0.2999, Test Accuracy = 0.8157\n",
      "Iteration 1405: Loss = 0.2559, Accuracy = 0.8400 Test Loss = 0.2987, Test Accuracy = 0.8156\n",
      "Iteration 1406: Loss = 0.2413, Accuracy = 0.8300 Test Loss = 0.2992, Test Accuracy = 0.8152\n",
      "Iteration 1407: Loss = 0.2659, Accuracy = 0.8200 Test Loss = 0.2983, Test Accuracy = 0.8159\n",
      "Iteration 1408: Loss = 0.2655, Accuracy = 0.7900 Test Loss = 0.2989, Test Accuracy = 0.8136\n",
      "Iteration 1409: Loss = 0.2532, Accuracy = 0.8200 Test Loss = 0.2985, Test Accuracy = 0.8144\n",
      "Iteration 1410: Loss = 0.2462, Accuracy = 0.8800 Test Loss = 0.2989, Test Accuracy = 0.8107\n",
      "Iteration 1411: Loss = 0.2629, Accuracy = 0.8300 Test Loss = 0.2982, Test Accuracy = 0.8134\n",
      "Iteration 1412: Loss = 0.2158, Accuracy = 0.8800 Test Loss = 0.2981, Test Accuracy = 0.8152\n",
      "Iteration 1413: Loss = 0.2273, Accuracy = 0.9100 Test Loss = 0.2982, Test Accuracy = 0.8147\n",
      "Iteration 1414: Loss = 0.2853, Accuracy = 0.8000 Test Loss = 0.2985, Test Accuracy = 0.8160\n",
      "Iteration 1415: Loss = 0.2472, Accuracy = 0.9200 Test Loss = 0.2984, Test Accuracy = 0.8115\n",
      "Iteration 1416: Loss = 0.2200, Accuracy = 0.8600 Test Loss = 0.2980, Test Accuracy = 0.8168\n",
      "Iteration 1417: Loss = 0.2267, Accuracy = 0.8600 Test Loss = 0.2976, Test Accuracy = 0.8151\n",
      "Iteration 1418: Loss = 0.2550, Accuracy = 0.8300 Test Loss = 0.2980, Test Accuracy = 0.8145\n",
      "Iteration 1419: Loss = 0.2628, Accuracy = 0.8400 Test Loss = 0.2983, Test Accuracy = 0.8161\n",
      "Iteration 1420: Loss = 0.2932, Accuracy = 0.7900 Test Loss = 0.2984, Test Accuracy = 0.8168\n",
      "Iteration 1421: Loss = 0.2373, Accuracy = 0.8500 Test Loss = 0.2977, Test Accuracy = 0.8147\n",
      "Iteration 1422: Loss = 0.2763, Accuracy = 0.8400 Test Loss = 0.2978, Test Accuracy = 0.8125\n",
      "Iteration 1423: Loss = 0.2537, Accuracy = 0.8500 Test Loss = 0.2981, Test Accuracy = 0.8187\n",
      "Iteration 1424: Loss = 0.2657, Accuracy = 0.8800 Test Loss = 0.2978, Test Accuracy = 0.8134\n",
      "Iteration 1425: Loss = 0.2420, Accuracy = 0.8800 Test Loss = 0.2975, Test Accuracy = 0.8127\n",
      "Iteration 1426: Loss = 0.2318, Accuracy = 0.8700 Test Loss = 0.2970, Test Accuracy = 0.8157\n",
      "Iteration 1427: Loss = 0.2397, Accuracy = 0.8800 Test Loss = 0.2977, Test Accuracy = 0.8136\n",
      "Iteration 1428: Loss = 0.2450, Accuracy = 0.8400 Test Loss = 0.2975, Test Accuracy = 0.8182\n",
      "Iteration 1429: Loss = 0.2639, Accuracy = 0.8600 Test Loss = 0.2975, Test Accuracy = 0.8170\n",
      "Iteration 1430: Loss = 0.2270, Accuracy = 0.7900 Test Loss = 0.2975, Test Accuracy = 0.8120\n",
      "Iteration 1431: Loss = 0.2498, Accuracy = 0.8600 Test Loss = 0.2970, Test Accuracy = 0.8156\n",
      "Iteration 1432: Loss = 0.2187, Accuracy = 0.8800 Test Loss = 0.2971, Test Accuracy = 0.8168\n",
      "Iteration 1433: Loss = 0.2354, Accuracy = 0.8800 Test Loss = 0.2968, Test Accuracy = 0.8135\n",
      "Iteration 1434: Loss = 0.3341, Accuracy = 0.8000 Test Loss = 0.2972, Test Accuracy = 0.8144\n",
      "Iteration 1435: Loss = 0.3076, Accuracy = 0.8200 Test Loss = 0.2969, Test Accuracy = 0.8129\n",
      "Iteration 1436: Loss = 0.2442, Accuracy = 0.8400 Test Loss = 0.2966, Test Accuracy = 0.8168\n",
      "Iteration 1437: Loss = 0.2388, Accuracy = 0.8600 Test Loss = 0.2962, Test Accuracy = 0.8157\n",
      "Iteration 1438: Loss = 0.2276, Accuracy = 0.8800 Test Loss = 0.2966, Test Accuracy = 0.8119\n",
      "Iteration 1439: Loss = 0.2347, Accuracy = 0.9000 Test Loss = 0.2963, Test Accuracy = 0.8147\n",
      "Iteration 1440: Loss = 0.2847, Accuracy = 0.7600 Test Loss = 0.2965, Test Accuracy = 0.8162\n",
      "Iteration 1441: Loss = 0.2851, Accuracy = 0.8300 Test Loss = 0.2968, Test Accuracy = 0.8165\n",
      "Iteration 1442: Loss = 0.2949, Accuracy = 0.8600 Test Loss = 0.2963, Test Accuracy = 0.8165\n",
      "Iteration 1443: Loss = 0.3187, Accuracy = 0.7600 Test Loss = 0.2959, Test Accuracy = 0.8152\n",
      "Iteration 1444: Loss = 0.2703, Accuracy = 0.8100 Test Loss = 0.2959, Test Accuracy = 0.8167\n",
      "Iteration 1445: Loss = 0.2544, Accuracy = 0.8400 Test Loss = 0.2970, Test Accuracy = 0.8111\n",
      "Iteration 1446: Loss = 0.2372, Accuracy = 0.8600 Test Loss = 0.2957, Test Accuracy = 0.8158\n",
      "Iteration 1447: Loss = 0.2767, Accuracy = 0.8300 Test Loss = 0.2959, Test Accuracy = 0.8143\n",
      "Iteration 1448: Loss = 0.2166, Accuracy = 0.8900 Test Loss = 0.2956, Test Accuracy = 0.8171\n",
      "Iteration 1449: Loss = 0.2839, Accuracy = 0.8300 Test Loss = 0.2961, Test Accuracy = 0.8150\n",
      "Iteration 1450: Loss = 0.3044, Accuracy = 0.9100 Test Loss = 0.2962, Test Accuracy = 0.8169\n",
      "Iteration 1451: Loss = 0.2542, Accuracy = 0.8200 Test Loss = 0.2956, Test Accuracy = 0.8150\n",
      "Iteration 1452: Loss = 0.2942, Accuracy = 0.8400 Test Loss = 0.2952, Test Accuracy = 0.8129\n",
      "Iteration 1453: Loss = 0.2687, Accuracy = 0.8000 Test Loss = 0.2955, Test Accuracy = 0.8161\n",
      "Iteration 1454: Loss = 0.2574, Accuracy = 0.8500 Test Loss = 0.2955, Test Accuracy = 0.8146\n",
      "Iteration 1455: Loss = 0.2291, Accuracy = 0.8500 Test Loss = 0.2954, Test Accuracy = 0.8121\n",
      "Iteration 1456: Loss = 0.2340, Accuracy = 0.8800 Test Loss = 0.2958, Test Accuracy = 0.8162\n",
      "Iteration 1457: Loss = 0.1821, Accuracy = 0.8900 Test Loss = 0.2956, Test Accuracy = 0.8160\n",
      "Iteration 1458: Loss = 0.2396, Accuracy = 0.8600 Test Loss = 0.2952, Test Accuracy = 0.8150\n",
      "Iteration 1459: Loss = 0.2418, Accuracy = 0.8600 Test Loss = 0.2955, Test Accuracy = 0.8165\n",
      "Iteration 1460: Loss = 0.2207, Accuracy = 0.8800 Test Loss = 0.2951, Test Accuracy = 0.8181\n",
      "Iteration 1461: Loss = 0.2698, Accuracy = 0.8200 Test Loss = 0.2954, Test Accuracy = 0.8160\n",
      "Iteration 1462: Loss = 0.2480, Accuracy = 0.8500 Test Loss = 0.2951, Test Accuracy = 0.8177\n",
      "Iteration 1463: Loss = 0.2688, Accuracy = 0.8700 Test Loss = 0.2948, Test Accuracy = 0.8146\n",
      "Iteration 1464: Loss = 0.2838, Accuracy = 0.8500 Test Loss = 0.2955, Test Accuracy = 0.8167\n",
      "Iteration 1465: Loss = 0.3182, Accuracy = 0.8200 Test Loss = 0.2943, Test Accuracy = 0.8145\n",
      "Iteration 1466: Loss = 0.2482, Accuracy = 0.8400 Test Loss = 0.2945, Test Accuracy = 0.8169\n",
      "Iteration 1467: Loss = 0.2727, Accuracy = 0.7700 Test Loss = 0.2947, Test Accuracy = 0.8167\n",
      "Iteration 1468: Loss = 0.2208, Accuracy = 0.8500 Test Loss = 0.2945, Test Accuracy = 0.8194\n",
      "Iteration 1469: Loss = 0.2717, Accuracy = 0.8500 Test Loss = 0.2947, Test Accuracy = 0.8156\n",
      "Iteration 1470: Loss = 0.2521, Accuracy = 0.8700 Test Loss = 0.2947, Test Accuracy = 0.8157\n",
      "Iteration 1471: Loss = 0.2462, Accuracy = 0.8600 Test Loss = 0.2948, Test Accuracy = 0.8158\n",
      "Iteration 1472: Loss = 0.2181, Accuracy = 0.8900 Test Loss = 0.2942, Test Accuracy = 0.8169\n",
      "Iteration 1473: Loss = 0.2382, Accuracy = 0.8400 Test Loss = 0.2949, Test Accuracy = 0.8176\n",
      "Iteration 1474: Loss = 0.2292, Accuracy = 0.8700 Test Loss = 0.2946, Test Accuracy = 0.8188\n",
      "Iteration 1475: Loss = 0.2291, Accuracy = 0.8800 Test Loss = 0.2939, Test Accuracy = 0.8164\n",
      "Iteration 1476: Loss = 0.2641, Accuracy = 0.8300 Test Loss = 0.2940, Test Accuracy = 0.8145\n",
      "Iteration 1477: Loss = 0.2291, Accuracy = 0.9000 Test Loss = 0.2941, Test Accuracy = 0.8180\n",
      "Iteration 1478: Loss = 0.2488, Accuracy = 0.8100 Test Loss = 0.2941, Test Accuracy = 0.8131\n",
      "Iteration 1479: Loss = 0.2389, Accuracy = 0.9200 Test Loss = 0.2939, Test Accuracy = 0.8148\n",
      "Iteration 1480: Loss = 0.2323, Accuracy = 0.8500 Test Loss = 0.2936, Test Accuracy = 0.8162\n",
      "Iteration 1481: Loss = 0.2315, Accuracy = 0.8700 Test Loss = 0.2935, Test Accuracy = 0.8162\n",
      "Iteration 1482: Loss = 0.2615, Accuracy = 0.8300 Test Loss = 0.2942, Test Accuracy = 0.8169\n",
      "Iteration 1483: Loss = 0.2592, Accuracy = 0.8200 Test Loss = 0.2938, Test Accuracy = 0.8163\n",
      "Iteration 1484: Loss = 0.2233, Accuracy = 0.8900 Test Loss = 0.2936, Test Accuracy = 0.8196\n",
      "Iteration 1485: Loss = 0.2514, Accuracy = 0.7900 Test Loss = 0.2931, Test Accuracy = 0.8179\n",
      "Iteration 1486: Loss = 0.2663, Accuracy = 0.7700 Test Loss = 0.2939, Test Accuracy = 0.8167\n",
      "Iteration 1487: Loss = 0.2392, Accuracy = 0.8400 Test Loss = 0.2937, Test Accuracy = 0.8139\n",
      "Iteration 1488: Loss = 0.2523, Accuracy = 0.7800 Test Loss = 0.2930, Test Accuracy = 0.8175\n",
      "Iteration 1489: Loss = 0.2659, Accuracy = 0.8600 Test Loss = 0.2933, Test Accuracy = 0.8169\n",
      "Iteration 1490: Loss = 0.2716, Accuracy = 0.8300 Test Loss = 0.2935, Test Accuracy = 0.8188\n",
      "Iteration 1491: Loss = 0.2360, Accuracy = 0.8600 Test Loss = 0.2933, Test Accuracy = 0.8175\n",
      "Iteration 1492: Loss = 0.2538, Accuracy = 0.8400 Test Loss = 0.2933, Test Accuracy = 0.8167\n",
      "Iteration 1493: Loss = 0.2647, Accuracy = 0.8500 Test Loss = 0.2928, Test Accuracy = 0.8152\n",
      "Iteration 1494: Loss = 0.2455, Accuracy = 0.8200 Test Loss = 0.2938, Test Accuracy = 0.8155\n",
      "Iteration 1495: Loss = 0.2426, Accuracy = 0.8100 Test Loss = 0.2929, Test Accuracy = 0.8185\n",
      "Iteration 1496: Loss = 0.2711, Accuracy = 0.7500 Test Loss = 0.2932, Test Accuracy = 0.8146\n",
      "Iteration 1497: Loss = 0.2446, Accuracy = 0.8500 Test Loss = 0.2924, Test Accuracy = 0.8165\n",
      "Iteration 1498: Loss = 0.2388, Accuracy = 0.8700 Test Loss = 0.2924, Test Accuracy = 0.8167\n",
      "Iteration 1499: Loss = 0.2352, Accuracy = 0.7900 Test Loss = 0.2924, Test Accuracy = 0.8189\n",
      "Iteration 1500: Loss = 0.2266, Accuracy = 0.8800 Test Loss = 0.2924, Test Accuracy = 0.8178\n",
      "Iteration 1501: Loss = 0.2134, Accuracy = 0.8900 Test Loss = 0.2924, Test Accuracy = 0.8167\n",
      "Iteration 1502: Loss = 0.2402, Accuracy = 0.9200 Test Loss = 0.2927, Test Accuracy = 0.8140\n",
      "Iteration 1503: Loss = 0.2482, Accuracy = 0.8400 Test Loss = 0.2920, Test Accuracy = 0.8177\n",
      "Iteration 1504: Loss = 0.2402, Accuracy = 0.8300 Test Loss = 0.2927, Test Accuracy = 0.8143\n",
      "Iteration 1505: Loss = 0.2453, Accuracy = 0.8500 Test Loss = 0.2923, Test Accuracy = 0.8190\n",
      "Iteration 1506: Loss = 0.2224, Accuracy = 0.8500 Test Loss = 0.2923, Test Accuracy = 0.8161\n",
      "Iteration 1507: Loss = 0.2636, Accuracy = 0.7800 Test Loss = 0.2921, Test Accuracy = 0.8176\n",
      "Iteration 1508: Loss = 0.2466, Accuracy = 0.8800 Test Loss = 0.2921, Test Accuracy = 0.8150\n",
      "Iteration 1509: Loss = 0.2326, Accuracy = 0.8300 Test Loss = 0.2921, Test Accuracy = 0.8174\n",
      "Iteration 1510: Loss = 0.2459, Accuracy = 0.8100 Test Loss = 0.2920, Test Accuracy = 0.8183\n",
      "Iteration 1511: Loss = 0.2315, Accuracy = 0.8700 Test Loss = 0.2916, Test Accuracy = 0.8169\n",
      "Iteration 1512: Loss = 0.2214, Accuracy = 0.8700 Test Loss = 0.2920, Test Accuracy = 0.8147\n",
      "Iteration 1513: Loss = 0.2704, Accuracy = 0.8000 Test Loss = 0.2918, Test Accuracy = 0.8189\n",
      "Iteration 1514: Loss = 0.2561, Accuracy = 0.8600 Test Loss = 0.2917, Test Accuracy = 0.8179\n",
      "Iteration 1515: Loss = 0.2527, Accuracy = 0.7900 Test Loss = 0.2921, Test Accuracy = 0.8191\n",
      "Iteration 1516: Loss = 0.2723, Accuracy = 0.8300 Test Loss = 0.2916, Test Accuracy = 0.8154\n",
      "Iteration 1517: Loss = 0.2145, Accuracy = 0.9200 Test Loss = 0.2913, Test Accuracy = 0.8181\n",
      "Iteration 1518: Loss = 0.2312, Accuracy = 0.8900 Test Loss = 0.2916, Test Accuracy = 0.8172\n",
      "Iteration 1519: Loss = 0.2391, Accuracy = 0.8500 Test Loss = 0.2913, Test Accuracy = 0.8176\n",
      "Iteration 1520: Loss = 0.2246, Accuracy = 0.8600 Test Loss = 0.2911, Test Accuracy = 0.8190\n",
      "Iteration 1521: Loss = 0.2675, Accuracy = 0.8100 Test Loss = 0.2917, Test Accuracy = 0.8156\n",
      "Iteration 1522: Loss = 0.2470, Accuracy = 0.8800 Test Loss = 0.2915, Test Accuracy = 0.8198\n",
      "Iteration 1523: Loss = 0.2341, Accuracy = 0.8800 Test Loss = 0.2910, Test Accuracy = 0.8190\n",
      "Iteration 1524: Loss = 0.2229, Accuracy = 0.8700 Test Loss = 0.2916, Test Accuracy = 0.8167\n",
      "Iteration 1525: Loss = 0.2269, Accuracy = 0.8700 Test Loss = 0.2911, Test Accuracy = 0.8177\n",
      "Iteration 1526: Loss = 0.2454, Accuracy = 0.8100 Test Loss = 0.2907, Test Accuracy = 0.8151\n",
      "Iteration 1527: Loss = 0.2606, Accuracy = 0.8800 Test Loss = 0.2906, Test Accuracy = 0.8189\n",
      "Iteration 1528: Loss = 0.2482, Accuracy = 0.8300 Test Loss = 0.2915, Test Accuracy = 0.8168\n",
      "Iteration 1529: Loss = 0.2693, Accuracy = 0.8200 Test Loss = 0.2912, Test Accuracy = 0.8175\n",
      "Iteration 1530: Loss = 0.2593, Accuracy = 0.8600 Test Loss = 0.2913, Test Accuracy = 0.8176\n",
      "Iteration 1531: Loss = 0.2690, Accuracy = 0.8400 Test Loss = 0.2916, Test Accuracy = 0.8201\n",
      "Iteration 1532: Loss = 0.2443, Accuracy = 0.8500 Test Loss = 0.2904, Test Accuracy = 0.8179\n",
      "Iteration 1533: Loss = 0.2240, Accuracy = 0.8600 Test Loss = 0.2910, Test Accuracy = 0.8168\n",
      "Iteration 1534: Loss = 0.2582, Accuracy = 0.8300 Test Loss = 0.2904, Test Accuracy = 0.8165\n",
      "Iteration 1535: Loss = 0.2129, Accuracy = 0.9300 Test Loss = 0.2905, Test Accuracy = 0.8182\n",
      "Iteration 1536: Loss = 0.2182, Accuracy = 0.8900 Test Loss = 0.2908, Test Accuracy = 0.8159\n",
      "Iteration 1537: Loss = 0.2559, Accuracy = 0.8200 Test Loss = 0.2906, Test Accuracy = 0.8182\n",
      "Iteration 1538: Loss = 0.2522, Accuracy = 0.8100 Test Loss = 0.2909, Test Accuracy = 0.8194\n",
      "Iteration 1539: Loss = 0.2506, Accuracy = 0.8400 Test Loss = 0.2904, Test Accuracy = 0.8192\n",
      "Iteration 1540: Loss = 0.2763, Accuracy = 0.8000 Test Loss = 0.2902, Test Accuracy = 0.8193\n",
      "Iteration 1541: Loss = 0.2108, Accuracy = 0.8800 Test Loss = 0.2905, Test Accuracy = 0.8179\n",
      "Iteration 1542: Loss = 0.2385, Accuracy = 0.8600 Test Loss = 0.2902, Test Accuracy = 0.8171\n",
      "Iteration 1543: Loss = 0.2311, Accuracy = 0.8200 Test Loss = 0.2902, Test Accuracy = 0.8176\n",
      "Iteration 1544: Loss = 0.2618, Accuracy = 0.8200 Test Loss = 0.2905, Test Accuracy = 0.8163\n",
      "Iteration 1545: Loss = 0.2858, Accuracy = 0.7900 Test Loss = 0.2902, Test Accuracy = 0.8166\n",
      "Iteration 1546: Loss = 0.2441, Accuracy = 0.9000 Test Loss = 0.2901, Test Accuracy = 0.8180\n",
      "Iteration 1547: Loss = 0.2513, Accuracy = 0.8600 Test Loss = 0.2899, Test Accuracy = 0.8176\n",
      "Iteration 1548: Loss = 0.2559, Accuracy = 0.7900 Test Loss = 0.2895, Test Accuracy = 0.8183\n",
      "Iteration 1549: Loss = 0.2107, Accuracy = 0.8900 Test Loss = 0.2893, Test Accuracy = 0.8197\n",
      "Iteration 1550: Loss = 0.2625, Accuracy = 0.8400 Test Loss = 0.2902, Test Accuracy = 0.8157\n",
      "Iteration 1551: Loss = 0.2333, Accuracy = 0.8100 Test Loss = 0.2902, Test Accuracy = 0.8166\n",
      "Iteration 1552: Loss = 0.2459, Accuracy = 0.8500 Test Loss = 0.2891, Test Accuracy = 0.8192\n",
      "Iteration 1553: Loss = 0.2682, Accuracy = 0.7700 Test Loss = 0.2909, Test Accuracy = 0.8185\n",
      "Iteration 1554: Loss = 0.2261, Accuracy = 0.8300 Test Loss = 0.2901, Test Accuracy = 0.8178\n",
      "Iteration 1555: Loss = 0.2105, Accuracy = 0.9000 Test Loss = 0.2894, Test Accuracy = 0.8181\n",
      "Iteration 1556: Loss = 0.2385, Accuracy = 0.7600 Test Loss = 0.2897, Test Accuracy = 0.8199\n",
      "Iteration 1557: Loss = 0.2368, Accuracy = 0.8800 Test Loss = 0.2892, Test Accuracy = 0.8172\n",
      "Iteration 1558: Loss = 0.2580, Accuracy = 0.8400 Test Loss = 0.2896, Test Accuracy = 0.8189\n",
      "Iteration 1559: Loss = 0.2437, Accuracy = 0.8500 Test Loss = 0.2885, Test Accuracy = 0.8182\n",
      "Iteration 1560: Loss = 0.2393, Accuracy = 0.8800 Test Loss = 0.2893, Test Accuracy = 0.8197\n",
      "Iteration 1561: Loss = 0.2593, Accuracy = 0.8300 Test Loss = 0.2892, Test Accuracy = 0.8173\n",
      "Iteration 1562: Loss = 0.3024, Accuracy = 0.8400 Test Loss = 0.2889, Test Accuracy = 0.8210\n",
      "Iteration 1563: Loss = 0.2415, Accuracy = 0.8200 Test Loss = 0.2895, Test Accuracy = 0.8196\n",
      "Iteration 1564: Loss = 0.2498, Accuracy = 0.8800 Test Loss = 0.2891, Test Accuracy = 0.8184\n",
      "Iteration 1565: Loss = 0.2490, Accuracy = 0.8900 Test Loss = 0.2887, Test Accuracy = 0.8146\n",
      "Iteration 1566: Loss = 0.2873, Accuracy = 0.8400 Test Loss = 0.2891, Test Accuracy = 0.8216\n",
      "Iteration 1567: Loss = 0.2354, Accuracy = 0.8900 Test Loss = 0.2894, Test Accuracy = 0.8163\n",
      "Iteration 1568: Loss = 0.2508, Accuracy = 0.8300 Test Loss = 0.2885, Test Accuracy = 0.8191\n",
      "Iteration 1569: Loss = 0.2651, Accuracy = 0.8000 Test Loss = 0.2892, Test Accuracy = 0.8202\n",
      "Iteration 1570: Loss = 0.2672, Accuracy = 0.8100 Test Loss = 0.2890, Test Accuracy = 0.8214\n",
      "Iteration 1571: Loss = 0.2396, Accuracy = 0.8500 Test Loss = 0.2886, Test Accuracy = 0.8183\n",
      "Iteration 1572: Loss = 0.2435, Accuracy = 0.8200 Test Loss = 0.2895, Test Accuracy = 0.8215\n",
      "Iteration 1573: Loss = 0.2405, Accuracy = 0.8500 Test Loss = 0.2882, Test Accuracy = 0.8191\n",
      "Iteration 1574: Loss = 0.2314, Accuracy = 0.8100 Test Loss = 0.2884, Test Accuracy = 0.8190\n",
      "Iteration 1575: Loss = 0.3215, Accuracy = 0.7900 Test Loss = 0.2882, Test Accuracy = 0.8197\n",
      "Iteration 1576: Loss = 0.2368, Accuracy = 0.8600 Test Loss = 0.2883, Test Accuracy = 0.8162\n",
      "Iteration 1577: Loss = 0.2118, Accuracy = 0.9100 Test Loss = 0.2887, Test Accuracy = 0.8195\n",
      "Iteration 1578: Loss = 0.2375, Accuracy = 0.8200 Test Loss = 0.2884, Test Accuracy = 0.8188\n",
      "Iteration 1579: Loss = 0.2619, Accuracy = 0.7900 Test Loss = 0.2879, Test Accuracy = 0.8195\n",
      "Iteration 1580: Loss = 0.2803, Accuracy = 0.7800 Test Loss = 0.2880, Test Accuracy = 0.8199\n",
      "Iteration 1581: Loss = 0.2345, Accuracy = 0.8700 Test Loss = 0.2879, Test Accuracy = 0.8216\n",
      "Iteration 1582: Loss = 0.2198, Accuracy = 0.8500 Test Loss = 0.2877, Test Accuracy = 0.8175\n",
      "Iteration 1583: Loss = 0.2593, Accuracy = 0.8300 Test Loss = 0.2879, Test Accuracy = 0.8193\n",
      "Iteration 1584: Loss = 0.2228, Accuracy = 0.8400 Test Loss = 0.2882, Test Accuracy = 0.8196\n",
      "Iteration 1585: Loss = 0.2242, Accuracy = 0.8900 Test Loss = 0.2881, Test Accuracy = 0.8186\n",
      "Iteration 1586: Loss = 0.2726, Accuracy = 0.7900 Test Loss = 0.2882, Test Accuracy = 0.8204\n",
      "Iteration 1587: Loss = 0.1934, Accuracy = 0.9200 Test Loss = 0.2878, Test Accuracy = 0.8181\n",
      "Iteration 1588: Loss = 0.2542, Accuracy = 0.8200 Test Loss = 0.2874, Test Accuracy = 0.8183\n",
      "Iteration 1589: Loss = 0.2457, Accuracy = 0.8500 Test Loss = 0.2881, Test Accuracy = 0.8213\n",
      "Iteration 1590: Loss = 0.2186, Accuracy = 0.8400 Test Loss = 0.2883, Test Accuracy = 0.8174\n",
      "Iteration 1591: Loss = 0.2102, Accuracy = 0.8500 Test Loss = 0.2873, Test Accuracy = 0.8206\n",
      "Iteration 1592: Loss = 0.2578, Accuracy = 0.8300 Test Loss = 0.2871, Test Accuracy = 0.8198\n",
      "Iteration 1593: Loss = 0.2443, Accuracy = 0.8700 Test Loss = 0.2875, Test Accuracy = 0.8195\n",
      "Iteration 1594: Loss = 0.2320, Accuracy = 0.8100 Test Loss = 0.2872, Test Accuracy = 0.8202\n",
      "Iteration 1595: Loss = 0.2747, Accuracy = 0.8700 Test Loss = 0.2870, Test Accuracy = 0.8176\n",
      "Iteration 1596: Loss = 0.2147, Accuracy = 0.8800 Test Loss = 0.2867, Test Accuracy = 0.8179\n",
      "Iteration 1597: Loss = 0.3059, Accuracy = 0.7900 Test Loss = 0.2872, Test Accuracy = 0.8204\n",
      "Iteration 1598: Loss = 0.2272, Accuracy = 0.8600 Test Loss = 0.2868, Test Accuracy = 0.8185\n",
      "Iteration 1599: Loss = 0.2233, Accuracy = 0.8400 Test Loss = 0.2878, Test Accuracy = 0.8216\n",
      "Iteration 1600: Loss = 0.2575, Accuracy = 0.8600 Test Loss = 0.2869, Test Accuracy = 0.8195\n",
      "Iteration 1601: Loss = 0.2446, Accuracy = 0.8500 Test Loss = 0.2876, Test Accuracy = 0.8216\n",
      "Iteration 1602: Loss = 0.2137, Accuracy = 0.9000 Test Loss = 0.2866, Test Accuracy = 0.8193\n",
      "Iteration 1603: Loss = 0.2677, Accuracy = 0.9000 Test Loss = 0.2869, Test Accuracy = 0.8191\n",
      "Iteration 1604: Loss = 0.2192, Accuracy = 0.8700 Test Loss = 0.2871, Test Accuracy = 0.8183\n",
      "Iteration 1605: Loss = 0.2745, Accuracy = 0.8200 Test Loss = 0.2865, Test Accuracy = 0.8191\n",
      "Iteration 1606: Loss = 0.2298, Accuracy = 0.8200 Test Loss = 0.2868, Test Accuracy = 0.8200\n",
      "Iteration 1607: Loss = 0.2246, Accuracy = 0.8600 Test Loss = 0.2863, Test Accuracy = 0.8188\n",
      "Iteration 1608: Loss = 0.2578, Accuracy = 0.7700 Test Loss = 0.2862, Test Accuracy = 0.8186\n",
      "Iteration 1609: Loss = 0.2766, Accuracy = 0.8300 Test Loss = 0.2860, Test Accuracy = 0.8213\n",
      "Iteration 1610: Loss = 0.2951, Accuracy = 0.8500 Test Loss = 0.2861, Test Accuracy = 0.8201\n",
      "Iteration 1611: Loss = 0.2598, Accuracy = 0.7800 Test Loss = 0.2865, Test Accuracy = 0.8206\n",
      "Iteration 1612: Loss = 0.2677, Accuracy = 0.8400 Test Loss = 0.2861, Test Accuracy = 0.8197\n",
      "Iteration 1613: Loss = 0.2652, Accuracy = 0.8400 Test Loss = 0.2862, Test Accuracy = 0.8210\n",
      "Iteration 1614: Loss = 0.2500, Accuracy = 0.8300 Test Loss = 0.2862, Test Accuracy = 0.8186\n",
      "Iteration 1615: Loss = 0.2249, Accuracy = 0.8500 Test Loss = 0.2864, Test Accuracy = 0.8202\n",
      "Iteration 1616: Loss = 0.2704, Accuracy = 0.8700 Test Loss = 0.2866, Test Accuracy = 0.8182\n",
      "Iteration 1617: Loss = 0.2422, Accuracy = 0.8200 Test Loss = 0.2858, Test Accuracy = 0.8189\n",
      "Iteration 1618: Loss = 0.2238, Accuracy = 0.8500 Test Loss = 0.2856, Test Accuracy = 0.8179\n",
      "Iteration 1619: Loss = 0.2663, Accuracy = 0.8300 Test Loss = 0.2870, Test Accuracy = 0.8169\n",
      "Iteration 1620: Loss = 0.2451, Accuracy = 0.8200 Test Loss = 0.2855, Test Accuracy = 0.8212\n",
      "Iteration 1621: Loss = 0.2591, Accuracy = 0.8500 Test Loss = 0.2862, Test Accuracy = 0.8207\n",
      "Iteration 1622: Loss = 0.2401, Accuracy = 0.8800 Test Loss = 0.2865, Test Accuracy = 0.8179\n",
      "Iteration 1623: Loss = 0.2357, Accuracy = 0.8500 Test Loss = 0.2857, Test Accuracy = 0.8204\n",
      "Iteration 1624: Loss = 0.2366, Accuracy = 0.8500 Test Loss = 0.2857, Test Accuracy = 0.8226\n",
      "Iteration 1625: Loss = 0.4008, Accuracy = 0.7700 Test Loss = 0.2856, Test Accuracy = 0.8205\n",
      "Iteration 1626: Loss = 0.2996, Accuracy = 0.7900 Test Loss = 0.2864, Test Accuracy = 0.8200\n",
      "Iteration 1627: Loss = 0.2513, Accuracy = 0.8200 Test Loss = 0.2861, Test Accuracy = 0.8199\n",
      "Iteration 1628: Loss = 0.3189, Accuracy = 0.7200 Test Loss = 0.2860, Test Accuracy = 0.8230\n",
      "Iteration 1629: Loss = 0.2610, Accuracy = 0.8400 Test Loss = 0.2855, Test Accuracy = 0.8169\n",
      "Iteration 1630: Loss = 0.2586, Accuracy = 0.8900 Test Loss = 0.2855, Test Accuracy = 0.8216\n",
      "Iteration 1631: Loss = 0.2385, Accuracy = 0.8700 Test Loss = 0.2856, Test Accuracy = 0.8218\n",
      "Iteration 1632: Loss = 0.2179, Accuracy = 0.8700 Test Loss = 0.2853, Test Accuracy = 0.8190\n",
      "Iteration 1633: Loss = 0.2358, Accuracy = 0.8200 Test Loss = 0.2857, Test Accuracy = 0.8175\n",
      "Iteration 1634: Loss = 0.2648, Accuracy = 0.7800 Test Loss = 0.2851, Test Accuracy = 0.8210\n",
      "Iteration 1635: Loss = 0.2469, Accuracy = 0.8300 Test Loss = 0.2850, Test Accuracy = 0.8207\n",
      "Iteration 1636: Loss = 0.2695, Accuracy = 0.8400 Test Loss = 0.2857, Test Accuracy = 0.8196\n",
      "Iteration 1637: Loss = 0.2284, Accuracy = 0.8900 Test Loss = 0.2850, Test Accuracy = 0.8210\n",
      "Iteration 1638: Loss = 0.2184, Accuracy = 0.8700 Test Loss = 0.2848, Test Accuracy = 0.8215\n",
      "Iteration 1639: Loss = 0.2553, Accuracy = 0.8700 Test Loss = 0.2855, Test Accuracy = 0.8172\n",
      "Iteration 1640: Loss = 0.2373, Accuracy = 0.9000 Test Loss = 0.2845, Test Accuracy = 0.8199\n",
      "Iteration 1641: Loss = 0.2236, Accuracy = 0.8300 Test Loss = 0.2850, Test Accuracy = 0.8186\n",
      "Iteration 1642: Loss = 0.1962, Accuracy = 0.9200 Test Loss = 0.2849, Test Accuracy = 0.8177\n",
      "Iteration 1643: Loss = 0.2847, Accuracy = 0.8300 Test Loss = 0.2850, Test Accuracy = 0.8191\n",
      "Iteration 1644: Loss = 0.2171, Accuracy = 0.8000 Test Loss = 0.2848, Test Accuracy = 0.8231\n",
      "Iteration 1645: Loss = 0.2747, Accuracy = 0.8700 Test Loss = 0.2848, Test Accuracy = 0.8185\n",
      "Iteration 1646: Loss = 0.2242, Accuracy = 0.8700 Test Loss = 0.2845, Test Accuracy = 0.8207\n",
      "Iteration 1647: Loss = 0.2544, Accuracy = 0.8400 Test Loss = 0.2851, Test Accuracy = 0.8183\n",
      "Iteration 1648: Loss = 0.2393, Accuracy = 0.8400 Test Loss = 0.2846, Test Accuracy = 0.8205\n",
      "Iteration 1649: Loss = 0.2392, Accuracy = 0.8700 Test Loss = 0.2845, Test Accuracy = 0.8181\n",
      "Iteration 1650: Loss = 0.2215, Accuracy = 0.9000 Test Loss = 0.2843, Test Accuracy = 0.8185\n",
      "Iteration 1651: Loss = 0.2313, Accuracy = 0.8600 Test Loss = 0.2843, Test Accuracy = 0.8205\n",
      "Iteration 1652: Loss = 0.2542, Accuracy = 0.8700 Test Loss = 0.2841, Test Accuracy = 0.8222\n",
      "Iteration 1653: Loss = 0.2332, Accuracy = 0.8600 Test Loss = 0.2845, Test Accuracy = 0.8223\n",
      "Iteration 1654: Loss = 0.2202, Accuracy = 0.8600 Test Loss = 0.2843, Test Accuracy = 0.8193\n",
      "Iteration 1655: Loss = 0.2440, Accuracy = 0.8700 Test Loss = 0.2847, Test Accuracy = 0.8191\n",
      "Iteration 1656: Loss = 0.2096, Accuracy = 0.8800 Test Loss = 0.2856, Test Accuracy = 0.8219\n",
      "Iteration 1657: Loss = 0.2580, Accuracy = 0.8000 Test Loss = 0.2838, Test Accuracy = 0.8217\n",
      "Iteration 1658: Loss = 0.2668, Accuracy = 0.8000 Test Loss = 0.2836, Test Accuracy = 0.8220\n",
      "Iteration 1659: Loss = 0.2281, Accuracy = 0.9200 Test Loss = 0.2837, Test Accuracy = 0.8189\n",
      "Iteration 1660: Loss = 0.2777, Accuracy = 0.8300 Test Loss = 0.2840, Test Accuracy = 0.8199\n",
      "Iteration 1661: Loss = 0.2399, Accuracy = 0.8400 Test Loss = 0.2843, Test Accuracy = 0.8202\n",
      "Iteration 1662: Loss = 0.2442, Accuracy = 0.8800 Test Loss = 0.2834, Test Accuracy = 0.8214\n",
      "Iteration 1663: Loss = 0.2362, Accuracy = 0.8700 Test Loss = 0.2838, Test Accuracy = 0.8197\n",
      "Iteration 1664: Loss = 0.2407, Accuracy = 0.8600 Test Loss = 0.2838, Test Accuracy = 0.8211\n",
      "Iteration 1665: Loss = 0.2317, Accuracy = 0.8100 Test Loss = 0.2836, Test Accuracy = 0.8208\n",
      "Iteration 1666: Loss = 0.2441, Accuracy = 0.8600 Test Loss = 0.2839, Test Accuracy = 0.8206\n",
      "Iteration 1667: Loss = 0.3254, Accuracy = 0.7400 Test Loss = 0.2833, Test Accuracy = 0.8212\n",
      "Iteration 1668: Loss = 0.2154, Accuracy = 0.9100 Test Loss = 0.2834, Test Accuracy = 0.8218\n",
      "Iteration 1669: Loss = 0.2163, Accuracy = 0.9200 Test Loss = 0.2836, Test Accuracy = 0.8189\n",
      "Iteration 1670: Loss = 0.2324, Accuracy = 0.8400 Test Loss = 0.2832, Test Accuracy = 0.8193\n",
      "Iteration 1671: Loss = 0.2276, Accuracy = 0.8800 Test Loss = 0.2831, Test Accuracy = 0.8204\n",
      "Iteration 1672: Loss = 0.2707, Accuracy = 0.8300 Test Loss = 0.2837, Test Accuracy = 0.8231\n",
      "Iteration 1673: Loss = 0.2311, Accuracy = 0.8200 Test Loss = 0.2841, Test Accuracy = 0.8212\n",
      "Iteration 1674: Loss = 0.2331, Accuracy = 0.8500 Test Loss = 0.2843, Test Accuracy = 0.8199\n",
      "Iteration 1675: Loss = 0.2357, Accuracy = 0.8300 Test Loss = 0.2835, Test Accuracy = 0.8184\n",
      "Iteration 1676: Loss = 0.2384, Accuracy = 0.8500 Test Loss = 0.2836, Test Accuracy = 0.8216\n",
      "Iteration 1677: Loss = 0.2070, Accuracy = 0.8600 Test Loss = 0.2827, Test Accuracy = 0.8217\n",
      "Iteration 1678: Loss = 0.2381, Accuracy = 0.8500 Test Loss = 0.2833, Test Accuracy = 0.8199\n",
      "Iteration 1679: Loss = 0.2586, Accuracy = 0.8100 Test Loss = 0.2836, Test Accuracy = 0.8195\n",
      "Iteration 1680: Loss = 0.2198, Accuracy = 0.8500 Test Loss = 0.2831, Test Accuracy = 0.8233\n",
      "Iteration 1681: Loss = 0.2151, Accuracy = 0.8800 Test Loss = 0.2831, Test Accuracy = 0.8195\n",
      "Iteration 1682: Loss = 0.2255, Accuracy = 0.8700 Test Loss = 0.2837, Test Accuracy = 0.8220\n",
      "Iteration 1683: Loss = 0.2509, Accuracy = 0.8000 Test Loss = 0.2833, Test Accuracy = 0.8223\n",
      "Iteration 1684: Loss = 0.2471, Accuracy = 0.8100 Test Loss = 0.2828, Test Accuracy = 0.8217\n",
      "Iteration 1685: Loss = 0.2600, Accuracy = 0.8100 Test Loss = 0.2831, Test Accuracy = 0.8237\n",
      "Iteration 1686: Loss = 0.2438, Accuracy = 0.8700 Test Loss = 0.2826, Test Accuracy = 0.8220\n",
      "Iteration 1687: Loss = 0.2261, Accuracy = 0.8400 Test Loss = 0.2829, Test Accuracy = 0.8176\n",
      "Iteration 1688: Loss = 0.2335, Accuracy = 0.8100 Test Loss = 0.2825, Test Accuracy = 0.8233\n",
      "Iteration 1689: Loss = 0.2011, Accuracy = 0.9400 Test Loss = 0.2827, Test Accuracy = 0.8204\n",
      "Iteration 1690: Loss = 0.2769, Accuracy = 0.8100 Test Loss = 0.2827, Test Accuracy = 0.8216\n",
      "Iteration 1691: Loss = 0.2703, Accuracy = 0.8000 Test Loss = 0.2821, Test Accuracy = 0.8226\n",
      "Iteration 1692: Loss = 0.2356, Accuracy = 0.8500 Test Loss = 0.2831, Test Accuracy = 0.8225\n",
      "Iteration 1693: Loss = 0.2381, Accuracy = 0.8700 Test Loss = 0.2829, Test Accuracy = 0.8206\n",
      "Iteration 1694: Loss = 0.2257, Accuracy = 0.8700 Test Loss = 0.2824, Test Accuracy = 0.8204\n",
      "Iteration 1695: Loss = 0.2510, Accuracy = 0.8100 Test Loss = 0.2824, Test Accuracy = 0.8213\n",
      "Iteration 1696: Loss = 0.1885, Accuracy = 0.9000 Test Loss = 0.2829, Test Accuracy = 0.8225\n",
      "Iteration 1697: Loss = 0.2576, Accuracy = 0.7900 Test Loss = 0.2827, Test Accuracy = 0.8217\n",
      "Iteration 1698: Loss = 0.2266, Accuracy = 0.8500 Test Loss = 0.2820, Test Accuracy = 0.8228\n",
      "Iteration 1699: Loss = 0.2688, Accuracy = 0.8500 Test Loss = 0.2818, Test Accuracy = 0.8210\n",
      "Iteration 1700: Loss = 0.2721, Accuracy = 0.7500 Test Loss = 0.2822, Test Accuracy = 0.8221\n",
      "Iteration 1701: Loss = 0.2431, Accuracy = 0.8500 Test Loss = 0.2821, Test Accuracy = 0.8217\n",
      "Iteration 1702: Loss = 0.1947, Accuracy = 0.9100 Test Loss = 0.2818, Test Accuracy = 0.8202\n",
      "Iteration 1703: Loss = 0.1976, Accuracy = 0.8800 Test Loss = 0.2820, Test Accuracy = 0.8204\n",
      "Iteration 1704: Loss = 0.2277, Accuracy = 0.8400 Test Loss = 0.2831, Test Accuracy = 0.8212\n",
      "Iteration 1705: Loss = 0.2466, Accuracy = 0.8800 Test Loss = 0.2824, Test Accuracy = 0.8207\n",
      "Iteration 1706: Loss = 0.2404, Accuracy = 0.8200 Test Loss = 0.2817, Test Accuracy = 0.8210\n",
      "Iteration 1707: Loss = 0.2032, Accuracy = 0.8700 Test Loss = 0.2816, Test Accuracy = 0.8233\n",
      "Iteration 1708: Loss = 0.2798, Accuracy = 0.8000 Test Loss = 0.2818, Test Accuracy = 0.8209\n",
      "Iteration 1709: Loss = 0.2123, Accuracy = 0.8600 Test Loss = 0.2816, Test Accuracy = 0.8227\n",
      "Iteration 1710: Loss = 0.2594, Accuracy = 0.8100 Test Loss = 0.2820, Test Accuracy = 0.8229\n",
      "Iteration 1711: Loss = 0.2331, Accuracy = 0.8700 Test Loss = 0.2813, Test Accuracy = 0.8218\n",
      "Iteration 1712: Loss = 0.2411, Accuracy = 0.7900 Test Loss = 0.2813, Test Accuracy = 0.8220\n",
      "Iteration 1713: Loss = 0.1928, Accuracy = 0.8700 Test Loss = 0.2813, Test Accuracy = 0.8232\n",
      "Iteration 1714: Loss = 0.2350, Accuracy = 0.8400 Test Loss = 0.2816, Test Accuracy = 0.8243\n",
      "Iteration 1715: Loss = 0.2155, Accuracy = 0.8800 Test Loss = 0.2816, Test Accuracy = 0.8221\n",
      "Iteration 1716: Loss = 0.2309, Accuracy = 0.8400 Test Loss = 0.2812, Test Accuracy = 0.8199\n",
      "Iteration 1717: Loss = 0.2237, Accuracy = 0.8300 Test Loss = 0.2818, Test Accuracy = 0.8227\n",
      "Iteration 1718: Loss = 0.2331, Accuracy = 0.8800 Test Loss = 0.2818, Test Accuracy = 0.8232\n",
      "Iteration 1719: Loss = 0.2910, Accuracy = 0.7700 Test Loss = 0.2813, Test Accuracy = 0.8223\n",
      "Iteration 1720: Loss = 0.2721, Accuracy = 0.7900 Test Loss = 0.2812, Test Accuracy = 0.8222\n",
      "Iteration 1721: Loss = 0.2265, Accuracy = 0.8800 Test Loss = 0.2810, Test Accuracy = 0.8220\n",
      "Iteration 1722: Loss = 0.2667, Accuracy = 0.8200 Test Loss = 0.2811, Test Accuracy = 0.8208\n",
      "Iteration 1723: Loss = 0.2310, Accuracy = 0.8200 Test Loss = 0.2810, Test Accuracy = 0.8218\n",
      "Iteration 1724: Loss = 0.2020, Accuracy = 0.8700 Test Loss = 0.2809, Test Accuracy = 0.8235\n",
      "Iteration 1725: Loss = 0.2213, Accuracy = 0.8900 Test Loss = 0.2814, Test Accuracy = 0.8225\n",
      "Iteration 1726: Loss = 0.2274, Accuracy = 0.8500 Test Loss = 0.2809, Test Accuracy = 0.8222\n",
      "Iteration 1727: Loss = 0.2336, Accuracy = 0.8600 Test Loss = 0.2808, Test Accuracy = 0.8238\n",
      "Iteration 1728: Loss = 0.2064, Accuracy = 0.8300 Test Loss = 0.2817, Test Accuracy = 0.8174\n",
      "Iteration 1729: Loss = 0.2366, Accuracy = 0.8800 Test Loss = 0.2810, Test Accuracy = 0.8216\n",
      "Iteration 1730: Loss = 0.2491, Accuracy = 0.8800 Test Loss = 0.2806, Test Accuracy = 0.8241\n",
      "Iteration 1731: Loss = 0.2055, Accuracy = 0.8800 Test Loss = 0.2808, Test Accuracy = 0.8207\n",
      "Iteration 1732: Loss = 0.2625, Accuracy = 0.8400 Test Loss = 0.2810, Test Accuracy = 0.8216\n",
      "Iteration 1733: Loss = 0.1933, Accuracy = 0.8900 Test Loss = 0.2803, Test Accuracy = 0.8221\n",
      "Iteration 1734: Loss = 0.2305, Accuracy = 0.8800 Test Loss = 0.2812, Test Accuracy = 0.8201\n",
      "Iteration 1735: Loss = 0.2508, Accuracy = 0.8000 Test Loss = 0.2810, Test Accuracy = 0.8220\n",
      "Iteration 1736: Loss = 0.2105, Accuracy = 0.8700 Test Loss = 0.2807, Test Accuracy = 0.8200\n",
      "Iteration 1737: Loss = 0.2505, Accuracy = 0.8500 Test Loss = 0.2806, Test Accuracy = 0.8246\n",
      "Iteration 1738: Loss = 0.2545, Accuracy = 0.8800 Test Loss = 0.2808, Test Accuracy = 0.8222\n",
      "Iteration 1739: Loss = 0.2339, Accuracy = 0.8800 Test Loss = 0.2804, Test Accuracy = 0.8193\n",
      "Iteration 1740: Loss = 0.2324, Accuracy = 0.8400 Test Loss = 0.2805, Test Accuracy = 0.8184\n",
      "Iteration 1741: Loss = 0.2562, Accuracy = 0.8000 Test Loss = 0.2803, Test Accuracy = 0.8221\n",
      "Iteration 1742: Loss = 0.2491, Accuracy = 0.8700 Test Loss = 0.2810, Test Accuracy = 0.8211\n",
      "Iteration 1743: Loss = 0.1908, Accuracy = 0.8600 Test Loss = 0.2802, Test Accuracy = 0.8220\n",
      "Iteration 1744: Loss = 0.2277, Accuracy = 0.8300 Test Loss = 0.2810, Test Accuracy = 0.8194\n",
      "Iteration 1745: Loss = 0.2204, Accuracy = 0.8700 Test Loss = 0.2804, Test Accuracy = 0.8175\n",
      "Iteration 1746: Loss = 0.2303, Accuracy = 0.8900 Test Loss = 0.2816, Test Accuracy = 0.8249\n",
      "Iteration 1747: Loss = 0.1992, Accuracy = 0.8800 Test Loss = 0.2799, Test Accuracy = 0.8232\n",
      "Iteration 1748: Loss = 0.2894, Accuracy = 0.8400 Test Loss = 0.2800, Test Accuracy = 0.8245\n",
      "Iteration 1749: Loss = 0.2433, Accuracy = 0.8500 Test Loss = 0.2801, Test Accuracy = 0.8237\n",
      "Iteration 1750: Loss = 0.2623, Accuracy = 0.8500 Test Loss = 0.2805, Test Accuracy = 0.8215\n",
      "Iteration 1751: Loss = 0.2450, Accuracy = 0.8600 Test Loss = 0.2798, Test Accuracy = 0.8225\n",
      "Iteration 1752: Loss = 0.2480, Accuracy = 0.8300 Test Loss = 0.2808, Test Accuracy = 0.8213\n",
      "Iteration 1753: Loss = 0.2202, Accuracy = 0.8600 Test Loss = 0.2801, Test Accuracy = 0.8213\n",
      "Iteration 1754: Loss = 0.2346, Accuracy = 0.8500 Test Loss = 0.2796, Test Accuracy = 0.8223\n",
      "Iteration 1755: Loss = 0.1992, Accuracy = 0.8500 Test Loss = 0.2803, Test Accuracy = 0.8219\n",
      "Iteration 1756: Loss = 0.2168, Accuracy = 0.8800 Test Loss = 0.2796, Test Accuracy = 0.8222\n",
      "Iteration 1757: Loss = 0.2126, Accuracy = 0.9400 Test Loss = 0.2795, Test Accuracy = 0.8225\n",
      "Iteration 1758: Loss = 0.2815, Accuracy = 0.8200 Test Loss = 0.2794, Test Accuracy = 0.8227\n",
      "Iteration 1759: Loss = 0.2235, Accuracy = 0.8000 Test Loss = 0.2795, Test Accuracy = 0.8224\n",
      "Iteration 1760: Loss = 0.2355, Accuracy = 0.8600 Test Loss = 0.2798, Test Accuracy = 0.8220\n",
      "Iteration 1761: Loss = 0.2572, Accuracy = 0.8400 Test Loss = 0.2798, Test Accuracy = 0.8243\n",
      "Iteration 1762: Loss = 0.2318, Accuracy = 0.8200 Test Loss = 0.2792, Test Accuracy = 0.8209\n",
      "Iteration 1763: Loss = 0.2203, Accuracy = 0.8300 Test Loss = 0.2798, Test Accuracy = 0.8243\n",
      "Iteration 1764: Loss = 0.2511, Accuracy = 0.8100 Test Loss = 0.2793, Test Accuracy = 0.8233\n",
      "Iteration 1765: Loss = 0.2181, Accuracy = 0.8800 Test Loss = 0.2788, Test Accuracy = 0.8215\n",
      "Iteration 1766: Loss = 0.1912, Accuracy = 0.8900 Test Loss = 0.2790, Test Accuracy = 0.8223\n",
      "Iteration 1767: Loss = 0.2392, Accuracy = 0.8500 Test Loss = 0.2799, Test Accuracy = 0.8233\n",
      "Iteration 1768: Loss = 0.2292, Accuracy = 0.8700 Test Loss = 0.2791, Test Accuracy = 0.8250\n",
      "Iteration 1769: Loss = 0.2483, Accuracy = 0.8400 Test Loss = 0.2791, Test Accuracy = 0.8221\n",
      "Iteration 1770: Loss = 0.2266, Accuracy = 0.8400 Test Loss = 0.2789, Test Accuracy = 0.8219\n",
      "Iteration 1771: Loss = 0.2506, Accuracy = 0.8800 Test Loss = 0.2799, Test Accuracy = 0.8217\n",
      "Iteration 1772: Loss = 0.2029, Accuracy = 0.8600 Test Loss = 0.2795, Test Accuracy = 0.8240\n",
      "Iteration 1773: Loss = 0.2376, Accuracy = 0.8800 Test Loss = 0.2792, Test Accuracy = 0.8224\n",
      "Iteration 1774: Loss = 0.2363, Accuracy = 0.8800 Test Loss = 0.2786, Test Accuracy = 0.8234\n",
      "Iteration 1775: Loss = 0.2235, Accuracy = 0.8900 Test Loss = 0.2790, Test Accuracy = 0.8214\n",
      "Iteration 1776: Loss = 0.2585, Accuracy = 0.8500 Test Loss = 0.2785, Test Accuracy = 0.8248\n",
      "Iteration 1777: Loss = 0.2299, Accuracy = 0.8800 Test Loss = 0.2788, Test Accuracy = 0.8240\n",
      "Iteration 1778: Loss = 0.2262, Accuracy = 0.8300 Test Loss = 0.2783, Test Accuracy = 0.8232\n",
      "Iteration 1779: Loss = 0.2219, Accuracy = 0.8400 Test Loss = 0.2791, Test Accuracy = 0.8227\n",
      "Iteration 1780: Loss = 0.2729, Accuracy = 0.8100 Test Loss = 0.2786, Test Accuracy = 0.8218\n",
      "Iteration 1781: Loss = 0.2572, Accuracy = 0.8400 Test Loss = 0.2787, Test Accuracy = 0.8253\n",
      "Iteration 1782: Loss = 0.2023, Accuracy = 0.8800 Test Loss = 0.2783, Test Accuracy = 0.8242\n",
      "Iteration 1783: Loss = 0.2574, Accuracy = 0.8100 Test Loss = 0.2789, Test Accuracy = 0.8198\n",
      "Iteration 1784: Loss = 0.2393, Accuracy = 0.8700 Test Loss = 0.2784, Test Accuracy = 0.8214\n",
      "Iteration 1785: Loss = 0.2426, Accuracy = 0.8700 Test Loss = 0.2781, Test Accuracy = 0.8233\n",
      "Iteration 1786: Loss = 0.2171, Accuracy = 0.8900 Test Loss = 0.2784, Test Accuracy = 0.8235\n",
      "Iteration 1787: Loss = 0.2203, Accuracy = 0.8800 Test Loss = 0.2782, Test Accuracy = 0.8209\n",
      "Iteration 1788: Loss = 0.2125, Accuracy = 0.8400 Test Loss = 0.2790, Test Accuracy = 0.8254\n",
      "Iteration 1789: Loss = 0.2378, Accuracy = 0.8500 Test Loss = 0.2785, Test Accuracy = 0.8224\n",
      "Iteration 1790: Loss = 0.2385, Accuracy = 0.8500 Test Loss = 0.2781, Test Accuracy = 0.8216\n",
      "Iteration 1791: Loss = 0.2413, Accuracy = 0.8500 Test Loss = 0.2783, Test Accuracy = 0.8200\n",
      "Iteration 1792: Loss = 0.2392, Accuracy = 0.8400 Test Loss = 0.2780, Test Accuracy = 0.8252\n",
      "Iteration 1793: Loss = 0.2481, Accuracy = 0.7900 Test Loss = 0.2783, Test Accuracy = 0.8219\n",
      "Iteration 1794: Loss = 0.2935, Accuracy = 0.7700 Test Loss = 0.2783, Test Accuracy = 0.8228\n",
      "Iteration 1795: Loss = 0.2141, Accuracy = 0.8800 Test Loss = 0.2788, Test Accuracy = 0.8248\n",
      "Iteration 1796: Loss = 0.2298, Accuracy = 0.8900 Test Loss = 0.2780, Test Accuracy = 0.8239\n",
      "Iteration 1797: Loss = 0.2404, Accuracy = 0.8600 Test Loss = 0.2780, Test Accuracy = 0.8233\n",
      "Iteration 1798: Loss = 0.2229, Accuracy = 0.8600 Test Loss = 0.2781, Test Accuracy = 0.8222\n",
      "Iteration 1799: Loss = 0.2542, Accuracy = 0.8200 Test Loss = 0.2782, Test Accuracy = 0.8240\n",
      "Iteration 1800: Loss = 0.2105, Accuracy = 0.8800 Test Loss = 0.2777, Test Accuracy = 0.8222\n",
      "Iteration 1801: Loss = 0.2572, Accuracy = 0.8400 Test Loss = 0.2782, Test Accuracy = 0.8259\n",
      "Iteration 1802: Loss = 0.1891, Accuracy = 0.8900 Test Loss = 0.2782, Test Accuracy = 0.8240\n",
      "Iteration 1803: Loss = 0.2410, Accuracy = 0.8500 Test Loss = 0.2777, Test Accuracy = 0.8221\n",
      "Iteration 1804: Loss = 0.1985, Accuracy = 0.8500 Test Loss = 0.2776, Test Accuracy = 0.8245\n",
      "Iteration 1805: Loss = 0.3005, Accuracy = 0.8200 Test Loss = 0.2775, Test Accuracy = 0.8241\n",
      "Iteration 1806: Loss = 0.2166, Accuracy = 0.8700 Test Loss = 0.2781, Test Accuracy = 0.8234\n",
      "Iteration 1807: Loss = 0.2672, Accuracy = 0.8300 Test Loss = 0.2784, Test Accuracy = 0.8219\n",
      "Iteration 1808: Loss = 0.2503, Accuracy = 0.8000 Test Loss = 0.2777, Test Accuracy = 0.8217\n",
      "Iteration 1809: Loss = 0.2392, Accuracy = 0.8400 Test Loss = 0.2773, Test Accuracy = 0.8259\n",
      "Iteration 1810: Loss = 0.2407, Accuracy = 0.8500 Test Loss = 0.2774, Test Accuracy = 0.8226\n",
      "Iteration 1811: Loss = 0.2283, Accuracy = 0.8400 Test Loss = 0.2778, Test Accuracy = 0.8237\n",
      "Iteration 1812: Loss = 0.2218, Accuracy = 0.8500 Test Loss = 0.2780, Test Accuracy = 0.8239\n",
      "Iteration 1813: Loss = 0.2246, Accuracy = 0.8500 Test Loss = 0.2770, Test Accuracy = 0.8232\n",
      "Iteration 1814: Loss = 0.2376, Accuracy = 0.8500 Test Loss = 0.2773, Test Accuracy = 0.8233\n",
      "Iteration 1815: Loss = 0.2454, Accuracy = 0.8600 Test Loss = 0.2777, Test Accuracy = 0.8254\n",
      "Iteration 1816: Loss = 0.2350, Accuracy = 0.8300 Test Loss = 0.2771, Test Accuracy = 0.8246\n",
      "Iteration 1817: Loss = 0.2420, Accuracy = 0.8600 Test Loss = 0.2772, Test Accuracy = 0.8248\n",
      "Iteration 1818: Loss = 0.2270, Accuracy = 0.8400 Test Loss = 0.2773, Test Accuracy = 0.8242\n",
      "Iteration 1819: Loss = 0.2329, Accuracy = 0.8600 Test Loss = 0.2771, Test Accuracy = 0.8236\n",
      "Iteration 1820: Loss = 0.2349, Accuracy = 0.9200 Test Loss = 0.2772, Test Accuracy = 0.8221\n",
      "Iteration 1821: Loss = 0.2367, Accuracy = 0.8800 Test Loss = 0.2772, Test Accuracy = 0.8215\n",
      "Iteration 1822: Loss = 0.2518, Accuracy = 0.8000 Test Loss = 0.2769, Test Accuracy = 0.8259\n",
      "Iteration 1823: Loss = 0.2849, Accuracy = 0.8400 Test Loss = 0.2771, Test Accuracy = 0.8248\n",
      "Iteration 1824: Loss = 0.2100, Accuracy = 0.8600 Test Loss = 0.2773, Test Accuracy = 0.8226\n",
      "Iteration 1825: Loss = 0.2263, Accuracy = 0.8500 Test Loss = 0.2766, Test Accuracy = 0.8244\n",
      "Iteration 1826: Loss = 0.2328, Accuracy = 0.8000 Test Loss = 0.2768, Test Accuracy = 0.8231\n",
      "Iteration 1827: Loss = 0.2514, Accuracy = 0.8200 Test Loss = 0.2772, Test Accuracy = 0.8245\n",
      "Iteration 1828: Loss = 0.2972, Accuracy = 0.8100 Test Loss = 0.2770, Test Accuracy = 0.8227\n",
      "Iteration 1829: Loss = 0.2245, Accuracy = 0.9000 Test Loss = 0.2768, Test Accuracy = 0.8233\n",
      "Iteration 1830: Loss = 0.2277, Accuracy = 0.8800 Test Loss = 0.2770, Test Accuracy = 0.8228\n",
      "Iteration 1831: Loss = 0.2253, Accuracy = 0.8800 Test Loss = 0.2765, Test Accuracy = 0.8237\n",
      "Iteration 1832: Loss = 0.2776, Accuracy = 0.8500 Test Loss = 0.2773, Test Accuracy = 0.8240\n",
      "Iteration 1833: Loss = 0.2013, Accuracy = 0.8700 Test Loss = 0.2768, Test Accuracy = 0.8208\n",
      "Iteration 1834: Loss = 0.2329, Accuracy = 0.8700 Test Loss = 0.2767, Test Accuracy = 0.8240\n",
      "Iteration 1835: Loss = 0.3127, Accuracy = 0.8400 Test Loss = 0.2770, Test Accuracy = 0.8241\n",
      "Iteration 1836: Loss = 0.2720, Accuracy = 0.8200 Test Loss = 0.2773, Test Accuracy = 0.8217\n",
      "Iteration 1837: Loss = 0.2364, Accuracy = 0.8700 Test Loss = 0.2769, Test Accuracy = 0.8204\n",
      "Iteration 1838: Loss = 0.2622, Accuracy = 0.8200 Test Loss = 0.2766, Test Accuracy = 0.8231\n",
      "Iteration 1839: Loss = 0.2197, Accuracy = 0.8800 Test Loss = 0.2768, Test Accuracy = 0.8208\n",
      "Iteration 1840: Loss = 0.2451, Accuracy = 0.8200 Test Loss = 0.2767, Test Accuracy = 0.8232\n",
      "Iteration 1841: Loss = 0.2326, Accuracy = 0.8700 Test Loss = 0.2762, Test Accuracy = 0.8242\n",
      "Iteration 1842: Loss = 0.2465, Accuracy = 0.7900 Test Loss = 0.2769, Test Accuracy = 0.8257\n",
      "Iteration 1843: Loss = 0.2264, Accuracy = 0.8800 Test Loss = 0.2765, Test Accuracy = 0.8239\n",
      "Iteration 1844: Loss = 0.2483, Accuracy = 0.8100 Test Loss = 0.2767, Test Accuracy = 0.8247\n",
      "Iteration 1845: Loss = 0.2263, Accuracy = 0.8400 Test Loss = 0.2762, Test Accuracy = 0.8215\n",
      "Iteration 1846: Loss = 0.2353, Accuracy = 0.8500 Test Loss = 0.2765, Test Accuracy = 0.8226\n",
      "Iteration 1847: Loss = 0.2136, Accuracy = 0.8700 Test Loss = 0.2761, Test Accuracy = 0.8234\n",
      "Iteration 1848: Loss = 0.2189, Accuracy = 0.8700 Test Loss = 0.2757, Test Accuracy = 0.8246\n",
      "Iteration 1849: Loss = 0.2013, Accuracy = 0.8700 Test Loss = 0.2757, Test Accuracy = 0.8239\n",
      "Iteration 1850: Loss = 0.2781, Accuracy = 0.8500 Test Loss = 0.2757, Test Accuracy = 0.8238\n",
      "Iteration 1851: Loss = 0.2315, Accuracy = 0.8600 Test Loss = 0.2758, Test Accuracy = 0.8246\n",
      "Iteration 1852: Loss = 0.2643, Accuracy = 0.8600 Test Loss = 0.2762, Test Accuracy = 0.8217\n",
      "Iteration 1853: Loss = 0.2736, Accuracy = 0.7800 Test Loss = 0.2758, Test Accuracy = 0.8247\n",
      "Iteration 1854: Loss = 0.2381, Accuracy = 0.8400 Test Loss = 0.2763, Test Accuracy = 0.8225\n",
      "Iteration 1855: Loss = 0.2186, Accuracy = 0.9100 Test Loss = 0.2760, Test Accuracy = 0.8234\n",
      "Iteration 1856: Loss = 0.2242, Accuracy = 0.8700 Test Loss = 0.2761, Test Accuracy = 0.8224\n",
      "Iteration 1857: Loss = 0.2777, Accuracy = 0.7400 Test Loss = 0.2759, Test Accuracy = 0.8249\n",
      "Iteration 1858: Loss = 0.2240, Accuracy = 0.8200 Test Loss = 0.2759, Test Accuracy = 0.8244\n",
      "Iteration 1859: Loss = 0.2326, Accuracy = 0.8700 Test Loss = 0.2759, Test Accuracy = 0.8233\n",
      "Iteration 1860: Loss = 0.2274, Accuracy = 0.8300 Test Loss = 0.2753, Test Accuracy = 0.8251\n",
      "Iteration 1861: Loss = 0.2378, Accuracy = 0.8500 Test Loss = 0.2760, Test Accuracy = 0.8206\n",
      "Iteration 1862: Loss = 0.2584, Accuracy = 0.8300 Test Loss = 0.2756, Test Accuracy = 0.8235\n",
      "Iteration 1863: Loss = 0.2522, Accuracy = 0.8500 Test Loss = 0.2756, Test Accuracy = 0.8231\n",
      "Iteration 1864: Loss = 0.2492, Accuracy = 0.8600 Test Loss = 0.2754, Test Accuracy = 0.8235\n",
      "Iteration 1865: Loss = 0.2660, Accuracy = 0.8800 Test Loss = 0.2755, Test Accuracy = 0.8261\n",
      "Iteration 1866: Loss = 0.2696, Accuracy = 0.8000 Test Loss = 0.2761, Test Accuracy = 0.8246\n",
      "Iteration 1867: Loss = 0.2125, Accuracy = 0.9000 Test Loss = 0.2754, Test Accuracy = 0.8238\n",
      "Iteration 1868: Loss = 0.1906, Accuracy = 0.9000 Test Loss = 0.2749, Test Accuracy = 0.8240\n",
      "Iteration 1869: Loss = 0.2138, Accuracy = 0.9100 Test Loss = 0.2756, Test Accuracy = 0.8246\n",
      "Iteration 1870: Loss = 0.2359, Accuracy = 0.8100 Test Loss = 0.2752, Test Accuracy = 0.8252\n",
      "Iteration 1871: Loss = 0.2398, Accuracy = 0.8700 Test Loss = 0.2751, Test Accuracy = 0.8246\n",
      "Iteration 1872: Loss = 0.2471, Accuracy = 0.8600 Test Loss = 0.2755, Test Accuracy = 0.8236\n",
      "Iteration 1873: Loss = 0.2322, Accuracy = 0.8700 Test Loss = 0.2761, Test Accuracy = 0.8232\n",
      "Iteration 1874: Loss = 0.2638, Accuracy = 0.8400 Test Loss = 0.2759, Test Accuracy = 0.8255\n",
      "Iteration 1875: Loss = 0.2476, Accuracy = 0.8300 Test Loss = 0.2752, Test Accuracy = 0.8218\n",
      "Iteration 1876: Loss = 0.2131, Accuracy = 0.8600 Test Loss = 0.2749, Test Accuracy = 0.8256\n",
      "Iteration 1877: Loss = 0.2113, Accuracy = 0.8700 Test Loss = 0.2747, Test Accuracy = 0.8248\n",
      "Iteration 1878: Loss = 0.2351, Accuracy = 0.9100 Test Loss = 0.2749, Test Accuracy = 0.8249\n",
      "Iteration 1879: Loss = 0.2134, Accuracy = 0.8600 Test Loss = 0.2749, Test Accuracy = 0.8248\n",
      "Iteration 1880: Loss = 0.2717, Accuracy = 0.7900 Test Loss = 0.2748, Test Accuracy = 0.8215\n",
      "Iteration 1881: Loss = 0.2373, Accuracy = 0.8800 Test Loss = 0.2749, Test Accuracy = 0.8237\n",
      "Iteration 1882: Loss = 0.2667, Accuracy = 0.9200 Test Loss = 0.2746, Test Accuracy = 0.8239\n",
      "Iteration 1883: Loss = 0.2240, Accuracy = 0.8500 Test Loss = 0.2744, Test Accuracy = 0.8254\n",
      "Iteration 1884: Loss = 0.2559, Accuracy = 0.8100 Test Loss = 0.2751, Test Accuracy = 0.8223\n",
      "Iteration 1885: Loss = 0.2623, Accuracy = 0.8700 Test Loss = 0.2744, Test Accuracy = 0.8243\n",
      "Iteration 1886: Loss = 0.2015, Accuracy = 0.8900 Test Loss = 0.2747, Test Accuracy = 0.8245\n",
      "Iteration 1887: Loss = 0.2218, Accuracy = 0.8900 Test Loss = 0.2749, Test Accuracy = 0.8229\n",
      "Iteration 1888: Loss = 0.2910, Accuracy = 0.7300 Test Loss = 0.2749, Test Accuracy = 0.8232\n",
      "Iteration 1889: Loss = 0.2542, Accuracy = 0.8200 Test Loss = 0.2745, Test Accuracy = 0.8249\n",
      "Iteration 1890: Loss = 0.2590, Accuracy = 0.8800 Test Loss = 0.2748, Test Accuracy = 0.8250\n",
      "Iteration 1891: Loss = 0.2383, Accuracy = 0.8600 Test Loss = 0.2749, Test Accuracy = 0.8253\n",
      "Iteration 1892: Loss = 0.2437, Accuracy = 0.8600 Test Loss = 0.2743, Test Accuracy = 0.8241\n",
      "Iteration 1893: Loss = 0.3096, Accuracy = 0.7800 Test Loss = 0.2745, Test Accuracy = 0.8270\n",
      "Iteration 1894: Loss = 0.2503, Accuracy = 0.8200 Test Loss = 0.2744, Test Accuracy = 0.8257\n",
      "Iteration 1895: Loss = 0.1855, Accuracy = 0.9300 Test Loss = 0.2741, Test Accuracy = 0.8245\n",
      "Iteration 1896: Loss = 0.2499, Accuracy = 0.8300 Test Loss = 0.2740, Test Accuracy = 0.8238\n",
      "Iteration 1897: Loss = 0.2705, Accuracy = 0.8300 Test Loss = 0.2745, Test Accuracy = 0.8262\n",
      "Iteration 1898: Loss = 0.2256, Accuracy = 0.8200 Test Loss = 0.2744, Test Accuracy = 0.8245\n",
      "Iteration 1899: Loss = 0.2651, Accuracy = 0.7700 Test Loss = 0.2756, Test Accuracy = 0.8243\n",
      "Iteration 1900: Loss = 0.2429, Accuracy = 0.8400 Test Loss = 0.2746, Test Accuracy = 0.8233\n",
      "Iteration 1901: Loss = 0.2358, Accuracy = 0.7800 Test Loss = 0.2739, Test Accuracy = 0.8245\n",
      "Iteration 1902: Loss = 0.2642, Accuracy = 0.8000 Test Loss = 0.2740, Test Accuracy = 0.8222\n",
      "Iteration 1903: Loss = 0.2311, Accuracy = 0.7900 Test Loss = 0.2745, Test Accuracy = 0.8227\n",
      "Iteration 1904: Loss = 0.2192, Accuracy = 0.8600 Test Loss = 0.2745, Test Accuracy = 0.8240\n",
      "Iteration 1905: Loss = 0.2459, Accuracy = 0.8300 Test Loss = 0.2750, Test Accuracy = 0.8244\n",
      "Iteration 1906: Loss = 0.2123, Accuracy = 0.8600 Test Loss = 0.2739, Test Accuracy = 0.8265\n",
      "Iteration 1907: Loss = 0.2328, Accuracy = 0.8500 Test Loss = 0.2742, Test Accuracy = 0.8257\n",
      "Iteration 1908: Loss = 0.2394, Accuracy = 0.8400 Test Loss = 0.2742, Test Accuracy = 0.8252\n",
      "Iteration 1909: Loss = 0.2394, Accuracy = 0.8300 Test Loss = 0.2740, Test Accuracy = 0.8248\n",
      "Iteration 1910: Loss = 0.2181, Accuracy = 0.8800 Test Loss = 0.2745, Test Accuracy = 0.8235\n",
      "Iteration 1911: Loss = 0.2682, Accuracy = 0.8400 Test Loss = 0.2735, Test Accuracy = 0.8253\n",
      "Iteration 1912: Loss = 0.2524, Accuracy = 0.8600 Test Loss = 0.2737, Test Accuracy = 0.8257\n",
      "Iteration 1913: Loss = 0.2190, Accuracy = 0.8500 Test Loss = 0.2739, Test Accuracy = 0.8254\n",
      "Iteration 1914: Loss = 0.2554, Accuracy = 0.8200 Test Loss = 0.2739, Test Accuracy = 0.8226\n",
      "Iteration 1915: Loss = 0.2284, Accuracy = 0.8700 Test Loss = 0.2737, Test Accuracy = 0.8263\n",
      "Iteration 1916: Loss = 0.1972, Accuracy = 0.9100 Test Loss = 0.2743, Test Accuracy = 0.8249\n",
      "Iteration 1917: Loss = 0.2589, Accuracy = 0.8200 Test Loss = 0.2734, Test Accuracy = 0.8242\n",
      "Iteration 1918: Loss = 0.2199, Accuracy = 0.8800 Test Loss = 0.2734, Test Accuracy = 0.8245\n",
      "Iteration 1919: Loss = 0.2251, Accuracy = 0.8900 Test Loss = 0.2735, Test Accuracy = 0.8269\n",
      "Iteration 1920: Loss = 0.2390, Accuracy = 0.8700 Test Loss = 0.2733, Test Accuracy = 0.8251\n",
      "Iteration 1921: Loss = 0.2507, Accuracy = 0.8500 Test Loss = 0.2738, Test Accuracy = 0.8254\n",
      "Iteration 1922: Loss = 0.2199, Accuracy = 0.8700 Test Loss = 0.2733, Test Accuracy = 0.8244\n",
      "Iteration 1923: Loss = 0.2488, Accuracy = 0.8000 Test Loss = 0.2739, Test Accuracy = 0.8244\n",
      "Iteration 1924: Loss = 0.2427, Accuracy = 0.8900 Test Loss = 0.2733, Test Accuracy = 0.8246\n",
      "Iteration 1925: Loss = 0.2362, Accuracy = 0.8600 Test Loss = 0.2732, Test Accuracy = 0.8260\n",
      "Iteration 1926: Loss = 0.2546, Accuracy = 0.8500 Test Loss = 0.2731, Test Accuracy = 0.8240\n",
      "Iteration 1927: Loss = 0.2241, Accuracy = 0.8300 Test Loss = 0.2733, Test Accuracy = 0.8237\n",
      "Iteration 1928: Loss = 0.2259, Accuracy = 0.8600 Test Loss = 0.2736, Test Accuracy = 0.8253\n",
      "Iteration 1929: Loss = 0.2666, Accuracy = 0.7600 Test Loss = 0.2734, Test Accuracy = 0.8242\n",
      "Iteration 1930: Loss = 0.2059, Accuracy = 0.9300 Test Loss = 0.2738, Test Accuracy = 0.8237\n",
      "Iteration 1931: Loss = 0.2244, Accuracy = 0.8000 Test Loss = 0.2730, Test Accuracy = 0.8262\n",
      "Iteration 1932: Loss = 0.2454, Accuracy = 0.8400 Test Loss = 0.2728, Test Accuracy = 0.8249\n",
      "Iteration 1933: Loss = 0.2278, Accuracy = 0.8500 Test Loss = 0.2729, Test Accuracy = 0.8267\n",
      "Iteration 1934: Loss = 0.2462, Accuracy = 0.8300 Test Loss = 0.2730, Test Accuracy = 0.8227\n",
      "Iteration 1935: Loss = 0.2642, Accuracy = 0.7900 Test Loss = 0.2732, Test Accuracy = 0.8258\n",
      "Iteration 1936: Loss = 0.2570, Accuracy = 0.8300 Test Loss = 0.2732, Test Accuracy = 0.8233\n",
      "Iteration 1937: Loss = 0.2625, Accuracy = 0.8400 Test Loss = 0.2729, Test Accuracy = 0.8261\n",
      "Iteration 1938: Loss = 0.2200, Accuracy = 0.8600 Test Loss = 0.2729, Test Accuracy = 0.8257\n",
      "Iteration 1939: Loss = 0.1947, Accuracy = 0.8600 Test Loss = 0.2731, Test Accuracy = 0.8231\n",
      "Iteration 1940: Loss = 0.2269, Accuracy = 0.8400 Test Loss = 0.2730, Test Accuracy = 0.8274\n",
      "Iteration 1941: Loss = 0.2604, Accuracy = 0.8500 Test Loss = 0.2726, Test Accuracy = 0.8247\n",
      "Iteration 1942: Loss = 0.2337, Accuracy = 0.8400 Test Loss = 0.2729, Test Accuracy = 0.8276\n",
      "Iteration 1943: Loss = 0.2612, Accuracy = 0.8300 Test Loss = 0.2735, Test Accuracy = 0.8244\n",
      "Iteration 1944: Loss = 0.2197, Accuracy = 0.8700 Test Loss = 0.2728, Test Accuracy = 0.8271\n",
      "Iteration 1945: Loss = 0.2322, Accuracy = 0.8300 Test Loss = 0.2731, Test Accuracy = 0.8253\n",
      "Iteration 1946: Loss = 0.2248, Accuracy = 0.8700 Test Loss = 0.2723, Test Accuracy = 0.8235\n",
      "Iteration 1947: Loss = 0.2791, Accuracy = 0.8300 Test Loss = 0.2730, Test Accuracy = 0.8251\n",
      "Iteration 1948: Loss = 0.2540, Accuracy = 0.8800 Test Loss = 0.2726, Test Accuracy = 0.8258\n",
      "Iteration 1949: Loss = 0.2179, Accuracy = 0.9100 Test Loss = 0.2722, Test Accuracy = 0.8236\n",
      "Iteration 1950: Loss = 0.2477, Accuracy = 0.8300 Test Loss = 0.2732, Test Accuracy = 0.8237\n",
      "Iteration 1951: Loss = 0.2304, Accuracy = 0.8500 Test Loss = 0.2724, Test Accuracy = 0.8258\n",
      "Iteration 1952: Loss = 0.2048, Accuracy = 0.8900 Test Loss = 0.2724, Test Accuracy = 0.8273\n",
      "Iteration 1953: Loss = 0.2091, Accuracy = 0.8500 Test Loss = 0.2724, Test Accuracy = 0.8241\n",
      "Iteration 1954: Loss = 0.2171, Accuracy = 0.8600 Test Loss = 0.2725, Test Accuracy = 0.8264\n",
      "Iteration 1955: Loss = 0.2341, Accuracy = 0.8200 Test Loss = 0.2728, Test Accuracy = 0.8234\n",
      "Iteration 1956: Loss = 0.2325, Accuracy = 0.8400 Test Loss = 0.2725, Test Accuracy = 0.8277\n",
      "Iteration 1957: Loss = 0.2535, Accuracy = 0.8600 Test Loss = 0.2725, Test Accuracy = 0.8271\n",
      "Iteration 1958: Loss = 0.2169, Accuracy = 0.8800 Test Loss = 0.2719, Test Accuracy = 0.8254\n",
      "Iteration 1959: Loss = 0.2242, Accuracy = 0.7600 Test Loss = 0.2720, Test Accuracy = 0.8254\n",
      "Iteration 1960: Loss = 0.2349, Accuracy = 0.8200 Test Loss = 0.2721, Test Accuracy = 0.8246\n",
      "Iteration 1961: Loss = 0.2921, Accuracy = 0.8300 Test Loss = 0.2737, Test Accuracy = 0.8233\n",
      "Iteration 1962: Loss = 0.2285, Accuracy = 0.8500 Test Loss = 0.2727, Test Accuracy = 0.8238\n",
      "Iteration 1963: Loss = 0.1750, Accuracy = 0.9300 Test Loss = 0.2720, Test Accuracy = 0.8269\n",
      "Iteration 1964: Loss = 0.2265, Accuracy = 0.8800 Test Loss = 0.2716, Test Accuracy = 0.8256\n",
      "Iteration 1965: Loss = 0.2303, Accuracy = 0.8600 Test Loss = 0.2721, Test Accuracy = 0.8260\n",
      "Iteration 1966: Loss = 0.2235, Accuracy = 0.8700 Test Loss = 0.2717, Test Accuracy = 0.8251\n",
      "Iteration 1967: Loss = 0.2573, Accuracy = 0.8600 Test Loss = 0.2720, Test Accuracy = 0.8249\n",
      "Iteration 1968: Loss = 0.2725, Accuracy = 0.8700 Test Loss = 0.2722, Test Accuracy = 0.8232\n",
      "Iteration 1969: Loss = 0.2486, Accuracy = 0.8500 Test Loss = 0.2721, Test Accuracy = 0.8258\n",
      "Iteration 1970: Loss = 0.2147, Accuracy = 0.8700 Test Loss = 0.2722, Test Accuracy = 0.8271\n",
      "Iteration 1971: Loss = 0.2395, Accuracy = 0.8700 Test Loss = 0.2720, Test Accuracy = 0.8265\n",
      "Iteration 1972: Loss = 0.2428, Accuracy = 0.8900 Test Loss = 0.2721, Test Accuracy = 0.8233\n",
      "Iteration 1973: Loss = 0.2157, Accuracy = 0.9000 Test Loss = 0.2722, Test Accuracy = 0.8255\n",
      "Iteration 1974: Loss = 0.2661, Accuracy = 0.8500 Test Loss = 0.2721, Test Accuracy = 0.8232\n",
      "Iteration 1975: Loss = 0.2423, Accuracy = 0.8600 Test Loss = 0.2719, Test Accuracy = 0.8260\n",
      "Iteration 1976: Loss = 0.2545, Accuracy = 0.8500 Test Loss = 0.2725, Test Accuracy = 0.8264\n",
      "Iteration 1977: Loss = 0.2453, Accuracy = 0.8100 Test Loss = 0.2719, Test Accuracy = 0.8246\n",
      "Iteration 1978: Loss = 0.2291, Accuracy = 0.8700 Test Loss = 0.2715, Test Accuracy = 0.8256\n",
      "Iteration 1979: Loss = 0.2162, Accuracy = 0.8400 Test Loss = 0.2716, Test Accuracy = 0.8235\n",
      "Iteration 1980: Loss = 0.2251, Accuracy = 0.8500 Test Loss = 0.2716, Test Accuracy = 0.8242\n",
      "Iteration 1981: Loss = 0.2265, Accuracy = 0.8600 Test Loss = 0.2718, Test Accuracy = 0.8243\n",
      "Iteration 1982: Loss = 0.2481, Accuracy = 0.8400 Test Loss = 0.2719, Test Accuracy = 0.8239\n",
      "Iteration 1983: Loss = 0.2298, Accuracy = 0.9000 Test Loss = 0.2715, Test Accuracy = 0.8241\n",
      "Iteration 1984: Loss = 0.3024, Accuracy = 0.7900 Test Loss = 0.2714, Test Accuracy = 0.8266\n",
      "Iteration 1985: Loss = 0.2378, Accuracy = 0.8700 Test Loss = 0.2715, Test Accuracy = 0.8263\n",
      "Iteration 1986: Loss = 0.2152, Accuracy = 0.8900 Test Loss = 0.2712, Test Accuracy = 0.8239\n",
      "Iteration 1987: Loss = 0.2713, Accuracy = 0.8300 Test Loss = 0.2715, Test Accuracy = 0.8249\n",
      "Iteration 1988: Loss = 0.2308, Accuracy = 0.8300 Test Loss = 0.2717, Test Accuracy = 0.8231\n",
      "Iteration 1989: Loss = 0.2721, Accuracy = 0.8000 Test Loss = 0.2712, Test Accuracy = 0.8261\n",
      "Iteration 1990: Loss = 0.2419, Accuracy = 0.8600 Test Loss = 0.2717, Test Accuracy = 0.8250\n",
      "Iteration 1991: Loss = 0.2649, Accuracy = 0.7900 Test Loss = 0.2718, Test Accuracy = 0.8244\n",
      "Iteration 1992: Loss = 0.2919, Accuracy = 0.8500 Test Loss = 0.2711, Test Accuracy = 0.8261\n",
      "Iteration 1993: Loss = 0.2552, Accuracy = 0.7800 Test Loss = 0.2714, Test Accuracy = 0.8275\n",
      "Iteration 1994: Loss = 0.2331, Accuracy = 0.8900 Test Loss = 0.2713, Test Accuracy = 0.8236\n",
      "Iteration 1995: Loss = 0.2002, Accuracy = 0.8700 Test Loss = 0.2710, Test Accuracy = 0.8242\n",
      "Iteration 1996: Loss = 0.2090, Accuracy = 0.8800 Test Loss = 0.2712, Test Accuracy = 0.8255\n",
      "Iteration 1997: Loss = 0.2528, Accuracy = 0.8600 Test Loss = 0.2712, Test Accuracy = 0.8271\n",
      "Iteration 1998: Loss = 0.2503, Accuracy = 0.8500 Test Loss = 0.2713, Test Accuracy = 0.8263\n",
      "Iteration 1999: Loss = 0.2378, Accuracy = 0.8500 Test Loss = 0.2708, Test Accuracy = 0.8250\n",
      "Total training time: 41.27s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = make_train_test_data(train_dataset, test_dataset, n=10000)\n",
    "print(X_tr.shape, X_ts.shape)\n",
    "history8 = train_model(X_tr, X_ts, y_tr, y_ts, ITR=2000)\n",
    "plot_history(history8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history5['test_acc'], label='Train Size = 100')\n",
    "plt.plot(history6['test_acc'], label='Train Size = 500')\n",
    "plt.plot(history7['test_acc'], label='Train Size = 1000')\n",
    "plt.plot(history8['test_acc'], label='Train Size = 10000')\n",
    "plt.legend()\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Comment on the accuracy as a function of dataset size:`\n",
    "\n",
    "This plot shows the test accuracy for different train size. It is clearly visible that when we have a larger training set, test accuracy improves significantly. \n",
    "\n",
    "When N=10000 which is equal to the test set size, the performance is better. And, when the train size is significantly lower than the test size, performance on test set is very low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "ITR = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0 Train Loss: 0.0507, Train Accuracy: 0.7838 Test Loss: 0.0520,  Test accuracy: 0.8244\n",
      "Iteration:1 Train Loss: 0.0470, Train Accuracy: 0.8285 Test Loss: 0.0493,  Test accuracy: 0.8439\n",
      "Iteration:2 Train Loss: 0.0420, Train Accuracy: 0.8399 Test Loss: 0.0481,  Test accuracy: 0.8487\n",
      "Iteration:3 Train Loss: 0.0440, Train Accuracy: 0.8443 Test Loss: 0.0474,  Test accuracy: 0.8547\n",
      "Iteration:4 Train Loss: 0.0451, Train Accuracy: 0.8471 Test Loss: 0.0469,  Test accuracy: 0.8552\n",
      "Iteration:5 Train Loss: 0.0431, Train Accuracy: 0.8492 Test Loss: 0.0464,  Test accuracy: 0.8569\n",
      "Iteration:6 Train Loss: 0.0404, Train Accuracy: 0.8504 Test Loss: 0.0460,  Test accuracy: 0.8581\n",
      "Iteration:7 Train Loss: 0.0400, Train Accuracy: 0.8511 Test Loss: 0.0459,  Test accuracy: 0.8588\n",
      "Iteration:8 Train Loss: 0.0399, Train Accuracy: 0.8523 Test Loss: 0.0456,  Test accuracy: 0.8602\n",
      "Iteration:9 Train Loss: 0.0388, Train Accuracy: 0.8527 Test Loss: 0.0454,  Test accuracy: 0.8613\n",
      "Iteration:10 Train Loss: 0.0468, Train Accuracy: 0.8541 Test Loss: 0.0453,  Test accuracy: 0.8617\n",
      "Iteration:11 Train Loss: 0.0402, Train Accuracy: 0.8539 Test Loss: 0.0451,  Test accuracy: 0.8619\n",
      "Iteration:12 Train Loss: 0.0426, Train Accuracy: 0.8545 Test Loss: 0.0450,  Test accuracy: 0.8612\n",
      "Iteration:13 Train Loss: 0.0413, Train Accuracy: 0.8544 Test Loss: 0.0449,  Test accuracy: 0.8617\n",
      "Iteration:14 Train Loss: 0.0374, Train Accuracy: 0.8548 Test Loss: 0.0447,  Test accuracy: 0.8640\n",
      "Iteration:15 Train Loss: 0.0379, Train Accuracy: 0.8552 Test Loss: 0.0447,  Test accuracy: 0.8635\n",
      "Iteration:16 Train Loss: 0.0418, Train Accuracy: 0.8552 Test Loss: 0.0445,  Test accuracy: 0.8631\n",
      "Iteration:17 Train Loss: 0.0398, Train Accuracy: 0.8555 Test Loss: 0.0445,  Test accuracy: 0.8631\n",
      "Iteration:18 Train Loss: 0.0398, Train Accuracy: 0.8561 Test Loss: 0.0445,  Test accuracy: 0.8632\n",
      "Iteration:19 Train Loss: 0.0400, Train Accuracy: 0.8565 Test Loss: 0.0444,  Test accuracy: 0.8619\n",
      "Iteration:20 Train Loss: 0.0330, Train Accuracy: 0.8561 Test Loss: 0.0443,  Test accuracy: 0.8621\n",
      "Iteration:21 Train Loss: 0.0353, Train Accuracy: 0.8560 Test Loss: 0.0442,  Test accuracy: 0.8640\n",
      "Iteration:22 Train Loss: 0.0397, Train Accuracy: 0.8563 Test Loss: 0.0441,  Test accuracy: 0.8640\n",
      "Iteration:23 Train Loss: 0.0384, Train Accuracy: 0.8559 Test Loss: 0.0441,  Test accuracy: 0.8633\n",
      "Iteration:24 Train Loss: 0.0390, Train Accuracy: 0.8559 Test Loss: 0.0440,  Test accuracy: 0.8630\n",
      "Iteration:25 Train Loss: 0.0364, Train Accuracy: 0.8569 Test Loss: 0.0439,  Test accuracy: 0.8609\n",
      "Iteration:26 Train Loss: 0.0373, Train Accuracy: 0.8556 Test Loss: 0.0438,  Test accuracy: 0.8632\n",
      "Iteration:27 Train Loss: 0.0333, Train Accuracy: 0.8566 Test Loss: 0.0440,  Test accuracy: 0.8645\n",
      "Iteration:28 Train Loss: 0.0389, Train Accuracy: 0.8562 Test Loss: 0.0439,  Test accuracy: 0.8646\n",
      "Iteration:29 Train Loss: 0.0433, Train Accuracy: 0.8565 Test Loss: 0.0438,  Test accuracy: 0.8658\n",
      "Iteration:30 Train Loss: 0.0341, Train Accuracy: 0.8564 Test Loss: 0.0437,  Test accuracy: 0.8640\n",
      "Iteration:31 Train Loss: 0.0364, Train Accuracy: 0.8560 Test Loss: 0.0438,  Test accuracy: 0.8649\n",
      "Iteration:32 Train Loss: 0.0416, Train Accuracy: 0.8562 Test Loss: 0.0437,  Test accuracy: 0.8622\n",
      "Iteration:33 Train Loss: 0.0379, Train Accuracy: 0.8554 Test Loss: 0.0437,  Test accuracy: 0.8645\n",
      "Iteration:34 Train Loss: 0.0392, Train Accuracy: 0.8565 Test Loss: 0.0437,  Test accuracy: 0.8634\n",
      "Iteration:35 Train Loss: 0.0401, Train Accuracy: 0.8562 Test Loss: 0.0436,  Test accuracy: 0.8636\n",
      "Iteration:36 Train Loss: 0.0387, Train Accuracy: 0.8558 Test Loss: 0.0436,  Test accuracy: 0.8633\n",
      "Iteration:37 Train Loss: 0.0432, Train Accuracy: 0.8558 Test Loss: 0.0435,  Test accuracy: 0.8636\n",
      "Iteration:38 Train Loss: 0.0377, Train Accuracy: 0.8565 Test Loss: 0.0436,  Test accuracy: 0.8621\n",
      "Iteration:39 Train Loss: 0.0375, Train Accuracy: 0.8561 Test Loss: 0.0434,  Test accuracy: 0.8636\n",
      "Iteration:40 Train Loss: 0.0393, Train Accuracy: 0.8562 Test Loss: 0.0434,  Test accuracy: 0.8630\n",
      "Iteration:41 Train Loss: 0.0389, Train Accuracy: 0.8559 Test Loss: 0.0434,  Test accuracy: 0.8643\n",
      "Iteration:42 Train Loss: 0.0346, Train Accuracy: 0.8561 Test Loss: 0.0434,  Test accuracy: 0.8656\n",
      "Iteration:43 Train Loss: 0.0424, Train Accuracy: 0.8563 Test Loss: 0.0434,  Test accuracy: 0.8643\n",
      "Iteration:44 Train Loss: 0.0403, Train Accuracy: 0.8557 Test Loss: 0.0434,  Test accuracy: 0.8651\n",
      "Iteration:45 Train Loss: 0.0380, Train Accuracy: 0.8561 Test Loss: 0.0433,  Test accuracy: 0.8641\n",
      "Iteration:46 Train Loss: 0.0392, Train Accuracy: 0.8559 Test Loss: 0.0433,  Test accuracy: 0.8652\n",
      "Iteration:47 Train Loss: 0.0413, Train Accuracy: 0.8559 Test Loss: 0.0433,  Test accuracy: 0.8640\n",
      "Iteration:48 Train Loss: 0.0314, Train Accuracy: 0.8558 Test Loss: 0.0432,  Test accuracy: 0.8638\n",
      "Iteration:49 Train Loss: 0.0429, Train Accuracy: 0.8557 Test Loss: 0.0432,  Test accuracy: 0.8639\n",
      "Iteration:50 Train Loss: 0.0411, Train Accuracy: 0.8562 Test Loss: 0.0433,  Test accuracy: 0.8644\n",
      "Iteration:51 Train Loss: 0.0408, Train Accuracy: 0.8562 Test Loss: 0.0432,  Test accuracy: 0.8629\n",
      "Iteration:52 Train Loss: 0.0363, Train Accuracy: 0.8559 Test Loss: 0.0431,  Test accuracy: 0.8637\n",
      "Iteration:53 Train Loss: 0.0417, Train Accuracy: 0.8559 Test Loss: 0.0431,  Test accuracy: 0.8642\n",
      "Iteration:54 Train Loss: 0.0348, Train Accuracy: 0.8558 Test Loss: 0.0431,  Test accuracy: 0.8642\n",
      "Iteration:55 Train Loss: 0.0402, Train Accuracy: 0.8558 Test Loss: 0.0432,  Test accuracy: 0.8637\n",
      "Iteration:56 Train Loss: 0.0440, Train Accuracy: 0.8558 Test Loss: 0.0431,  Test accuracy: 0.8637\n",
      "Iteration:57 Train Loss: 0.0378, Train Accuracy: 0.8561 Test Loss: 0.0431,  Test accuracy: 0.8640\n",
      "Iteration:58 Train Loss: 0.0425, Train Accuracy: 0.8559 Test Loss: 0.0431,  Test accuracy: 0.8628\n",
      "Iteration:59 Train Loss: 0.0356, Train Accuracy: 0.8558 Test Loss: 0.0431,  Test accuracy: 0.8640\n",
      "Iteration:60 Train Loss: 0.0372, Train Accuracy: 0.8561 Test Loss: 0.0431,  Test accuracy: 0.8636\n",
      "Iteration:61 Train Loss: 0.0384, Train Accuracy: 0.8563 Test Loss: 0.0432,  Test accuracy: 0.8640\n",
      "Iteration:62 Train Loss: 0.0373, Train Accuracy: 0.8564 Test Loss: 0.0431,  Test accuracy: 0.8645\n",
      "Iteration:63 Train Loss: 0.0380, Train Accuracy: 0.8561 Test Loss: 0.0430,  Test accuracy: 0.8647\n",
      "Iteration:64 Train Loss: 0.0352, Train Accuracy: 0.8564 Test Loss: 0.0430,  Test accuracy: 0.8644\n",
      "Iteration:65 Train Loss: 0.0339, Train Accuracy: 0.8559 Test Loss: 0.0431,  Test accuracy: 0.8637\n",
      "Iteration:66 Train Loss: 0.0403, Train Accuracy: 0.8561 Test Loss: 0.0431,  Test accuracy: 0.8637\n",
      "Iteration:67 Train Loss: 0.0388, Train Accuracy: 0.8563 Test Loss: 0.0430,  Test accuracy: 0.8639\n",
      "Iteration:68 Train Loss: 0.0402, Train Accuracy: 0.8555 Test Loss: 0.0429,  Test accuracy: 0.8639\n",
      "Iteration:69 Train Loss: 0.0406, Train Accuracy: 0.8561 Test Loss: 0.0430,  Test accuracy: 0.8637\n",
      "Iteration:70 Train Loss: 0.0382, Train Accuracy: 0.8558 Test Loss: 0.0430,  Test accuracy: 0.8632\n",
      "Iteration:71 Train Loss: 0.0393, Train Accuracy: 0.8559 Test Loss: 0.0430,  Test accuracy: 0.8627\n",
      "Iteration:72 Train Loss: 0.0406, Train Accuracy: 0.8560 Test Loss: 0.0430,  Test accuracy: 0.8638\n",
      "Iteration:73 Train Loss: 0.0359, Train Accuracy: 0.8563 Test Loss: 0.0429,  Test accuracy: 0.8636\n",
      "Iteration:74 Train Loss: 0.0326, Train Accuracy: 0.8561 Test Loss: 0.0430,  Test accuracy: 0.8622\n",
      "Iteration:75 Train Loss: 0.0362, Train Accuracy: 0.8558 Test Loss: 0.0430,  Test accuracy: 0.8639\n",
      "Iteration:76 Train Loss: 0.0381, Train Accuracy: 0.8559 Test Loss: 0.0430,  Test accuracy: 0.8643\n",
      "Iteration:77 Train Loss: 0.0370, Train Accuracy: 0.8562 Test Loss: 0.0430,  Test accuracy: 0.8644\n",
      "Iteration:78 Train Loss: 0.0348, Train Accuracy: 0.8562 Test Loss: 0.0429,  Test accuracy: 0.8633\n",
      "Iteration:79 Train Loss: 0.0367, Train Accuracy: 0.8559 Test Loss: 0.0429,  Test accuracy: 0.8636\n",
      "Iteration:80 Train Loss: 0.0374, Train Accuracy: 0.8564 Test Loss: 0.0429,  Test accuracy: 0.8627\n",
      "Iteration:81 Train Loss: 0.0404, Train Accuracy: 0.8560 Test Loss: 0.0429,  Test accuracy: 0.8623\n",
      "Iteration:82 Train Loss: 0.0367, Train Accuracy: 0.8562 Test Loss: 0.0429,  Test accuracy: 0.8633\n",
      "Iteration:83 Train Loss: 0.0433, Train Accuracy: 0.8557 Test Loss: 0.0428,  Test accuracy: 0.8640\n",
      "Iteration:84 Train Loss: 0.0433, Train Accuracy: 0.8564 Test Loss: 0.0429,  Test accuracy: 0.8624\n",
      "Iteration:85 Train Loss: 0.0349, Train Accuracy: 0.8557 Test Loss: 0.0429,  Test accuracy: 0.8630\n",
      "Iteration:86 Train Loss: 0.0335, Train Accuracy: 0.8556 Test Loss: 0.0429,  Test accuracy: 0.8638\n",
      "Iteration:87 Train Loss: 0.0431, Train Accuracy: 0.8559 Test Loss: 0.0429,  Test accuracy: 0.8629\n",
      "Iteration:88 Train Loss: 0.0463, Train Accuracy: 0.8560 Test Loss: 0.0428,  Test accuracy: 0.8632\n",
      "Iteration:89 Train Loss: 0.0365, Train Accuracy: 0.8560 Test Loss: 0.0427,  Test accuracy: 0.8627\n",
      "Iteration:90 Train Loss: 0.0390, Train Accuracy: 0.8562 Test Loss: 0.0428,  Test accuracy: 0.8627\n",
      "Iteration:91 Train Loss: 0.0391, Train Accuracy: 0.8561 Test Loss: 0.0428,  Test accuracy: 0.8637\n",
      "Iteration:92 Train Loss: 0.0398, Train Accuracy: 0.8558 Test Loss: 0.0428,  Test accuracy: 0.8631\n",
      "Iteration:93 Train Loss: 0.0387, Train Accuracy: 0.8560 Test Loss: 0.0428,  Test accuracy: 0.8625\n",
      "Iteration:94 Train Loss: 0.0381, Train Accuracy: 0.8560 Test Loss: 0.0428,  Test accuracy: 0.8626\n",
      "Iteration:95 Train Loss: 0.0365, Train Accuracy: 0.8560 Test Loss: 0.0428,  Test accuracy: 0.8629\n",
      "Iteration:96 Train Loss: 0.0381, Train Accuracy: 0.8561 Test Loss: 0.0427,  Test accuracy: 0.8626\n",
      "Iteration:97 Train Loss: 0.0432, Train Accuracy: 0.8554 Test Loss: 0.0429,  Test accuracy: 0.8628\n",
      "Iteration:98 Train Loss: 0.0383, Train Accuracy: 0.8562 Test Loss: 0.0428,  Test accuracy: 0.8626\n",
      "Iteration:99 Train Loss: 0.0361, Train Accuracy: 0.8556 Test Loss: 0.0428,  Test accuracy: 0.8631\n"
     ]
    }
   ],
   "source": [
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.linear = nn.Linear(784, 10)   \n",
    "        self.linear.weight.data.fill_(0)    # set initial weights to zero\n",
    "        self.linear.bias.data.fill_(0)      # set initial biases to zero\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)   \n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LinearClassifier()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_mse = nn.MSELoss() \n",
    "\n",
    "train_losses = [] \n",
    "test_losses = [] \n",
    "train_acc = []\n",
    "test_acc = [] \n",
    "\n",
    "for epoch in range(ITR):\n",
    "    tr_correct = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        outputs = model(images)\n",
    "        loss = loss_mse(outputs, torch.nn.functional.one_hot(labels, num_classes=10).float())\n",
    "        pred_tr = torch.argmax(outputs, dim=1)\n",
    "        tr_correct += torch.sum(pred_tr == labels).item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_losses.append(loss) \n",
    "    tr_accuracy = tr_correct / len(train_dataset)\n",
    "    train_acc.append(tr_accuracy) \n",
    "\n",
    "    total_correct = 0\n",
    "    for x, y in test_loader:\n",
    "        x = x.view(-1, 784) \n",
    "        y_pred = model(x)\n",
    "        loss_ts = loss_mse(y_pred, torch.nn.functional.one_hot(y, num_classes=10).float())\n",
    "        pred = torch.argmax(y_pred, dim=1)\n",
    "        total_correct += torch.sum(pred == y).item()\n",
    "    test_accuracy = total_correct / len(test_dataset) \n",
    "    \n",
    "    test_losses.append(loss_ts) \n",
    "    test_acc.append(test_accuracy) \n",
    "\n",
    "    print(f\"Iteration:{epoch} Train Loss: {loss.item():0.4f}, Train Accuracy: {tr_accuracy:0.4f} Test Loss: {loss_ts:0.4f},  Test accuracy: {test_accuracy:0.4f}\")\n",
    "\n",
    "history_ = dict() \n",
    "history_['acc']       = train_acc \n",
    "history_['loss']      = train_losses\n",
    "history_['test_acc']  = test_acc\n",
    "history_['test_loss'] = test_losses \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFNCAYAAABFbcjcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABMcUlEQVR4nO3dd3hc5Z328e9PvVqSJfeOG25gY2M6oYQeIARCT0KWAGmkLClkN6HtZpdk8yYkm0BCzxKagRBIcMABTA3FFXDvRW4qVpdGGs087x/PSJZlSR7JM9LYvj/XpUuamXPmPHNGM+c+TzvmnENEREREEkNSXxdARERERPZQOBMRERFJIApnIiIiIglE4UxEREQkgSiciYiIiCQQhTMRERGRBKJwJiJyCDOzU8xsdV+XQ0Sip3AmIlExszfMrMLM0vu6LAcLMxttZs7MUiK3HzWz/4zzNp2ZjWu57Zx72zk3MZ7bFJHYUjgTkf0ys9HAKYADLurlbaf05vYSmfaFyOFB4UxEovFF4H3gUeBLbR8wsxFm9mczKzWzcjP7bZvHbjCzlWZWY2YrzOyYyP171e60rVEys9PMrNjMfmhmO4FHzKzAzP4W2UZF5O/hbdbvb2aPmNn2yON/idy/zMwubLNcqpmVmdmM9i8wUs7PtLmdEtneMWaWYWZ/iry+SjNbYGaDurMDzexG4BrgB2ZWa2Z/jdw/1Myei2xro5l9q806d5jZs5FtVwPXmdlsM3svUo4dZvZbM0uLLP9WZNWPItu4omV/tnnOSZFa0EozW25mF7V57FEz+52ZvRR5zz4ws7HdeZ0icuAUzkQkGl8EHo/8nNMSTMwsGfgbsBkYDQwDnoo89nngjsi6/fA1buVRbm8w0B8YBdyI/656JHJ7JNAA/LbN8o8BWcAUYCDwq8j9/wdc22a584EdzrklHWzzSeCqNrfPAcqcc4vxgTQPGAEUAl+NlCFqzrn78fvv5865HOfchWaWBPwV+Ai/784EvmNm57RZ9WLgWSA/sn4I+C5QBJwQWefrkW2cGlnn6Mg2nm5bBjNLjWxvHn4/3Qw8bmZtmz2vBO4ECoB1wE+78zpF5MApnIlIl8zsZHwomuOcWwSsB66OPDwbGAp83zlX55wLOOfeiTz2FXwQWeC8dc65zVFuNgzc7pxrdM41OOfKnXPPOefqnXM1+MDwqUj5hgDnAV91zlU454LOuTcjz/Mn4Hwz6xe5/QV8kOvIE8BFZpYVuX01PrABBPGhbJxzLuScW+Scq47ytXTlWGCAc+4u51yTc24D8AA+ILV4zzn3F+dcOLIvFjnn3nfONTvnNgF/ILIvonA8kAPcHdne6/hw3TaUPu+c+9A514wPg9MP7CWKSHcpnInI/nwJmOecK4vcfoI9TZsjgM2RA3l7I/BBridKnXOBlhtmlmVmfzCzzZHmvbeA/EjN3Qhgt3Ouov2TOOe2A+8Cl5pZPj7EPd7RBp1z64CVwIWRgHYR/rWCD3SvAE9Fmk5/HqmFOlCjgKGRJsZKM6sE/g1o22S6te0KZjYh0qy7M7Iv/gtfixaNocBW51y4zX2b8bV2LXa2+bseH+ZEpBepc6mIdMrMMoHLgeRI/y+AdHwwOhofHEaaWUoHAW0r0Fl/pXp8M2SLwUBxm9uu3fK3ABOB45xzO81sOrAEsMh2+ptZvnOusoNt/RFfi5eCr4Xa1tnrZU/TZhKwIhLYcM4F8U19d0YGR8wFVgMPdfFcHWn/urYCG51z47uxzn34136Vc67GzL4DXBbl9rcDI8wsqU1AGwmsiXJ9EekFqjkTka58Ft/HaTK+eWs6MAl4G9+X7ENgB3C3mWVHOs6fFFn3QeB7ZjbTvHFmNiry2FLgajNLNrNz2X+zXC6+j1elmfUHbm95wDm3A/g7cG9k4ECqmZ3aZt2/AMcA38b3QevKU8DZwNfYU2uGmZ1uZtMiNXXV+GbOcMdP0aVdwBFtbn8I1EQGP2RG9sdUMzu2i+fIjZSh1syOjJS1q2209QE+GP8gsp9OAy4k0k9QRBKDwpmIdOVLwCPOuS3OuZ0tP/jO+Nfga64uBMYBW/C1X1cAOOeewfcNewKowYek/pHn/XZkvcrI8/xlP+W4B8gEyvCjRl9u9/gX8IFpFVACfKflAedcA/AcMAb4c1cbiQS994ATgbad6QfjO+VX45s+3yTSd83Mfm9mv99P+Vs8BEyONGH+xTkXAj6DD70bI6/vQfzgg858D98frgbfP+3pdo/fAfwxso3L272+Jvx+Py+yrXuBLzrnVkVZfhHpBeZc+xpzEZFDi5ndBkxwzl2734VFRPqY+pyJyCEt0gx6Pb52TUQk4alZU0QOWWZ2A77T/d+dc2/tb3kRkUSgZk0RERGRBKKaMxEREZEEonAmIiIikkAOmQEBRUVFbvTo0X1dDBEREZH9WrRoUZlzbkBHjx0y4Wz06NEsXLiwr4shIiIisl9m1um1htWsKSIiIpJAFM5EREREEojCmYiIiEgCUTgTERERSSAKZyIiIiIJROFMREREJIEonImIiIgkEIUzERERkQSicCYiIiKSQBTORPpKbQmsn9/XpRARkQSjcCbSF1a9BPceD499Ft79TV+Xpm81VMIL34D5/w2h5r4ujYhInztkrq0pclBorIVXfgSL/w8GHwUjjoN//ATSc2HWl/u6dL1vx0cw54tQuQVcGDa9A5c9DLmDOl6+tgSa6qD/mK6fd9dyWPEizL4RsgtjX24RkThSzZlIbyleBH84BRY/Bid9B77yGnz+jzD+bPjbd+HjZzpeb/M/4a/fgeodvVna+HIOFj0KD54FoSB8+WX47O9hW2QfbXpn7+V3b/D74FdT4Tcz4IVvQm3pvs/b3Aiv/xT+cCq8eTfcdyKse603XtHhwzlorPG/RSQuzB0iH7BZs2a5hQsX9nUxRHyYWv86BKqhsdr/DlTBlvcgdwhc8nsYc8qe5YMN8KfL/ONXPAZHXuDv3/ExvP4fsHaevz3xfLjyCTDrfNsr/wqF42DgpPi9vgPVVAcv3QIfPQlHnA6XPgjZRf6xXct9TdruDXDmbTD2DHj317D8eUhKgenXQFo2fPB7SM2G038Ex34FklNhywfw4s1QthqOuhJmXAMvfc/fPu5r8Ok7IDWj5+Wu3w3p/SD5MGlwCAX9/+Tmf0LlVqjaClXF/ifUCFmFMHAyDJqy52fIDEg6TM/5Q8HIZ74K0nIhZ0Bfl0gSnJktcs7N6vAxhTORGAmH4M2fw5s/87fT+0FGvz2/B02BM34MmQX7rttYA/93Mez8BC78ta/tWfYsZOTDyd/1X/zz/xMufwwmX9Tx9le84INNUgqc/K9w6vcgJT1uL7dHytb6MpashNNuhVO/D0nJey/TWOND1vLn/e20XDj2X+D4r0PuYH9f6Rp4+Yc+BA+YBCOO9TWSecPhM/fA+E/75YIN8I/b4cM/+CDxuQdg8NToyhoOw/bFsOYVWPuKb4IdMAmufdZvJ1o1O33A3rV839qm1AwYcyqMOvnAgmOs1Jb6sq59xQ9WaawGzO/3vOF7fjL7+wBdssK/l8F6v37+KN88P+MLewL3oSZQBVs/9MF1y/tQvt7f19ywZ5mkVDjlFjjlXxPvMygJQ+FM4m/1y/6AOvxYmHA2jD8H+g3pu/K89zvfvBVu18E8NROmXgrHXu/DUqzUlcFzX4EN8+Hoq+CC/+dreLqjfjc8eoE/4KVmwfFfgxO/BZn5vqP8A6f57XzjA8jI23vdik3w+1OhcCwMmOhrpYomwkX/CyOPi9GLPEDL/uz/R1LSfUgad2bnyzrn++U1VMDM6/w+6GiZ1XPh5R/5Pmuzb/C1bem5+y679h/wl69DfTnkj4yEjBH+d7+hPvw2Vu2p7azf7Q++daVgSb5v4MgTYMGDkJYD1zzTecgLh2HHEh/q1rwCO5b6+9NyfHBuK1gPoSb/fh9xmm/iHnuGD/NthZqhfB2ULIddK/z/SPk6mHgenPPfkJ7TcVl2b4S/fsv/f4w4HkYeD6NO9P8bSUm+FmzL+3uCxq7lgIOcwXs+x0ec1vnzt7zeio1QvNC/Z5vfgeQ0mHwxzLoeBh657/tWv3vvmriqYmiq2fe5U7P2DoV5I/z7l5rZeXk6LWcI1r3qa1nzRkLesO49zwd/8CcAu5YBDiwZhhztv0cy8vxPy4nY+tfhk2dgwJFw0W/9yUM8Bargo6d8V4G8Eb7fZlfvWUdqS/3/16iT41s73JI5umoBOEwonEl8VW6F35/sv5xc2H/pgu/wPuEcGH2yD23dDSs99dFT8PxN/qAyZPrej1Vv8x3FQ43+YHvsV2DShQd2drvlA3jmOn/gP/9/4Jgv9vyLp7YEPn4apn1+Ty1Ri22L4MFP+wPeBb/Yc38oCA+f62ulvvoWFIyGta/C377jD3qzb/QHyuptex8QLRkGTd7TNFU4zoeH6m2RALDcH6wtGc75adc1IbuWw1u/gMHTYNpl/gDaorkJ5v3Y114Nnw2ff9QfGGMlGICaHfsfJFBX5ptDd2/Ysw9qdvj/2RbJ6f7gmpEHQ2f4cDLuTMjq7x/fuQwe/zw01fom6CNO2/t1fvIMvHsPlK3xoW74sT5wTTgHBk3d9/8i2AAb3/Y1VWte2fPZ6Up6nm+2zh3k/5cLRvuw2zYAOAdLn4C//8C/f2NO8bU9dSX+8Yx8H2JbtpeW48s66iQYf5YPHT39Hy5ZBQsf9icIjdVRrBCpmUvvt+82G2sj71Foz31JqTD6JJhwrt+3hWP3v4ldK/yJwbZ2x4isIsgfAcd/A476fOfrv3E3vPHf/v933Kd9yB0+q+vvtDWv+L6k1dv9idYZP/b/q60Be7mvVZ1xLUy6qGf7e8dHsOAh/38XrIdB0/zzDpvlTyA6Oqlpr2Iz/PN/Yclj0ByAwvG+rJMvjm2Acg5Wvui/C4INMOUSmHa534+HaVBTOJP4CTX72p5dy+GmN6H/Eb6ZY83Lvnlk6wf+4NdyljnyBBgxu4OmPQdN9Xv6aDVW++at0afsaaKKxrpX4YkrfO3ANc92HLrqd8OSP/kDSMVG30Qz/NhIUIn0nSka78+w92fBQ/4AmDcCLv+jf43x9Pcf+jP46+f5/Qgw7yfwz9/4wQVTPrtn2cYaeO0u+PABoM3nPLO/r4UINflA13LgS06DlExfg9Si3zAfOvsNhWuf8+9vexvehKev9TUTwTp/38gTfEgbPtsfoLYt9AfAs+6Mbr/2llDQB+LkNB/KognpVdvg8cv8vrv4d76P4OL/g/d+64Pt4Gm+j9uEc7s3UtQ5/9nZ8k9frrYsyYewgZP9e9dyMNv8T/jzTX67n/oBnPI9/9n523d8M/eok3wfx/yR/vkrNvoass3/9H3/Rhzng8agqbGvLWms9VPGNOze97HMgj21YblDISWt8+cJNfuA1hKod34Ea+b5voTgTyrGn+MD8MgT9n6u5iZ4+//5n4x+cPZP/b6oKo6cqGz1A3V2feJrqT99x77N7C3BbPo1via6/eNdCVTDa3f6GteUDB9+WvdBfx/uqrbC0GMifSxPj+55ty+FV/4NNr/rP7PTLvOtAUNn+MD+7L/4WrsvPN9537ddK/yJxCfP+v+vo6/0/y/v3gOlq/xznXmb7xdq5r+fS1f5WtvdG/3/eUe1vB0pWem/uza+6b9ji8b51pZQo/+/nvZ5/zNgYnSvP56c85/tploYdkxcN6VwJvHz2l3+i+/Sh/wXRHuBKti6YE+zybaFe39BdcWSfXA48WY48/b9H9S3LYZHP+MDxJfn7v9LIxyGDa/7UZI7P/G1HeHIQTE5HS68B6Zf3fn66+fDY5f4mobPPRDdWeqBaqyB3x3na3Zuegs2vOGDwqzr4TO/7HidncugdlekGW/Y3mf7zY3+de+K1JI11flamUFT/O/MAl/j8sQV/gv86jkwfOae9T+e45sLC8f5vlihoO8r9/Ezew6e6f3g4t/6M/FDRUOlD6Sb3vY1WY1Vvjno5O/6mrberAkIVMHc7/sa12Ez/ajeulI449994OhOmDiY7N7oTwDXvOLfh1CT75849nQfjPsNgZf/DUpX+gP/uXd3XPsbCvoTrIUP+5B36YN7vjsOJJi1tfmfsOy5PQF70BTIGeRPXD96ym+jaqvvf3jmHXt/xtqqK4fX74JFf/Sv5eR/helX7Xuyu+41eOoa/3n/4gt7+kg2VPjw9skzfp+lZvs+gsd/fU9tdjjk/5fm/zdUbfGtD401vsaZdnkhKRVGneD32/iz9+3KEmyAd37lTyjTc+CMn8DML/sTgUA1rPqb/w7Z+KbfF4On+dq0qZd2XbseDvmm+l3LfVis3Or3bUtLQP6oPQNTwmH//VdVDDXb/fdRy3dhS7N2c6MfIb52nq9YqNjkKwau+1sXb+qBUziT+Fj/Ojz2OTjmC/6LKxrNTb7PRrBh38dSM/futwHwyr/Dggf8GfFlD/sanI7s3gAPne3PIr/yj32bBKMtW/laf0a58GEoXgDXvdRxn63aErjvJP+leOP83muyBV8b8dTV/gv146f9CNCvvBbfDuVl6+BPn/Ov+/OP+IPfO7/ytQKjT4Er/rR3OHXOB96Nb/pRptE0PR1smht9bUBdKZz07T01mX3lk2fhb/8KOQN9wBg6vW/L05ua6nwNbkuNfU1k2pl+w+Azv/K1avuz4EGY+wN/onHVkz7AxCKYRaO50X/nvPU/vqa6YLT/zmv56T8GFj7iBwU11cHsm+C0H+7b97StLe/7JviMPPjUD2H13/2+CQf9azz6Sn9S19Jk32GZHoGPn/LhbuCUPa0L+SN8N4uWfpWlK7t4cQYzvwRn3NZ5TXLNLj8A6JM5/nkxX4s35lTfXNu2RaW2BEpXtxmAYZA9YE+TPfhm+sKx/sSlatuek+72sop8oCzf4Gv9UzJgzKf29LfMH9HF6zpwCmcSezW74Pcn+X/uG16HtKz4beuTZ+HFb/ltXPrg3v18AtW+qWbOl/wH8fp5vknyQDVUwP2n+y+GG9/YOxSGw/D4pf5s+IbXYzuwIFpPXePPOlOz4MY3YcCE+G+ztgSeuNz3czniNB/Op14Gn71XI9ISRWONP8AkUtNxb2s5Mdi13Dc5R9Ps1mLjW340cTDgD/69EczaaqyBJY/7Wq0t70N9mb8/Od03AR5xGpz7s30HWXRmx0e+dr++3A/ymHaZ/xkyPba1uxWb/WCoxg4GdYw5tXvdPcrX+1rGj+f4k+Wk1L1HvWcV+ibblhrIAUf6Y0Njje/v2NKnr3zdnubz/BG+tix3iF+uqtjXClYV+/CWPzLSP/qU+B7L2lE4k32FQ74zatu+F1XF/h9/xhe6PmMIh+FPl/iO8DfO7505tUpX+y/NsjX+w15X5ssciPSPSsmEL/01tqOiSlb6DvhFE+DLf99TM/X2L32N0Wfu6btZ/au3w+OXw8nf6bg5OV6a6uCZL/sO7Cd9xzc3H67zWsmhafdGeO56HyjO/0XfNQs75wPGlvd8H7MjTvODl7obqiq3+tHMI48/uJq4nfO1dynph+yAAYUz8Z05ty2K9P16z/cDaz90PSNvz5nP+HP8SMaxZ/iDbyjoO/evedlXY5etgQt/46ure+011PlOsNsW7ZkGoeVn6DH7H63XEyv/Bk9f46fH+Ox9vv/VI+f5ucYue+SQ/dLoUjjkDxqJ0HlXROQgpXB2OCtZBS/f6qvJw82A+ergUSf4KuG8ljmfhvmh9ZVb/Fw5i//P96UpGO07aW54y3d6bhnGPvVSX8N2OISTlk7Bn7rVj/JMTvGd8bvq7yEiItKFPgtnZnYu8GsgGXjQOXd3u8dHAn8E8iPL3Oqcmxt57CjgD0A/IAwc65zrdJifwlk7zU3+sjdv/dx3Vj/mS76D5YhjO56hvqP1V/3VTxVRsRnGnuZr08ae3vEkn4eycBjmfMH38UpKhetf8aPiREREeqhPwpmZJQNrgLOAYmABcJVzbkWbZe4Hljjn7jOzycBc59xoM0sBFgNfcM59ZGaFQKVzbWci3JvCWRvbFsELN/uOkVM+B+f9XNd5O1CNNfDs9b7PxzFf6OvSiIjIQa6rcBbPK/jOBtY55zZECvEUcDGwos0yDl8zBpAHbI/8fTbwsXPuIwDnXHkcy3noCAX9vGPv/dbPoXPlk3Dk+X1dqkNDei5cM6evSyEiIoeBeIazYUDba5EUA+0njLoDmGdmNwPZQMtU8BMAZ2avAAOAp5xzP49jWQ9+deV+NOPmd3wT5tn/oT5RIiIiB6F4hrNoXAU86pz7f2Z2AvCYmU2NlOtk4FigHngtUv33WtuVzexG4EaAkSNHctjatQKevNJPjXHJ/XD0FX1dIhEREemheE5QtA1oO1nW8Mh9bV0PzAFwzr0HZABF+Fq2t5xzZc65emAusM9Frpxz9zvnZjnnZg0YcJj2qVo1Fx46y88H8+W5CmYiIiIHuXiGswXAeDMbY2ZpwJXAi+2W2QKcCWBmk/DhrBR4BZhmZlmRwQGfYu++atLcBG/9wl/Gp2i8nwx2eIf9CkVEROQgErdmTedcs5l9Ex+0koGHnXPLzewuYKFz7kXgFuABM/sufnDAdc4PH60ws1/iA57Dj+J8KV5lPahUFft5yBb90V9LbOpl/qLSLRdwFRERkYOaJqE9GDjnr2O44CFY83d/e8I5/qK14886PCaCFREROYT01VQaEgu1pfDizT6UZRX56xnOvA4KRvV1yURERCQOFM4S2Zp58MLXIVAN5/yXv9ZlSnpfl0pERETiSOEsETXVwz9+AgsehIFT4Isv+OtgioiIyCFP4SzRlK6Gp6+FsjVwwjfhjJ9AakZfl+qwt6s6wK9fW8txY/pz8fRhfV0cERE5hCmcJZKSVfDHzwAGX/iLv8i47GVnVYBgKMzwgkysFwZChMOOJz7cws/+voqaxmae+GALS7ZU8u8XTCI1ed+ZaOqbmnngrY1sq6xn1uj+HD+mkBH99y1rcyjMlt31lNY0kp2eQr+MVHIzUsjNSCGlg+c9EB9u3M3uuiamDO0Xk/22rqSG9zfs5ujh+Uwe2o/kJA1IORQ552gIhmgMhinITtvv8sFQuMPPhHRPdSBIbnpKr3y/SeJSOEsULcHMkuC6l/zcZYe5YCjMyh3VLNpcwaLNFSzeXMH2qgAAhdlpTB+R739G5jN+YC6pyUZKcpL/nZREUyjMprI6NpbVtf4urW3kyMG5zBhZwPQR+QzJy+j0S3BdSS0/+vPHLNhUwYljC7nr4ik88cFWHn53Iyt2VPO7q49hQK7vA+ic4+VlO/mPv61ge1WAfhkpzFlYDMCQvAyOG9OfIfmZbCytY31pLZvK6wiGOh4pnZuRwtSheUwf6V/fjBH5DOyXgXOOyvogO6oC7KoOUF7XxAljCxmW3/E0KuW1jdz51xW8+NH2vZ570pB+TB7SjylD+3HU8HzGDczZb8AKhsLMW76Lx97fxPsbdrfen5+VyoljCzlpXBGzR/fHzKhrbKauqZm6xhCBYIhhBZlMHJRLdnrHXze1jc1sKK1lR1WAstpGymubWn/3z07jvKmDOe6Iwk7LWFITYOvuegbmZjCwXzrpKcldvpaeaGgKsXDzbsprm/Z5LCc9hRH9sxhekNnpa4y1cNixozpAWnIShdlpJHUjIDvn2FXdyMayOkpqApTWNFJS00hJdYCy2iZ21zVRUe9/NzaHARjUL51pw/I5enge04bnMXZADpvL6/lkWxXLtlexfFsVm8rrGTcwhzOPHMjpRw5k5qiCDsNaY3OInVUBtlU2sL0ywPbKBrZXNjA4L4OrjxvJwNzOWwqq6oNsrfDbyUjt2ftc19jMqp01rNxRzYod1azZWUNuRgpjinIYMyCbMYXZjBmQzZB+Gd3ar43NIbaU17OxrI6d1QEamkI0BP1PoCkEwLhBuUwe0o8jB+/5PDQ2h1i4qYI315TyxuoS1uyqpX92GjNHFTB7dH9mjS5g6rA8ks2oqG+ipKaRXdX+fRuan8nMUQUd7ovSmkaeX1LMMwuLqW1s5uLpw/j8rOGMHZDTo/22P+GwozoQbPP/E6SirgnMf0ay0pLJSU8hOz2FQf0y6B9F4O/OtsPOEXIO5yAUdiSZkZnW9f+Ic46FmysoyEpl3MDcmJUnFjSVRiJQMGtV29jMm6tLmbdiJ6+vKqEm0AzA0LwMjhlV0PqFv3RrJUu3VrKupDbq5x6al0FBdhprd9XSFNr7oFOQlUpmWjKZqclkpCZTHQjy+PtbyExL5t8vmMTnZw5vDXF/WbKNW//8MfmZadx37TH0y0zljheX8/baMo4cnMt/fHYqM0cWsK60lg82lPP+xt18sGE3lfVNjCrMYuyAHMYOzGHsgBwG98ugrqmZmkAzNYEgNYFmSmoCfFxcxYrt1TSH/eezKCeNmkBz68GyRXKSccG0IdxwyhFMG+6vpeqc44Wl27nzr8upbWzmm6eP59QJRazcUcOKHf55V+2soT5ywMhKS2bq0DyOGp7H6KJsUpKMpCQjyYzkJNhQWsdTC7ZSWtPIsPxMrjl+JGdPHsSybdW8s66Md9eVsSMSmrsyon8mEwf1Y+LgHGoCzawvrWV9iT+QtZeXmUphTho7KgM0BEMU5aRxzpTBXHDUEEYVZrNg424+2FjOBxt2s6Gsbq91C7PTGJyXQVFO+j6BLskgPyuNwpw0BuSkU5iTRlFOOv0yUumXuaf2Mi05iVU7a3hrTSlvry3jw027aWq37ztSkJXKiP5ZFOWk7zlZSPK/M1OTGZCbzsDcdAb2S2dgbgb5WakEQ476pmYCwRANTWECwRAh5yIHHAg5R7DZ17SuL61lfWkdG0prW/8XkpOMopw0BvXLYGBuOkU56RRkp9E/K83/zk6luqGZFTuqWbHdB5LddXuHzLSUJAb18+sWZqdRkJVG/2y/frIZy7dX8fG2KjaU1u3zmocXZDJtWB5HDMjmo61VfLCxnGDIkZuRwqnjB5CekuTDX02AXdWNVDUE93mOwuw0dtc3kZqUxIVHD+X6k8cweWg/AJqaw8xfXcLzi7fx+qoSmkJhUpONyUP6tZ5kjRuYQ2V9kF3VgdZtldU20dDU7ANSU4iGYJiaQJBtlQ20HPb6ZaQwcXAutY0hNpXV0RAMtZYpOy2ZCYNzOXJwLhMH5TJxcD+y0pL3ei2lNQGKKxrYVF7HtooGwh0cTtNTkshMSyYUctQ0+u8zMxhdmM2QvAyWbq2kvilEarIxe0x/jhtTyJbd9SzctJtN5fWt70847Fq/D9o//7Gj+3PiuEJOGltESU0jcxZu5fVVJYTCjpmjCsjPTOWNNaWEwo5Zowq4fNYIzps2mNyM1A7/jwPBEMu3V7FocwXLt1dT17j3fgwEQzQGQzSFwjQGwzQ2h1u/U6NVmJ3G+EE5jB+Yy4RBOeRmpLKzOsDOqshPdYCK+iaCzWGCYUdzKExzyO8DH8IcochnpDOzR/fnytkjOH/akL0CbGNziBeWbufBtzewZpc/hkwd1o9LZgznoqOHtp50x1tXU2konPW1wzyYNYfCrN5Vw+ItlcxfVcI768poag7TPzuNT08ayKkTBjBzVAFD8jquHapqCPJxcSVbdtfTHHIEQ2GaIx/k5KQkRhdmMboom9GF2a1nUY3NIVbuqGHplgqWbq1kxY5qagPNe85yg/5L5sKjh3LbZyZ3+EFdvr2Kmx5bREl1Iw5HRkoyt5w9gWuPH9Vhs2TLF0l3miz9F2Q1S7ZUsGZXDXmZqQzOy2RwvwwG52WQlZbMc4uKeWrBVmobmzn+iP5cc9wo/ry4mPmrS5kxMp+fXXoUEwbte0YYDjs2lNXxcXElHxdX8XFxJcu3V+8T/sAfSE6bMIAvnDCKT00YuE/gcc6xsayOJVsqSUm2yFlyCtnpyaSnJLO5vI7VO2tYtauG1Ttr2FBaS3ZaCkcMzGHsgGzGDczhiKIchhdkUpSTTv/sNNJS/H5qaAoxf3UJL32yg9dXlux18MzNSGH26P4cd0R/xg3Moay2iZ1VgdaaxbLaRtp/vYXCjor6Jsprm7o8mKQkWeuBcOKgXE4ZX8TJ44sYVZi9z2uvDjSzdXc9Wyvq2bq7geKKenbXNfn/x3DkgBIKU9cU6jCYRMsMRhRkMXZANmMH+Fqe5pCjpCZASXWk9qumkd11jeyua9qnZjYtJYmJkZqbSUNyGTcwl0GRkNgvM7pmtOpAkGXbqlhfWseYwmymDutHftbeNSC1jc28s7aU11eV8M7aMsysNZS2BMjBeRkMy89kaH4mg/MyyEhNZmNZHY+8u5FnFhbTEAxx4thCRhdlM/eTHVTWBynKSePCo4cyY2QBKyKfi0+2VbWeZLSVnZZMUW462WkpZKYlk5XmT7qy0pI5oiiHyUP9PhiWv6eZv6VGcUNZLRtK61hXUsuqnf5EprK+4/etMDuNIfkZvtatKJsxRVmMKcphWH4m2enJZKQkt9a+OefYXhVgxfZqX2u3vZqtFfVMH5HPaRMHcuLYwn1qXktqAizcVMGSLRWkJCcxKDedgW1C+IayWt5dV86768pYtbOmdb2inHQunTmMz88cwbiBvqaspDrAn5dsY87Cra0hu392Wuv3yeC8DNKSk/iouJLl26pbPx/D8jPJz0ptPXH1P0lkpCaTnpJEWkoS6SnJpKUkkZeZSv/s1D3hPvK/4WvSfW16XWMz2yobWLurljUlNazbVdsaWgFy01MYlJfBkDxfu5bapjUkJdlaTx6TzZ9A+hNJ/O3ISWWS+RrSFz/azqbyenIzUrhkxjAunj6U9zfs5tF/bqK0xrei/MvJY6gNNPP8km18sq2K5CTj5HFFXHGsD3XxpHCWiJobYcObfqqMQzCYOecormhg+fZqgu0Ogs3hMKt21LBkayWfFFe1HnBH9M/k7MmDOWfKYGaOKuizvkzhsD+o7q95rKKuiX//yyfkpqfyvXMm9trZVnvVgSBPfbiFR97dxI6qAJmpyXz/nIl86cTR3dqHwVCY3XVNvnkgvKd5ICcjhaKc2L22YChMSpJ1u09NQ1OIN1aXUFLTyMxRBUwa0vP+bi2hqry2kbLaJqobgtQ0BiM1mP5n7IBsThk/gMF5sRuQ09gcorSmsbXWpbI+2HrA21Nzm0Rya81l5MCTlMSQSIiJ9vXVNYXYXdvE7vomMlOTGTsgO+b9GeOhqj7Ikwu28Md/bqKivomzJw/mkhnDOGV80T7lbw6FWVtSy6ayOvpnp7UGl1g2LzvnKKlpZNXOGpqaw601n752NHH2Z2lNI+9tKCc7LZlTJwzotGzOORZtruC99eWtNVUtJzR1Tc1MG5bnWylGFnDMqIKYfvY7K8/O6gB1jc0M6pfRaW1eT5/7/Q27eXrBFuYu29la+33K+CJuPPUITh5XtNf30LqSGv68eBsvLN3O0SPyuPeamTErS0cUzhJF9Q5YOw/WvAIb3oBgHeQOgS/99aAPZo3NIZZtq4r0Datk0ZYKSmsaO10+LTmJyUP7MaO1X1VBhx3nJXrBUJh315UxflBup/3QRA4WobCjOYqTJJFoVNY38fqqEiYN6cekIf26XDYcdtQEmsnLil1Q7IiuEJAI3vgZvPFf/u+8ETD9Khh/Dow5JaGvi1lZ38TGsrrWZqrsNN+hsyEYYvGWChZs3M3CTRUsLa5sPSsZ2T+Lk8YWMnNUAUcNzyc7fe8vVzNjeEGmvnRjLDU5idMmDuzrYojERHKSkZyk7wiJjfysND53zPColk1KsrgHs/1ROOsN4TAseABGnwLn/RwGTurz62G21Jh2VFNVUhNg3vJdvLxsJ+9tKCfURY/LlCRjyrA8vnj8KGaN9tXgXY22EhERka4pnPWGnR9BXSmc/VMYNLmvS8O6khq+8fgS1pfWto5Wa/nZurueBZt34xwcUZTNTacewTEjC2hsDlPX2ExtYzP1Tc2YGTMi01hkpenfSEREJFZ0VO0N6171v8ee0bflAF5etpNb5iwlIzWZfzl5DBV1kTml6ppYu6uGvKw0vn3meM6bOoQJg3LUB0xERKSXKZz1hrWvwtAZkDOgz4oQCjt+9Y81/Hb+Oo4ensd9185kqDqNi4iIJByFs3hrqIDiD+GUW/qsCFX1Qb711BLeXFPKFbNGcOfFU3o8u7aIiIjEl8JZvG14A1wYxp3Va5tsDoVZsaOaBZsqWLhpN+9vKKe2sZmfXjKVq2ePVFOliIhIAlM4i7d1r0JGHgyL72R2AFvK67nrb8v55/ry1lmzR/TP5LSJA/niCaOYMbIg7mUQERGRA6NwFk/OwbrX/ECA5Pju6heWbuPfn1+GGVw2czjHRi6Y29llj0RERCQxKZzF067lULMDxn06bpuoa2zm9heX8+yiYmaOKuDXV05neEFW3LYnIiIi8aVwFk/r/uF/xymcLdtWxc1PLmFzeR3fOnM83zpj3EFx7TwRERHpnMJZPK17DQZNg9zBMXvKcNjxz/XlPPHhZuYt38WA3HSeuOF4jj+iMGbbEBERkb6jcBYvgWrY8h6ceHNMnq6stpFnFhbz1IItbC6vJz8rletOHM03Th9HQXZaTLYhIiIifU/hLF42vgXh5gNu0mxqDvO7+eu49411BEOO2WP6869nTeCcKYM1V5mIiMghSOEsXtb9A9JyYcRxPX6KVTuruWXORyzfXs3F04dy8xnjGDcwN4aFFBERkUSjcBYPLVNoHPEpSE7t9urNoTB/eGsD97y6hrzMVH5/7UzOnRq7fmsiIiKSuBTO4qF0NVRthVO/1+1Vt1U28I3HF7N0ayXnTxvMf1w8lcKc9DgUUkRERBKRwlk8rHvV/+5mf7OGphDXP7qAbRUN/OaqGVx41BBdaklEROQwo3AWD2vnwYBJkDc86lWcc9z6549ZvauGR647ltMmDoxjAUVERCRRacbSWKstgU1vw8TzurXaI+9u4oWl27nlrAkKZiIiIocxhbNYW/48uDAcdXnUq7y/oZyfzl3JWZMH8fXTxsWxcCIiIpLoFM5i7eM5/qoAAydFtfjOqgDffGIxo/pn8cvLjyYpSX3MREREDmcKZ7FUvh62LYSjPh/V4o3NIb76p0U0NIX4wxdmkpvR/Wk3RERE5NCiAQGxtOw5wGDqZVEt/otXVrN0ayX3XXMM4wdpclkRERFRzVnsOOebNEedBHnD9rv4qp3VPPzuJq6aPZLzpg3phQKKiIjIwUDhLFZ2LIXytVE1aTrnuO2F5eRmpPCDcybGv2wiIiJy0FA4i5VPnoWkVJh88X4XfWHpdj7cuJsfnnskBdlpvVA4EREROVgonMVCOOTD2fizIbOgy0VrAkF+OnclR4/I54pZI3qpgCIiInKw0ICAWNj0NtTujKpJ855X11JW28hDX5qlaTNERERkH6o5i4VPnoG0XJhwbpeLrdpZzaP/9IMAjhqe3ztlExERkYOKwtmBCgZgxYsw6UJIzex0sZZBAP0yUvj+2RoEICIiIh1TODtQa1+Bxur9NmlqEICIiIhEQ+HsQH08B7IHwphPdbqIc47/fX0tU4b243INAhAREZEuKJwdqA1vwpEXQFJyp4ss2lzB+tI6vnTiaA0CEBERkS4pnB2IpjpoqoGCUV0u9uSHW8lJT+EzR+lKACIiItI1hbMDUVfqf2cP6HSR6kCQlz7ZzkXTh5KVpplLREREpGsKZweirsz/zh7Y6SIvLt1OIBjmymPV10xERET2T+HsQLTWnBV1ushTC7YweUg/pg3L66VCiYiIyMFM4exA1Jb43500ay7bVsWybdVcOXsEZhoIICIiIvuncHYg9tPn7KkFW0hPSeLio4f1YqFERETkYKZwdiDqyiC9H6Rm7PNQQ1OIF5Zs54JpQ8jLSu2DwomIiMjBKK7hzMzONbPVZrbOzG7t4PGRZjbfzJaY2cdmdn4Hj9ea2ffiWc4eqyvptL/ZS5/soKaxmSs0EEBERES6IW7hzMySgd8B5wGTgavMbHK7xX4MzHHOzQCuBO5t9/gvgb/Hq4wHrK600ybNpxds4YiibGaP6d/LhRIREZGDWTxrzmYD65xzG5xzTcBTwMXtlnFAv8jfecD2lgfM7LPARmB5HMt4YOrKOgxn60pqWLCpgiuO1UAAERER6Z54hrNhwNY2t4sj97V1B3CtmRUDc4GbAcwsB/ghcGccy3fgaks6DGdPL9hKSpJx6czhfVAoEREROZj19YCAq4BHnXPDgfOBx8wsCR/afuWcq+1qZTO70cwWmtnC0tLS+Je2rXAI6ss7DGevrSzh1AkDKMpJ790yiYiIyEEvntcT2ga07Q0/PHJfW9cD5wI4594zswygCDgOuMzMfg7kA2EzCzjnftt2Zefc/cD9ALNmzXLxeBGdqt8NOMjZ++oAwVCYLbvrOX+arqMpIiIi3RfPcLYAGG9mY/Ch7Erg6nbLbAHOBB41s0lABlDqnDulZQEzuwOobR/M+lwnVwcormigOewYXZTdB4USERGRg13cmjWdc83AN4FXgJX4UZnLzewuM7sostgtwA1m9hHwJHCdc653a8B6qq7jqwNsLPMtsWMUzkRERKQH4llzhnNuLr6jf9v7bmvz9wrgpP08xx1xKdyB6uSi5xtK6wA4QuFMREREeqCvBwQcvDpp1txYVkd+VioF2Wl9UCgRERE52Cmc9VRtCSSlQEb+XndvLKtTk6aIiIj0mMJZT7VcHSBp712ocCYiIiIHQuGsp+rK9mnSrG9qZkdVQP3NREREpMcUznqqbt+rA2wqqwdgTFFOX5RIREREDgEKZz3VwUXPN5b5kZpq1hQREZGeUjjrqQ4uet4yx9nooqy+KJGIiIgcAhTOeqKxFoL1+4SzDWV1DMnLICstrtPHiYiIyCFM4awnWuc427dZU02aIiIiciAUznqi5eoA7S56rnAmIiIiB0rhrCdar6u5ZyqNiromKuuDCmciIiJyQBTOeqKDZs2N5ZFrag5QOBMREZGeUzjriY7CWWnLNBqa40xERER6TuGsJ2pLIT0PUtJb79pYVkdKkjG8ILMPCyYiIiIHO4Wznqgr3efSTRvL6hjZP4vUZO1SERER6TkliZ6oK91npOYGjdQUERGRGFA464l2NWfhsGOTwpmIiIjEgMJZT7S7ruaumgANwRCjFc5ERETkACmcdVeoGep3dzhS8wiFMxERETlACmfdVV8OuL3C2YayyDQamuNMREREDtB+w5mZXWhmCnEtOprjrKyOzNRkBuVm9FGhRERE5FARTei6AlhrZj83syPjXaCE10k4G12UTVKS9VGhRERE5FCx33DmnLsWmAGsBx41s/fM7EYzy4176RJRSzhrM5XGxrI69TcTERGRmIiqudI5Vw08CzwFDAEuARab2c1xLFtiaq0581NpBENhtuyu1zQaIiIiEhPR9Dm7yMyeB94AUoHZzrnzgKOBW+JbvARUVwpJqZCRD8DW3fWEwk7hTERERGIiJYplLgV+5Zx7q+2dzrl6M7s+PsVKYLWROc7M9y/bqJGaIiIiEkPRhLM7gB0tN8wsExjknNvknHstXgVLWO2uDtASztTnTERERGIhmj5nzwDhNrdDkfsOT+2uDrChrI6CrFTys9L6sFAiIiJyqIgmnKU455pabkT+PnyTSLuLnm8s1TU1RUREJHaiCWelZnZRyw0zuxgoi1+REphzHTZr6pqaIiIiEivR9Dn7KvC4mf0WMGAr8MW4lipRNdVCc2CvZs2K+iYG5Kb3YaFERETkULLfcOacWw8cb2Y5kdu1cS9Voqot8b8j4SwcdjQ2h8lISe7DQomIiMihJJqaM8zsAmAKkGGRKSScc3fFsVyJqS7Smpvt+5w1NvtxEplpCmciIiISG9FMQvt7/PU1b8Y3a34eGBXnciWmdlcHaAiGAMhMVTgTERGR2IhmQMCJzrkvAhXOuTuBE4AJ8S1Wgmp30XOFMxEREYm1aMJZIPK73syGAkH89TUPP+3DWZMPZ+mpUV2iVERERGS/oulz9lczywf+B1gMOOCBeBYqYdWVQkYepPhp3gKqORMREZEY6zKcmVkS8JpzrhJ4zsz+BmQ456p6o3AJp93VAVrDmQYEiIiISIx02R7nnAsDv2tzu/GwDWYQuej5nqsDqM+ZiIiIxFo0naVeM7NLrWUOjcNZu6sDtPQ5y1A4ExERkRiJJpzdhL/QeaOZVZtZjZlVx7lcial9s2ZknjOFMxEREYmVaK4QkNsbBUl4oSA07N7roueBJvU5ExERkdjabzgzs1M7ut8591bsi5PAAtWQOxRyB7fepT5nIiIiEmvRTKXx/TZ/ZwCzgUXAGXEpUaLKLoRbVu51V0s4y9A8ZyIiIhIj0TRrXtj2tpmNAO6JV4EOJi1TaejC5yIiIhIrPanyKQYmxbogB6OGYIj0lCSSkjSQVURERGIjmj5n/4u/KgD4MDcdf6WAw16gKaSRmiIiIhJT0fQ5W9jm72bgSefcu3Eqz0GlIRjSYAARERGJqWjC2bNAwDkXAjCzZDPLcs7Vx7doiS8QDGsaDREREYmpqK4QAGS2uZ0JvBqf4hxcGoJq1hQREZHYiiacZTjnaltuRP7Oil+RDh6BYEjTaIiIiEhMRZMs6szsmJYbZjYTaIhfkQ4eDU3qcyYiIiKxFU04+w7wjJm9bWbvAE8D34zmyc3sXDNbbWbrzOzWDh4faWbzzWyJmX1sZudH7j/LzBaZ2SeR3wk54W2gWeFMREREYiuaSWgXmNmRwMTIXaudc8H9rWdmycDvgLPwc6MtMLMXnXMr2iz2Y2COc+4+M5sMzAVGA2XAhc657WY2FXgFGNaN19UrGppCZGhAgIiIiMTQfmvOzOwbQLZzbplzbhmQY2Zfj+K5ZwPrnHMbnHNNwFPAxe2WcUC/yN95wHYA59wS59z2yP3LgUwzS49im70qEAzr6gAiIiISU9E0a97gnKtsueGcqwBuiGK9YcDWNreL2bf26w7gWjMrxtea3dzB81wKLHbONbZ/wMxuNLOFZrawtLQ0iiLFVkMwRGaaBgSIiIhI7ESTLJLNrPX6RJHmyrQYbf8q4FHn3HDgfOAxM2stk5lNAX4G3NTRys65+51zs5xzswYMGBCjIkUvoEloRUREJMaimYT2ZeBpM/tD5PZNwN+jWG8bMKLN7eGR+9q6HjgXwDn3npllAEVAiZkNB54HvuicWx/F9nqVc05XCBAREZGYi6bm7IfA68BXIz+fsPektJ1ZAIw3szFmlgZcCbzYbpktwJkAZjYJyABKzSwfeAm4NVEvFdXYHMY5SFc4ExERkRjabzhzzoWBD4BN+E7+ZwAro1ivGT/lxiuR5ec455ab2V1mdlFksVuAG8zsI+BJ4DrnnIusNw64zcyWRn4GdvvVxVEgGAJQzZmIiIjEVKfNmmY2Ad8n7Cr81BZPAzjnTo/2yZ1zc/Ed/dved1ubv1cAJ3Ww3n8C/xntdvpCIBgG0LU1RUREJKa66nO2Cngb+Ixzbh2AmX23V0p1EGhQzZmIiIjEQVfNmp8DdgDzzewBMzsTsC6WP6w0NPlwpmtrioiISCx1miycc39xzl0JHAnMx1/GaaCZ3WdmZ/dS+RJWS81ZhmrOREREJIaiGRBQ55x7wjl3IX46jCX4EZyHtUY1a4qIiEgcdKtNzjlXEZn49cx4Fehg0drnTAMCREREJIbUYaqH1KwpIiIi8aBw1kOtU2konImIiEgMKZz1kGrOREREJB4Uznoo0KQ+ZyIiIhJ7Cmc91FpzlqJdKCIiIrGjZNFDgWCI1GQjJVm7UERERGJHyaKHGoIh9TcTERGRmFM466FAMKSRmiIiIhJzCmc91NCkmjMRERGJPYWzHgoEw6o5ExERkZhTOOuhhmCIDE2jISIiIjGmcNZDDcEQmanafSIiIhJbShc9FNBoTREREYkDhbMe0mhNERERiQeFsx5qUDgTERGROFA466GGprAGBIiIiEjMKZz1UCAYIiNF4UxERERiS+GshwLBEJlp2n0iIiISW0oXPRAMhWkOO/U5ExERkZhTOOuBhmAIQFNpiIiISMwpnPVAoEnhTEREROJD4awHAsEwgJo1RUREJOYUznqgpVkzU1NpiIiISIwpnPVAazhTzZmIiIjEmMJZDzRE+pyl68LnIiIiEmNKFz0QaFbNmYiIiMSHwlkPtIzWVJ8zERERiTWFsx5onedMl28SERGRGFM46wGN1hQREZF4UTjrgZZ5zjQJrYiIiMSawlkPBDSVhoiIiMSJwlkPNDSFSDJITba+LoqIiIgcYhTOeqAhGCIzNRkzhTMRERGJLYWzHggEQxoMICIiInGhcNYDDcGQBgOIiIhIXCic9UBA4UxERETiROGsBxqaQhqpKSIiInGhcNYDgWBY4UxERETiQuGsBxqCITI0IEBERETiQOGsBwLBEBkp2nUiIiISe0oYPdCgqTREREQkThTOeiAQ1IAAERERiQ+Fsx5oaNJUGiIiIhIfCmc9EAiGFc5EREQkLhTOuikUdjSFNJWGiIiIxIfCWTcFgiEAMtO060RERCT24powzOxcM1ttZuvM7NYOHh9pZvPNbImZfWxm57d57EeR9Vab2TnxLGd3NLSEM9WciYiISBykxOuJzSwZ+B1wFlAMLDCzF51zK9os9mNgjnPuPjObDMwFRkf+vhKYAgwFXjWzCc65ULzKG62GJl+EdIUzERERiYN41pzNBtY55zY455qAp4CL2y3jgH6Rv/OA7ZG/Lwaecs41Ouc2Ausiz9fnAqo5ExERkTiKZzgbBmxtc7s4cl9bdwDXmlkxvtbs5m6s2ycCwTCgcCYiIiLx0de92q8CHnXODQfOBx4zs6jLZGY3mtlCM1tYWloat0K21drnTFcIEBERkTiIZzjbBoxoc3t45L62rgfmADjn3gMygKIo18U5d79zbpZzbtaAAQNiWPTOtYSzjNS+zrUiIiJyKIpnwlgAjDezMWaWhu/g/2K7ZbYAZwKY2SR8OCuNLHelmaWb2RhgPPBhHMsatZYBAZqEVkREROIhbqM1nXPNZvZN4BUgGXjYObfczO4CFjrnXgRuAR4ws+/iBwdc55xzwHIzmwOsAJqBbyTCSE2AxmYNCBAREZH4iVs4A3DOzcV39G97321t/l4BnNTJuj8FfhrP8vVES82Z+pyJiIhIPKjjVDe19jlLUTgTERGR2FM46yaN1hQREZF4UjjrppZ5ztJTtOtEREQk9pQwuikQDJGZmoyZ9XVRRERE5BCkcNZNDU0hzXEmIiIicaOU0U0NkZozERERkXhQOOumQDBEhgYDiIiISJwonHVTQDVnIiIiEkcKZ93UEAzp0k0iIiISNwpn3dTQpJozERERiR+Fs24KBMOqORMREZG4UTjrpkAwpKsDiIiISNwonHVTQzBEhq4OICIiInGilNFNDao5ExERkThSOOsmTaUhIiIi8aRw1g3hsCMQDJOucCYiIiJxonDWDY3NYQDVnImIiEjcKJx1Q0MwBECmLnwuIiIicZLS1wU4mARawpkGBIiIyGEuGAxSXFxMIBDo66IktIyMDIYPH05qamrU6yicdUNLzZkmoRURkcNdcXExubm5jB49GjPr6+IkJOcc5eXlFBcXM2bMmKjXU/tcNzQ0KZyJiIgABAIBCgsLFcy6YGYUFhZ2u3ZR4awbWps1Fc5EREQUzKLQk32kcNYNgWBktKb6nImIiPS5yspK7r333m6vd/7551NZWdnlMrfddhuvvvpqD0t2YBTOuqG1z1mKwpmIiEhf6yycNTc3d7ne3Llzyc/P73KZu+66i09/+tMHUrweUzjrhtapNNK020RERPrarbfeyvr165k+fTrHHnssp5xyChdddBGTJ08G4LOf/SwzZ85kypQp3H///a3rjR49mrKyMjZt2sSkSZO44YYbmDJlCmeffTYNDQ0AXHfddTz77LOty99+++0cc8wxTJs2jVWrVgFQWlrKWWedxZQpU/jKV77CqFGjKCsrO+DXpdGa3RDQgAAREZF93PnX5azYXh3T55w8tB+3Xzily2Xuvvtuli1bxtKlS3njjTe44IILWLZsWevIyIcffpj+/fvT0NDAsccey6WXXkphYeFez7F27VqefPJJHnjgAS6//HKee+45rr322n22VVRUxOLFi7n33nv5xS9+wYMPPsidd97JGWecwY9+9CNefvllHnrooZi8dlUBdUOgWQMCREREEtXs2bP3mrLiN7/5DUcffTTHH388W7duZe3atfusM2bMGKZPnw7AzJkz2bRpU4fP/bnPfW6fZd555x2uvPJKAM4991wKCgpi8jpUc9YNmkpDRERkX/ur4eot2dnZrX+/8cYbvPrqq7z33ntkZWVx2mmndTilRXp6euvfycnJrc2anS2XnJy83z5tB0o1Z92gSWhFREQSR25uLjU1NR0+VlVVRUFBAVlZWaxatYr3338/5ts/6aSTmDNnDgDz5s2joqIiJs+rmrNuaAiGSEtJIjlJ87qIiIj0tcLCQk466SSmTp1KZmYmgwYNan3s3HPP5fe//z2TJk1i4sSJHH/88THf/u23385VV13FY489xgknnMDgwYPJzc094Oc151wMitf3Zs2a5RYuXBjXbdzx4nKeX7KNj24/O67bERERSXQrV65k0qRJfV2MPtXY2EhycjIpKSm89957fO1rX2Pp0qX7LNfRvjKzRc65WR09r2rOuqGhKURGqlqCRUREBLZs2cLll19OOBwmLS2NBx54ICbPq3DWDQ3BkEZqioiICADjx49nyZIlMX9eVQN1Q0MwpMEAIiIiElcKZ90QCIZ0XU0RERGJK4WzbggEQ7qupoiIiMSVwlk3NKjmTEREROJM4awbGpo0IEBERCRRVFZWcu+99/Zo3XvuuYf6+voYlyg2FM66IRAMa0CAiIhIgjhUw5mm0uiGQFDznImIiCSKW2+9lfXr1zN9+nTOOussBg4cyJw5c2hsbOSSSy7hzjvvpK6ujssvv5zi4mJCoRA/+clP2LVrF9u3b+f000+nqKiI+fPn9/VL2YvCWTdonjMREZEO/P1W2PlJbJ9z8DQ47+4uF7n77rtZtmwZS5cuZd68eTz77LN8+OGHOOe46KKLeOuttygtLWXo0KG89NJLgL/mZl5eHr/85S+ZP38+RUVFsS13DKgaKErOOQ0IEBERSVDz5s1j3rx5zJgxg2OOOYZVq1axdu1apk2bxj/+8Q9++MMf8vbbb5OXl9fXRd0v1ZxFqSkUxjnU50xERKS9/dRw9QbnHD/60Y+46aab9nls8eLFzJ07lx//+MeceeaZ3HbbbX1Qwuip5ixKgaYwoHAmIiKSKHJzc6mpqQHgnHPO4eGHH6a2thaAbdu2UVJSwvbt28nKyuLaa6/l+9//PosXL95n3USjmrMoZacn89K3TmZgbkZfF0VERESAwsJCTjrpJKZOncp5553H1VdfzQknnABATk4Of/rTn1i3bh3f//73SUpKIjU1lfvuuw+AG2+8kXPPPZehQ4cm3IAAc871dRliYtasWW7hwoV9XQwREZHDwsqVK5k0aVJfF+Og0NG+MrNFzrlZHS2vZk0RERGRBKJwJiIiIpJAFM5EREREEojCmYiIiPTIodJvPZ56so8UzkRERKTbMjIyKC8vV0DrgnOO8vJyMjK6N9NDXKfSMLNzgV8DycCDzrm72z3+K+D0yM0sYKBzLj/y2M+BC/AB8h/At53+A0RERBLC8OHDKS4uprS0tK+LktAyMjIYPnx4t9aJWzgzs2Tgd8BZQDGwwMxedM6taFnGOffdNsvfDMyI/H0icBJwVOThd4BPAW/Eq7wiIiISvdTUVMaMGdPXxTgkxbNZczawzjm3wTnXBDwFXNzF8lcBT0b+dkAGkAakA6nArjiWVURERCQhxDOcDQO2trldHLlvH2Y2ChgDvA7gnHsPmA/siPy84pxbGceyioiIiCSERBkQcCXwrHMuBGBm44BJwHB8oDvDzE5pv5KZ3WhmC81sodq8RURE5FAQzwEB24ARbW4Pj9zXkSuBb7S5fQnwvnOuFsDM/g6cALzddiXn3P3A/ZFlSs1sc2yK3qUioKwXtiPdo/clcem9SUx6XxKX3pvEFOv3ZVRnD8QznC0AxpvZGHwouxK4uv1CZnYkUAC81+buLcANZvbfgOEHA9zT1caccwNiU+yumdnCzq6FJX1H70vi0nuTmPS+JC69N4mpN9+XuDVrOueagW8CrwArgTnOueVmdpeZXdRm0SuBp9pNk/EssB74BPgI+Mg599d4lVVEREQkUcR1njPn3Fxgbrv7bmt3+44O1gsBN8WzbCIiIiKJKFEGBBxM7u/rAkiH9L4kLr03iUnvS+LSe5OYeu19MU26LyIiIpI4VHMmIiIikkAUzqJkZuea2WozW2dmt/Z1eQ5nZjbCzOab2QozW25m347c39/M/mFmayO/C/q6rIcjM0s2syVm9rfI7TFm9kHks/O0maX1dRkPR2aWb2bPmtkqM1tpZifoM9P3zOy7ke+xZWb2pJll6DPTN8zsYTMrMbNlbe7r8DNi3m8i79HHZnZMLMuicBaFNtcJPQ+YDFxlZpP7tlSHtWbgFufcZOB44BuR9+NW4DXn3Hjgtcht6X3fxo/QbvEz4FfOuXFABXB9n5RKfg287Jw7Ejga/x7pM9OHzGwY8C1glnNuKpCMn8FAn5m+8Shwbrv7OvuMnAeMj/zcCNwXy4IonEWnu9cJlThyzu1wzi2O/F2DP8gMw78nf4ws9kfgs31SwMOYmQ0HLgAejNw24Az89Dig96VPmFkecCrwEIBzrsk5V4k+M4kgBcg0sxQgC3/JQn1m+oBz7i1gd7u7O/uMXAz8n/PeB/LNbEisyqJwFp2orxMqvcvMRgMzgA+AQc65HZGHdgKD+qpch7F7gB8A4cjtQqAyMu8h6LPTV8YApcAjkSbnB80sG31m+pRzbhvwC/zE6zuAKmAR+swkks4+I3HNBQpnctAysxzgOeA7zrnqto9FJjXWUOReZGafAUqcc4v6uiyyjxTgGOA+59wMoI52TZj6zPS+SP+li/HheSiQzb7NapIgevMzonAWne5cJ1R6gZml4oPZ4865P0fu3tVSrRz5XdJX5TtMnQRcZGab8E3/Z+D7OeVHmmxAn52+UgwUO+c+iNx+Fh/W9JnpW58GNjrnSp1zQeDP+M+RPjOJo7PPSFxzgcJZdFqvExoZNXMl8GIfl+mwFenH9BCw0jn3yzYPvQh8KfL3l4AXertshzPn3I+cc8Odc6Pxn5HXnXPXAPOByyKL6X3pA865ncBWM5sYuetMYAX6zPS1LcDxZpYV+V5reV/0mUkcnX1GXgS+GBm1eTxQ1ab584BpEtoomdn5+P40ycDDzrmf9m2JDl9mdjLwNv7aqy19m/4N3+9sDjAS2Axc7pxr37lTeoGZnQZ8zzn3GTM7Al+T1h9YAlzrnGvsw+IdlsxsOn6gRhqwAfgy/gRdn5k+ZGZ3AlfgR6EvAb6C77ukz0wvM7MngdOAImAXcDvwFzr4jETC9G/xzdD1wJedcwtjVhaFMxEREZHEoWZNERERkQSicCYiIiKSQBTORERERBKIwpmIiIhIAlE4ExEREUkgCmcickgxs9rI79FmdnWMn/vf2t3+ZyyfX0QEFM5E5NA1GuhWOGszK3tn9gpnzrkTu1kmEZH9UjgTkUPV3cApZrbUzL5rZslm9j9mtsDMPjazm8BPmGtmb5vZi/jZ2TGzv5jZIjNbbmY3Ru67G8iMPN/jkftaauks8tzLzOwTM7uizXO/YWbPmtkqM3s8MnmliEin9neWKCJysLqVyFUKACIhq8o5d6yZpQPvmtm8yLLHAFOdcxsjt/8lMgt4JrDAzJ5zzt1qZt90zk3vYFufA6YDR+NnF19gZm9FHpsBTAG2A+/ir534TqxfrIgcOlRzJiKHi7Px18Jbir/UVyEwPvLYh22CGcC3zOwj4H38xY3H07WTgSedcyHn3C7gTeDYNs9d7JwLA0vxza0iIp1SzZmIHC4MuNk598ped/rrgNa1u/1p4ATnXL2ZvQFkHMB2214TMYS+d0VkP1RzJiKHqhogt83tV4CvmVkqgJlNMLPsDtbLAyoiwexI4Pg2jwVb1m/nbeCKSL+2AcCpwIcxeRUictjRGZyIHKo+BkKR5slHgV/jmxQXRzrllwKf7WC9l4GvmtlKYDW+abPF/cDHZrbYOXdNm/ufB04APgIc8APn3M5IuBMR6RZzzvV1GUREREQkQs2aIiIiIglE4UxEREQkgSiciYiIiCQQhTMRERGRBKJwJiIiIpJAFM5EREREEojCmYiIiEgCUTgTERERSSD/H1BSow1+HsYFAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history_['acc'], label='training')\n",
    "plt.plot(history_['test_acc'], label='test') \n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs. Iteration')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Classifier, Best Test Accuracy:  0.8658\n",
      "My Best Test Accuracy:  0.8578000068664551\n"
     ]
    }
   ],
   "source": [
    "best_score_idx2 = torch.argmax(torch.Tensor(history_['test_acc'])).item()\n",
    "print( \"Using Linear Classifier, Best Test Accuracy: \", history_['test_acc'][best_score_idx2] ) \n",
    "print( \"My Best Test Accuracy: \", test_acc0[2] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this comparison, we can see that my scratch implementation gives similar/close test accuracy to the PyTorch linear model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
